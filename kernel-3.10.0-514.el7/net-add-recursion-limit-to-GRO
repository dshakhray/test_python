From d37a90bdd7b32518fe3b6c8363f3aa2e6464be1b Mon Sep 17 00:00:00 2001
From: Sabrina Dubroca <sdubroca@redhat.com>
Date: Tue, 20 Sep 2016 15:42:07 -0400
Subject: [net] add recursion limit to GRO

Message-id: <1a9023b1e2020e2a999c28eec8be0bb41f0c6b5b.1474285966.git.sdubroca@redhat.com>
Patchwork-id: 5317
O-Subject: [kernel team] [EMBARGOED PATCH RHEL7.3 net] net: add recursion limit to GRO
Bugzilla: 1374191
CVE: CVE-2016-7039
RH-Acked-by: Jiri Benc <jbenc@redhat.com>
RH-Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
RH-Acked-by: David S. Miller <davem@redhat.com>
RH-Acked-by: Paolo Abeni <pabeni@redhat.com>
RH-Acked-by: Jakub Sitnicki <jkbs@redhat.com>
RH-Acked-by: Ivan Vecera <ivecera@redhat.com>

Bugzilla: https://bugzilla.redhat.com/show_bug.cgi?id=1374191
CVE: CVE-2016-7039
Upstream Status: not upstream yet because of the embargo
Brew: https://brewweb.engineering.redhat.com/brew/taskinfo?taskID=11773464

Notes:
 - different context in struct napi_gro_cb and dev_gro_receive
 - although we don't compile FOU, I kept the changes in fou_gro_receive

This patch has not been submitted upstream yet, because the CVE is embargoed.

(no upstream commit yet)
Author: Sabrina Dubroca <sd@queasysnail.net>

    net: add recursion limit to GRO

    Currently, GRO can do unlimited recursion through the gro_receive
    handlers.  This was fixed for tunneling protocols by limiting tunnel GRO
    to one level with encap_mark, but both VLAN and TEB still have this
    problem.  Thus, the kernel is vulnerable to a stack overflow, if we
    receive a packet composed entirely of VLAN headers.

    This patch adds a recursion counter to the GRO layer to prevent stack
    overflow.  When a gro_receive function hits the recursion limit, GRO is
    aborted for this skb and it is processed normally.

    Fixes: 9b174d88c257 ("net: Add Transparent Ethernet Bridging GRO support.")
    Fixes: 66e5133f19e9 ("vlan: Add GRO support for non hardware accelerated vlan")
    Signed-off-by: Sabrina Dubroca <sd@queasysnail.net>
    Reviewed-by: Jiri Benc <jbenc@redhat.com>
    Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>

Signed-off-by: Sabrina Dubroca <sdubroca@redhat.com>
Signed-off-by: Rafael Aquini <aquini@redhat.com>

diff --git a/drivers/net/geneve.c b/drivers/net/geneve.c
index 6afdfa6..cd018ae 100644
--- a/drivers/net/geneve.c
+++ b/drivers/net/geneve.c
@@ -471,7 +471,7 @@ static struct sk_buff **geneve_gro_receive(struct sock *sk,
 
  skb_gro_pull(skb, gh_len);
  skb_gro_postpull_rcsum(skb, gh, gh_len);
- pp = ptype->callbacks.gro_receive(head, skb);
+ pp = call_gro_receive(ptype->callbacks.gro_receive, head, skb);
  flush = 0;
 
 out_unlock:
diff --git a/drivers/net/vxlan.c b/drivers/net/vxlan.c
index 86f0804..75178c6 100644
--- a/drivers/net/vxlan.c
+++ b/drivers/net/vxlan.c
@@ -601,7 +601,7 @@ static struct sk_buff **vxlan_gro_receive(struct sock *sk,
   }
  }
 
- pp = eth_gro_receive(head, skb);
+ pp = call_gro_receive(eth_gro_receive, head, skb);
  flush = 0;
 
 out:
diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h
index 7182f6d..b6150f9 100644
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -2082,7 +2082,10 @@ struct napi_gro_cb {
  /* This is non-zero if the packet may be of the same flow. */
  u8 same_flow:1;
 
- /* 7 bit hole */
+ /* Number of gro_receive callbacks this packet already went through */
+ u8 recursion_counter:4;
+
+ /* 3 bit hole */
 
  /* used to support CHECKSUM_COMPLETE for tunneling protocols */
  __wsum csum;
@@ -2093,6 +2096,25 @@ struct napi_gro_cb {
 
 #define NAPI_GRO_CB(skb) ((struct napi_gro_cb *)(skb)->cb)
 
+#define GRO_RECURSION_LIMIT 15
+static inline int gro_recursion_inc_test(struct sk_buff *skb)
+{
+ return ++NAPI_GRO_CB(skb)->recursion_counter == GRO_RECURSION_LIMIT;
+}
+
+typedef struct sk_buff **(*gro_receive_t)(struct sk_buff **, struct sk_buff *);
+static inline struct sk_buff **call_gro_receive(gro_receive_t cb,
+      struct sk_buff **head,
+      struct sk_buff *skb)
+{
+ if (gro_recursion_inc_test(skb)) {
+  NAPI_GRO_CB(skb)->flush |= 1;
+  return NULL;
+ }
+
+ return cb(head, skb);
+}
+
 struct packet_type {
  __be16   type; /* This is really htons(ether_type). */
  struct net_device *dev; /* NULL is wildcarded here      */
diff --git a/net/8021q/vlan.c b/net/8021q/vlan.c
index 06ee260..e007133 100644
--- a/net/8021q/vlan.c
+++ b/net/8021q/vlan.c
@@ -640,7 +640,7 @@ static struct sk_buff **vlan_gro_receive(struct sk_buff **head,
 
  skb_gro_pull(skb, sizeof(*vhdr));
  skb_gro_postpull_rcsum(skb, vhdr, sizeof(*vhdr));
- pp = ptype->callbacks.gro_receive(head, skb);
+ pp = call_gro_receive(ptype->callbacks.gro_receive, head, skb);
 
 out_unlock:
  rcu_read_unlock();
diff --git a/net/core/dev.c b/net/core/dev.c
index 92b5848..72fb163 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -4112,6 +4112,7 @@ static enum gro_result dev_gro_receive(struct napi_struct *napi, struct sk_buff
   NAPI_GRO_CB(skb)->flush = 0;
   NAPI_GRO_CB(skb)->free = 0;
   NAPI_GRO_CB(skb)->encap_mark = 0;
+  NAPI_GRO_CB(skb)->recursion_counter = 0;
   NAPI_GRO_CB(skb)->gro_remcsum_start = 0;
 
   /* Setup for GRO checksum validation */
diff --git a/net/ethernet/eth.c b/net/ethernet/eth.c
index c29714f..de86b55 100644
--- a/net/ethernet/eth.c
+++ b/net/ethernet/eth.c
@@ -501,7 +501,7 @@ struct sk_buff **eth_gro_receive(struct sk_buff **head,
 
  skb_gro_pull(skb, sizeof(*eh));
  skb_gro_postpull_rcsum(skb, eh, sizeof(*eh));
- pp = ptype->callbacks.gro_receive(head, skb);
+ pp = call_gro_receive(ptype->callbacks.gro_receive, head, skb);
 
 out_unlock:
  rcu_read_unlock();
diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 601158b..3068a0e 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1362,7 +1362,7 @@ static struct sk_buff **inet_gro_receive(struct sk_buff **head,
  skb_gro_pull(skb, sizeof(*iph));
  skb_set_transport_header(skb, skb_gro_offset(skb));
 
- pp = ops->callbacks.gro_receive(head, skb);
+ pp = call_gro_receive(ops->callbacks.gro_receive, head, skb);
 
 out_unlock:
  rcu_read_unlock();
diff --git a/net/ipv4/fou.c b/net/ipv4/fou.c
index 62b4699..f471d69 100644
--- a/net/ipv4/fou.c
+++ b/net/ipv4/fou.c
@@ -195,7 +195,7 @@ static struct sk_buff **fou_gro_receive(struct sk_buff **head,
  if (!ops || !ops->callbacks.gro_receive)
   goto out_unlock;
 
- pp = ops->callbacks.gro_receive(head, skb);
+ pp = call_gro_receive(ops->callbacks.gro_receive, head, skb);
 
 out_unlock:
  rcu_read_unlock();
@@ -352,7 +352,7 @@ static struct sk_buff **gue_gro_receive(struct sk_buff **head,
  if (WARN_ON(!ops || !ops->callbacks.gro_receive))
   goto out_unlock;
 
- pp = ops->callbacks.gro_receive(head, skb);
+ pp = call_gro_receive(ops->callbacks.gro_receive, head, skb);
  flush = 0;
 
 out_unlock:
diff --git a/net/ipv4/gre_offload.c b/net/ipv4/gre_offload.c
index c7a30f7..69342a9 100644
--- a/net/ipv4/gre_offload.c
+++ b/net/ipv4/gre_offload.c
@@ -205,7 +205,7 @@ static struct sk_buff **gre_gro_receive(struct sk_buff **head,
  /* Adjusted NAPI_GRO_CB(skb)->csum after skb_gro_pull()*/
  skb_gro_postpull_rcsum(skb, greh, grehlen);
 
- pp = ptype->callbacks.gro_receive(head, skb);
+ pp = call_gro_receive(ptype->callbacks.gro_receive, head, skb);
  flush = 0;
 
 out_unlock:
diff --git a/net/ipv4/udp_offload.c b/net/ipv4/udp_offload.c
index d2d62f4..a35be44 100644
--- a/net/ipv4/udp_offload.c
+++ b/net/ipv4/udp_offload.c
@@ -268,7 +268,13 @@ unflush:
 
  skb_gro_pull(skb, sizeof(struct udphdr)); /* pull encapsulating udp header */
  skb_gro_postpull_rcsum(skb, uh, sizeof(struct udphdr));
- pp = udp_sk(sk)->gro_receive(sk, head, skb);
+
+ if (gro_recursion_inc_test(skb)) {
+  flush = 1;
+  pp = NULL;
+ } else {
+  pp = udp_sk(sk)->gro_receive(sk, head, skb);
+ }
 
 out_unlock:
  if (sk)
diff --git a/net/ipv6/ip6_offload.c b/net/ipv6/ip6_offload.c
index 0dd6ffe..3facfa1 100644
--- a/net/ipv6/ip6_offload.c
+++ b/net/ipv6/ip6_offload.c
@@ -230,7 +230,7 @@ static struct sk_buff **ipv6_gro_receive(struct sk_buff **head,
 
  skb_gro_postpull_rcsum(skb, iph, nlen);
 
- pp = ops->callbacks.gro_receive(head, skb);
+ pp = call_gro_receive(ops->callbacks.gro_receive, head, skb);
 
 out_unlock:
  rcu_read_unlock();
-- 
1.7.1