From d201e803427a2182f7c08802614c4436bbe9da0f Mon Sep 17 00:00:00 2001
From: Motohiro Kosaki <mkosaki@redhat.com>
Date: Tue, 2 Dec 2014 17:49:01 -0500
Subject: [mm] make __free_pages_bootmem() only available at boot time

Message-id: <1417542543-1642-4-git-send-email-mkosaki@redhat.com>
Patchwork-id: 101075
O-Subject: [RHEL7 PATCH 3/5] mm: make __free_pages_bootmem() only available at boot time
Bugzilla: 1156396
RH-Acked-by: Rafael Aquini <aquini@redhat.com>
RH-Acked-by: Larry Woodman <lwoodman@redhat.com>

From: KOSAKI Motohiro <mkosaki@redhat.com>

Bugzilla: https://bugzilla.redhat.com/show_bug.cgi?id=1156396
Upstream-tree: linus
Brew: https://brewweb.devel.redhat.com/taskinfo?taskID=8243943
Changes-from-upstream: none

commit 170a5a7eb2bf10161197e5490fbc29ca4561aedb
Author: Jiang Liu <liuj97@gmail.com>
Date:   Wed Jul 3 15:03:17 2013 -0700

    mm: make __free_pages_bootmem() only available at boot time

    In order to simpilify management of totalram_pages and
    zone->managed_pages, make __free_pages_bootmem() only available at boot
    time.  With this change applied, __free_pages_bootmem() will only be
    used by bootmem.c and nobootmem.c at boot time, so mark it as __init.
    Other callers of __free_pages_bootmem() have been converted to use
    free_reserved_page(), which handles totalram_pages and
    zone->managed_pages in a safer way.

    This patch also fix a bug in free_pagetable() for x86_64, which should
    increase zone->managed_pages instead of zone->present_pages when freeing
    reserved pages.

    And now we have managed_pages_count_lock to protect totalram_pages and
    zone->managed_pages, so remove the redundant ppb_lock lock in
    put_page_bootmem().  This greatly simplifies the locking rules.

    Signed-off-by: Jiang Liu <jiang.liu@huawei.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Yinghai Lu <yinghai@kernel.org>
    Cc: Wen Congyang <wency@cn.fujitsu.com>
    Cc: Tang Chen <tangchen@cn.fujitsu.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Minchan Kim <minchan@kernel.org>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: <sworddragon2@aol.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Jeremy Fitzhardinge <jeremy@goop.org>
    Cc: Jianguo Wu <wujianguo@huawei.com>
    Cc: Joonsoo Kim <js1304@gmail.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Michel Lespinasse <walken@google.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Rusty Russell <rusty@rustcorp.com.au>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

Signed-off-by: KOSAKI Motohiro <mkosaki@redhat.com>
Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c
index 47c5c34..79259c2 100644
--- a/arch/x86/mm/init_64.c
+++ b/arch/x86/mm/init_64.c
@@ -723,36 +723,22 @@ EXPORT_SYMBOL_GPL(arch_add_memory);
 
 static void __meminit free_pagetable(struct page *page, int order)
 {
- struct zone *zone;
- bool bootmem = false;
  unsigned long magic;
  unsigned int nr_pages = 1 << order;
 
  /* bootmem page has reserved flag */
  if (PageReserved(page)) {
   __ClearPageReserved(page);
-  bootmem = true;
 
   magic = (unsigned long)page->lru.next;
   if (magic == SECTION_INFO || magic == MIX_SECTION_INFO) {
    while (nr_pages--)
     put_page_bootmem(page++);
   } else
-   __free_pages_bootmem(page, order);
+   while (nr_pages--)
+    free_reserved_page(page++);
  } else
   free_pages((unsigned long)page_address(page), order);
-
- /*
-  * SECTION_INFO pages and MIX_SECTION_INFO pages
-  * are all allocated by bootmem.
-  */
- if (bootmem) {
-  zone = page_zone(page);
-  zone_span_writelock(zone);
-  zone->present_pages += nr_pages;
-  zone_span_writeunlock(zone);
-  totalram_pages += nr_pages;
- }
 }
 
 static void __meminit free_pte_table(pte_t *pte_start, pmd_t *pmd)
diff --git a/mm/memory_hotplug.c b/mm/memory_hotplug.c
index ddbad49..c23d7c6 100644
--- a/mm/memory_hotplug.c
+++ b/mm/memory_hotplug.c
@@ -98,12 +98,9 @@ void get_page_bootmem(unsigned long info,  struct page *page,
  atomic_inc(&page->_count);
 }
 
-/* reference to __meminit __free_pages_bootmem is valid
- * so use __ref to tell modpost not to generate a warning */
-void __ref put_page_bootmem(struct page *page)
+void put_page_bootmem(struct page *page)
 {
  unsigned long type;
- static DEFINE_MUTEX(ppb_lock);
 
  type = (unsigned long) page->lru.next;
  BUG_ON(type < MEMORY_HOTPLUG_MIN_BOOTMEM_TYPE ||
@@ -113,17 +110,8 @@ void __ref put_page_bootmem(struct page *page)
   ClearPagePrivate(page);
   set_page_private(page, 0);
   INIT_LIST_HEAD(&page->lru);
-
-  /*
-   * Please refer to comment for __free_pages_bootmem()
-   * for why we serialize here.
-   */
-  mutex_lock(&ppb_lock);
-  __free_pages_bootmem(page, 0);
-  mutex_unlock(&ppb_lock);
-  totalram_pages++;
+  free_reserved_page(page);
  }
-
 }
 
 #ifdef CONFIG_HAVE_BOOTMEM_INFO_NODE
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 7d8d264..ff81683 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -760,14 +760,7 @@ static void __free_pages_ok(struct page *page, unsigned int order)
  local_irq_restore(flags);
 }
 
-/*
- * Read access to zone->managed_pages is safe because it's unsigned long,
- * but we still need to serialize writers. Currently all callers of
- * __free_pages_bootmem() except put_page_bootmem() should only be used
- * at boot time. So for shorter boot time, we shift the burden to
- * put_page_bootmem() to serialize writers.
- */
-void __meminit __free_pages_bootmem(struct page *page, unsigned int order)
+void __init __free_pages_bootmem(struct page *page, unsigned int order)
 {
  unsigned int nr_pages = 1 << order;
  unsigned int loop;
-- 
1.7.1