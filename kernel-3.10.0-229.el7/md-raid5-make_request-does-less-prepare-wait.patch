From e45dc8fa8923285750d9ee7876c1008ad2c5daf9 Mon Sep 17 00:00:00 2001
From: Jes Sorensen <Jes.Sorensen@redhat.com>
Date: Mon, 1 Sep 2014 09:25:58 -0400
Subject: [md] raid5: make_request does less prepare wait

Message-id: <1409563584-9000-57-git-send-email-Jes.Sorensen@redhat.com>
Patchwork-id: 89976
O-Subject: [RHEL7.1 PATCH 56/82] raid5: make_request does less prepare wait
Bugzilla: 1085530
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>

From: Shaohua Li <shli@kernel.org>

In NUMA machine, prepare_to_wait/finish_wait in make_request exposes a
lot of contention for sequential workload (or big request size
workload). For such workload, each bio includes several stripes. So we
can just do prepare_to_wait/finish_wait once for the whold bio instead
of every stripe.  This reduces the lock contention completely for such
workload. Random workload might have the similar lock contention too,
but I didn't see it yet, maybe because my stroage is still not fast
enough.

Signed-off-by: Shaohua Li <shli@fusionio.com>
Signed-off-by: NeilBrown <neilb@suse.de>
(cherry picked from commit 27c0f68f0745218cec70f19ba7560c8c5fc3f817)
Signed-off-by: Jes Sorensen <Jes.Sorensen@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/drivers/md/raid5.c b/drivers/md/raid5.c
index fd900ef..41e4cdb 100644
--- a/drivers/md/raid5.c
+++ b/drivers/md/raid5.c
@@ -4553,6 +4553,8 @@ static void make_request(struct mddev *mddev, struct bio * bi)
  struct stripe_head *sh;
  const int rw = bio_data_dir(bi);
  int remaining;
+ DEFINE_WAIT(w);
+ bool do_prepare;
 
  if (unlikely(bi->bi_rw & REQ_FLUSH)) {
   md_flush_request(mddev, bi);
@@ -4576,15 +4578,18 @@ static void make_request(struct mddev *mddev, struct bio * bi)
  bi->bi_next = NULL;
  bi->bi_phys_segments = 1; /* over-loaded to count active stripes */
 
+ prepare_to_wait(&conf->wait_for_overlap, &w, TASK_UNINTERRUPTIBLE);
  for (;logical_sector < last_sector; logical_sector += STRIPE_SECTORS) {
-  DEFINE_WAIT(w);
   int previous;
   int seq;
 
+  do_prepare = false;
  retry:
   seq = read_seqcount_begin(&conf->gen_lock);
   previous = 0;
-  prepare_to_wait(&conf->wait_for_overlap, &w, TASK_UNINTERRUPTIBLE);
+  if (do_prepare)
+   prepare_to_wait(&conf->wait_for_overlap, &w,
+    TASK_UNINTERRUPTIBLE);
   if (unlikely(conf->reshape_progress != MaxSector)) {
    /* spinlock is needed as reshape_progress may be
     * 64bit on a 32bit platform, and so it might be
@@ -4605,6 +4610,7 @@ static void make_request(struct mddev *mddev, struct bio * bi)
         : logical_sector >= conf->reshape_safe) {
      spin_unlock_irq(&conf->device_lock);
      schedule();
+     do_prepare = true;
      goto retry;
     }
    }
@@ -4641,6 +4647,7 @@ static void make_request(struct mddev *mddev, struct bio * bi)
     if (must_retry) {
      release_stripe(sh);
      schedule();
+     do_prepare = true;
      goto retry;
     }
    }
@@ -4664,8 +4671,10 @@ static void make_request(struct mddev *mddev, struct bio * bi)
     prepare_to_wait(&conf->wait_for_overlap,
       &w, TASK_INTERRUPTIBLE);
     if (logical_sector >= mddev->suspend_lo &&
-        logical_sector < mddev->suspend_hi)
+        logical_sector < mddev->suspend_hi) {
      schedule();
+     do_prepare = true;
+    }
     goto retry;
    }
 
@@ -4678,9 +4687,9 @@ static void make_request(struct mddev *mddev, struct bio * bi)
     md_wakeup_thread(mddev->thread);
     release_stripe(sh);
     schedule();
+    do_prepare = true;
     goto retry;
    }
-   finish_wait(&conf->wait_for_overlap, &w);
    set_bit(STRIPE_HANDLE, &sh->state);
    clear_bit(STRIPE_DELAYED, &sh->state);
    if ((bi->bi_rw & REQ_SYNC) &&
@@ -4690,10 +4699,10 @@ static void make_request(struct mddev *mddev, struct bio * bi)
   } else {
    /* cannot get stripe for read-ahead, just give-up */
    clear_bit(BIO_UPTODATE, &bi->bi_flags);
-   finish_wait(&conf->wait_for_overlap, &w);
    break;
   }
  }
+ finish_wait(&conf->wait_for_overlap, &w);
 
  remaining = raid5_dec_bi_active_stripes(bi);
  if (remaining == 0) {
-- 
1.7.1