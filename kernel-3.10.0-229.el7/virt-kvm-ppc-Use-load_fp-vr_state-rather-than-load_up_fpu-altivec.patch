From 277a74ecbb7cc716d682945240ab5c302aa9e745 Mon Sep 17 00:00:00 2001
From: Don Zickus <dzickus@redhat.com>
Date: Fri, 12 Sep 2014 18:09:21 -0400
Subject: [virt] kvm/ppc: Use load_fp/vr_state rather than load_up_fpu/altivec

Message-id: <1410545655-205645-333-git-send-email-dzickus@redhat.com>
Patchwork-id: 94687
O-Subject: [RHEL7 PATCH 332/626] KVM: PPC: Use load_fp/vr_state rather than load_up_fpu/altivec
Bugzilla: 1127366
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: David Gibson <dgibson@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1127366

commit 09548fdaf32ce77a68e7f9a8a3098c1306b04858
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Oct 15 20:43:01 2013 +1100

    KVM: PPC: Use load_fp/vr_state rather than load_up_fpu/altivec

    The load_up_fpu and load_up_altivec functions were never intended to
    be called from C, and do things like modifying the MSR value in their
    callers' stack frames, which are assumed to be interrupt frames.  In
    addition, on 32-bit Book S they require the MMU to be off.

    This makes KVM use the new load_fp_state() and load_vr_state() functions
    instead of load_up_fpu/altivec.  This means we can remove the assembler
    glue in book3s_rmhandlers.S, and potentially fixes a bug on Book E,
    where load_up_fpu was called directly from C.

    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Alexander Graf <agraf@suse.de>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/include/asm/kvm_book3s.h b/arch/powerpc/include/asm/kvm_book3s.h
index 4a594b7..8bb8706 100644
--- a/arch/powerpc/include/asm/kvm_book3s.h
+++ b/arch/powerpc/include/asm/kvm_book3s.h
@@ -186,9 +186,6 @@ extern void kvmppc_update_lpcr(struct kvm *kvm, unsigned long lpcr,
 
 extern void kvmppc_entry_trampoline(void);
 extern void kvmppc_hv_entry_trampoline(void);
-extern void kvmppc_load_up_fpu(void);
-extern void kvmppc_load_up_altivec(void);
-extern void kvmppc_load_up_vsx(void);
 extern u32 kvmppc_alignment_dsisr(struct kvm_vcpu *vcpu, unsigned int inst);
 extern ulong kvmppc_alignment_dar(struct kvm_vcpu *vcpu, unsigned int inst);
 extern int kvmppc_h_pr(struct kvm_vcpu *vcpu, unsigned long cmd);
diff --git a/arch/powerpc/include/asm/switch_to.h b/arch/powerpc/include/asm/switch_to.h
index 890358d..e98c3a7 100644
--- a/arch/powerpc/include/asm/switch_to.h
+++ b/arch/powerpc/include/asm/switch_to.h
@@ -26,10 +26,8 @@ static inline void save_tar(struct thread_struct *prev) {}
 #endif
 
 extern void giveup_fpu(struct task_struct *);
-extern void load_up_fpu(void);
 extern void enable_kernel_fp(void);
 extern void enable_kernel_altivec(void);
-extern void load_up_altivec(struct task_struct *);
 extern int emulate_altivec(struct pt_regs *);
 extern void __giveup_vsx(struct task_struct *);
 extern void giveup_vsx(struct task_struct *);
diff --git a/arch/powerpc/kvm/book3s_exports.c b/arch/powerpc/kvm/book3s_exports.c
index 852989a..20d4ea8 100644
--- a/arch/powerpc/kvm/book3s_exports.c
+++ b/arch/powerpc/kvm/book3s_exports.c
@@ -25,9 +25,5 @@ EXPORT_SYMBOL_GPL(kvmppc_hv_entry_trampoline);
 #endif
 #ifdef CONFIG_KVM_BOOK3S_PR_POSSIBLE
 EXPORT_SYMBOL_GPL(kvmppc_entry_trampoline);
-EXPORT_SYMBOL_GPL(kvmppc_load_up_fpu);
-#ifdef CONFIG_ALTIVEC
-EXPORT_SYMBOL_GPL(kvmppc_load_up_altivec);
-#endif
 #endif
 
diff --git a/arch/powerpc/kvm/book3s_pr.c b/arch/powerpc/kvm/book3s_pr.c
index a8fb7ed..ae01d96 100644
--- a/arch/powerpc/kvm/book3s_pr.c
+++ b/arch/powerpc/kvm/book3s_pr.c
@@ -690,7 +690,8 @@ static int kvmppc_handle_ext(struct kvm_vcpu *vcpu, unsigned int exit_nr,
 #endif
   t->fp_state.fpscr = vcpu->arch.fpscr;
   t->fpexc_mode = 0;
-  kvmppc_load_up_fpu();
+  enable_kernel_fp();
+  load_fp_state(&t->fp_state);
  }
 
  if (msr & MSR_VEC) {
@@ -698,7 +699,8 @@ static int kvmppc_handle_ext(struct kvm_vcpu *vcpu, unsigned int exit_nr,
   memcpy(t->vr_state.vr, vcpu->arch.vr, sizeof(vcpu->arch.vr));
   t->vr_state.vscr = vcpu->arch.vscr;
   t->vrsave = -1;
-  kvmppc_load_up_altivec();
+  enable_kernel_altivec();
+  load_vr_state(&t->vr_state);
 #endif
  }
 
@@ -721,10 +723,14 @@ static void kvmppc_handle_lost_ext(struct kvm_vcpu *vcpu)
  if (!lost_ext)
   return;
 
- if (lost_ext & MSR_FP)
-  kvmppc_load_up_fpu();
- if (lost_ext & MSR_VEC)
-  kvmppc_load_up_altivec();
+ if (lost_ext & MSR_FP) {
+  enable_kernel_fp();
+  load_fp_state(&current->thread.fp_state);
+ }
+ if (lost_ext & MSR_VEC) {
+  enable_kernel_altivec();
+  load_vr_state(&current->thread.vr_state);
+ }
  current->thread.regs->msr |= lost_ext;
 }
 
diff --git a/arch/powerpc/kvm/book3s_rmhandlers.S b/arch/powerpc/kvm/book3s_rmhandlers.S
index a38c4c9..c78ffbc 100644
--- a/arch/powerpc/kvm/book3s_rmhandlers.S
+++ b/arch/powerpc/kvm/book3s_rmhandlers.S
@@ -166,51 +166,4 @@ _GLOBAL(kvmppc_entry_trampoline)
  mtsrr1 r6
  RFI
 
-#if defined(CONFIG_PPC_BOOK3S_32)
-#define STACK_LR INT_FRAME_SIZE+4
-
-/* load_up_xxx have to run with MSR_DR=0 on Book3S_32 */
-#define MSR_EXT_START      \
- PPC_STL r20, _NIP(r1);     \
- mfmsr r20;      \
- LOAD_REG_IMMEDIATE(r3, MSR_DR|MSR_EE);   \
- andc r3,r20,r3;  /* Disable DR,EE */ \
- mtmsr r3;      \
- sync
-
-#define MSR_EXT_END      \
- mtmsr r20;   /* Enable DR,EE */ \
- sync;       \
- PPC_LL r20, _NIP(r1)
-
-#elif defined(CONFIG_PPC_BOOK3S_64)
-#define STACK_LR _LINK
-#define MSR_EXT_START
-#define MSR_EXT_END
-#endif
-
-/*
- * Activate current's external feature (FPU/Altivec/VSX)
- */
-#define define_load_up(what)      \
-        \
-_GLOBAL(kvmppc_load_up_ ## what);    \
- PPC_STLU r1, -INT_FRAME_SIZE(r1);   \
- mflr r3;      \
- PPC_STL r3, STACK_LR(r1);    \
- MSR_EXT_START;      \
-        \
- bl FUNC(load_up_ ## what);    \
-        \
- MSR_EXT_END;      \
- PPC_LL r3, STACK_LR(r1);    \
- mtlr r3;      \
- addi r1, r1, INT_FRAME_SIZE;    \
- blr
-
-define_load_up(fpu)
-#ifdef CONFIG_ALTIVEC
-define_load_up(altivec)
-#endif
-
 #include "book3s_segment.S"
diff --git a/arch/powerpc/kvm/booke.h b/arch/powerpc/kvm/booke.h
index ef6354b..28c0f24 100644
--- a/arch/powerpc/kvm/booke.h
+++ b/arch/powerpc/kvm/booke.h
@@ -136,7 +136,8 @@ static inline void kvmppc_load_guest_fp(struct kvm_vcpu *vcpu)
 {
 #ifdef CONFIG_PPC_FPU
  if (vcpu->fpu_active && !(current->thread.regs->msr & MSR_FP)) {
-  load_up_fpu();
+  enable_kernel_fp();
+  load_fp_state(&current->thread.fp_state);
   current->thread.regs->msr |= MSR_FP;
  }
 #endif
-- 
1.7.1