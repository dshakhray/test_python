From 96ab8d99b99d4972ab653588827b5f0203242dd9 Mon Sep 17 00:00:00 2001
From: Gustavo Duarte <gduarte@redhat.com>
Date: Tue, 2 Sep 2014 21:09:19 -0400
Subject: [powerpc] start loop at section start of start in vmemmap_populated()

Message-id: <1409692159-32351-5-git-send-email-gduarte@redhat.com>
Patchwork-id: 90690
O-Subject: [RHEL7.1 PATCH BZ 1090174 4/4] powerpc: start loop at section start of start in vmemmap_populated()
Bugzilla: 1090174
RH-Acked-by: Stefan Assmann <sassmann@redhat.com>
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>

Bugzilla: https://bugzilla.redhat.com/show_bug.cgi?id=1090174
Upstream Status: 16a05bff128de196fc17edd2beaa40d0f07ae04a

commit 16a05bff128de196fc17edd2beaa40d0f07ae04a
Author: Li Zhong <zhong@linux.vnet.ibm.com>
Date:   Wed Jun 11 16:23:39 2014 +0800

    powerpc: start loop at section start of start in vmemmap_populated()

    vmemmap_populated() checks whether the [start, start + page_size) has valid
    pfn numbers, to know whether a vmemmap mapping has been created that includes
    this range.

    Some range before end might not be checked by this loop:
      sec11start......start11..sec11end/sec12start..end....start12..sec12end
    as the above, for start11(section 11), it checks [sec11start, sec11end), and
    loop ends as the next start(start12) is bigger than end. However,
    [sec11end/sec12start, end) is not checked here.

    So before the loop, adjust the start to be the start of the section, so we don't miss ranges like the above.

    After we adjust start to be the start of the section, it also means it's
    aligned with vmemmap as of the sizeof struct page, so we could use
    page_to_pfn directly in the loop.

    Signed-off-by: Li Zhong <zhong@linux.vnet.ibm.com>
    Cc: Nathan Fontenot <nfont@linux.vnet.ibm.com>
    Acked-by: Nathan Fontenot <nfont@linux.vnet.ibm.com>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/mm/init_64.c b/arch/powerpc/mm/init_64.c
index b275b7a..48dc2a0 100644
--- a/arch/powerpc/mm/init_64.c
+++ b/arch/powerpc/mm/init_64.c
@@ -175,9 +175,10 @@ static unsigned long __meminit vmemmap_section_start(unsigned long page)
 static int __meminit vmemmap_populated(unsigned long start, int page_size)
 {
  unsigned long end = start + page_size;
+ start = (unsigned long)(pfn_to_page(vmemmap_section_start(start)));
 
  for (; start < end; start += (PAGES_PER_SECTION * sizeof(struct page)))
-  if (pfn_valid(vmemmap_section_start(start)))
+  if (pfn_valid(page_to_pfn((struct page *)start)))
    return 1;
 
  return 0;
-- 
1.7.1