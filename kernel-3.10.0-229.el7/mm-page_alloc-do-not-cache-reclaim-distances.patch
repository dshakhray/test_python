From 80f1101b7014e155f6350e51ee262a36e865c65a Mon Sep 17 00:00:00 2001
From: Larry Woodman <lwoodman@redhat.com>
Date: Thu, 24 Jul 2014 19:09:43 -0400
Subject: [mm] page_alloc: do not cache reclaim distances

Message-id: <1406228983-22655-1-git-send-email-lwoodman@redhat.com>
Patchwork-id: 86642
O-Subject: [RHEL7.1 PATCH 2/2 V2] mm: page_alloc: do not cache reclaim distances
Bugzilla: 1120342
RH-Acked-by: Johannes Weiner <jweiner@redhat.com>
RH-Acked-by: Rafael Aquini <aquini@redhat.com>
RH-Acked-by: Rik van Riel <riel@redhat.com>

V2 does not remove the "nodemask_t reclaim_nodes;" line from the "struct pglist_data"
 in include/linux/mmzone.h.  I verified that this would NOT break the kABI but leaving
 it in place is free expansion space if its ever needed.

 commit 5f7a75acdb24c7b9c436b3a0a66eec12e101d19c
 Author: Mel Gorman <mgorman@suse.de>
 Date:   Wed Jun 4 16:07:15 2014 -0700

    mm: page_alloc: do not cache reclaim distances

    pgdat->reclaim_nodes tracks if a remote node is allowed to be reclaimed
    by zone_reclaim due to its distance.  As it is expected that
    zone_reclaim_mode will be rarely enabled it is unreasonable for all
    machines to take a penalty.  Fortunately, the zone_reclaim_mode() path
    is already slow and it is the path that takes the hit.

    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Reviewed-by: Zhang Yanfei <zhangyanfei@cn.fujitsu.com>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Reviewed-by: Christoph Lameter <cl@linux.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index c2c1427..ee6c799 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1802,16 +1802,8 @@ static bool zone_local(struct zone *local_zone, struct zone *zone)
 
 static bool zone_allows_reclaim(struct zone *local_zone, struct zone *zone)
 {
- return node_isset(local_zone->node, zone->zone_pgdat->reclaim_nodes);
-}
-
-static void __paginginit init_zone_allows_reclaim(int nid)
-{
- int i;
-
- for_each_node_state(i, N_MEMORY)
-  if (node_distance(nid, i) <= RECLAIM_DISTANCE)
-   node_set(i, NODE_DATA(nid)->reclaim_nodes);
+ return node_distance(zone_to_nid(local_zone), zone_to_nid(zone)) <
+    RECLAIM_DISTANCE;
 }
 
 #else /* CONFIG_NUMA */
@@ -1845,9 +1837,6 @@ static bool zone_allows_reclaim(struct zone *local_zone, struct zone *zone)
  return true;
 }
 
-static inline void init_zone_allows_reclaim(int nid)
-{
-}
 #endif /* CONFIG_NUMA */
 
 /*
@@ -4809,8 +4798,6 @@ void __paginginit free_area_init_node(int nid, unsigned long *zones_size,
 
  pgdat->node_id = nid;
  pgdat->node_start_pfn = node_start_pfn;
- if (node_state(nid, N_MEMORY))
-  init_zone_allows_reclaim(nid);
  calculate_node_totalpages(pgdat, zones_size, zholes_size);
 
  alloc_node_mem_map(pgdat);
-- 
1.7.1