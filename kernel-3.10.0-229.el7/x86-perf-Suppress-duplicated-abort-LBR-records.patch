From 4b989e37ee86bf023c0a6cbfec3dc9444ad27ae4 Mon Sep 17 00:00:00 2001
From: Jiri Olsa <jolsa@redhat.com>
Date: Tue, 19 Aug 2014 15:23:01 -0400
Subject: [x86] perf: Suppress duplicated abort LBR records

Message-id: <1408462094-14194-13-git-send-email-jolsa@redhat.com>
Patchwork-id: 88006
O-Subject: [PATCH RHEL7.1 BZ1131394 012/325] perf/x86: Suppress duplicated abort LBR records
Bugzilla: 1131394
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>

From: Jiri Olsa <jolsa@kernel.org>

Bugzilla: 1131394
https://bugzilla.redhat.com/show_bug.cgi?id=1131394

upstream
========
commit b7af41a1bc255c0098c37a4bcf5c7e5e168ce875
Author: Andi Kleen <ak@linux.intel.com>
Date: Fri Sep 20 07:40:44 2013 -0700

description
===========
Haswell always give an extra LBR record after every TSX abort.
Suppress the extra record.

This only works when the abort is visible in the LBR
If the original abort has already left the 16 LBR entries
the extra entry will will stay.
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/x86/kernel/cpu/perf_event.h b/arch/x86/kernel/cpu/perf_event.h
index afcd17e..9df775d 100644
--- a/arch/x86/kernel/cpu/perf_event.h
+++ b/arch/x86/kernel/cpu/perf_event.h
@@ -445,6 +445,7 @@ struct x86_pmu {
  int  lbr_nr;      /* hardware stack size */
  u64  lbr_sel_mask;     /* LBR_SELECT valid bits */
  const int *lbr_sel_map;     /* lbr_select mappings */
+ bool  lbr_double_abort;    /* duplicated lbr aborts */
 
  /*
   * Extra registers for events
diff --git a/arch/x86/kernel/cpu/perf_event_intel.c b/arch/x86/kernel/cpu/perf_event_intel.c
index 8420041..56356d4 100644
--- a/arch/x86/kernel/cpu/perf_event_intel.c
+++ b/arch/x86/kernel/cpu/perf_event_intel.c
@@ -2514,6 +2514,7 @@ __init int intel_pmu_init(void)
   x86_pmu.hw_config = hsw_hw_config;
   x86_pmu.get_event_constraints = hsw_get_event_constraints;
   x86_pmu.cpu_events = hsw_events_attrs;
+  x86_pmu.lbr_double_abort = true;
   pr_cont("Haswell events, ");
   break;
 
diff --git a/arch/x86/kernel/cpu/perf_event_intel_lbr.c b/arch/x86/kernel/cpu/perf_event_intel_lbr.c
index d5be06a..90ee6c1 100644
--- a/arch/x86/kernel/cpu/perf_event_intel_lbr.c
+++ b/arch/x86/kernel/cpu/perf_event_intel_lbr.c
@@ -284,6 +284,7 @@ static void intel_pmu_lbr_read_64(struct cpu_hw_events *cpuc)
  int lbr_format = x86_pmu.intel_cap.lbr_format;
  u64 tos = intel_pmu_lbr_tos();
  int i;
+ int out = 0;
 
  for (i = 0; i < x86_pmu.lbr_nr; i++) {
   unsigned long lbr_idx = (tos - i) & mask;
@@ -306,15 +307,27 @@ static void intel_pmu_lbr_read_64(struct cpu_hw_events *cpuc)
   }
   from = (u64)((((s64)from) << skip) >> skip);
 
-  cpuc->lbr_entries[i].from = from;
-  cpuc->lbr_entries[i].to  = to;
-  cpuc->lbr_entries[i].mispred = mis;
-  cpuc->lbr_entries[i].predicted = pred;
-  cpuc->lbr_entries[i].in_tx = in_tx;
-  cpuc->lbr_entries[i].abort = abort;
-  cpuc->lbr_entries[i].reserved = 0;
+  /*
+   * Some CPUs report duplicated abort records,
+   * with the second entry not having an abort bit set.
+   * Skip them here. This loop runs backwards,
+   * so we need to undo the previous record.
+   * If the abort just happened outside the window
+   * the extra entry cannot be removed.
+   */
+  if (abort && x86_pmu.lbr_double_abort && out > 0)
+   out--;
+
+  cpuc->lbr_entries[out].from  = from;
+  cpuc->lbr_entries[out].to  = to;
+  cpuc->lbr_entries[out].mispred  = mis;
+  cpuc->lbr_entries[out].predicted = pred;
+  cpuc->lbr_entries[out].in_tx  = in_tx;
+  cpuc->lbr_entries[out].abort  = abort;
+  cpuc->lbr_entries[out].reserved  = 0;
+  out++;
  }
- cpuc->lbr_stack.nr = i;
+ cpuc->lbr_stack.nr = out;
 }
 
 void intel_pmu_lbr_read(void)
-- 
1.7.1