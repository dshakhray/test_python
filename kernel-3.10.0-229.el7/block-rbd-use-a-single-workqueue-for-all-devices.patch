From 8ec3390b88df1d3fb55c6a898174196f3737ae9d Mon Sep 17 00:00:00 2001
From: Ilya Dryomov <ilya.dryomov@inktank.com>
Date: Tue, 18 Nov 2014 15:49:56 -0500
Subject: [block] rbd: use a single workqueue for all devices
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Message-id: <1416325805-26490-42-git-send-email-idryomov@redhat.com>
Patchwork-id: 100233
O-Subject: [RHEL7.1 PATCH 41/50] rbd: use a single workqueue for all devices
Bugzilla: 1165232
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: Sage Weil <sweil@redhat.com>
RH-Acked-by: Ã¤Â¸Â¥Ã¦Â­Â£ <zyan@redhat.com>

Using one queue per device doesn't make much sense given that our
workfn processes "devices" and not "requests".  Switch to a single
workqueue for all devices.

Signed-off-by: Ilya Dryomov <idryomov@redhat.com>
Reviewed-by: Sage Weil <sage@redhat.com>
(cherry picked from commit f5ee37bd31678d6cb2313631f203794b5c25e862)
Signed-off-by: Jarod Wilson <jarod@redhat.com>

Conflicts:
 drivers/block/rbd.c [ context: sysfs bus_groups not in RHEL ]
---

diff --git a/drivers/block/rbd.c b/drivers/block/rbd.c
index 8577d97..d8b3f0a 100644
--- a/drivers/block/rbd.c
+++ b/drivers/block/rbd.c
@@ -342,7 +342,6 @@ struct rbd_device {
 
  struct list_head rq_queue; /* incoming rq queue */
  spinlock_t  lock;  /* queue, flags, open_count */
- struct workqueue_struct *rq_wq;
  struct work_struct rq_work;
 
  struct rbd_image_header header;
@@ -402,6 +401,8 @@ static struct kmem_cache *rbd_segment_name_cache;
 static int rbd_major;
 static DEFINE_IDA(rbd_dev_id_ida);
 
+static struct workqueue_struct *rbd_wq;
+
 /*
  * Default to false for now, as single-major requires >= 0.75 version of
  * userspace rbd utility.
@@ -3495,7 +3496,7 @@ static void rbd_request_fn(struct request_queue *q)
  }
 
  if (queued)
-  queue_work(rbd_dev->rq_wq, &rbd_dev->rq_work);
+  queue_work(rbd_wq, &rbd_dev->rq_work);
 }
 
 /*
@@ -5285,16 +5286,9 @@ static int rbd_dev_device_setup(struct rbd_device *rbd_dev)
  set_capacity(rbd_dev->disk, rbd_dev->mapping.size / SECTOR_SIZE);
  set_disk_ro(rbd_dev->disk, rbd_dev->mapping.read_only);
 
- rbd_dev->rq_wq = alloc_workqueue("%s", WQ_MEM_RECLAIM, 0,
-      rbd_dev->disk->disk_name);
- if (!rbd_dev->rq_wq) {
-  ret = -ENOMEM;
-  goto err_out_mapping;
- }
-
  ret = rbd_bus_add_dev(rbd_dev);
  if (ret)
-  goto err_out_workqueue;
+  goto err_out_mapping;
 
  /* Everything's ready.  Announce the disk to the world. */
 
@@ -5306,9 +5300,6 @@ static int rbd_dev_device_setup(struct rbd_device *rbd_dev)
 
  return ret;
 
-err_out_workqueue:
- destroy_workqueue(rbd_dev->rq_wq);
- rbd_dev->rq_wq = NULL;
 err_out_mapping:
  rbd_dev_mapping_clear(rbd_dev);
 err_out_disk:
@@ -5555,7 +5546,6 @@ static void rbd_dev_device_release(struct device *dev)
 {
  struct rbd_device *rbd_dev = dev_to_rbd_dev(dev);
 
- destroy_workqueue(rbd_dev->rq_wq);
  rbd_free_disk(rbd_dev);
  clear_bit(RBD_DEV_FLAG_EXISTS, &rbd_dev->flags);
  rbd_dev_mapping_clear(rbd_dev);
@@ -5759,12 +5749,22 @@ static int __init rbd_init(void)
  if (rc)
   return rc;
 
+ /*
+  * The number of active work items is limited by the number of
+  * rbd devices, so leave @max_active at default.
+  */
+ rbd_wq = alloc_workqueue(RBD_DRV_NAME, WQ_MEM_RECLAIM, 0);
+ if (!rbd_wq) {
+  rc = -ENOMEM;
+  goto err_out_slab;
+ }
+
  rbd_bus_type.bus_attrs = rbd_bus_attrs;
  if (single_major) {
   rbd_major = register_blkdev(0, RBD_DRV_NAME);
   if (rbd_major < 0) {
    rc = rbd_major;
-   goto err_out_slab;
+   goto err_out_wq;
   }
   rbd_bus_type.bus_attrs = rbd_bus_attrs_single_major;
  }
@@ -5783,6 +5783,8 @@ static int __init rbd_init(void)
 err_out_blkdev:
  if (single_major)
   unregister_blkdev(rbd_major, RBD_DRV_NAME);
+err_out_wq:
+ destroy_workqueue(rbd_wq);
 err_out_slab:
  rbd_slab_exit();
  return rc;
@@ -5794,6 +5796,7 @@ static void __exit rbd_exit(void)
  rbd_sysfs_cleanup();
  if (single_major)
   unregister_blkdev(rbd_major, RBD_DRV_NAME);
+ destroy_workqueue(rbd_wq);
  rbd_slab_exit();
 }
 
-- 
1.7.1