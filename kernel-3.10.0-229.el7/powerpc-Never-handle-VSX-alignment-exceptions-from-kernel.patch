From bc0ae98f6088e23de738d5755e30b8ed4e2bba8a Mon Sep 17 00:00:00 2001
From: Don Zickus <dzickus@redhat.com>
Date: Fri, 12 Sep 2014 18:04:55 -0400
Subject: [powerpc] Never handle VSX alignment exceptions from kernel

Message-id: <1410545655-205645-67-git-send-email-dzickus@redhat.com>
Patchwork-id: 94165
O-Subject: [RHEL7 PATCH 066/626] powerpc: Never handle VSX alignment exceptions from kernel
Bugzilla: 1127366
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: David Gibson <dgibson@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1127366

commit 5c2e08231b68a3c8082716a7ed4e972dde406e4a
Author: Anton Blanchard <anton@samba.org>
Date:   Tue Aug 20 20:30:07 2013 +1000

    powerpc: Never handle VSX alignment exceptions from kernel

    The VSX alignment handler needs to write out the existing VSX
    state to memory before operating on it (flush_vsx_to_thread()).
    If we take a VSX alignment exception in the kernel bad things
    will happen. It looks like we could write the kernel state out
    to the user process, or we could handle the kernel exception
    using data from the user process (depending if MSR_VSX is set
    or not).

    Worse still, if the code to read or write the VSX state causes an
    alignment exception, we will recurse forever. I ended up with
    hundreds of megabytes of kernel stack to look through as a result.

    Floating point and SPE code have similar issues but already include
    a user check. Add the same check to emulate_vsx().

    With this patch any unaligned VSX loads and stores in the kernel
    will show up as a clear oops rather than silent corruption of
    kernel or userspace VSX state, or worse, corruption of a potentially
    unlimited amount of kernel memory.

    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/kernel/align.c b/arch/powerpc/kernel/align.c
index dcab453..de91f3a 100644
--- a/arch/powerpc/kernel/align.c
+++ b/arch/powerpc/kernel/align.c
@@ -658,6 +658,10 @@ static int emulate_vsx(unsigned char __user *addr, unsigned int reg,
  int sw = 0;
  int i, j;
 
+ /* userland only */
+ if (unlikely(!user_mode(regs)))
+  return 0;
+
  flush_vsx_to_thread(current);
 
  if (reg < 32)
-- 
1.7.1