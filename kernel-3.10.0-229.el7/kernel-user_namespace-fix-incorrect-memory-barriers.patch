From 000d6cd09cce27b9b23cb24af7144ad9d1ef3b88 Mon Sep 17 00:00:00 2001
From: Mikulas Patocka <mpatocka@redhat.com>
Date: Mon, 11 Aug 2014 23:31:12 -0400
Subject: [kernel] user_namespace: fix incorrect memory barriers

Message-id: <alpine.LRH.2.02.1408111929070.17192@file01.intranet.prod.int.rdu2.redhat.com>
Patchwork-id: 87645
O-Subject: [PATCH RHEL7 bz1128950] backport fix for a race condition in user namespace
Bugzilla: 1128950
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Aristeu Rozanski <aris@redhat.com>

Backport of upstream commit e79323bd87808fdfbc68ce6c5371bd224d9672ee.

Testing: the probability that this bug happens is very low, it can't be
tested. But the bug can trigget random crash, so we should backport it.

commit e79323bd87808fdfbc68ce6c5371bd224d9672ee
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Mon Apr 14 16:58:55 2014 -0400

    user namespace: fix incorrect memory barriers

    smp_read_barrier_depends() can be used if there is data dependency between
    the readers - i.e. if the read operation after the barrier uses address
    that was obtained from the read operation before the barrier.

    In this file, there is only control dependency, no data dependecy, so the
    use of smp_read_barrier_depends() is incorrect. The code could fail in the
    following way:
    * the cpu predicts that idx < entries is true and starts executing the
      body of the for loop
    * the cpu fetches map->extent[0].first and map->extent[0].count
    * the cpu fetches map->nr_extents
    * the cpu verifies that idx < extents is true, so it commits the
      instructions in the body of the for loop

    The problem is that in this scenario, the cpu read map->extent[0].first
    and map->nr_extents in the wrong order. We need a full read memory barrier
    to prevent it.

    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/kernel/user_namespace.c b/kernel/user_namespace.c
index e54de2f..536ecfb 100644
--- a/kernel/user_namespace.c
+++ b/kernel/user_namespace.c
@@ -153,7 +153,7 @@ static u32 map_id_range_down(struct uid_gid_map *map, u32 id, u32 count)
 
  /* Find the matching extent */
  extents = map->nr_extents;
- smp_read_barrier_depends();
+ smp_rmb();
  for (idx = 0; idx < extents; idx++) {
   first = map->extent[idx].first;
   last = first + map->extent[idx].count - 1;
@@ -177,7 +177,7 @@ static u32 map_id_down(struct uid_gid_map *map, u32 id)
 
  /* Find the matching extent */
  extents = map->nr_extents;
- smp_read_barrier_depends();
+ smp_rmb();
  for (idx = 0; idx < extents; idx++) {
   first = map->extent[idx].first;
   last = first + map->extent[idx].count - 1;
@@ -200,7 +200,7 @@ static u32 map_id_up(struct uid_gid_map *map, u32 id)
 
  /* Find the matching extent */
  extents = map->nr_extents;
- smp_read_barrier_depends();
+ smp_rmb();
  for (idx = 0; idx < extents; idx++) {
   first = map->extent[idx].lower_first;
   last = first + map->extent[idx].count - 1;
@@ -616,9 +616,8 @@ static ssize_t map_write(struct file *file, const char __user *buf,
   * were written before the count of the extents.
   *
   * To achieve this smp_wmb() is used on guarantee the write
-  * order and smp_read_barrier_depends() is guaranteed that we
-  * don't have crazy architectures returning stale data.
-  *
+  * order and smp_rmb() is guaranteed that we don't have crazy
+  * architectures returning stale data.
   */
  mutex_lock(&id_map_mutex);
 
-- 
1.7.1