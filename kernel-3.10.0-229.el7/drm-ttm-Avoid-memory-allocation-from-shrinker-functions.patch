From 848672abda08b1e42ebb4876e22c0d6b0f675d32 Mon Sep 17 00:00:00 2001
From: Rob Clark <rclark@redhat.com>
Date: Wed, 17 Dec 2014 21:39:38 -0500
Subject: [drm] ttm: Avoid memory allocation from shrinker functions

Message-id: <1418852380-13061-88-git-send-email-rclark@redhat.com>
Patchwork-id: 102227
O-Subject: [RHEL7 drm 87/89] drm/ttm: Avoid memory allocation from shrinker functions.
Bugzilla: 1173317
RH-Acked-by: Jerome Glisse <jglisse@redhat.com>
RH-Acked-by: Dave Airlie <airlied@redhat.com>

Bugzilla: https://bugzilla.redhat.com/show_bug.cgi?id=1173317
Upstream: since Not upstream

commit 881fdaa5e4cb0d68e52acab0ad4e1820e2bfffa4

Author:     Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
AuthorDate: Thu Nov 13 22:43:23 2014 +0900
Commit:     Rob Clark <rclark@redhat.com>
CommitDate: Mon Dec 15 14:58:04 2014 -0500

    drm/ttm: Avoid memory allocation from shrinker functions.

    Andrew Morton wrote:
    > On Wed, 12 Nov 2014 13:08:55 +0900 Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp> wrote:
    >
    > > Andrew Morton wrote:
    > > > Poor ttm guys - this is a bit of a trap we set for them.
    > >
    > > Commit a91576d7916f6cce ("drm/ttm: Pass GFP flags in order to avoid deadlock.")
    > > changed to use sc->gfp_mask rather than GFP_KERNEL.
    > >
    > > -       pages_to_free = kmalloc(npages_to_free * sizeof(struct page *),
    > > -                       GFP_KERNEL);
    > > +       pages_to_free = kmalloc(npages_to_free * sizeof(struct page *), gfp);
    > >
    > > But this bug is caused by sc->gfp_mask containing some flags which are not
    > > in GFP_KERNEL, right? Then, I think
    > >
    > > -       pages_to_free = kmalloc(npages_to_free * sizeof(struct page *), gfp);
    > > +       pages_to_free = kmalloc(npages_to_free * sizeof(struct page *), gfp & GFP_KERNEL);
    > >
    > > would hide this bug.
    > >
    > > But I think we should use GFP_ATOMIC (or drop __GFP_WAIT flag)
    >
    > Well no - ttm_page_pool_free() should stop calling kmalloc altogether.
    > Just do
    >
    >  struct page *pages_to_free[16];
    >
    > and rework the code to free 16 pages at a time.  Easy.

    Well, ttm code wants to process 512 pages at a time for performance.
    Memory footprint increased by 512 * sizeof(struct page *) buffer is
    only 4096 bytes. What about using static buffer like below?
    ----------
    >From d3cb5393c9c8099d6b37e769f78c31af1541fe8c Mon Sep 17 00:00:00 2001
    From: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Date: Thu, 13 Nov 2014 22:21:54 +0900
    Subject: [PATCH] drm/ttm: Avoid memory allocation from shrinker functions.

    Commit a91576d7916f6cce ("drm/ttm: Pass GFP flags in order to avoid
    deadlock.") caused BUG_ON() due to sc->gfp_mask containing flags
    which are not in GFP_KERNEL.

      https://bugzilla.kernel.org/show_bug.cgi?id=87891

    Changing from sc->gfp_mask to (sc->gfp_mask & GFP_KERNEL) would
    avoid the BUG_ON(), but avoiding memory allocation from shrinker
    function is better and reliable fix.

    Shrinker function is already serialized by global lock, and
    clean up function is called after shrinker function is unregistered.
    Thus, we can use static buffer when called from shrinker function
    and clean up function.

    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Cc: stable <stable@kernel.org> [2.6.35+]
    Signed-off-by: Dave Airlie <airlied@redhat.com>

Signed-off-by: Rob Clark <rclark@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/drivers/gpu/drm/ttm/ttm_page_alloc.c b/drivers/gpu/drm/ttm/ttm_page_alloc.c
index 606b598..609adf1 100644
--- a/drivers/gpu/drm/ttm/ttm_page_alloc.c
+++ b/drivers/gpu/drm/ttm/ttm_page_alloc.c
@@ -297,9 +297,11 @@ static void ttm_pool_update_free_locked(struct ttm_page_pool *pool,
  *
  * @pool: to free the pages from
  * @free_all: If set to true will free all pages in pool
+ * @use_static: Safe to use static buffer
  **/
-static int ttm_page_pool_free(struct ttm_page_pool *pool, unsigned nr_free)
+static int ttm_page_pool_free(struct ttm_page_pool *pool, unsigned nr_free, bool use_static)
 {
+ static struct page *static_buf[NUM_PAGES_TO_ALLOC];
  unsigned long irq_flags;
  struct page *p;
  struct page **pages_to_free;
@@ -309,8 +311,11 @@ static int ttm_page_pool_free(struct ttm_page_pool *pool, unsigned nr_free)
  if (NUM_PAGES_TO_ALLOC < nr_free)
   npages_to_free = NUM_PAGES_TO_ALLOC;
 
- pages_to_free = kmalloc(npages_to_free * sizeof(struct page *),
-   GFP_KERNEL);
+ if (use_static)
+  pages_to_free = static_buf;
+ else
+  pages_to_free = kmalloc(npages_to_free * sizeof(struct page *),
+    GFP_KERNEL);
  if (!pages_to_free) {
   pr_err("Failed to allocate memory for pool free operation\n");
   return 0;
@@ -373,7 +378,8 @@ restart:
  if (freed_pages)
   ttm_pages_put(pages_to_free, freed_pages);
 out:
- kfree(pages_to_free);
+ if (pages_to_free != static_buf)
+  kfree(pages_to_free);
  return nr_free;
 }
 
@@ -410,7 +416,7 @@ static int ttm_pool_mm_shrink(struct shrinker *shrink,
   if (shrink_pages == 0)
    break;
   pool = &_manager->pools[(i + pool_offset)%NUM_POOLS];
-  shrink_pages = ttm_page_pool_free(pool, nr_free);
+  shrink_pages = ttm_page_pool_free(pool, nr_free, true);
  }
  mutex_unlock(&lock);
  /* return estimated number of unused pages in pool */
@@ -698,7 +704,7 @@ static void ttm_put_pages(struct page **pages, unsigned npages, int flags,
  }
  spin_unlock_irqrestore(&pool->lock, irq_flags);
  if (npages)
-  ttm_page_pool_free(pool, npages);
+  ttm_page_pool_free(pool, npages, false);
 }
 
 /*
@@ -837,8 +843,9 @@ void ttm_page_alloc_fini(void)
  pr_info("Finalizing pool allocator\n");
  ttm_pool_mm_shrink_fini(_manager);
 
+ /* OK to use static buffer since global mutex is no longer used. */
  for (i = 0; i < NUM_POOLS; ++i)
-  ttm_page_pool_free(&_manager->pools[i], FREE_ALL_PAGES);
+  ttm_page_pool_free(&_manager->pools[i], FREE_ALL_PAGES, true);
 
  kobject_put(&_manager->kobj);
  _manager = NULL;
diff --git a/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c b/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c
index df4cc02..bf366d4 100644
--- a/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c
+++ b/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c
@@ -410,9 +410,12 @@ static void ttm_dma_page_put(struct dma_pool *pool, struct dma_page *d_page)
  *
  * @pool: to free the pages from
  * @nr_free: If set to true will free all pages in pool
+ * @use_static: Safe to use static buffer
+ *
  **/
-static unsigned ttm_dma_page_pool_free(struct dma_pool *pool, unsigned nr_free)
+static unsigned ttm_dma_page_pool_free(struct dma_pool *pool, unsigned nr_free, bool use_static)
 {
+ static struct page *static_buf[NUM_PAGES_TO_ALLOC];
  unsigned long irq_flags;
  struct dma_page *dma_p, *tmp;
  struct page **pages_to_free;
@@ -429,8 +432,11 @@ static unsigned ttm_dma_page_pool_free(struct dma_pool *pool, unsigned nr_free)
     npages_to_free, nr_free);
  }
 #endif
- pages_to_free = kmalloc(npages_to_free * sizeof(struct page *),
-   GFP_KERNEL);
+ if (use_static)
+  pages_to_free = static_buf;
+ else
+  pages_to_free = kmalloc(npages_to_free * sizeof(struct page *),
+    GFP_KERNEL);
 
  if (!pages_to_free) {
   pr_err("%s: Failed to allocate memory for pool free operation\n",
@@ -500,7 +506,8 @@ restart:
  if (freed_pages)
   ttm_dma_pages_put(pool, &d_pages, pages_to_free, freed_pages);
 out:
- kfree(pages_to_free);
+ if (pages_to_free != static_buf)
+  kfree(pages_to_free);
  return nr_free;
 }
 
@@ -529,7 +536,8 @@ static void ttm_dma_free_pool(struct device *dev, enum pool_type type)
   if (pool->type != type)
    continue;
   /* Takes a spinlock.. */
-  ttm_dma_page_pool_free(pool, FREE_ALL_PAGES);
+  /* OK to use static buffer since global mutex is held. */
+  ttm_dma_page_pool_free(pool, FREE_ALL_PAGES, true);
   WARN_ON(((pool->npages_in_use + pool->npages_free) != 0));
   /* This code path is called after _all_ references to the
    * struct device has been dropped - so nobody should be
@@ -995,7 +1003,7 @@ void ttm_dma_unpopulate(struct ttm_dma_tt *ttm_dma, struct device *dev)
 
  /* shrink pool if necessary (only on !is_cached pools)*/
  if (npages)
-  ttm_dma_page_pool_free(pool, npages);
+  ttm_dma_page_pool_free(pool, npages, false);
  ttm->state = tt_unpopulated;
 }
 EXPORT_SYMBOL_GPL(ttm_dma_unpopulate);
@@ -1031,7 +1039,7 @@ static int ttm_dma_pool_mm_shrink(struct shrinker *shrink,
   if (++idx < pool_offset)
    continue;
   nr_free = shrink_pages;
-  shrink_pages = ttm_dma_page_pool_free(p->pool, nr_free);
+  shrink_pages = ttm_dma_page_pool_free(p->pool, nr_free, true);
   pr_debug("%s: (%s:%d) Asked to shrink %d, have %d more to go\n",
     p->pool->dev_name, p->pool->name, current->pid,
     nr_free, shrink_pages);
-- 
1.7.1