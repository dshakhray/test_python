From dc6739ad98f1f569f147e2890d54ccdac153f38e Mon Sep 17 00:00:00 2001
From: Lukas Czerner <lczerner@redhat.com>
Date: Thu, 23 Oct 2014 09:53:15 -0400
Subject: [fs] ext4: fix up error handling for mpage_map_and_submit_extent()

Message-id: <1414058125-4183-42-git-send-email-lczerner@redhat.com>
Patchwork-id: 98128
O-Subject: [RHEL 7.1 PATCH v2 041/171] ext4: fix up error handling for mpage_map_and_submit_extent()
Bugzilla: 1150139
RH-Acked-by: Eric Sandeen <sandeen@redhat.com>

From: Theodore Ts'o <tytso@mit.edu>

BZ 1150139
https://bugzilla.redhat.com/show_bug.cgi?id=1150139

BREW 8142710
https://brewweb.devel.redhat.com/taskinfo?taskID=8142710

Upstream commit cb530541182bee14112675046331f20a1c831507

 The function mpage_released_unused_page() must only be called once;
 otherwise the kernel will BUG() when the second call to
 mpage_released_unused_page() tries to unlock the pages which had been
 unlocked by the first call.

 Also restructure the error handling so that we only give up on writing
 the dirty pages in the case of ENOSPC where retrying the allocation
 won't help.  Otherwise, a transient failure, such as a kmalloc()
 failure in calling ext4_map_blocks() might cause us to give up on
 those pages, leading to a scary message in /var/log/messages plus data
 loss.

 Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
 Reviewed-by: Jan Kara <jack@suse.cz>
 Signed-off-by: Lukas Czerner <lczerner@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index dd1cc4a..1d1a068 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -2154,7 +2154,8 @@ static int mpage_map_one_extent(handle_t *handle, struct mpage_da_data *mpd)
  * guaranteed). After mapping we submit all mapped pages for IO.
  */
 static int mpage_map_and_submit_extent(handle_t *handle,
-           struct mpage_da_data *mpd)
+           struct mpage_da_data *mpd,
+           bool *give_up_on_write)
 {
  struct inode *inode = mpd->inode;
  struct ext4_map_blocks *map = &mpd->map;
@@ -2168,29 +2169,30 @@ static int mpage_map_and_submit_extent(handle_t *handle,
   if (err < 0) {
    struct super_block *sb = inode->i_sb;
 
+   if (EXT4_SB(sb)->s_mount_flags & EXT4_MF_FS_ABORTED)
+    goto invalidate_dirty_pages;
    /*
-    * Need to commit transaction to free blocks. Let upper
-    * layers sort it out.
+    * Let the uper layers retry transient errors.
+    * In the case of ENOSPC, if ext4_count_free_blocks()
+    * is non-zero, a commit should free up blocks.
     */
-   if (err == -ENOSPC && ext4_count_free_clusters(sb))
-    return -ENOSPC;
-
-   if (!(EXT4_SB(sb)->s_mount_flags & EXT4_MF_FS_ABORTED)) {
-    ext4_msg(sb, KERN_CRIT,
-      "Delayed block allocation failed for "
-      "inode %lu at logical offset %llu with"
-      " max blocks %u with error %d",
-      inode->i_ino,
-      (unsigned long long)map->m_lblk,
-      (unsigned)map->m_len, err);
-    ext4_msg(sb, KERN_CRIT,
-      "This should not happen!! Data will "
-      "be lost\n");
-    if (err == -ENOSPC)
-     ext4_print_free_blocks(inode);
-   }
-   /* invalidate all the pages */
-   mpage_release_unused_pages(mpd, true);
+   if ((err == -ENOMEM) ||
+       (err == -ENOSPC && ext4_count_free_clusters(sb)))
+    return err;
+   ext4_msg(sb, KERN_CRIT,
+     "Delayed block allocation failed for "
+     "inode %lu at logical offset %llu with"
+     " max blocks %u with error %d",
+     inode->i_ino,
+     (unsigned long long)map->m_lblk,
+     (unsigned)map->m_len, -err);
+   ext4_msg(sb, KERN_CRIT,
+     "This should not happen!! Data will "
+     "be lost\n");
+   if (err == -ENOSPC)
+    ext4_print_free_blocks(inode);
+  invalidate_dirty_pages:
+   *give_up_on_write = true;
    return err;
   }
   /*
@@ -2378,6 +2380,7 @@ static int ext4_writepages(struct address_space *mapping,
  struct ext4_sb_info *sbi = EXT4_SB(mapping->host->i_sb);
  bool done;
  struct blk_plug plug;
+ bool give_up_on_write = false;
 
  trace_ext4_writepages(inode, wbc);
 
@@ -2495,7 +2498,8 @@ retry:
   ret = mpage_prepare_extent_to_map(&mpd);
   if (!ret) {
    if (mpd.map.m_len)
-    ret = mpage_map_and_submit_extent(handle, &mpd);
+    ret = mpage_map_and_submit_extent(handle, &mpd,
+     &give_up_on_write);
    else {
     /*
      * We scanned the whole range (or exhausted
@@ -2510,7 +2514,7 @@ retry:
   /* Submit prepared bio */
   ext4_io_submit(&mpd.io_submit);
   /* Unlock pages we didn't use */
-  mpage_release_unused_pages(&mpd, false);
+  mpage_release_unused_pages(&mpd, give_up_on_write);
   /* Drop our io_end reference we got from init */
   ext4_put_io_end(mpd.io_submit.io_end);
 
-- 
1.7.1