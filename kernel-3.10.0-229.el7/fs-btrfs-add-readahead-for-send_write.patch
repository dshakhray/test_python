From 7060487674582cef1fb9ba8f6bd6470538412bdd Mon Sep 17 00:00:00 2001
From: Eric Sandeen <sandeen@redhat.com>
Date: Mon, 4 Aug 2014 19:02:09 -0400
Subject: [fs] btrfs: add readahead for send_write

Message-id: <1407179109-13714-243-git-send-email-sandeen@redhat.com>
Patchwork-id: 87146
O-Subject: [RHEL7.1 PATCH 242/422] Btrfs: add readahead for send_write
Bugzilla: 1071179
RH-Acked-by: Zach Brown <zab@redhat.com>

From: Liu Bo <bo.li.liu@oracle.com>

commit 2131bcd38b18167f499f190acf3409dfe5b3c280
Author: Liu Bo <bo.li.liu@oracle.com>
Date:   Wed Mar 5 10:07:35 2014 +0800

    Btrfs: add readahead for send_write

    Btrfs send reads data from disk and then writes to a stream via pipe or
    a file via flush.

    Currently we're going to read each page a time, so every page results
    in a disk read, which is not friendly to disks, esp. HDD.  Given that,
    the performance can be gained by adding readahead for those pages.

    Here is a quick test:
    $ btrfs subvolume create send
    $ xfs_io -f -c "pwrite 0 1G" send/foobar
    $ btrfs subvolume snap -r send ro
    $ time "btrfs send ro -f /dev/null"

               w/o             w
    real    1m37.527s       0m9.097s
    user    0m0.122s        0m0.086s
    sys     0m53.191s       0m12.857s

    Signed-off-by: Liu Bo <bo.li.liu@oracle.com>
    Reviewed-by: David Sterba <dsterba@suse.cz>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
Signed-off-by: Eric Sandeen <sandeen@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/fs/btrfs/send.c b/fs/btrfs/send.c
index 112eb64..6463691 100644
--- a/fs/btrfs/send.c
+++ b/fs/btrfs/send.c
@@ -124,6 +124,8 @@ struct send_ctx {
  struct list_head name_cache_list;
  int name_cache_size;
 
+ struct file_ra_state ra;
+
  char *read_buf;
 
  /*
@@ -4170,6 +4172,13 @@ static ssize_t fill_read_buf(struct send_ctx *sctx, u64 offset, u32 len)
   goto out;
 
  last_index = (offset + len - 1) >> PAGE_CACHE_SHIFT;
+
+ /* initial readahead */
+ memset(&sctx->ra, 0, sizeof(struct file_ra_state));
+ file_ra_state_init(&sctx->ra, inode->i_mapping);
+ btrfs_force_ra(inode->i_mapping, &sctx->ra, NULL, index,
+         last_index - index + 1);
+
  while (index <= last_index) {
   unsigned cur_len = min_t(unsigned, len,
       PAGE_CACHE_SIZE - pg_offset);
-- 
1.7.1