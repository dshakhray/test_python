From f46e16b392055ad5dfd55a3a7009242c54266c09 Mon Sep 17 00:00:00 2001
From: Don Zickus <dzickus@redhat.com>
Date: Fri, 12 Sep 2014 18:05:40 -0400
Subject: [virt] kvm/ppc: Call trace_hardirqs_on before entry

Message-id: <1410545655-205645-112-git-send-email-dzickus@redhat.com>
Patchwork-id: 94131
O-Subject: [RHEL7 PATCH 111/626] kvm/ppc: Call trace_hardirqs_on before entry
Bugzilla: 1127366
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: David Gibson <dgibson@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1127366

commit 5f1c248f52c12e155e0fe6a614178181f7629901
Author: Scott Wood <scottwood@freescale.com>
Date:   Wed Jul 10 17:47:39 2013 -0500

    kvm/ppc: Call trace_hardirqs_on before entry

    Currently this is only being done on 64-bit.  Rather than just move it
    out of the 64-bit ifdef, move it to kvm_lazy_ee_enable() so that it is
    consistent with lazy ee state, and so that we don't track more host
    code as interrupts-enabled than necessary.

    Rename kvm_lazy_ee_enable() to kvm_fix_ee_before_entry() to reflect
    that this function now has a role on 32-bit as well.

    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/include/asm/kvm_ppc.h b/arch/powerpc/include/asm/kvm_ppc.h
index 5a26bfc..b15554a 100644
--- a/arch/powerpc/include/asm/kvm_ppc.h
+++ b/arch/powerpc/include/asm/kvm_ppc.h
@@ -394,10 +394,15 @@ static inline void kvmppc_mmu_flush_icache(pfn_t pfn)
  }
 }
 
-/* Please call after prepare_to_enter. This function puts the lazy ee state
-   back to normal mode, without actually enabling interrupts. */
-static inline void kvmppc_lazy_ee_enable(void)
+/*
+ * Please call after prepare_to_enter. This function puts the lazy ee and irq
+ * disabled tracking state back to normal mode, without actually enabling
+ * interrupts.
+ */
+static inline void kvmppc_fix_ee_before_entry(void)
 {
+ trace_hardirqs_on();
+
 #ifdef CONFIG_PPC64
  /* Only need to enable IRQs by hard enabling them after this */
  local_paca->irq_happened = 0;
diff --git a/arch/powerpc/kvm/book3s_pr.c b/arch/powerpc/kvm/book3s_pr.c
index dfbe8dc..0dd6aa7 100644
--- a/arch/powerpc/kvm/book3s_pr.c
+++ b/arch/powerpc/kvm/book3s_pr.c
@@ -910,7 +910,7 @@ program_interrupt:
    local_irq_enable();
    r = s;
   } else {
-   kvmppc_lazy_ee_enable();
+   kvmppc_fix_ee_before_entry();
   }
   kvmppc_handle_lost_ext(vcpu);
  }
@@ -1179,7 +1179,7 @@ int kvmppc_vcpu_run(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
  if (vcpu->arch.shared->msr & MSR_FP)
   kvmppc_handle_ext(vcpu, BOOK3S_INTERRUPT_FP_UNAVAIL, MSR_FP);
 
- kvmppc_lazy_ee_enable();
+ kvmppc_fix_ee_before_entry();
 
  ret = __kvmppc_vcpu_run(kvm_run, vcpu);
 
diff --git a/arch/powerpc/kvm/booke.c b/arch/powerpc/kvm/booke.c
index 9318fb7..85c3c7d 100644
--- a/arch/powerpc/kvm/booke.c
+++ b/arch/powerpc/kvm/booke.c
@@ -697,7 +697,7 @@ int kvmppc_vcpu_run(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
  kvmppc_load_guest_fp(vcpu);
 #endif
 
- kvmppc_lazy_ee_enable();
+ kvmppc_fix_ee_before_entry();
 
  ret = __kvmppc_vcpu_run(kvm_run, vcpu);
 
@@ -1167,7 +1167,7 @@ int kvmppc_handle_exit(struct kvm_run *run, struct kvm_vcpu *vcpu,
    local_irq_enable();
    r = (s << 2) | RESUME_HOST | (r & RESUME_FLAG_NV);
   } else {
-   kvmppc_lazy_ee_enable();
+   kvmppc_fix_ee_before_entry();
   }
  }
 
diff --git a/arch/powerpc/kvm/powerpc.c b/arch/powerpc/kvm/powerpc.c
index ae63ae4..f55e14c 100644
--- a/arch/powerpc/kvm/powerpc.c
+++ b/arch/powerpc/kvm/powerpc.c
@@ -117,8 +117,6 @@ int kvmppc_prepare_to_enter(struct kvm_vcpu *vcpu)
    kvm_guest_exit();
    continue;
   }
-
-  trace_hardirqs_on();
 #endif
 
   kvm_guest_enter();
-- 
1.7.1