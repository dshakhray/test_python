From 6af691ca80d07a3ba27910f7f40d66a1ac640cb6 Mon Sep 17 00:00:00 2001
From: Andrea Arcangeli <aarcange@redhat.com>
Date: Tue, 9 Sep 2014 01:16:37 -0400
Subject: [mm] page_alloc: convert hot/cold parameter and immediate callers to bool

Message-id: <1410225399-8094-21-git-send-email-aarcange@redhat.com>
Patchwork-id: 93372
O-Subject: [RHEL7.1 PATCH 20/22] mm: page_alloc: convert hot/cold parameter and immediate callers to bool
Bugzilla: 1135506
RH-Acked-by: Rik van Riel <riel@redhat.com>
RH-Acked-by: Larry Woodman <lwoodman@redhat.com>
RH-Acked-by: Rafael Aquini <aquini@redhat.com>

From: Mel Gorman <mgorman@suse.de>

cold is a bool, make it one.  Make the likely case the "if" part of the
block instead of the else as according to the optimisation manual this is
preferred.

Signed-off-by: Mel Gorman <mgorman@suse.de>
Acked-by: Rik van Riel <riel@redhat.com>
Cc: Johannes Weiner <hannes@cmpxchg.org>
Cc: Vlastimil Babka <vbabka@suse.cz>
Cc: Jan Kara <jack@suse.cz>
Cc: Michal Hocko <mhocko@suse.cz>
Cc: Hugh Dickins <hughd@google.com>
Cc: Dave Hansen <dave.hansen@intel.com>
Cc: Theodore Ts'o <tytso@mit.edu>
Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
Cc: Oleg Nesterov <oleg@redhat.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Andrea Arcangeli <aarcange@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/tile/mm/homecache.c b/arch/tile/mm/homecache.c
index 1ae9119..eacb91b 100644
--- a/arch/tile/mm/homecache.c
+++ b/arch/tile/mm/homecache.c
@@ -438,7 +438,7 @@ void __homecache_free_pages(struct page *page, unsigned int order)
  if (put_page_testzero(page)) {
   homecache_change_page_home(page, order, initial_page_home());
   if (order == 0) {
-   free_hot_cold_page(page, 0);
+   free_hot_cold_page(page, false);
   } else {
    init_page_count(page);
    __free_pages(page, order);
diff --git a/fs/fuse/dev.c b/fs/fuse/dev.c
index 1d55f94..e5326f1 100644
--- a/fs/fuse/dev.c
+++ b/fs/fuse/dev.c
@@ -1625,7 +1625,7 @@ out_finish:
 
 static void fuse_retrieve_end(struct fuse_conn *fc, struct fuse_req *req)
 {
- release_pages(req->pages, req->num_pages, 0);
+ release_pages(req->pages, req->num_pages, false);
 }
 
 static int fuse_retrieve(struct fuse_conn *fc, struct inode *inode,
diff --git a/include/linux/gfp.h b/include/linux/gfp.h
index d660c8e..07dd33b 100644
--- a/include/linux/gfp.h
+++ b/include/linux/gfp.h
@@ -369,8 +369,8 @@ void *alloc_pages_exact_nid(int nid, size_t size, gfp_t gfp_mask);
 
 extern void __free_pages(struct page *page, unsigned int order);
 extern void free_pages(unsigned long addr, unsigned int order);
-extern void free_hot_cold_page(struct page *page, int cold);
-extern void free_hot_cold_page_list(struct list_head *list, int cold);
+extern void free_hot_cold_page(struct page *page, bool cold);
+extern void free_hot_cold_page_list(struct list_head *list, bool cold);
 
 extern void __free_memcg_kmem_pages(struct page *page, unsigned int order);
 extern void free_memcg_kmem_pages(unsigned long addr, unsigned int order);
diff --git a/include/linux/pagemap.h b/include/linux/pagemap.h
index e772973..5c0d280 100644
--- a/include/linux/pagemap.h
+++ b/include/linux/pagemap.h
@@ -110,7 +110,7 @@ static inline void mapping_set_gfp_mask(struct address_space *m, gfp_t mask)
 
 #define page_cache_get(page)  get_page(page)
 #define page_cache_release(page) put_page(page)
-void release_pages(struct page **pages, int nr, int cold);
+void release_pages(struct page **pages, int nr, bool cold);
 
 /*
  * speculatively take a reference to a page.
diff --git a/include/linux/swap.h b/include/linux/swap.h
index 248897d..3c2b901 100644
--- a/include/linux/swap.h
+++ b/include/linux/swap.h
@@ -463,7 +463,7 @@ mem_cgroup_uncharge_swapcache(struct page *page, swp_entry_t ent, bool swapout)
 #define free_page_and_swap_cache(page) \
  page_cache_release(page)
 #define free_pages_and_swap_cache(pages, nr) \
- release_pages((pages), (nr), 0);
+ release_pages((pages), (nr), false);
 
 static inline void show_swap_cache_info(void)
 {
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 4c9d212..471c261 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1156,7 +1156,7 @@ retry_reserve:
  */
 static int rmqueue_bulk(struct zone *zone, unsigned int order,
    unsigned long count, struct list_head *list,
-   int migratetype, int cold)
+   int migratetype, bool cold)
 {
  int mt = migratetype, i;
 
@@ -1175,7 +1175,7 @@ static int rmqueue_bulk(struct zone *zone, unsigned int order,
    * merge IO requests if the physical pages are ordered
    * properly.
    */
-  if (likely(cold == 0))
+  if (likely(!cold))
    list_add(&page->lru, list);
   else
    list_add_tail(&page->lru, list);
@@ -1340,9 +1340,9 @@ void mark_free_pages(struct zone *zone)
 
 /*
  * Free a 0-order page
- * cold == 1 ? free a cold page : free a hot page
+ * cold == true ? free a cold page : free a hot page
  */
-void free_hot_cold_page(struct page *page, int cold)
+void free_hot_cold_page(struct page *page, bool cold)
 {
  struct zone *zone = page_zone(page);
  struct per_cpu_pages *pcp;
@@ -1373,10 +1373,10 @@ void free_hot_cold_page(struct page *page, int cold)
  }
 
  pcp = &this_cpu_ptr(zone->pageset)->pcp;
- if (cold)
-  list_add_tail(&page->lru, &pcp->lists[migratetype]);
- else
+ if (!cold)
   list_add(&page->lru, &pcp->lists[migratetype]);
+ else
+  list_add_tail(&page->lru, &pcp->lists[migratetype]);
  pcp->count++;
  if (pcp->count >= pcp->high) {
   free_pcppages_bulk(zone, pcp->batch, pcp);
@@ -1390,7 +1390,7 @@ out:
 /*
  * Free a list of 0-order pages
  */
-void free_hot_cold_page_list(struct list_head *list, int cold)
+void free_hot_cold_page_list(struct list_head *list, bool cold)
 {
  struct page *page, *next;
 
@@ -1507,7 +1507,7 @@ struct page *buffered_rmqueue(struct zone *preferred_zone,
 {
  unsigned long flags;
  struct page *page;
- int cold = !!(gfp_flags & __GFP_COLD);
+ bool cold = ((gfp_flags & __GFP_COLD) != 0);
 
 again:
  if (likely(order == 0)) {
@@ -2788,7 +2788,7 @@ void __free_pages(struct page *page, unsigned int order)
 {
  if (put_page_testzero(page)) {
   if (order == 0)
-   free_hot_cold_page(page, 0);
+   free_hot_cold_page(page, false);
   else
    __free_pages_ok(page, order);
  }
diff --git a/mm/swap.c b/mm/swap.c
index be34809..b4d20d2 100644
--- a/mm/swap.c
+++ b/mm/swap.c
@@ -67,7 +67,7 @@ static void __page_cache_release(struct page *page)
 static void __put_single_page(struct page *page)
 {
  __page_cache_release(page);
- free_hot_cold_page(page, 0);
+ free_hot_cold_page(page, false);
 }
 
 static void __put_compound_page(struct page *page)
@@ -845,7 +845,7 @@ void lru_add_drain_all(void)
  * grabbed the page via the LRU.  If it did, give up: shrink_inactive_list()
  * will free it.
  */
-void release_pages(struct page **pages, int nr, int cold)
+void release_pages(struct page **pages, int nr, bool cold)
 {
  int i;
  LIST_HEAD(pages_to_free);
diff --git a/mm/swap_state.c b/mm/swap_state.c
index 98e85e9..5b75033 100644
--- a/mm/swap_state.c
+++ b/mm/swap_state.c
@@ -268,7 +268,7 @@ void free_pages_and_swap_cache(struct page **pages, int nr)
 
   for (i = 0; i < todo; i++)
    free_swap_cache(pagep[i]);
-  release_pages(pagep, todo, 0);
+  release_pages(pagep, todo, false);
   pagep += todo;
   nr -= todo;
  }
diff --git a/mm/vmscan.c b/mm/vmscan.c
index dde7105..b6e677b 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -1068,7 +1068,7 @@ keep:
   VM_BUG_ON_PAGE(PageLRU(page) || PageUnevictable(page), page);
  }
 
- free_hot_cold_page_list(&free_pages, 1);
+ free_hot_cold_page_list(&free_pages, true);
 
  list_splice(&ret_pages, page_list);
  count_vm_events(PGACTIVATE, pgactivate);
@@ -1466,7 +1466,7 @@ shrink_inactive_list(unsigned long nr_to_scan, struct lruvec *lruvec,
 
  spin_unlock_irq(&zone->lru_lock);
 
- free_hot_cold_page_list(&page_list, 1);
+ free_hot_cold_page_list(&page_list, true);
 
  /*
   * If reclaim is isolating dirty pages under writeback, it implies
@@ -1687,7 +1687,7 @@ static void shrink_active_list(unsigned long nr_to_scan,
  __mod_zone_page_state(zone, NR_ISOLATED_ANON + file, -nr_taken);
  spin_unlock_irq(&zone->lru_lock);
 
- free_hot_cold_page_list(&l_hold, 1);
+ free_hot_cold_page_list(&l_hold, true);
 }
 
 #ifdef CONFIG_SWAP
-- 
1.7.1