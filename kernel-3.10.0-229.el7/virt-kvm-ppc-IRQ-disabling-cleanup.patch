From 3d0eafea040faae99d2c8641b77ecb9a1321c297 Mon Sep 17 00:00:00 2001
From: David Gibson <dgibson@redhat.com>
Date: Mon, 15 Sep 2014 07:12:53 -0400
Subject: [virt] kvm/ppc: IRQ disabling cleanup

Message-id: <1410765214-16377-38-git-send-email-dgibson@redhat.com>
Patchwork-id: 94744
O-Subject: [PATCH 37/78] kvm/ppc: IRQ disabling cleanup
Bugzilla: 1123145 1123133 1123367
RH-Acked-by: Radim Krcmar <rkrcmar@redhat.com>
RH-Acked-by: Don Zickus <dzickus@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1123145

Signed-off-by: David Gibson <dgibson@redhat.com>

commit 6c85f52b10fd60e45c6e30c5b85d116406bd3c9b
Author: Scott Wood <scottwood@freescale.com>
Date:   Thu Jan 9 19:18:40 2014 -0600

    kvm/ppc: IRQ disabling cleanup

    Simplify the handling of lazy EE by going directly from fully-enabled
    to hard-disabled.  This replaces the lazy_irq_pending() check
    (including its misplaced kvm_guest_exit() call).

    As suggested by Tiejun Chen, move the interrupt disabling into
    kvmppc_prepare_to_enter() rather than have each caller do it.  Also
    move the IRQ enabling on heavyweight exit into
    kvmppc_prepare_to_enter().

    Signed-off-by: Scott Wood <scottwood@freescale.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/include/asm/kvm_ppc.h b/arch/powerpc/include/asm/kvm_ppc.h
index b12f79f..e2fd5a1 100644
--- a/arch/powerpc/include/asm/kvm_ppc.h
+++ b/arch/powerpc/include/asm/kvm_ppc.h
@@ -543,6 +543,12 @@ static inline void kvmppc_fix_ee_before_entry(void)
  trace_hardirqs_on();
 
 #ifdef CONFIG_PPC64
+ /*
+  * To avoid races, the caller must have gone directly from having
+  * interrupts fully-enabled to hard-disabled.
+  */
+ WARN_ON(local_paca->irq_happened != PACA_IRQ_HARD_DIS);
+
  /* Only need to enable IRQs by hard enabling them after this */
  local_paca->irq_happened = 0;
  local_paca->soft_enabled = 1;
diff --git a/arch/powerpc/kvm/book3s_pr.c b/arch/powerpc/kvm/book3s_pr.c
index 4cb2528..8b0c384 100644
--- a/arch/powerpc/kvm/book3s_pr.c
+++ b/arch/powerpc/kvm/book3s_pr.c
@@ -1013,14 +1013,14 @@ program_interrupt:
    * and if we really did time things so badly, then we just exit
    * again due to a host external interrupt.
    */
-  local_irq_disable();
   s = kvmppc_prepare_to_enter(vcpu);
-  if (s <= 0) {
-   local_irq_enable();
+  if (s <= 0)
    r = s;
-  } else {
+  else {
+   /* interrupts now hard-disabled */
    kvmppc_fix_ee_before_entry();
   }
+
   kvmppc_handle_lost_ext(vcpu);
  }
 
@@ -1239,12 +1239,10 @@ static int kvmppc_vcpu_run_pr(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
   * really did time things so badly, then we just exit again due to
   * a host external interrupt.
   */
- local_irq_disable();
  ret = kvmppc_prepare_to_enter(vcpu);
- if (ret <= 0) {
-  local_irq_enable();
+ if (ret <= 0)
   goto out;
- }
+ /* interrupts now hard-disabled */
 
  /* Save FPU state in thread_struct */
  if (current->thread.regs->msr & MSR_FP)
diff --git a/arch/powerpc/kvm/booke.c b/arch/powerpc/kvm/booke.c
index 4e57c4c..b1424f6 100644
--- a/arch/powerpc/kvm/booke.c
+++ b/arch/powerpc/kvm/booke.c
@@ -617,7 +617,7 @@ int kvmppc_core_prepare_to_enter(struct kvm_vcpu *vcpu)
   local_irq_enable();
   kvm_vcpu_block(vcpu);
   clear_bit(KVM_REQ_UNHALT, &vcpu->requests);
-  local_irq_disable();
+  hard_irq_disable();
 
   kvmppc_set_exit_type(vcpu, EMULATED_MTMSRWE_EXITS);
   r = 1;
@@ -661,13 +661,12 @@ int kvmppc_vcpu_run(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
   return -EINVAL;
  }
 
- local_irq_disable();
  s = kvmppc_prepare_to_enter(vcpu);
  if (s <= 0) {
-  local_irq_enable();
   ret = s;
   goto out;
  }
+ /* interrupts now hard-disabled */
 
  kvm_guest_enter();
 
@@ -1141,12 +1140,11 @@ int kvmppc_handle_exit(struct kvm_run *run, struct kvm_vcpu *vcpu,
   * aren't already exiting to userspace for some other reason.
   */
  if (!(r & RESUME_HOST)) {
-  local_irq_disable();
   s = kvmppc_prepare_to_enter(vcpu);
-  if (s <= 0) {
-   local_irq_enable();
+  if (s <= 0)
    r = (s << 2) | RESUME_HOST | (r & RESUME_FLAG_NV);
-  } else {
+  else {
+   /* interrupts now hard-disabled */
    kvmppc_fix_ee_before_entry();
   }
  }
diff --git a/arch/powerpc/kvm/powerpc.c b/arch/powerpc/kvm/powerpc.c
index d3883ff..b85d412 100644
--- a/arch/powerpc/kvm/powerpc.c
+++ b/arch/powerpc/kvm/powerpc.c
@@ -68,14 +68,16 @@ int kvm_arch_vcpu_should_kick(struct kvm_vcpu *vcpu)
  */
 int kvmppc_prepare_to_enter(struct kvm_vcpu *vcpu)
 {
- int r = 1;
+ int r;
+
+ WARN_ON(irqs_disabled());
+ hard_irq_disable();
 
- WARN_ON_ONCE(!irqs_disabled());
  while (true) {
   if (need_resched()) {
    local_irq_enable();
    cond_resched();
-   local_irq_disable();
+   hard_irq_disable();
    continue;
   }
 
@@ -101,7 +103,7 @@ int kvmppc_prepare_to_enter(struct kvm_vcpu *vcpu)
    local_irq_enable();
    trace_kvm_check_requests(vcpu);
    r = kvmppc_core_check_requests(vcpu);
-   local_irq_disable();
+   hard_irq_disable();
    if (r > 0)
     continue;
    break;
@@ -113,22 +115,12 @@ int kvmppc_prepare_to_enter(struct kvm_vcpu *vcpu)
    continue;
   }
 
-#ifdef CONFIG_PPC64
-  /* lazy EE magic */
-  hard_irq_disable();
-  if (lazy_irq_pending()) {
-   /* Got an interrupt in between, try again */
-   local_irq_enable();
-   local_irq_disable();
-   kvm_guest_exit();
-   continue;
-  }
-#endif
-
   kvm_guest_enter();
-  break;
+  return 1;
  }
 
+ /* return to host */
+ local_irq_enable();
  return r;
 }
 EXPORT_SYMBOL_GPL(kvmppc_prepare_to_enter);
-- 
1.7.1