From d06b51ada4843aee05b36ff708a364bea4a728c4 Mon Sep 17 00:00:00 2001
From: Paolo Bonzini <pbonzini@redhat.com>
Date: Tue, 22 Jul 2014 14:39:43 -0400
Subject: [virt] kvm/x86: Fix CR3 reserved bits

Message-id: <1406040016-3289-189-git-send-email-pbonzini@redhat.com>
Patchwork-id: 86267
O-Subject: [RHEL7 PATCH v2 188/221] KVM: x86: Fix CR3 reserved bits
Bugzilla: 1116936
RH-Acked-by: Radim Krcmar <rkrcmar@redhat.com>
RH-Acked-by: Bandan Das <bsd@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>

From: Nadav Amit <namit@cs.technion.ac.il>

According to Intel specifications, PAE and non-PAE does not have any reserved
bits.  In long-mode, regardless to PCIDE, only the high bits (above the
physical address) are reserved.

Signed-off-by: Nadav Amit <namit@cs.technion.ac.il>
Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
(cherry picked from commit 346874c9507a2582d0c00021f848de6e115f276c)
Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 7de069a..e21aee9 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -50,11 +50,7 @@
      | X86_CR0_ET | X86_CR0_NE | X86_CR0_WP | X86_CR0_AM \
      | X86_CR0_NW | X86_CR0_CD | X86_CR0_PG))
 
-#define CR3_PAE_RESERVED_BITS ((X86_CR3_PWT | X86_CR3_PCD) - 1)
-#define CR3_NONPAE_RESERVED_BITS ((PAGE_SIZE-1) & ~(X86_CR3_PWT | X86_CR3_PCD))
-#define CR3_PCID_ENABLED_RESERVED_BITS 0xFFFFFF0000000000ULL
-#define CR3_L_MODE_RESERVED_BITS (CR3_NONPAE_RESERVED_BITS | \
-      0xFFFFFF0000000000ULL)
+#define CR3_L_MODE_RESERVED_BITS 0xFFFFFF0000000000ULL
 #define CR4_RESERVED_BITS                                               \
  (~(unsigned long)(X86_CR4_VME | X86_CR4_PVI | X86_CR4_TSD | X86_CR4_DE\
      | X86_CR4_PSE | X86_CR4_PAE | X86_CR4_MCE     \
diff --git a/arch/x86/kvm/emulate.c b/arch/x86/kvm/emulate.c
index 0dec502..f3834bb 100644
--- a/arch/x86/kvm/emulate.c
+++ b/arch/x86/kvm/emulate.c
@@ -3388,10 +3388,6 @@ static int check_cr_write(struct x86_emulate_ctxt *ctxt)
   ctxt->ops->get_msr(ctxt, MSR_EFER, &efer);
   if (efer & EFER_LMA)
    rsvd = CR3_L_MODE_RESERVED_BITS;
-  else if (ctxt->ops->get_cr(ctxt, 4) & X86_CR4_PAE)
-   rsvd = CR3_PAE_RESERVED_BITS;
-  else if (ctxt->ops->get_cr(ctxt, 0) & X86_CR0_PG)
-   rsvd = CR3_NONPAE_RESERVED_BITS;
 
   if (new_val & rsvd)
    return emulate_gp(ctxt, 0);
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index fbb43fc..5b9a4f9 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -703,26 +703,11 @@ int kvm_set_cr3(struct kvm_vcpu *vcpu, unsigned long cr3)
   return 0;
  }
 
- if (is_long_mode(vcpu)) {
-  if (kvm_read_cr4_bits(vcpu, X86_CR4_PCIDE)) {
-   if (cr3 & CR3_PCID_ENABLED_RESERVED_BITS)
-    return 1;
-  } else
-   if (cr3 & CR3_L_MODE_RESERVED_BITS)
-    return 1;
- } else {
-  if (is_pae(vcpu)) {
-   if (cr3 & CR3_PAE_RESERVED_BITS)
-    return 1;
-   if (is_paging(vcpu) &&
-       !load_pdptrs(vcpu, vcpu->arch.walk_mmu, cr3))
-    return 1;
-  }
-  /*
-   * We don't check reserved bits in nonpae mode, because
-   * this isn't enforced, and VMware depends on this.
-   */
- }
+ if (is_long_mode(vcpu) && (cr3 & CR3_L_MODE_RESERVED_BITS))
+  return 1;
+ if (is_pae(vcpu) && is_paging(vcpu) &&
+     !load_pdptrs(vcpu, vcpu->arch.walk_mmu, cr3))
+  return 1;
 
  vcpu->arch.cr3 = cr3;
  __set_bit(VCPU_EXREG_CR3, (ulong *)&vcpu->arch.regs_avail);
-- 
1.7.1