From c52edd76d966243e74d6e35354487b6da56e5ff1 Mon Sep 17 00:00:00 2001
From: Don Zickus <dzickus@redhat.com>
Date: Fri, 12 Sep 2014 18:08:03 -0400
Subject: [powerpc] add barrier after writing kernel PTE

Message-id: <1410545655-205645-255-git-send-email-dzickus@redhat.com>
Patchwork-id: 94211
O-Subject: [RHEL7 PATCH 254/626] powerpc: add barrier after writing kernel PTE
Bugzilla: 1127366
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: David Gibson <dgibson@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1127366

commit 47ce8af4209f4344f152aa6fc538efe9d6bdfd1a
Author: Scott Wood <scottwood@freescale.com>
Date:   Fri Oct 11 19:22:37 2013 -0500

    powerpc: add barrier after writing kernel PTE

    There is no barrier between something like ioremap() writing to
    a PTE, and returning the value to a caller that may then store the
    pointer in a place that is visible to other CPUs.  Such callers
    generally don't perform barriers of their own.

    Even if callers of ioremap() and similar things did use barriers,
    the most logical choise would be smp_wmb(), which is not
    architecturally sufficient when BookE hardware tablewalk is used.  A
    full sync is specified by the architecture.

    For userspace mappings, OTOH, we generally already have an lwsync due
    to locking, and if we occasionally take a spurious fault due to not
    having a full sync with hardware tablewalk, it will not be fatal
    because we will retry rather than oops.

    Signed-off-by: Scott Wood <scottwood@freescale.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/mm/pgtable_32.c b/arch/powerpc/mm/pgtable_32.c
index 5b96017..343a87f 100644
--- a/arch/powerpc/mm/pgtable_32.c
+++ b/arch/powerpc/mm/pgtable_32.c
@@ -299,6 +299,7 @@ int map_page(unsigned long va, phys_addr_t pa, int flags)
   set_pte_at(&init_mm, va, pg, pfn_pte(pa >> PAGE_SHIFT,
            __pgprot(flags)));
  }
+ smp_wmb();
  return err;
 }
 
diff --git a/arch/powerpc/mm/pgtable_64.c b/arch/powerpc/mm/pgtable_64.c
index dc19b49..8a676cb 100644
--- a/arch/powerpc/mm/pgtable_64.c
+++ b/arch/powerpc/mm/pgtable_64.c
@@ -153,6 +153,18 @@ int map_kernel_page(unsigned long ea, unsigned long pa, int flags)
   }
 #endif /* !CONFIG_PPC_MMU_NOHASH */
  }
+
+#ifdef CONFIG_PPC_BOOK3E_64
+ /*
+  * With hardware tablewalk, a sync is needed to ensure that
+  * subsequent accesses see the PTE we just wrote.  Unlike userspace
+  * mappings, we can't tolerate spurious faults, so make sure
+  * the new PTE will be seen the first time.
+  */
+ mb();
+#else
+ smp_wmb();
+#endif
  return 0;
 }
 
-- 
1.7.1