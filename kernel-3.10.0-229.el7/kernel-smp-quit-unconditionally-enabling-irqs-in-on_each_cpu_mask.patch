From 88d24ee825eade9cbc20149e03421f5cb09553a4 Mon Sep 17 00:00:00 2001
From: Prarit Bhargava <prarit@redhat.com>
Date: Wed, 11 Jun 2014 11:53:04 -0400
Subject: [kernel] smp: quit unconditionally enabling irqs in on_each_cpu_mask()

Message-id: <1402487594-26332-5-git-send-email-prarit@redhat.com>
Patchwork-id: 83636
O-Subject: [RHEL7.1 PATCH BZ 1105192 04/14] kernel/smp.c: quit unconditionally enabling irqs in on_each_cpu_mask().
Bugzilla: 1105192
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: Neil Horman <nhorman@redhat.com>

commit 202da400570d991bacda4a06e878cb901e96a783
Author: David Daney <david.daney@cavium.com>
Date:   Wed Sep 11 14:23:29 2013 -0700

    kernel/smp.c: quit unconditionally enabling irqs in on_each_cpu_mask().

    As in commit f21afc25f9ed ("smp.h: Use local_irq_{save,restore}() in
    !SMP version of on_each_cpu()"), we don't want to enable irqs if they
    are not already enabled.

    I don't know of any bugs currently caused by this unconditional
    local_irq_enable(), but I want to use this function in MIPS/OCTEON early
    boot (when we have early_boot_irqs_disabled).  This also makes this
    function have similar semantics to on_each_cpu() which is good in
    itself.

    Signed-off-by: David Daney <david.daney@cavium.com>
    Cc: Gilad Ben-Yossef <gilad@benyossef.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Chris Metcalf <cmetcalf@tilera.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/kernel/smp.c b/kernel/smp.c
index df0e765..069d20b 100644
--- a/kernel/smp.c
+++ b/kernel/smp.c
@@ -580,8 +580,10 @@ EXPORT_SYMBOL(on_each_cpu);
  *
  * If @wait is true, then returns once @func has returned.
  *
- * You must not call this function with disabled interrupts or
- * from a hardware interrupt handler or from a bottom half handler.
+ * You must not call this function with disabled interrupts or from a
+ * hardware interrupt handler or from a bottom half handler.  The
+ * exception is that it may be used during early boot while
+ * early_boot_irqs_disabled is set.
  */
 void on_each_cpu_mask(const struct cpumask *mask, smp_call_func_t func,
    void *info, bool wait)
@@ -590,9 +592,10 @@ void on_each_cpu_mask(const struct cpumask *mask, smp_call_func_t func,
 
  smp_call_function_many(mask, func, info, wait);
  if (cpumask_test_cpu(cpu, mask)) {
-  local_irq_disable();
+  unsigned long flags;
+  local_irq_save(flags);
   func(info);
-  local_irq_enable();
+  local_irq_restore(flags);
  }
  put_cpu();
 }
-- 
1.7.1