From 3bcba0c625730bc72f4e888e74fb8aa9ca5aec69 Mon Sep 17 00:00:00 2001
From: Jiri Pirko <jpirko@redhat.com>
Date: Wed, 27 Aug 2014 14:32:23 -0400
Subject: [net] tcp: tsq: fix nonagle handling

Message-id: <1409149943-20384-1-git-send-email-jpirko@redhat.com>
Patchwork-id: 89265
O-Subject: [patch rhel7 net] tcp: tsq: fix nonagle handling
Bugzilla: 1134402
RH-Acked-by: Hannes Frederic Sowa <hannes@redhat.com>
RH-Acked-by: David S. Miller <davem@redhat.com>
RH-Acked-by: Vlad Yasevich <vyasevic@redhat.com>
RH-Acked-by: Nikolay Aleksandrov <nikolay@redhat.com>
RH-Acked-by: Daniel Borkmann <dborkman@redhat.com>

BZ1134402
https://brewweb.devel.redhat.com/taskinfo?taskID=7886191

upstream commit bf06200e732de613a1277984bf34d1a21c2de03d
Author: John Ogness <john.ogness@linutronix.de>
Date:   Sun Feb 9 18:40:11 2014 -0800

    tcp: tsq: fix nonagle handling

    Commit 46d3ceabd8d9 ("tcp: TCP Small Queues") introduced a possible
    regression for applications using TCP_NODELAY.

    If TCP session is throttled because of tsq, we should consult
    tp->nonagle when TX completion is done and allow us to send additional
    segment, especially if this segment is not a full MSS.
    Otherwise this segment is sent after an RTO.

    [edumazet] : Cooked the changelog, added another fix about testing
    sk_wmem_alloc twice because TX completion can happen right before
    setting TSQ_THROTTLED bit.

    This problem is particularly visible with recent auto corking,
    but might also be triggered with low tcp_limit_output_bytes
    values or NIC drivers delaying TX completion by hundred of usec,
    and very low rtt.

    Thomas Glanzmann for example reported an iscsi regression, caused
    by tcp auto corking making this bug quite visible.

Signed-off-by: Jiri Pirko <jpirko@redhat.com>
Signed-off-by: Jiri Benc <jbenc@redhat.com>
Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/net/ipv4/tcp_output.c b/net/ipv4/tcp_output.c
index 145a4df..497a4fc 100644
--- a/net/ipv4/tcp_output.c
+++ b/net/ipv4/tcp_output.c
@@ -688,7 +688,8 @@ static void tcp_tsq_handler(struct sock *sk)
  if ((1 << sk->sk_state) &
      (TCPF_ESTABLISHED | TCPF_FIN_WAIT1 | TCPF_CLOSING |
       TCPF_CLOSE_WAIT  | TCPF_LAST_ACK))
-  tcp_write_xmit(sk, tcp_current_mss(sk), 0, 0, GFP_ATOMIC);
+  tcp_write_xmit(sk, tcp_current_mss(sk), tcp_sk(sk)->nonagle,
+          0, GFP_ATOMIC);
 }
 /*
  * One tasklest per cpu tries to send more skbs.
@@ -1877,7 +1878,15 @@ static bool tcp_write_xmit(struct sock *sk, unsigned int mss_now, int nonagle,
 
   if (atomic_read(&sk->sk_wmem_alloc) > limit) {
    set_bit(TSQ_THROTTLED, &tp->tsq_flags);
-   break;
+   /* It is possible TX completion already happened
+    * before we set TSQ_THROTTLED, so we must
+    * test again the condition.
+    * We abuse smp_mb__after_clear_bit() because
+    * there is no smp_mb__after_set_bit() yet
+    */
+   smp_mb__after_clear_bit();
+   if (atomic_read(&sk->sk_wmem_alloc) > limit)
+    break;
   }
 
   limit = mss_now;
-- 
1.7.1