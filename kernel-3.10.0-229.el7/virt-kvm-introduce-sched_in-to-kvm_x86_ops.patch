From 42443b79f5ce21b5e1b03de99b9278cc75772cd4 Mon Sep 17 00:00:00 2001
From: Radim Krcmar <rkrcmar@redhat.com>
Date: Wed, 12 Nov 2014 16:31:59 -0500
Subject: [virt] kvm: introduce sched_in to kvm_x86_ops

Message-id: <1415809922-10128-3-git-send-email-rkrcmar@redhat.com>
Patchwork-id: 99846
O-Subject: [RHEL7.1 kernel PATCH 2/5] KVM: x86: introduce sched_in to kvm_x86_ops
Bugzilla: 1163296
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: Andrew Jones <drjones@redhat.com>
RH-Acked-by: Paolo Bonzini <pbonzini@redhat.com>

sched_in preempt notifier is available for x86, allow its use in
specific virtualization technlogies as well.

Signed-off-by: Radim Krcmar <rkrcmar@redhat.com>
Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit ae97a3b818324b92b5b9cc885c63c3f4bd46ee9d)
Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index e8a3030..06a8c9a 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -770,6 +770,8 @@ struct kvm_x86_ops {
  bool (*mpx_supported)(void);
 
  int (*check_nested_events)(struct kvm_vcpu *vcpu, bool external_intr);
+
+ void (*sched_in)(struct kvm_vcpu *kvm, int cpu);
 };
 
 struct kvm_arch_async_pf {
diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c
index cc0f927..5a61888 100644
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@ -4299,6 +4299,10 @@ static void svm_handle_external_intr(struct kvm_vcpu *vcpu)
  local_irq_enable();
 }
 
+static void svm_sched_in(struct kvm_vcpu *vcpu, int cpu)
+{
+}
+
 static struct kvm_x86_ops svm_x86_ops = {
  .cpu_has_kvm_support = has_svm,
  .disabled_by_bios = is_disabled,
@@ -4400,6 +4404,8 @@ static struct kvm_x86_ops svm_x86_ops = {
 
  .check_intercept = svm_check_intercept,
  .handle_external_intr = svm_handle_external_intr,
+
+ .sched_in = svm_sched_in,
 };
 
 static int __init svm_init(void)
diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c
index ebee3f4..62a19bb 100644
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@ -8821,6 +8821,10 @@ static int vmx_check_intercept(struct kvm_vcpu *vcpu,
  return X86EMUL_CONTINUE;
 }
 
+void vmx_sched_in(struct kvm_vcpu *vcpu, int cpu)
+{
+}
+
 static struct kvm_x86_ops vmx_x86_ops = {
  .cpu_has_kvm_support = cpu_has_kvm_support,
  .disabled_by_bios = vmx_disabled_by_bios,
@@ -8927,6 +8931,8 @@ static struct kvm_x86_ops vmx_x86_ops = {
  .mpx_supported = vmx_mpx_supported,
 
  .check_nested_events = vmx_check_nested_events,
+
+ .sched_in = vmx_sched_in,
 };
 
 static int __init vmx_init(void)
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 793ffab..a518ce5 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -7128,6 +7128,7 @@ void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu)
 
 void kvm_arch_sched_in(struct kvm_vcpu *vcpu, int cpu)
 {
+ kvm_x86_ops->sched_in(vcpu, cpu);
 }
 
 int kvm_arch_init_vm(struct kvm *kvm, unsigned long type)
-- 
1.7.1