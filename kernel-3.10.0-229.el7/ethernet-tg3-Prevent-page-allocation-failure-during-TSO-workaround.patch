From 0eb289e420b2d82f11ddfccbf00bdc7e0ba69696 Mon Sep 17 00:00:00 2001
From: Ivan Vecera <ivecera@redhat.com>
Date: Mon, 8 Sep 2014 12:26:06 -0400
Subject: [ethernet] tg3: Prevent page allocation failure during TSO workaround

Message-id: <1410179173-14304-13-git-send-email-ivecera@redhat.com>
Patchwork-id: 91675
O-Subject: [RHEL7.1 PATCH 12/19] tg3: Prevent page allocation failure during TSO workaround
Bugzilla: 1088637
RH-Acked-by: John Linville <linville@redhat.com>
RH-Acked-by: Nikolay Aleksandrov <nikolay@redhat.com>
RH-Acked-by: Stefan Assmann <sassmann@redhat.com>

BZ: #1088637

Upstream commit(s):
commit d3f6f3a1d818410c17445bce4f4caab52eb102f1
Author: Michael Chan <mchan@broadcom.com>
Date:   Sun May 11 20:22:54 2014 -0700

    tg3: Prevent page allocation failure during TSO workaround

    If any TSO fragment hits hardware bug conditions (e.g. 4G boundary), the
    driver will workaround by calling skb_copy() to copy to a linear SKB.  Users
    have reported page allocation failures as the TSO packet can be up to 64K.
    Copying such a large packet is also very inefficient.  We fix this by using
    existing tg3_tso_bug() to transmit the packet using GSO.

    Signed-off-by: Prashant Sreedharan <prashant@broadcom.com>
    Signed-off-by: Michael Chan <mchan@broadcom.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

Signed-off-by: Ivan Vecera <ivecera@redhat.com>
Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/drivers/net/ethernet/broadcom/tg3.c b/drivers/net/ethernet/broadcom/tg3.c
index 623ba82..1b13c2b 100644
--- a/drivers/net/ethernet/broadcom/tg3.c
+++ b/drivers/net/ethernet/broadcom/tg3.c
@@ -7881,6 +7881,10 @@ static netdev_tx_t tg3_start_xmit(struct sk_buff *skb, struct net_device *dev)
  struct tg3_napi *tnapi;
  struct netdev_queue *txq;
  unsigned int last;
+ struct iphdr *iph = NULL;
+ struct tcphdr *tcph = NULL;
+ __sum16 tcp_csum = 0, ip_csum = 0;
+ __be16 ip_tot_len = 0;
 
  txq = netdev_get_tx_queue(dev, skb_get_queue_mapping(skb));
  tnapi = &tp->napi[skb_get_queue_mapping(skb)];
@@ -7912,7 +7916,6 @@ static netdev_tx_t tg3_start_xmit(struct sk_buff *skb, struct net_device *dev)
 
  mss = skb_shinfo(skb)->gso_size;
  if (mss) {
-  struct iphdr *iph;
   u32 tcp_opt_len, hdr_len;
 
   if (skb_cow_head(skb, 0))
@@ -7928,6 +7931,8 @@ static netdev_tx_t tg3_start_xmit(struct sk_buff *skb, struct net_device *dev)
        tg3_flag(tp, TSO_BUG))
     return tg3_tso_bug(tp, skb);
 
+   ip_csum = iph->check;
+   ip_tot_len = iph->tot_len;
    iph->check = 0;
    iph->tot_len = htons(mss + hdr_len);
   }
@@ -7935,16 +7940,18 @@ static netdev_tx_t tg3_start_xmit(struct sk_buff *skb, struct net_device *dev)
   base_flags |= (TXD_FLAG_CPU_PRE_DMA |
           TXD_FLAG_CPU_POST_DMA);
 
+  tcph = tcp_hdr(skb);
+  tcp_csum = tcph->check;
+
   if (tg3_flag(tp, HW_TSO_1) ||
       tg3_flag(tp, HW_TSO_2) ||
       tg3_flag(tp, HW_TSO_3)) {
-   tcp_hdr(skb)->check = 0;
+   tcph->check = 0;
    base_flags &= ~TXD_FLAG_TCPUDP_CSUM;
-  } else
-   tcp_hdr(skb)->check = ~csum_tcpudp_magic(iph->saddr,
-         iph->daddr, 0,
-         IPPROTO_TCP,
-         0);
+  } else {
+   tcph->check = ~csum_tcpudp_magic(iph->saddr, iph->daddr,
+        0, IPPROTO_TCP, 0);
+  }
 
   if (tg3_flag(tp, HW_TSO_3)) {
    mss |= (hdr_len & 0xc) << 12;
@@ -8044,6 +8051,18 @@ static netdev_tx_t tg3_start_xmit(struct sk_buff *skb, struct net_device *dev)
  if (would_hit_hwbug) {
   tg3_tx_skb_unmap(tnapi, tnapi->tx_prod, i);
 
+  if (mss) {
+   /* If it's a TSO packet, do GSO instead of
+    * allocating and copying to a large linear SKB
+    */
+   if (ip_tot_len) {
+    iph->check = ip_csum;
+    iph->tot_len = ip_tot_len;
+   }
+   tcph->check = tcp_csum;
+   return tg3_tso_bug(tp, skb);
+  }
+
   /* If the workaround fails due to memory/mapping
    * failure, silently drop this packet.
    */
-- 
1.7.1