From a61a61419649b2b045299b89876fae6ff66d3014 Mon Sep 17 00:00:00 2001
From: Jiri Olsa <jolsa@redhat.com>
Date: Mon, 8 Sep 2014 13:04:30 -0400
Subject: [x86] perf/intel: fix Haswell precise store data source encoding

Message-id: <1410181752-25631-26-git-send-email-jolsa@redhat.com>
Patchwork-id: 91701
O-Subject: [PATCH RHEL7.1 BZ1134356 025/307] fix Haswell precise store data source encoding
Bugzilla: 1134356
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Don Zickus <dzickus@redhat.com>

From: Jiri Olsa <jolsa@kernel.org>

Bugzilla: 1134356
https://bugzilla.redhat.com/show_bug.cgi?id=1134356

upstream
========
commit 722e76e60f2775c21b087ff12c5e678cf0ebcaaf
Author: Stephane Eranian <eranian@google.com>
Date: Thu May 15 17:56:44 2014 +0200

description
===========
This patch fixes a bug in  precise_store_data_hsw() whereby
it would set the data source memory level to the wrong value.

As per the the SDM Vol 3b Table 18-41 (Layout of Data Linear
Address Information in PEBS Record), when status bit 0 is set
this is a L1 hit, otherwise this is a L1 miss.

This patch encodes the memory level according to the specification.

In V2, we added the filtering on the store events.
Only the following events produce L1 information:
 * MEM_UOPS_RETIRED.STLB_MISS_STORES
 * MEM_UOPS_RETIRED.LOCK_STORES
 * MEM_UOPS_RETIRED.SPLIT_STORES
 * MEM_UOPS_RETIRED.ALL_STORES
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/x86/kernel/cpu/perf_event_intel_ds.c b/arch/x86/kernel/cpu/perf_event_intel_ds.c
index 07d344c..65fd266 100644
--- a/arch/x86/kernel/cpu/perf_event_intel_ds.c
+++ b/arch/x86/kernel/cpu/perf_event_intel_ds.c
@@ -108,15 +108,31 @@ static u64 precise_store_data(u64 status)
  return val;
 }
 
-static u64 precise_store_data_hsw(u64 status)
+static u64 precise_store_data_hsw(struct perf_event *event, u64 status)
 {
  union perf_mem_data_src dse;
+ u64 cfg = event->hw.config & INTEL_ARCH_EVENT_MASK;
 
  dse.val = 0;
  dse.mem_op = PERF_MEM_OP_STORE;
  dse.mem_lvl = PERF_MEM_LVL_NA;
+
+ /*
+  * L1 info only valid for following events:
+  *
+  * MEM_UOPS_RETIRED.STLB_MISS_STORES
+  * MEM_UOPS_RETIRED.LOCK_STORES
+  * MEM_UOPS_RETIRED.SPLIT_STORES
+  * MEM_UOPS_RETIRED.ALL_STORES
+  */
+ if (cfg != 0x12d0 && cfg != 0x22d0 && cfg != 0x42d0 && cfg != 0x82d0)
+  return dse.mem_lvl;
+
  if (status & 1)
-  dse.mem_lvl = PERF_MEM_LVL_L1;
+  dse.mem_lvl = PERF_MEM_LVL_L1 | PERF_MEM_LVL_HIT;
+ else
+  dse.mem_lvl = PERF_MEM_LVL_L1 | PERF_MEM_LVL_MISS;
+
  /* Nothing else supported. Sorry. */
  return dse.val;
 }
@@ -880,7 +896,7 @@ static void __intel_pmu_pebs_event(struct perf_event *event,
     data.data_src.val = load_latency_data(pebs->dse);
    else if (event->hw.flags & PERF_X86_EVENT_PEBS_ST_HSW)
     data.data_src.val =
-     precise_store_data_hsw(pebs->dse);
+     precise_store_data_hsw(event, pebs->dse);
    else
     data.data_src.val = precise_store_data(pebs->dse);
   }
-- 
1.7.1