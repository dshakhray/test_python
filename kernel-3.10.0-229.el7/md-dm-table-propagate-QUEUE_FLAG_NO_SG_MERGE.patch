From ad43261404c096fb9ca3a9f024e4a8444bd9afc1 Mon Sep 17 00:00:00 2001
From: Jeff Moyer <jmoyer@redhat.com>
Date: Thu, 28 Aug 2014 19:16:11 -0400
Subject: [md] dm-table: propagate QUEUE_FLAG_NO_SG_MERGE

Message-id: <1409253371-23161-22-git-send-email-jmoyer@redhat.com>
Patchwork-id: 89853
O-Subject: [RHEL7 PATCH 21/21] dm table: propagate QUEUE_FLAG_NO_SG_MERGE
Bugzilla: 1105698
RH-Acked-by: Mike Snitzer <snitzer@redhat.com>
RH-Acked-by: Fam Zheng <famz@redhat.com>

This is a backport of the following upstream commit.
Related to bug 1105698.

  commit 200612ec33e555a356eebc717630b866ae2b694f
  Author: Jeff Moyer <jmoyer@redhat.com>
  Date:   Fri Aug 8 11:03:41 2014 -0400

    dm table: propagate QUEUE_FLAG_NO_SG_MERGE

    Commit 05f1dd5 ("block: add queue flag for disabling SG merging")
    introduced a new queue flag: QUEUE_FLAG_NO_SG_MERGE.  This gets set by
    default in blk_mq_init_queue for mq-enabled devices.  The effect of
    the flag is to bypass the SG segment merging.  Instead, the
    bio->bi_vcnt is used as the number of hardware segments.

    With a device mapper target on top of a device with
    QUEUE_FLAG_NO_SG_MERGE set, we can end up sending down more segments
    than a driver is prepared to handle.  I ran into this when backporting
    the virtio_blk mq support.  It triggerred this BUG_ON, in
    virtio_queue_rq:

            BUG_ON(req->nr_phys_segments + 2 > vblk->sg_elems);

    The queue's max is set here:
            blk_queue_max_segments(q, vblk->sg_elems-2);

    Basically, what happens is that a bio is built up for the dm device
    (which does not have the QUEUE_FLAG_NO_SG_MERGE flag set) using
    bio_add_page.  That path will call into __blk_recalc_rq_segments, so
    what you end up with is bi_phys_segments being much smaller than bi_vcnt
    (and bi_vcnt grows beyond the maximum sg elements).  Then, when the bio
    is submitted, it gets cloned.  When the cloned bio is submitted, it will
    end up in blk_recount_segments, here:

            if (test_bit(QUEUE_FLAG_NO_SG_MERGE, &q->queue_flags))
                    bio->bi_phys_segments = bio->bi_vcnt;

    and now we've set bio->bi_phys_segments to a number that is beyond what
    was registered as queue_max_segments by the driver.

    The right way to fix this is to propagate the queue flag up the stack.

    The rules for propagating the flag are simple:
    - if the flag is set for any underlying device, it must be set for the
      upper device
    - consequently, if the flag is not set for any underlying device, it
      should not be set for the upper device.

    Signed-off-by: Jeff Moyer <jmoyer@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Cc: stable@vger.kernel.org # 3.16+

Signed-off-by: Jeff Moyer <jmoyer@redhat.com>
Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/drivers/md/dm-table.c b/drivers/md/dm-table.c
index 410a8c2..35830c9 100644
--- a/drivers/md/dm-table.c
+++ b/drivers/md/dm-table.c
@@ -1386,6 +1386,14 @@ static int device_is_not_random(struct dm_target *ti, struct dm_dev *dev,
  return q && !blk_queue_add_random(q);
 }
 
+static int queue_supports_sg_merge(struct dm_target *ti, struct dm_dev *dev,
+       sector_t start, sector_t len, void *data)
+{
+ struct request_queue *q = bdev_get_queue(dev->bdev);
+
+ return q && !test_bit(QUEUE_FLAG_NO_SG_MERGE, &q->queue_flags);
+}
+
 static bool dm_table_all_devices_attribute(struct dm_table *t,
         iterate_devices_callout_fn func)
 {
@@ -1520,6 +1528,11 @@ void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q,
  if (!dm_table_supports_write_same(t))
   q->limits.max_write_same_sectors = 0;
 
+ if (dm_table_all_devices_attribute(t, queue_supports_sg_merge))
+  queue_flag_clear_unlocked(QUEUE_FLAG_NO_SG_MERGE, q);
+ else
+  queue_flag_set_unlocked(QUEUE_FLAG_NO_SG_MERGE, q);
+
  dm_table_set_integrity(t);
 
  /*
-- 
1.7.1