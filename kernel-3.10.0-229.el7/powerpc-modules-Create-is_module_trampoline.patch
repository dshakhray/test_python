From 2a7318f15688fc16065d3491ebe6378d546d0692 Mon Sep 17 00:00:00 2001
From: Don Zickus <dzickus@redhat.com>
Date: Fri, 12 Sep 2014 18:11:10 -0400
Subject: [powerpc] modules: Create is_module_trampoline()

Message-id: <1410545655-205645-442-git-send-email-dzickus@redhat.com>
Patchwork-id: 94351
O-Subject: [RHEL7 PATCH 441/626] powerpc/modules: Create is_module_trampoline()
Bugzilla: 1127366
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: David Gibson <dgibson@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1127366

commit 83775b85668a85036973c71264a959236e7becbd
Author: Anton Blanchard <anton@samba.org>
Date:   Thu Apr 3 20:00:43 2014 +1100

    powerpc/modules: Create is_module_trampoline()

    ftrace has way too much knowledge of our kernel module trampoline
    layout hidden inside it. Create is_module_trampoline() that can
    abstract this away inside the module loader code.

    Signed-off-by: Anton Blanchard <anton@samba.org>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/include/asm/module.h b/arch/powerpc/include/asm/module.h
index f54a230..ddda466 100644
--- a/arch/powerpc/include/asm/module.h
+++ b/arch/powerpc/include/asm/module.h
@@ -82,6 +82,7 @@ struct mod_arch_specific {
 #    endif /* MODULE */
 #endif
 
+bool is_module_trampoline(u32 *insns);
 
 struct exception_table_entry;
 void sort_ex_table(struct exception_table_entry *start,
diff --git a/arch/powerpc/kernel/module_64.c b/arch/powerpc/kernel/module_64.c
index 0423601..4db5ecd 100644
--- a/arch/powerpc/kernel/module_64.c
+++ b/arch/powerpc/kernel/module_64.c
@@ -22,6 +22,7 @@
 #include <linux/vmalloc.h>
 #include <linux/ftrace.h>
 #include <linux/bug.h>
+#include <linux/uaccess.h>
 #include <asm/module.h>
 #include <asm/firmware.h>
 #include <asm/code-patching.h>
@@ -102,7 +103,9 @@ static unsigned int local_entry_offset(const Elf64_Sym *sym)
    jump, actually, to reset r2 (TOC+0x8000). */
 struct ppc64_stub_entry
 {
- /* 28 byte jump instruction sequence (7 instructions) */
+ /* 28 byte jump instruction sequence (7 instructions). We only
+  * need 6 instructions on ABIv2 but we always allocate 7 so
+  * so we don't have to modify the trampoline load instruction. */
  u32 jump[7];
  u32 unused;
  /* Data for the above code */
@@ -122,8 +125,8 @@ struct ppc64_stub_entry
  * end of the stub code, and patch the stub address (32-bits relative
  * to the TOC ptr, r2) into the stub.
  */
-static struct ppc64_stub_entry ppc64_stub =
-{ .jump = {
+
+static u32 ppc64_stub_insns[] = {
  0x3d620000,   /* addis   r11,r2, <high> */
  0x396b0000,   /* addi    r11,r11, <low> */
  /* Save current r2 value in magic place on the stack. */
@@ -135,7 +138,45 @@ static struct ppc64_stub_entry ppc64_stub =
 #endif
  0x7d8903a6,   /* mtctr   r12 */
  0x4e800420   /* bctr */
-} };
+};
+
+#ifdef CONFIG_DYNAMIC_FTRACE
+
+static u32 ppc64_stub_mask[] = {
+ 0xffff0000,
+ 0xffff0000,
+ 0xffffffff,
+ 0xffffffff,
+#if !defined(_CALL_ELF) || _CALL_ELF != 2
+ 0xffffffff,
+#endif
+ 0xffffffff,
+ 0xffffffff
+};
+
+bool is_module_trampoline(u32 *p)
+{
+ unsigned int i;
+ u32 insns[ARRAY_SIZE(ppc64_stub_insns)];
+
+ BUILD_BUG_ON(sizeof(ppc64_stub_insns) != sizeof(ppc64_stub_mask));
+
+ if (probe_kernel_read(insns, p, sizeof(insns)))
+  return -EFAULT;
+
+ for (i = 0; i < ARRAY_SIZE(ppc64_stub_insns); i++) {
+  u32 insna = insns[i];
+  u32 insnb = ppc64_stub_insns[i];
+  u32 mask = ppc64_stub_mask[i];
+
+  if ((insna & mask) != (insnb & mask))
+   return false;
+ }
+
+ return true;
+}
+
+#endif
 
 /* Count how many different 24-bit relocations (different symbol,
    different addend) */
@@ -350,7 +391,7 @@ static inline int create_stub(Elf64_Shdr *sechdrs,
 {
  long reladdr;
 
- *entry = ppc64_stub;
+ memcpy(entry->jump, ppc64_stub_insns, sizeof(ppc64_stub_insns));
 
  /* Stub uses address relative to r2. */
  reladdr = (unsigned long)entry - my_r2(sechdrs, me);
-- 
1.7.1