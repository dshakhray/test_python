From c22ee655719a68ea2590c3a904869eadc474e471 Mon Sep 17 00:00:00 2001
From: Paolo Bonzini <pbonzini@redhat.com>
Date: Tue, 22 Jul 2014 14:38:03 -0400
Subject: [virt] kvm/nvmx: Do not generate #DF if #PF happens during exception delivery into L2

Message-id: <1406040016-3289-89-git-send-email-pbonzini@redhat.com>
Patchwork-id: 86167
O-Subject: [RHEL7 PATCH v2 088/221] KVM: nVMX: Do not generate #DF if #PF happens during exception delivery into L2
Bugzilla: 1116936
RH-Acked-by: Radim Krcmar <rkrcmar@redhat.com>
RH-Acked-by: Bandan Das <bsd@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>

From: Gleb Natapov <gleb@redhat.com>

If #PF happens during delivery of an exception into L2 and L1 also do
not have the page mapped in its shadow page table then L0 needs to
generate vmexit to L2 with original event in IDT_VECTORING_INFO, but
current code combines both exception and generates #DF instead. Fix that
by providing nVMX specific function to handle page faults during page
table walk that handles this case correctly.

Signed-off-by: Gleb Natapov <gleb@redhat.com>
Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit feaf0c7dc473fefa1f263d88788f57e39b4b007e)
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c
index f049a8a..d370696 100644
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@ -7523,6 +7523,20 @@ static void nested_ept_uninit_mmu_context(struct kvm_vcpu *vcpu)
  vcpu->arch.walk_mmu = &vcpu->arch.mmu;
 }
 
+static void vmx_inject_page_fault_nested(struct kvm_vcpu *vcpu,
+  struct x86_exception *fault)
+{
+ struct vmcs12 *vmcs12 = get_vmcs12(vcpu);
+
+ WARN_ON(!is_guest_mode(vcpu));
+
+ /* TODO: also check PFEC_MATCH/MASK, not just EB.PF. */
+ if (vmcs12->exception_bitmap & (1u << PF_VECTOR))
+  nested_vmx_vmexit(vcpu);
+ else
+  kvm_inject_page_fault(vcpu, fault);
+}
+
 /*
  * prepare_vmcs02 is called when the L1 guest hypervisor runs its nested
  * L2 guest. L1 has a vmcs for L2 (vmcs12), and this function "merges" it
@@ -7776,6 +7790,9 @@ static void prepare_vmcs02(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12)
  kvm_set_cr3(vcpu, vmcs12->guest_cr3);
  kvm_mmu_reset_context(vcpu);
 
+ if (!enable_ept)
+  vcpu->arch.walk_mmu->inject_page_fault = vmx_inject_page_fault_nested;
+
  /*
   * L1 may access the L2's PDPTR, so save them to construct vmcs12
   */
@@ -8231,6 +8248,9 @@ static void load_vmcs12_host_state(struct kvm_vcpu *vcpu,
  kvm_set_cr3(vcpu, vmcs12->host_cr3);
  kvm_mmu_reset_context(vcpu);
 
+ if (!enable_ept)
+  vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;
+
  if (enable_vpid) {
   /*
    * Trivially support vpid by letting L2s share their parent
-- 
1.7.1