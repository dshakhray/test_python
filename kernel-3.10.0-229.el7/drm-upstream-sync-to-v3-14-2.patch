From 647a5259f8b7b32133d7057db02d232c464f68d9 Mon Sep 17 00:00:00 2001
From: Rob Clark <rclark@redhat.com>
Date: Fri, 15 Aug 2014 14:56:10 -0400
Subject: [drm] upstream sync to v3.14.2

Message-id: <1408114570-31601-2-git-send-email-rclark@redhat.com>
Patchwork-id: 87787
O-Subject: [RHEL7 drm 7/7 v2] drm: upstream sync to v3.14.2
Bugzilla: 1119341
RH-Acked-by: Jerome Glisse <jglisse@redhat.com>
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Dave Airlie <airlied@redhat.com>

RHBZ: 1119341
Sync drm to:

commit 798d3c532b82dce20bcdc512572f542093142d02
Author:     Greg Kroah-Hartman <gregkh@linuxfoundation.org>
AuthorDate: Sat Apr 26 17:19:26 2014 -0700
Commit:     Greg Kroah-Hartman <gregkh@linuxfoundation.org>
CommitDate: Sat Apr 26 17:19:26 2014 -0700

    Linux 3.14.2

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/drivers/char/agp/Kconfig b/drivers/char/agp/Kconfig
index d8b1b57..c528f96 100644
--- a/drivers/char/agp/Kconfig
+++ b/drivers/char/agp/Kconfig
@@ -68,6 +68,7 @@ config AGP_AMD64
 config AGP_INTEL
  tristate "Intel 440LX/BX/GX, I8xx and E7x05 chipset support"
  depends on AGP && X86
+ select INTEL_GTT
  help
    This option gives you AGP support for the GLX component of X
    on Intel 440LX/BX/GX, 815, 820, 830, 840, 845, 850, 860, 875,
@@ -155,3 +156,7 @@ config AGP_SGI_TIOCA
           This option gives you AGP GART support for the SGI TIO chipset
           for IA64 processors.
 
+config INTEL_GTT
+ tristate
+ depends on X86 && PCI
+
diff --git a/drivers/char/agp/Makefile b/drivers/char/agp/Makefile
index 8eb56e2..604489b 100644
--- a/drivers/char/agp/Makefile
+++ b/drivers/char/agp/Makefile
@@ -13,7 +13,7 @@ obj-$(CONFIG_AGP_HP_ZX1) += hp-agp.o
 obj-$(CONFIG_AGP_PARISC) += parisc-agp.o
 obj-$(CONFIG_AGP_I460)  += i460-agp.o
 obj-$(CONFIG_AGP_INTEL)  += intel-agp.o
-obj-$(CONFIG_AGP_INTEL)  += intel-gtt.o
+obj-$(CONFIG_INTEL_GTT)  += intel-gtt.o
 obj-$(CONFIG_AGP_NVIDIA) += nvidia-agp.o
 obj-$(CONFIG_AGP_SGI_TIOCA) += sgi-agp.o
 obj-$(CONFIG_AGP_SIS)  += sis-agp.o
diff --git a/drivers/char/agp/amd64-agp.c b/drivers/char/agp/amd64-agp.c
index 95326ac..3b47ed0 100644
--- a/drivers/char/agp/amd64-agp.c
+++ b/drivers/char/agp/amd64-agp.c
@@ -732,7 +732,7 @@ static struct pci_device_id agp_amd64_pci_table[] = {
 
 MODULE_DEVICE_TABLE(pci, agp_amd64_pci_table);
 
-static DEFINE_PCI_DEVICE_TABLE(agp_amd64_pci_promisc_table) = {
+static const struct pci_device_id agp_amd64_pci_promisc_table[] = {
  { PCI_DEVICE_CLASS(0, 0) },
  { }
 };
diff --git a/drivers/char/agp/intel-agp.c b/drivers/char/agp/intel-agp.c
index a7c2765..f9b9ca5 100644
--- a/drivers/char/agp/intel-agp.c
+++ b/drivers/char/agp/intel-agp.c
@@ -14,9 +14,6 @@
 #include "intel-agp.h"
 #include <drm/intel-gtt.h>
 
-int intel_agp_enabled;
-EXPORT_SYMBOL(intel_agp_enabled);
-
 static int intel_fetch_size(void)
 {
  int i;
@@ -806,8 +803,6 @@ static int agp_intel_probe(struct pci_dev *pdev,
 found_gmch:
  pci_set_drvdata(pdev, bridge);
  err = agp_add_bridge(bridge);
- if (!err)
-  intel_agp_enabled = 1;
  return err;
 }
 
diff --git a/drivers/char/agp/intel-gtt.c b/drivers/char/agp/intel-gtt.c
index ad5da1f..5c85350 100644
--- a/drivers/char/agp/intel-gtt.c
+++ b/drivers/char/agp/intel-gtt.c
@@ -94,6 +94,7 @@ static struct _intel_private {
 #define IS_IRONLAKE intel_private.driver->is_ironlake
 #define HAS_PGTBL_EN intel_private.driver->has_pgtbl_enable
 
+#if IS_ENABLED(CONFIG_AGP_INTEL)
 static int intel_gtt_map_memory(struct page **pages,
     unsigned int num_entries,
     struct sg_table *st)
@@ -168,6 +169,7 @@ static void i8xx_destroy_pages(struct page *page)
  __free_pages(page, 2);
  atomic_dec(&agp_bridge->current_memory_agp);
 }
+#endif
 
 #define I810_GTT_ORDER 4
 static int i810_setup(void)
@@ -208,6 +210,7 @@ static void i810_cleanup(void)
  free_gatt_pages(intel_private.i81x_gtt_table, I810_GTT_ORDER);
 }
 
+#if IS_ENABLED(CONFIG_AGP_INTEL)
 static int i810_insert_dcache_entries(struct agp_memory *mem, off_t pg_start,
           int type)
 {
@@ -288,6 +291,7 @@ static void intel_i810_free_by_type(struct agp_memory *curr)
  }
  kfree(curr);
 }
+#endif
 
 static int intel_gtt_setup_scratch_page(void)
 {
@@ -645,7 +649,9 @@ static int intel_gtt_init(void)
   return -ENOMEM;
  }
 
+#if IS_ENABLED(CONFIG_AGP_INTEL)
  global_cache_flush();   /* FIXME: ? */
+#endif
 
  intel_private.stolen_size = intel_gtt_stolen_size();
 
@@ -666,6 +672,7 @@ static int intel_gtt_init(void)
  return 0;
 }
 
+#if IS_ENABLED(CONFIG_AGP_INTEL)
 static int intel_fake_agp_fetch_size(void)
 {
  int num_sizes = ARRAY_SIZE(intel_fake_agp_sizes);
@@ -684,6 +691,7 @@ static int intel_fake_agp_fetch_size(void)
 
  return 0;
 }
+#endif
 
 static void i830_cleanup(void)
 {
@@ -795,6 +803,7 @@ static int i830_setup(void)
  return 0;
 }
 
+#if IS_ENABLED(CONFIG_AGP_INTEL)
 static int intel_fake_agp_create_gatt_table(struct agp_bridge_data *bridge)
 {
  agp_bridge->gatt_table_real = NULL;
@@ -819,6 +828,7 @@ static int intel_fake_agp_configure(void)
 
  return 0;
 }
+#endif
 
 static bool i830_check_flags(unsigned int flags)
 {
@@ -857,6 +867,7 @@ void intel_gtt_insert_sg_entries(struct sg_table *st,
 }
 EXPORT_SYMBOL(intel_gtt_insert_sg_entries);
 
+#if IS_ENABLED(CONFIG_AGP_INTEL)
 static void intel_gtt_insert_pages(unsigned int first_entry,
        unsigned int num_entries,
        struct page **pages,
@@ -922,6 +933,7 @@ out_err:
  mem->is_flushed = true;
  return ret;
 }
+#endif
 
 void intel_gtt_clear_range(unsigned int first_entry, unsigned int num_entries)
 {
@@ -935,6 +947,7 @@ void intel_gtt_clear_range(unsigned int first_entry, unsigned int num_entries)
 }
 EXPORT_SYMBOL(intel_gtt_clear_range);
 
+#if IS_ENABLED(CONFIG_AGP_INTEL)
 static int intel_fake_agp_remove_entries(struct agp_memory *mem,
       off_t pg_start, int type)
 {
@@ -976,6 +989,7 @@ static struct agp_memory *intel_fake_agp_alloc_by_type(size_t pg_count,
  /* always return NULL for other allocation types for now */
  return NULL;
 }
+#endif
 
 static int intel_alloc_chipset_flush_resource(void)
 {
@@ -1129,6 +1143,7 @@ static int i9xx_setup(void)
  return 0;
 }
 
+#if IS_ENABLED(CONFIG_AGP_INTEL)
 static const struct agp_bridge_driver intel_fake_agp_driver = {
  .owner   = THIS_MODULE,
  .size_type  = FIXED_APER_SIZE,
@@ -1150,6 +1165,7 @@ static const struct agp_bridge_driver intel_fake_agp_driver = {
  .agp_destroy_page = agp_generic_destroy_page,
  .agp_destroy_pages      = agp_generic_destroy_pages,
 };
+#endif
 
 static const struct intel_gtt_driver i81x_gtt_driver = {
  .gen = 1,
@@ -1367,11 +1383,13 @@ int intel_gmch_probe(struct pci_dev *bridge_pdev, struct pci_dev *gpu_pdev,
 
  intel_private.refcount++;
 
+#if IS_ENABLED(CONFIG_AGP_INTEL)
  if (bridge) {
   bridge->driver = &intel_fake_agp_driver;
   bridge->dev_private_data = &intel_private;
   bridge->dev = bridge_pdev;
  }
+#endif
 
  intel_private.bridge_dev = pci_dev_get(bridge_pdev);
 
diff --git a/drivers/gpu/drm/Kconfig b/drivers/gpu/drm/Kconfig
index 90ba028..d016de4 100644
--- a/drivers/gpu/drm/Kconfig
+++ b/drivers/gpu/drm/Kconfig
@@ -20,6 +20,10 @@ menuconfig DRM
    details.  You should also select and configure AGP
    (/dev/agpgart) support if it is available for your platform.
 
+config DRM_MIPI_DSI
+ bool
+ depends on DRM
+
 config DRM_USB
  tristate
  depends on DRM
diff --git a/drivers/gpu/drm/Makefile b/drivers/gpu/drm/Makefile
index 69cab6f..9dae3f6 100644
--- a/drivers/gpu/drm/Makefile
+++ b/drivers/gpu/drm/Makefile
@@ -18,6 +18,7 @@ drm-y       := drm_auth.o drm_buffer.o drm_bufs.o drm_cache.o \
 drm-$(CONFIG_COMPAT) += drm_ioc32.o
 drm-$(CONFIG_DRM_GEM_CMA_HELPER) += drm_gem_cma_helper.o
 drm-$(CONFIG_PCI) += ati_pcigart.o
+drm-$(CONFIG_DRM_PANEL) += drm_panel.o
 
 drm-usb-y   := drm_usb.o
 
@@ -31,6 +32,7 @@ obj-$(CONFIG_DRM_KMS_HELPER) += drm_kms_helper.o
 CFLAGS_drm_trace_points.o := -I$(src)
 
 obj-$(CONFIG_DRM) += drm.o
+obj-$(CONFIG_DRM_MIPI_DSI) += drm_mipi_dsi.o
 obj-$(CONFIG_DRM_USB)   += drm_usb.o
 obj-$(CONFIG_DRM_TTM) += ttm/
 obj-$(CONFIG_DRM_TDFX) += tdfx/
diff --git a/drivers/gpu/drm/ast/ast_main.c b/drivers/gpu/drm/ast/ast_main.c
index af0b868..50535fd 100644
--- a/drivers/gpu/drm/ast/ast_main.c
+++ b/drivers/gpu/drm/ast/ast_main.c
@@ -189,53 +189,6 @@ static int ast_get_dram_info(struct drm_device *dev)
  return 0;
 }
 
-uint32_t ast_get_max_dclk(struct drm_device *dev, int bpp)
-{
- struct ast_private *ast = dev->dev_private;
- uint32_t dclk, jreg;
- uint32_t dram_bus_width, mclk, dram_bandwidth, actual_dram_bandwidth, dram_efficency = 500;
-
- dram_bus_width = ast->dram_bus_width;
- mclk = ast->mclk;
-
- if (ast->chip == AST2100 ||
-     ast->chip == AST1100 ||
-     ast->chip == AST2200 ||
-     ast->chip == AST2150 ||
-     ast->dram_bus_width == 16)
-  dram_efficency = 600;
- else if (ast->chip == AST2300)
-  dram_efficency = 400;
-
- dram_bandwidth = mclk * dram_bus_width * 2 / 8;
- actual_dram_bandwidth = dram_bandwidth * dram_efficency / 1000;
-
- if (ast->chip == AST1180)
-  dclk = actual_dram_bandwidth / ((bpp + 1) / 8);
- else {
-  jreg = ast_get_index_reg_mask(ast, AST_IO_CRTC_PORT, 0xd0, 0xff);
-  if ((jreg & 0x08) && (ast->chip == AST2000))
-   dclk = actual_dram_bandwidth / ((bpp + 1 + 16) / 8);
-  else if ((jreg & 0x08) && (bpp == 8))
-   dclk = actual_dram_bandwidth / ((bpp + 1 + 24) / 8);
-  else
-   dclk = actual_dram_bandwidth / ((bpp + 1) / 8);
- }
-
- if (ast->chip == AST2100 ||
-     ast->chip == AST2200 ||
-     ast->chip == AST2300 ||
-     ast->chip == AST1180) {
-  if (dclk > 200)
-   dclk = 200;
- } else {
-  if (dclk > 165)
-   dclk = 165;
- }
-
- return dclk;
-}
-
 static void ast_user_framebuffer_destroy(struct drm_framebuffer *fb)
 {
  struct ast_framebuffer *ast_fb = to_ast_framebuffer(fb);
@@ -449,7 +402,7 @@ int ast_dumb_create(struct drm_file *file,
  return 0;
 }
 
-void ast_bo_unref(struct ast_bo **bo)
+static void ast_bo_unref(struct ast_bo **bo)
 {
  struct ttm_buffer_object *tbo;
 
diff --git a/drivers/gpu/drm/ast/ast_mode.c b/drivers/gpu/drm/ast/ast_mode.c
index 7fc9f72..cca063b 100644
--- a/drivers/gpu/drm/ast/ast_mode.c
+++ b/drivers/gpu/drm/ast/ast_mode.c
@@ -404,7 +404,7 @@ static void ast_set_ext_reg(struct drm_crtc *crtc, struct drm_display_mode *mode
  }
 }
 
-void ast_set_sync_reg(struct drm_device *dev, struct drm_display_mode *mode,
+static void ast_set_sync_reg(struct drm_device *dev, struct drm_display_mode *mode,
         struct ast_vbios_mode_info *vbios_mode)
 {
  struct ast_private *ast = dev->dev_private;
@@ -415,7 +415,7 @@ void ast_set_sync_reg(struct drm_device *dev, struct drm_display_mode *mode,
  ast_io_write8(ast, AST_IO_MISC_PORT_WRITE, jreg);
 }
 
-bool ast_set_dac_reg(struct drm_crtc *crtc, struct drm_display_mode *mode,
+static bool ast_set_dac_reg(struct drm_crtc *crtc, struct drm_display_mode *mode,
        struct ast_vbios_mode_info *vbios_mode)
 {
  switch (crtc->fb->bits_per_pixel) {
@@ -427,7 +427,7 @@ bool ast_set_dac_reg(struct drm_crtc *crtc, struct drm_display_mode *mode,
  return true;
 }
 
-void ast_set_start_address_crt1(struct drm_crtc *crtc, unsigned offset)
+static void ast_set_start_address_crt1(struct drm_crtc *crtc, unsigned offset)
 {
  struct ast_private *ast = crtc->dev->dev_private;
  u32 addr;
@@ -623,7 +623,7 @@ static const struct drm_crtc_funcs ast_crtc_funcs = {
  .destroy = ast_crtc_destroy,
 };
 
-int ast_crtc_init(struct drm_device *dev)
+static int ast_crtc_init(struct drm_device *dev)
 {
  struct ast_crtc *crtc;
  int i;
@@ -710,7 +710,7 @@ static const struct drm_encoder_helper_funcs ast_enc_helper_funcs = {
  .mode_set = ast_encoder_mode_set,
 };
 
-int ast_encoder_init(struct drm_device *dev)
+static int ast_encoder_init(struct drm_device *dev)
 {
  struct ast_encoder *ast_encoder;
 
@@ -777,7 +777,7 @@ static const struct drm_connector_funcs ast_connector_funcs = {
  .destroy = ast_connector_destroy,
 };
 
-int ast_connector_init(struct drm_device *dev)
+static int ast_connector_init(struct drm_device *dev)
 {
  struct ast_connector *ast_connector;
  struct drm_connector *connector;
@@ -810,7 +810,7 @@ int ast_connector_init(struct drm_device *dev)
 }
 
 /* allocate cursor cache and pin at start of VRAM */
-int ast_cursor_init(struct drm_device *dev)
+static int ast_cursor_init(struct drm_device *dev)
 {
  struct ast_private *ast = dev->dev_private;
  int size;
@@ -847,7 +847,7 @@ fail:
  return ret;
 }
 
-void ast_cursor_fini(struct drm_device *dev)
+static void ast_cursor_fini(struct drm_device *dev)
 {
  struct ast_private *ast = dev->dev_private;
  ttm_bo_kunmap(&ast->cache_kmap);
@@ -965,7 +965,7 @@ static void ast_i2c_destroy(struct ast_i2c_chan *i2c)
  kfree(i2c);
 }
 
-void ast_show_cursor(struct drm_crtc *crtc)
+static void ast_show_cursor(struct drm_crtc *crtc)
 {
  struct ast_private *ast = crtc->dev->dev_private;
  u8 jreg;
@@ -976,7 +976,7 @@ void ast_show_cursor(struct drm_crtc *crtc)
  ast_set_index_reg_mask(ast, AST_IO_CRTC_PORT, 0xcb, 0xfc, jreg);
 }
 
-void ast_hide_cursor(struct drm_crtc *crtc)
+static void ast_hide_cursor(struct drm_crtc *crtc)
 {
  struct ast_private *ast = crtc->dev->dev_private;
  ast_set_index_reg_mask(ast, AST_IO_CRTC_PORT, 0xcb, 0xfc, 0x00);
diff --git a/drivers/gpu/drm/ast/ast_ttm.c b/drivers/gpu/drm/ast/ast_ttm.c
index 32aecb3..4ea9b17 100644
--- a/drivers/gpu/drm/ast/ast_ttm.c
+++ b/drivers/gpu/drm/ast/ast_ttm.c
@@ -80,7 +80,7 @@ static int ast_ttm_global_init(struct ast_private *ast)
  return 0;
 }
 
-void
+static void
 ast_ttm_global_release(struct ast_private *ast)
 {
  if (ast->ttm.mem_global_ref.release == NULL)
@@ -102,7 +102,7 @@ static void ast_bo_ttm_destroy(struct ttm_buffer_object *tbo)
  kfree(bo);
 }
 
-bool ast_ttm_bo_is_ast_bo(struct ttm_buffer_object *bo)
+static bool ast_ttm_bo_is_ast_bo(struct ttm_buffer_object *bo)
 {
  if (bo->destroy == &ast_bo_ttm_destroy)
   return true;
@@ -208,7 +208,7 @@ static struct ttm_backend_func ast_tt_backend_func = {
 };
 
 
-struct ttm_tt *ast_ttm_tt_create(struct ttm_bo_device *bdev,
+static struct ttm_tt *ast_ttm_tt_create(struct ttm_bo_device *bdev,
      unsigned long size, uint32_t page_flags,
      struct page *dummy_read_page)
 {
diff --git a/drivers/gpu/drm/cirrus/cirrus_drv.h b/drivers/gpu/drm/cirrus/cirrus_drv.h
index b6aded7..117d3ec 100644
--- a/drivers/gpu/drm/cirrus/cirrus_drv.h
+++ b/drivers/gpu/drm/cirrus/cirrus_drv.h
@@ -222,7 +222,7 @@ void cirrus_fbdev_fini(struct cirrus_device *cdev);
 void cirrus_driver_irq_preinstall(struct drm_device *dev);
 int cirrus_driver_irq_postinstall(struct drm_device *dev);
 void cirrus_driver_irq_uninstall(struct drm_device *dev);
-irqreturn_t cirrus_driver_irq_handler(DRM_IRQ_ARGS);
+irqreturn_t cirrus_driver_irq_handler(int irq, void *arg);
 
     /* cirrus_kms.c */
 int cirrus_driver_load(struct drm_device *dev, unsigned long flags);
diff --git a/drivers/gpu/drm/cirrus/cirrus_fbdev.c b/drivers/gpu/drm/cirrus/cirrus_fbdev.c
index 86d779a..32bbba0 100644
--- a/drivers/gpu/drm/cirrus/cirrus_fbdev.c
+++ b/drivers/gpu/drm/cirrus/cirrus_fbdev.c
@@ -233,6 +233,9 @@ static int cirrusfb_create(struct drm_fb_helper *helper,
  info->apertures->ranges[0].base = cdev->dev->mode_config.fb_base;
  info->apertures->ranges[0].size = cdev->mc.vram_size;
 
+ info->fix.smem_start = cdev->dev->mode_config.fb_base;
+ info->fix.smem_len = cdev->mc.vram_size;
+
  info->screen_base = sysram;
  info->screen_size = size;
 
diff --git a/drivers/gpu/drm/cirrus/cirrus_main.c b/drivers/gpu/drm/cirrus/cirrus_main.c
index 78e76f2..4b0170c 100644
--- a/drivers/gpu/drm/cirrus/cirrus_main.c
+++ b/drivers/gpu/drm/cirrus/cirrus_main.c
@@ -255,7 +255,7 @@ int cirrus_dumb_create(struct drm_file *file,
  return 0;
 }
 
-void cirrus_bo_unref(struct cirrus_bo **bo)
+static void cirrus_bo_unref(struct cirrus_bo **bo)
 {
  struct ttm_buffer_object *tbo;
 
diff --git a/drivers/gpu/drm/cirrus/cirrus_mode.c b/drivers/gpu/drm/cirrus/cirrus_mode.c
index 3592616..530f78f 100644
--- a/drivers/gpu/drm/cirrus/cirrus_mode.c
+++ b/drivers/gpu/drm/cirrus/cirrus_mode.c
@@ -102,7 +102,7 @@ static bool cirrus_crtc_mode_fixup(struct drm_crtc *crtc,
  return true;
 }
 
-void cirrus_set_start_address(struct drm_crtc *crtc, unsigned offset)
+static void cirrus_set_start_address(struct drm_crtc *crtc, unsigned offset)
 {
  struct cirrus_device *cdev = crtc->dev->dev_private;
  u32 addr;
@@ -453,7 +453,7 @@ static void cirrus_encoder_commit(struct drm_encoder *encoder)
 {
 }
 
-void cirrus_encoder_destroy(struct drm_encoder *encoder)
+static void cirrus_encoder_destroy(struct drm_encoder *encoder)
 {
  struct cirrus_encoder *cirrus_encoder = to_cirrus_encoder(encoder);
  drm_encoder_cleanup(encoder);
@@ -492,7 +492,7 @@ static struct drm_encoder *cirrus_encoder_init(struct drm_device *dev)
 }
 
 
-int cirrus_vga_get_modes(struct drm_connector *connector)
+static int cirrus_vga_get_modes(struct drm_connector *connector)
 {
  int count;
 
@@ -509,7 +509,7 @@ static int cirrus_vga_mode_valid(struct drm_connector *connector,
  return MODE_OK;
 }
 
-struct drm_encoder *cirrus_connector_best_encoder(struct drm_connector
+static struct drm_encoder *cirrus_connector_best_encoder(struct drm_connector
         *connector)
 {
  int enc_id = connector->encoder_ids[0];
diff --git a/drivers/gpu/drm/cirrus/cirrus_ttm.c b/drivers/gpu/drm/cirrus/cirrus_ttm.c
index 75becde..8b37c25 100644
--- a/drivers/gpu/drm/cirrus/cirrus_ttm.c
+++ b/drivers/gpu/drm/cirrus/cirrus_ttm.c
@@ -80,7 +80,7 @@ static int cirrus_ttm_global_init(struct cirrus_device *cirrus)
  return 0;
 }
 
-void
+static void
 cirrus_ttm_global_release(struct cirrus_device *cirrus)
 {
  if (cirrus->ttm.mem_global_ref.release == NULL)
@@ -102,7 +102,7 @@ static void cirrus_bo_ttm_destroy(struct ttm_buffer_object *tbo)
  kfree(bo);
 }
 
-bool cirrus_ttm_bo_is_cirrus_bo(struct ttm_buffer_object *bo)
+static bool cirrus_ttm_bo_is_cirrus_bo(struct ttm_buffer_object *bo)
 {
  if (bo->destroy == &cirrus_bo_ttm_destroy)
   return true;
@@ -208,7 +208,7 @@ static struct ttm_backend_func cirrus_tt_backend_func = {
 };
 
 
-struct ttm_tt *cirrus_ttm_tt_create(struct ttm_bo_device *bdev,
+static struct ttm_tt *cirrus_ttm_tt_create(struct ttm_bo_device *bdev,
      unsigned long size, uint32_t page_flags,
      struct page *dummy_read_page)
 {
@@ -375,26 +375,6 @@ int cirrus_bo_pin(struct cirrus_bo *bo, u32 pl_flag, u64 *gpu_addr)
  return 0;
 }
 
-int cirrus_bo_unpin(struct cirrus_bo *bo)
-{
- int i, ret;
- if (!bo->pin_count) {
-  DRM_ERROR("unpin bad %p\n", bo);
-  return 0;
- }
- bo->pin_count--;
- if (bo->pin_count)
-  return 0;
-
- for (i = 0; i < bo->placement.num_placement ; i++)
-  bo->placements[i] &= ~TTM_PL_FLAG_NO_EVICT;
- ret = ttm_bo_validate(&bo->bo, &bo->placement, false, false);
- if (ret)
-  return ret;
-
- return 0;
-}
-
 int cirrus_bo_push_sysram(struct cirrus_bo *bo)
 {
  int i, ret;
diff --git a/drivers/gpu/drm/drm_agpsupport.c b/drivers/gpu/drm/drm_agpsupport.c
index e301d65..dde205c 100644
--- a/drivers/gpu/drm/drm_agpsupport.c
+++ b/drivers/gpu/drm/drm_agpsupport.c
@@ -53,7 +53,7 @@
  */
 int drm_agp_info(struct drm_device *dev, struct drm_agp_info *info)
 {
- DRM_AGP_KERN *kern;
+ struct agp_kern_info *kern;
 
  if (!dev->agp || !dev->agp->acquired)
   return -EINVAL;
@@ -198,17 +198,15 @@ int drm_agp_enable_ioctl(struct drm_device *dev, void *data,
 int drm_agp_alloc(struct drm_device *dev, struct drm_agp_buffer *request)
 {
  struct drm_agp_mem *entry;
- DRM_AGP_MEM *memory;
+ struct agp_memory *memory;
  unsigned long pages;
  u32 type;
 
  if (!dev->agp || !dev->agp->acquired)
   return -EINVAL;
- if (!(entry = kmalloc(sizeof(*entry), GFP_KERNEL)))
+ if (!(entry = kzalloc(sizeof(*entry), GFP_KERNEL)))
   return -ENOMEM;
 
- memset(entry, 0, sizeof(*entry));
-
  pages = (request->size + PAGE_SIZE - 1) / PAGE_SIZE;
  type = (u32) request->type;
  if (!(memory = agp_allocate_memory(dev->agp->bridge, pages, type))) {
@@ -393,14 +391,16 @@ int drm_agp_free_ioctl(struct drm_device *dev, void *data,
  * Gets the drm_agp_t structure which is made available by the agpgart module
  * via the inter_module_* functions. Creates and initializes a drm_agp_head
  * structure.
+ *
+ * Note that final cleanup of the kmalloced structure is directly done in
+ * drm_pci_agp_destroy.
  */
 struct drm_agp_head *drm_agp_init(struct drm_device *dev)
 {
  struct drm_agp_head *head = NULL;
 
- if (!(head = kmalloc(sizeof(*head), GFP_KERNEL)))
+ if (!(head = kzalloc(sizeof(*head), GFP_KERNEL)))
   return NULL;
- memset((void *)head, 0, sizeof(*head));
  head->bridge = agp_find_bridge(dev->pdev);
  if (!head->bridge) {
   if (!(head->bridge = agp_backend_acquire(dev->pdev))) {
@@ -439,7 +439,7 @@ void drm_agp_clear(struct drm_device *dev)
 {
  struct drm_agp_mem *entry, *tempe;
 
- if (!drm_core_has_AGP(dev) || !dev->agp)
+ if (!dev->agp)
   return;
  if (drm_core_check_feature(dev, DRIVER_MODESET))
   return;
@@ -460,35 +460,20 @@ void drm_agp_clear(struct drm_device *dev)
 }
 
 /**
- * drm_agp_destroy - Destroy AGP head
- * @dev: DRM device
- *
- * Destroy resources that were previously allocated via drm_agp_initp. Caller
- * must ensure to clean up all AGP resources before calling this. See
- * drm_agp_clear().
- *
- * Call this to destroy AGP heads allocated via drm_agp_init().
- */
-void drm_agp_destroy(struct drm_agp_head *agp)
-{
- kfree(agp);
-}
-
-/**
  * Binds a collection of pages into AGP memory at the given offset, returning
  * the AGP memory structure containing them.
  *
  * No reference is held on the pages during this time -- it is up to the
  * caller to handle that.
  */
-DRM_AGP_MEM *
+struct agp_memory *
 drm_agp_bind_pages(struct drm_device *dev,
      struct page **pages,
      unsigned long num_pages,
      uint32_t gtt_offset,
      u32 type)
 {
- DRM_AGP_MEM *mem;
+ struct agp_memory *mem;
  int ret, i;
 
  DRM_DEBUG("\n");
diff --git a/drivers/gpu/drm/drm_buffer.c b/drivers/gpu/drm/drm_buffer.c
index 39a7183..0406110 100644
--- a/drivers/gpu/drm/drm_buffer.c
+++ b/drivers/gpu/drm/drm_buffer.c
@@ -114,7 +114,7 @@ int drm_buffer_copy_from_user(struct drm_buffer *buf,
 
  for (idx = 0; idx < nr_pages; ++idx) {
 
-  if (DRM_COPY_FROM_USER(buf->data[idx],
+  if (copy_from_user(buf->data[idx],
    user_data + idx * PAGE_SIZE,
    min(PAGE_SIZE, size - idx * PAGE_SIZE))) {
    DRM_ERROR("Failed to copy user data (%p) to drm buffer"
diff --git a/drivers/gpu/drm/drm_bufs.c b/drivers/gpu/drm/drm_bufs.c
index 471e051..edec31f 100644
--- a/drivers/gpu/drm/drm_bufs.c
+++ b/drivers/gpu/drm/drm_bufs.c
@@ -261,7 +261,7 @@ static int drm_addmap_core(struct drm_device * dev, resource_size_t offset,
   struct drm_agp_mem *entry;
   int valid = 0;
 
-  if (!drm_core_has_AGP(dev)) {
+  if (!dev->agp) {
    kfree(map);
    return -EINVAL;
   }
@@ -303,9 +303,6 @@ static int drm_addmap_core(struct drm_device * dev, resource_size_t offset,
 
   break;
  }
- case _DRM_GEM:
-  DRM_ERROR("tried to addmap GEM object\n");
-  break;
  case _DRM_SCATTER_GATHER:
   if (!dev->sg) {
    kfree(map);
@@ -483,9 +480,6 @@ int drm_rmmap_locked(struct drm_device *dev, struct drm_local_map *map)
   dmah.size = map->size;
   __drm_pci_free(dev, &dmah);
   break;
- case _DRM_GEM:
-  DRM_ERROR("tried to rmmap GEM object\n");
-  break;
  }
  kfree(map);
 
@@ -1396,7 +1390,7 @@ int drm_mapbufs(struct drm_device *dev, void *data,
  spin_unlock(&dev->count_lock);
 
  if (request->count >= dma->buf_count) {
-  if ((drm_core_has_AGP(dev) && (dma->flags & _DRM_DMA_USE_AGP))
+  if ((dev->agp && (dma->flags & _DRM_DMA_USE_AGP))
       || (drm_core_check_feature(dev, DRIVER_SG)
    && (dma->flags & _DRM_DMA_USE_SG))) {
    struct drm_local_map *map = dev->agp_buffer_map;
diff --git a/drivers/gpu/drm/drm_crtc.c b/drivers/gpu/drm/drm_crtc.c
index d6cf77c..3b7d32d 100644
--- a/drivers/gpu/drm/drm_crtc.c
+++ b/drivers/gpu/drm/drm_crtc.c
@@ -675,6 +675,29 @@ void drm_crtc_cleanup(struct drm_crtc *crtc)
 EXPORT_SYMBOL(drm_crtc_cleanup);
 
 /**
+ * drm_crtc_index - find the index of a registered CRTC
+ * @crtc: CRTC to find index for
+ *
+ * Given a registered CRTC, return the index of that CRTC within a DRM
+ * device's list of CRTCs.
+ */
+unsigned int drm_crtc_index(struct drm_crtc *crtc)
+{
+ unsigned int index = 0;
+ struct drm_crtc *tmp;
+
+ list_for_each_entry(tmp, &crtc->dev->mode_config.crtc_list, head) {
+  if (tmp == crtc)
+   return index;
+
+  index++;
+ }
+
+ BUG();
+}
+EXPORT_SYMBOL(drm_crtc_index);
+
+/**
  * drm_mode_probed_add - add a mode to a connector's probed mode list
  * @connector: connector the new mode
  * @mode: mode data
@@ -2767,10 +2790,8 @@ int drm_mode_dirtyfb_ioctl(struct drm_device *dev,
  }
 
  if (fb->funcs->dirty) {
-  drm_modeset_lock_all(dev);
   ret = fb->funcs->dirty(fb, file_priv, flags, r->color,
            clips, num_clips);
-  drm_modeset_unlock_all(dev);
  } else {
   ret = -ENOSYS;
  }
diff --git a/drivers/gpu/drm/drm_crtc_helper.c b/drivers/gpu/drm/drm_crtc_helper.c
index 01361ab..ea92b82 100644
--- a/drivers/gpu/drm/drm_crtc_helper.c
+++ b/drivers/gpu/drm/drm_crtc_helper.c
@@ -324,35 +324,6 @@ void drm_helper_disable_unused_functions(struct drm_device *dev)
 }
 EXPORT_SYMBOL(drm_helper_disable_unused_functions);
 
-/**
- * drm_encoder_crtc_ok - can a given crtc drive a given encoder?
- * @encoder: encoder to test
- * @crtc: crtc to test
- *
- * Return false if @encoder can't be driven by @crtc, true otherwise.
- */
-static bool drm_encoder_crtc_ok(struct drm_encoder *encoder,
-    struct drm_crtc *crtc)
-{
- struct drm_device *dev;
- struct drm_crtc *tmp;
- int crtc_mask = 1;
-
- WARN(!crtc, "checking null crtc?\n");
-
- dev = crtc->dev;
-
- list_for_each_entry(tmp, &dev->mode_config.crtc_list, head) {
-  if (tmp == crtc)
-   break;
-  crtc_mask <<= 1;
- }
-
- if (encoder->possible_crtcs & crtc_mask)
-  return true;
- return false;
-}
-
 /*
  * Check the CRTC we're going to map each output to vs. its current
  * CRTC.  If they don't match, we have to disable the output and the CRTC
@@ -536,7 +507,7 @@ bool drm_crtc_helper_set_mode(struct drm_crtc *crtc,
   * are later needed by vblank and swap-completion
   * timestamping. They are derived from true hwmode.
   */
- drm_calc_timestamping_constants(crtc);
+ drm_calc_timestamping_constants(crtc, &crtc->hwmode);
 
  /* FIXME: add subpixel order */
 done:
diff --git a/drivers/gpu/drm/drm_drv.c b/drivers/gpu/drm/drm_drv.c
index d9137e4..345be03 100644
--- a/drivers/gpu/drm/drm_drv.c
+++ b/drivers/gpu/drm/drm_drv.c
@@ -315,9 +315,6 @@ long drm_ioctl(struct file *filp,
  if (drm_device_is_unplugged(dev))
   return -ENODEV;
 
- atomic_inc(&dev->ioctl_count);
- ++file_priv->ioctl_count;
-
  if ((nr >= DRM_CORE_IOCTL_COUNT) &&
      ((nr < DRM_COMMAND_BASE) || (nr >= DRM_COMMAND_END)))
   goto err_i1;
@@ -410,7 +407,6 @@ long drm_ioctl(struct file *filp,
 
  if (kdata != stack_kdata)
   kfree(kdata);
- atomic_dec(&dev->ioctl_count);
  if (retcode)
   DRM_DEBUG("ret = %d\n", retcode);
  return retcode;
diff --git a/drivers/gpu/drm/drm_edid.c b/drivers/gpu/drm/drm_edid.c
index 8835dcd..b924306 100644
--- a/drivers/gpu/drm/drm_edid.c
+++ b/drivers/gpu/drm/drm_edid.c
@@ -605,347 +605,347 @@ static const struct drm_display_mode edid_cea_modes[] = {
  { DRM_MODE("640x480", DRM_MODE_TYPE_DRIVER, 25175, 640, 656,
      752, 800, 0, 480, 490, 492, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 2 - 720x480@60Hz */
  { DRM_MODE("720x480", DRM_MODE_TYPE_DRIVER, 27000, 720, 736,
      798, 858, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 3 - 720x480@60Hz */
  { DRM_MODE("720x480", DRM_MODE_TYPE_DRIVER, 27000, 720, 736,
      798, 858, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 4 - 1280x720@60Hz */
  { DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 74250, 1280, 1390,
      1430, 1650, 0, 720, 725, 730, 750, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 5 - 1920x1080i@60Hz */
  { DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2008,
      2052, 2200, 0, 1080, 1084, 1094, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
    DRM_MODE_FLAG_INTERLACE),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 6 - 1440x480i@60Hz */
  { DRM_MODE("1440x480i", DRM_MODE_TYPE_DRIVER, 27000, 1440, 1478,
      1602, 1716, 0, 480, 488, 494, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 7 - 1440x480i@60Hz */
  { DRM_MODE("1440x480i", DRM_MODE_TYPE_DRIVER, 27000, 1440, 1478,
      1602, 1716, 0, 480, 488, 494, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 8 - 1440x240@60Hz */
  { DRM_MODE("1440x240", DRM_MODE_TYPE_DRIVER, 27000, 1440, 1478,
      1602, 1716, 0, 240, 244, 247, 262, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 9 - 1440x240@60Hz */
  { DRM_MODE("1440x240", DRM_MODE_TYPE_DRIVER, 27000, 1440, 1478,
      1602, 1716, 0, 240, 244, 247, 262, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 10 - 2880x480i@60Hz */
  { DRM_MODE("2880x480i", DRM_MODE_TYPE_DRIVER, 54000, 2880, 2956,
      3204, 3432, 0, 480, 488, 494, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 11 - 2880x480i@60Hz */
  { DRM_MODE("2880x480i", DRM_MODE_TYPE_DRIVER, 54000, 2880, 2956,
      3204, 3432, 0, 480, 488, 494, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 12 - 2880x240@60Hz */
  { DRM_MODE("2880x240", DRM_MODE_TYPE_DRIVER, 54000, 2880, 2956,
      3204, 3432, 0, 240, 244, 247, 262, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 13 - 2880x240@60Hz */
  { DRM_MODE("2880x240", DRM_MODE_TYPE_DRIVER, 54000, 2880, 2956,
      3204, 3432, 0, 240, 244, 247, 262, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 14 - 1440x480@60Hz */
  { DRM_MODE("1440x480", DRM_MODE_TYPE_DRIVER, 54000, 1440, 1472,
      1596, 1716, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 15 - 1440x480@60Hz */
  { DRM_MODE("1440x480", DRM_MODE_TYPE_DRIVER, 54000, 1440, 1472,
      1596, 1716, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 16 - 1920x1080@60Hz */
  { DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2008,
      2052, 2200, 0, 1080, 1084, 1089, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 17 - 720x576@50Hz */
  { DRM_MODE("720x576", DRM_MODE_TYPE_DRIVER, 27000, 720, 732,
      796, 864, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 18 - 720x576@50Hz */
  { DRM_MODE("720x576", DRM_MODE_TYPE_DRIVER, 27000, 720, 732,
      796, 864, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 19 - 1280x720@50Hz */
  { DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 74250, 1280, 1720,
      1760, 1980, 0, 720, 725, 730, 750, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 20 - 1920x1080i@50Hz */
  { DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2448,
      2492, 2640, 0, 1080, 1084, 1094, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
    DRM_MODE_FLAG_INTERLACE),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 21 - 1440x576i@50Hz */
  { DRM_MODE("1440x576i", DRM_MODE_TYPE_DRIVER, 27000, 1440, 1464,
      1590, 1728, 0, 576, 580, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 22 - 1440x576i@50Hz */
  { DRM_MODE("1440x576i", DRM_MODE_TYPE_DRIVER, 27000, 1440, 1464,
      1590, 1728, 0, 576, 580, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 23 - 1440x288@50Hz */
  { DRM_MODE("1440x288", DRM_MODE_TYPE_DRIVER, 27000, 1440, 1464,
      1590, 1728, 0, 288, 290, 293, 312, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 24 - 1440x288@50Hz */
  { DRM_MODE("1440x288", DRM_MODE_TYPE_DRIVER, 27000, 1440, 1464,
      1590, 1728, 0, 288, 290, 293, 312, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 25 - 2880x576i@50Hz */
  { DRM_MODE("2880x576i", DRM_MODE_TYPE_DRIVER, 54000, 2880, 2928,
      3180, 3456, 0, 576, 580, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 26 - 2880x576i@50Hz */
  { DRM_MODE("2880x576i", DRM_MODE_TYPE_DRIVER, 54000, 2880, 2928,
      3180, 3456, 0, 576, 580, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 27 - 2880x288@50Hz */
  { DRM_MODE("2880x288", DRM_MODE_TYPE_DRIVER, 54000, 2880, 2928,
      3180, 3456, 0, 288, 290, 293, 312, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 28 - 2880x288@50Hz */
  { DRM_MODE("2880x288", DRM_MODE_TYPE_DRIVER, 54000, 2880, 2928,
      3180, 3456, 0, 288, 290, 293, 312, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 29 - 1440x576@50Hz */
  { DRM_MODE("1440x576", DRM_MODE_TYPE_DRIVER, 54000, 1440, 1464,
      1592, 1728, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 30 - 1440x576@50Hz */
  { DRM_MODE("1440x576", DRM_MODE_TYPE_DRIVER, 54000, 1440, 1464,
      1592, 1728, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 31 - 1920x1080@50Hz */
  { DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2448,
      2492, 2640, 0, 1080, 1084, 1089, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 32 - 1920x1080@24Hz */
  { DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2558,
      2602, 2750, 0, 1080, 1084, 1089, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 24, },
+   .vrefresh = 24, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 33 - 1920x1080@25Hz */
  { DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2448,
      2492, 2640, 0, 1080, 1084, 1089, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 25, },
+   .vrefresh = 25, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 34 - 1920x1080@30Hz */
  { DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2008,
      2052, 2200, 0, 1080, 1084, 1089, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 30, },
+   .vrefresh = 30, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 35 - 2880x480@60Hz */
  { DRM_MODE("2880x480", DRM_MODE_TYPE_DRIVER, 108000, 2880, 2944,
      3192, 3432, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 36 - 2880x480@60Hz */
  { DRM_MODE("2880x480", DRM_MODE_TYPE_DRIVER, 108000, 2880, 2944,
      3192, 3432, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 60, },
+   .vrefresh = 60, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 37 - 2880x576@50Hz */
  { DRM_MODE("2880x576", DRM_MODE_TYPE_DRIVER, 108000, 2880, 2928,
      3184, 3456, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 38 - 2880x576@50Hz */
  { DRM_MODE("2880x576", DRM_MODE_TYPE_DRIVER, 108000, 2880, 2928,
      3184, 3456, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 39 - 1920x1080i@50Hz */
  { DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 72000, 1920, 1952,
      2120, 2304, 0, 1080, 1126, 1136, 1250, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE),
-   .vrefresh = 50, },
+   .vrefresh = 50, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 40 - 1920x1080i@100Hz */
  { DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2448,
      2492, 2640, 0, 1080, 1084, 1094, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
    DRM_MODE_FLAG_INTERLACE),
-   .vrefresh = 100, },
+   .vrefresh = 100, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 41 - 1280x720@100Hz */
  { DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 148500, 1280, 1720,
      1760, 1980, 0, 720, 725, 730, 750, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 100, },
+   .vrefresh = 100, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 42 - 720x576@100Hz */
  { DRM_MODE("720x576", DRM_MODE_TYPE_DRIVER, 54000, 720, 732,
      796, 864, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 100, },
+   .vrefresh = 100, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 43 - 720x576@100Hz */
  { DRM_MODE("720x576", DRM_MODE_TYPE_DRIVER, 54000, 720, 732,
      796, 864, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 100, },
+   .vrefresh = 100, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 44 - 1440x576i@100Hz */
  { DRM_MODE("1440x576", DRM_MODE_TYPE_DRIVER, 54000, 1440, 1464,
      1590, 1728, 0, 576, 580, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 100, },
+   .vrefresh = 100, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 45 - 1440x576i@100Hz */
  { DRM_MODE("1440x576", DRM_MODE_TYPE_DRIVER, 54000, 1440, 1464,
      1590, 1728, 0, 576, 580, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 100, },
+   .vrefresh = 100, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 46 - 1920x1080i@120Hz */
  { DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2008,
      2052, 2200, 0, 1080, 1084, 1094, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
    DRM_MODE_FLAG_INTERLACE),
-   .vrefresh = 120, },
+   .vrefresh = 120, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 47 - 1280x720@120Hz */
  { DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 148500, 1280, 1390,
      1430, 1650, 0, 720, 725, 730, 750, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 120, },
+   .vrefresh = 120, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 48 - 720x480@120Hz */
  { DRM_MODE("720x480", DRM_MODE_TYPE_DRIVER, 54000, 720, 736,
      798, 858, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 120, },
+   .vrefresh = 120, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 49 - 720x480@120Hz */
  { DRM_MODE("720x480", DRM_MODE_TYPE_DRIVER, 54000, 720, 736,
      798, 858, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 120, },
+   .vrefresh = 120, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 50 - 1440x480i@120Hz */
  { DRM_MODE("1440x480i", DRM_MODE_TYPE_DRIVER, 54000, 1440, 1478,
      1602, 1716, 0, 480, 488, 494, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 120, },
+   .vrefresh = 120, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 51 - 1440x480i@120Hz */
  { DRM_MODE("1440x480i", DRM_MODE_TYPE_DRIVER, 54000, 1440, 1478,
      1602, 1716, 0, 480, 488, 494, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 120, },
+   .vrefresh = 120, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 52 - 720x576@200Hz */
  { DRM_MODE("720x576", DRM_MODE_TYPE_DRIVER, 108000, 720, 732,
      796, 864, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 200, },
+   .vrefresh = 200, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 53 - 720x576@200Hz */
  { DRM_MODE("720x576", DRM_MODE_TYPE_DRIVER, 108000, 720, 732,
      796, 864, 0, 576, 581, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 200, },
+   .vrefresh = 200, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 54 - 1440x576i@200Hz */
  { DRM_MODE("1440x576i", DRM_MODE_TYPE_DRIVER, 108000, 1440, 1464,
      1590, 1728, 0, 576, 580, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 200, },
+   .vrefresh = 200, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 55 - 1440x576i@200Hz */
  { DRM_MODE("1440x576i", DRM_MODE_TYPE_DRIVER, 108000, 1440, 1464,
      1590, 1728, 0, 576, 580, 586, 625, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 200, },
+   .vrefresh = 200, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 56 - 720x480@240Hz */
  { DRM_MODE("720x480", DRM_MODE_TYPE_DRIVER, 108000, 720, 736,
      798, 858, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 240, },
+   .vrefresh = 240, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 57 - 720x480@240Hz */
  { DRM_MODE("720x480", DRM_MODE_TYPE_DRIVER, 108000, 720, 736,
      798, 858, 0, 480, 489, 495, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC),
-   .vrefresh = 240, },
+   .vrefresh = 240, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 58 - 1440x480i@240 */
  { DRM_MODE("1440x480i", DRM_MODE_TYPE_DRIVER, 108000, 1440, 1478,
      1602, 1716, 0, 480, 488, 494, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 240, },
+   .vrefresh = 240, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_4_3, },
  /* 59 - 1440x480i@240 */
  { DRM_MODE("1440x480i", DRM_MODE_TYPE_DRIVER, 108000, 1440, 1478,
      1602, 1716, 0, 480, 488, 494, 525, 0,
      DRM_MODE_FLAG_NHSYNC | DRM_MODE_FLAG_NVSYNC |
    DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
-   .vrefresh = 240, },
+   .vrefresh = 240, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 60 - 1280x720@24Hz */
  { DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 59400, 1280, 3040,
      3080, 3300, 0, 720, 725, 730, 750, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 24, },
+   .vrefresh = 24, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 61 - 1280x720@25Hz */
  { DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 74250, 1280, 3700,
      3740, 3960, 0, 720, 725, 730, 750, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 25, },
+   .vrefresh = 25, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 62 - 1280x720@30Hz */
  { DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 74250, 1280, 3040,
      3080, 3300, 0, 720, 725, 730, 750, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-   .vrefresh = 30, },
+   .vrefresh = 30, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 63 - 1920x1080@120Hz */
  { DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 297000, 1920, 2008,
      2052, 2200, 0, 1080, 1084, 1089, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-  .vrefresh = 120, },
+  .vrefresh = 120, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
  /* 64 - 1920x1080@100Hz */
  { DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 297000, 1920, 2448,
      2492, 2640, 0, 1080, 1084, 1094, 1125, 0,
      DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
-  .vrefresh = 100, },
+  .vrefresh = 100, .picture_aspect_ratio = HDMI_PICTURE_ASPECT_16_9, },
 };
 
 /*
@@ -2562,25 +2562,40 @@ add_alternate_cea_modes(struct drm_connector *connector, struct edid *edid)
  return modes;
 }
 
-static int
-do_cea_modes(struct drm_connector *connector, const u8 *db, u8 len)
+static struct drm_display_mode *
+drm_display_mode_from_vic_index(struct drm_connector *connector,
+    const u8 *video_db, u8 video_len,
+    u8 video_index)
 {
  struct drm_device *dev = connector->dev;
- const u8 *mode;
+ struct drm_display_mode *newmode;
  u8 cea_mode;
- int modes = 0;
 
- for (mode = db; mode < db + len; mode++) {
-  cea_mode = (*mode & 127) - 1; /* CEA modes are numbered 1..127 */
-  if (cea_mode < ARRAY_SIZE(edid_cea_modes)) {
-   struct drm_display_mode *newmode;
-   newmode = drm_mode_duplicate(dev,
-           &edid_cea_modes[cea_mode]);
-   if (newmode) {
-    newmode->vrefresh = 0;
-    drm_mode_probed_add(connector, newmode);
-    modes++;
-   }
+ if (video_db == NULL || video_index >= video_len)
+  return NULL;
+
+ /* CEA modes are numbered 1..127 */
+ cea_mode = (video_db[video_index] & 127) - 1;
+ if (cea_mode >= ARRAY_SIZE(edid_cea_modes))
+  return NULL;
+
+ newmode = drm_mode_duplicate(dev, &edid_cea_modes[cea_mode]);
+ newmode->vrefresh = 0;
+
+ return newmode;
+}
+
+static int
+do_cea_modes(struct drm_connector *connector, const u8 *db, u8 len)
+{
+ int i, modes = 0;
+
+ for (i = 0; i < len; i++) {
+  struct drm_display_mode *mode;
+  mode = drm_display_mode_from_vic_index(connector, db, len, i);
+  if (mode) {
+   drm_mode_probed_add(connector, mode);
+   modes++;
   }
  }
 
@@ -2674,21 +2689,13 @@ static int add_hdmi_mode(struct drm_connector *connector, u8 vic)
 static int add_3d_struct_modes(struct drm_connector *connector, u16 structure,
           const u8 *video_db, u8 video_len, u8 video_index)
 {
- struct drm_device *dev = connector->dev;
  struct drm_display_mode *newmode;
  int modes = 0;
- u8 cea_mode;
-
- if (video_db == NULL || video_index >= video_len)
-  return 0;
-
- /* CEA modes are numbered 1..127 */
- cea_mode = (video_db[video_index] & 127) - 1;
- if (cea_mode >= ARRAY_SIZE(edid_cea_modes))
-  return 0;
 
  if (structure & (1 << 0)) {
-  newmode = drm_mode_duplicate(dev, &edid_cea_modes[cea_mode]);
+  newmode = drm_display_mode_from_vic_index(connector, video_db,
+         video_len,
+         video_index);
   if (newmode) {
    newmode->flags |= DRM_MODE_FLAG_3D_FRAME_PACKING;
    drm_mode_probed_add(connector, newmode);
@@ -2696,7 +2703,9 @@ static int add_3d_struct_modes(struct drm_connector *connector, u16 structure,
   }
  }
  if (structure & (1 << 6)) {
-  newmode = drm_mode_duplicate(dev, &edid_cea_modes[cea_mode]);
+  newmode = drm_display_mode_from_vic_index(connector, video_db,
+         video_len,
+         video_index);
   if (newmode) {
    newmode->flags |= DRM_MODE_FLAG_3D_TOP_AND_BOTTOM;
    drm_mode_probed_add(connector, newmode);
@@ -2704,7 +2713,9 @@ static int add_3d_struct_modes(struct drm_connector *connector, u16 structure,
   }
  }
  if (structure & (1 << 8)) {
-  newmode = drm_mode_duplicate(dev, &edid_cea_modes[cea_mode]);
+  newmode = drm_display_mode_from_vic_index(connector, video_db,
+         video_len,
+         video_index);
   if (newmode) {
    newmode->flags |= DRM_MODE_FLAG_3D_SIDE_BY_SIDE_HALF;
    drm_mode_probed_add(connector, newmode);
@@ -2728,7 +2739,7 @@ static int
 do_hdmi_vsdb_modes(struct drm_connector *connector, const u8 *db, u8 len,
      const u8 *video_db, u8 video_len)
 {
- int modes = 0, offset = 0, i, multi_present = 0;
+ int modes = 0, offset = 0, i, multi_present = 0, multi_len;
  u8 vic_len, hdmi_3d_len = 0;
  u16 mask;
  u16 structure_all;
@@ -2774,32 +2785,84 @@ do_hdmi_vsdb_modes(struct drm_connector *connector, const u8 *db, u8 len,
  }
  offset += 1 + vic_len;
 
- if (!(multi_present == 1 || multi_present == 2))
-  goto out;
+ if (multi_present == 1)
+  multi_len = 2;
+ else if (multi_present == 2)
+  multi_len = 4;
+ else
+  multi_len = 0;
 
- if ((multi_present == 1 && len < (9 + offset)) ||
-     (multi_present == 2 && len < (11 + offset)))
+ if (len < (8 + offset + hdmi_3d_len - 1))
   goto out;
 
- if ((multi_present == 1 && hdmi_3d_len < 2) ||
-     (multi_present == 2 && hdmi_3d_len < 4))
+ if (hdmi_3d_len < multi_len)
   goto out;
 
- /* 3D_Structure_ALL */
- structure_all = (db[8 + offset] << 8) | db[9 + offset];
+ if (multi_present == 1 || multi_present == 2) {
+  /* 3D_Structure_ALL */
+  structure_all = (db[8 + offset] << 8) | db[9 + offset];
 
- /* check if 3D_MASK is present */
- if (multi_present == 2)
-  mask = (db[10 + offset] << 8) | db[11 + offset];
- else
-  mask = 0xffff;
-
- for (i = 0; i < 16; i++) {
-  if (mask & (1 << i))
-   modes += add_3d_struct_modes(connector,
-           structure_all,
-           video_db,
-           video_len, i);
+  /* check if 3D_MASK is present */
+  if (multi_present == 2)
+   mask = (db[10 + offset] << 8) | db[11 + offset];
+  else
+   mask = 0xffff;
+
+  for (i = 0; i < 16; i++) {
+   if (mask & (1 << i))
+    modes += add_3d_struct_modes(connector,
+      structure_all,
+      video_db,
+      video_len, i);
+  }
+ }
+
+ offset += multi_len;
+
+ for (i = 0; i < (hdmi_3d_len - multi_len); i++) {
+  int vic_index;
+  struct drm_display_mode *newmode = NULL;
+  unsigned int newflag = 0;
+  bool detail_present;
+
+  detail_present = ((db[8 + offset + i] & 0x0f) > 7);
+
+  if (detail_present && (i + 1 == hdmi_3d_len - multi_len))
+   break;
+
+  /* 2D_VIC_order_X */
+  vic_index = db[8 + offset + i] >> 4;
+
+  /* 3D_Structure_X */
+  switch (db[8 + offset + i] & 0x0f) {
+  case 0:
+   newflag = DRM_MODE_FLAG_3D_FRAME_PACKING;
+   break;
+  case 6:
+   newflag = DRM_MODE_FLAG_3D_TOP_AND_BOTTOM;
+   break;
+  case 8:
+   /* 3D_Detail_X */
+   if ((db[9 + offset + i] >> 4) == 1)
+    newflag = DRM_MODE_FLAG_3D_SIDE_BY_SIDE_HALF;
+   break;
+  }
+
+  if (newflag != 0) {
+   newmode = drm_display_mode_from_vic_index(connector,
+          video_db,
+          video_len,
+          vic_index);
+
+   if (newmode) {
+    newmode->flags |= newflag;
+    drm_mode_probed_add(connector, newmode);
+    modes++;
+   }
+  }
+
+  if (detail_present)
+   i++;
  }
 
 out:
diff --git a/drivers/gpu/drm/drm_edid_load.c b/drivers/gpu/drm/drm_edid_load.c
index 9081172..1b4c7a5 100644
--- a/drivers/gpu/drm/drm_edid_load.c
+++ b/drivers/gpu/drm/drm_edid_load.c
@@ -141,7 +141,7 @@ static int edid_size(const u8 *edid, int data_size)
  return (edid[0x7e] + 1) * EDID_LENGTH;
 }
 
-static u8 *edid_load(struct drm_connector *connector, const char *name,
+static void *edid_load(struct drm_connector *connector, const char *name,
    const char *connector_name)
 {
  const struct firmware *fw = NULL;
@@ -263,7 +263,7 @@ int drm_load_edid_firmware(struct drm_connector *connector)
  if (*last == '\n')
   *last = '\0';
 
- edid = (struct edid *) edid_load(connector, edidname, connector_name);
+ edid = edid_load(connector, edidname, connector_name);
  if (IS_ERR_OR_NULL(edid))
   return 0;
 
diff --git a/drivers/gpu/drm/drm_fb_helper.c b/drivers/gpu/drm/drm_fb_helper.c
index 0a19401..98a0363 100644
--- a/drivers/gpu/drm/drm_fb_helper.c
+++ b/drivers/gpu/drm/drm_fb_helper.c
@@ -359,6 +359,11 @@ static bool drm_fb_helper_is_bound(struct drm_fb_helper *fb_helper)
  struct drm_crtc *crtc;
  int bound = 0, crtcs_bound = 0;
 
+ /* Sometimes user space wants everything disabled, so don't steal the
+  * display if there's a master. */
+ if (dev->primary->master)
+  return false;
+
  list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
   if (crtc->fb)
    crtcs_bound++;
@@ -368,6 +373,7 @@ static bool drm_fb_helper_is_bound(struct drm_fb_helper *fb_helper)
 
  if (bound < crtcs_bound)
   return false;
+
  return true;
 }
 
diff --git a/drivers/gpu/drm/drm_fops.c b/drivers/gpu/drm/drm_fops.c
index 2eb2d26..309023f 100644
--- a/drivers/gpu/drm/drm_fops.c
+++ b/drivers/gpu/drm/drm_fops.c
@@ -232,7 +232,6 @@ static int drm_open_helper(struct inode *inode, struct file *filp,
   goto out_put_pid;
  }
 
- priv->ioctl_count = 0;
  /* for compatibility root is always authenticated */
  priv->always_authenticated = capable(CAP_SYS_ADMIN);
  priv->authenticated = priv->always_authenticated;
@@ -393,9 +392,6 @@ static void drm_legacy_dev_reinit(struct drm_device *dev)
  if (drm_core_check_feature(dev, DRIVER_MODESET))
   return;
 
- atomic_set(&dev->ioctl_count, 0);
- atomic_set(&dev->vma_count, 0);
-
  dev->sigdata.lock = NULL;
 
  dev->context_flag = 0;
@@ -579,12 +575,7 @@ int drm_release(struct inode *inode, struct file *filp)
   */
 
  if (!--dev->open_count) {
-  if (atomic_read(&dev->ioctl_count)) {
-   DRM_ERROR("Device busy: %d\n",
-      atomic_read(&dev->ioctl_count));
-   retcode = -EBUSY;
-  } else
-   retcode = drm_lastclose(dev);
+  retcode = drm_lastclose(dev);
   if (drm_device_is_unplugged(dev))
    drm_put_dev(dev);
  }
diff --git a/drivers/gpu/drm/drm_gem.c b/drivers/gpu/drm/drm_gem.c
index cfd7708..5bbad87 100644
--- a/drivers/gpu/drm/drm_gem.c
+++ b/drivers/gpu/drm/drm_gem.c
@@ -91,19 +91,19 @@
 int
 drm_gem_init(struct drm_device *dev)
 {
- struct drm_gem_mm *mm;
+ struct drm_vma_offset_manager *vma_offset_manager;
 
  mutex_init(&dev->object_name_lock);
  idr_init(&dev->object_name_idr);
 
- mm = kzalloc(sizeof(struct drm_gem_mm), GFP_KERNEL);
- if (!mm) {
+ vma_offset_manager = kzalloc(sizeof(*vma_offset_manager), GFP_KERNEL);
+ if (!vma_offset_manager) {
   DRM_ERROR("out of memory\n");
   return -ENOMEM;
  }
 
- dev->mm_private = mm;
- drm_vma_offset_manager_init(&mm->vma_manager,
+ dev->vma_offset_manager = vma_offset_manager;
+ drm_vma_offset_manager_init(vma_offset_manager,
         DRM_FILE_PAGE_OFFSET_START,
         DRM_FILE_PAGE_OFFSET_SIZE);
 
@@ -113,11 +113,10 @@ drm_gem_init(struct drm_device *dev)
 void
 drm_gem_destroy(struct drm_device *dev)
 {
- struct drm_gem_mm *mm = dev->mm_private;
 
- drm_vma_offset_manager_destroy(&mm->vma_manager);
- kfree(mm);
- dev->mm_private = NULL;
+ drm_vma_offset_manager_destroy(dev->vma_offset_manager);
+ kfree(dev->vma_offset_manager);
+ dev->vma_offset_manager = NULL;
 }
 
 /**
@@ -176,11 +175,6 @@ drm_gem_remove_prime_handles(struct drm_gem_object *obj, struct drm_file *filp)
  mutex_unlock(&filp->prime.lock);
 }
 
-static void drm_gem_object_ref_bug(struct kref *list_kref)
-{
- BUG();
-}
-
 /**
  * Called after the last handle to the object has been closed
  *
@@ -196,13 +190,6 @@ static void drm_gem_object_handle_free(struct drm_gem_object *obj)
  if (obj->name) {
   idr_remove(&dev->object_name_idr, obj->name);
   obj->name = 0;
-  /*
-   * The object name held a reference to this object, drop
-   * that now.
-  *
-  * This cannot be the last reference, since the handle holds one too.
-   */
-  kref_put(&obj->refcount, drm_gem_object_ref_bug);
  }
 }
 
@@ -375,9 +362,8 @@ void
 drm_gem_free_mmap_offset(struct drm_gem_object *obj)
 {
  struct drm_device *dev = obj->dev;
- struct drm_gem_mm *mm = dev->mm_private;
 
- drm_vma_offset_remove(&mm->vma_manager, &obj->vma_node);
+ drm_vma_offset_remove(dev->vma_offset_manager, &obj->vma_node);
 }
 EXPORT_SYMBOL(drm_gem_free_mmap_offset);
 
@@ -399,9 +385,8 @@ int
 drm_gem_create_mmap_offset_size(struct drm_gem_object *obj, size_t size)
 {
  struct drm_device *dev = obj->dev;
- struct drm_gem_mm *mm = dev->mm_private;
 
- return drm_vma_offset_add(&mm->vma_manager, &obj->vma_node,
+ return drm_vma_offset_add(dev->vma_offset_manager, &obj->vma_node,
       size / PAGE_SIZE);
 }
 EXPORT_SYMBOL(drm_gem_create_mmap_offset_size);
@@ -603,9 +588,6 @@ drm_gem_flink_ioctl(struct drm_device *dev, void *data,
    goto err;
 
   obj->name = ret;
-
-  /* Allocate a reference for the name table.  */
-  drm_gem_object_reference(obj);
  }
 
  args->name = (uint64_t) obj->name;
@@ -834,7 +816,6 @@ int drm_gem_mmap(struct file *filp, struct vm_area_struct *vma)
 {
  struct drm_file *priv = filp->private_data;
  struct drm_device *dev = priv->minor->dev;
- struct drm_gem_mm *mm = dev->mm_private;
  struct drm_gem_object *obj;
  struct drm_vma_offset_node *node;
  int ret = 0;
@@ -844,7 +825,8 @@ int drm_gem_mmap(struct file *filp, struct vm_area_struct *vma)
 
  mutex_lock(&dev->struct_mutex);
 
- node = drm_vma_offset_exact_lookup(&mm->vma_manager, vma->vm_pgoff,
+ node = drm_vma_offset_exact_lookup(dev->vma_offset_manager,
+        vma->vm_pgoff,
         vma_pages(vma));
  if (!node) {
   mutex_unlock(&dev->struct_mutex);
diff --git a/drivers/gpu/drm/drm_info.c b/drivers/gpu/drm/drm_info.c
index 7d5a152..7473035 100644
--- a/drivers/gpu/drm/drm_info.c
+++ b/drivers/gpu/drm/drm_info.c
@@ -186,14 +186,14 @@ int drm_clients_info(struct seq_file *m, void *data)
  struct drm_file *priv;
 
  mutex_lock(&dev->struct_mutex);
- seq_printf(m, "a dev pid    uid magic   ioctls\n\n");
+ seq_printf(m, "a dev pid    uid magic\n\n");
  list_for_each_entry(priv, &dev->filelist, lhead) {
-  seq_printf(m, "%c %3d %5d %5d %10u %10lu\n",
+  seq_printf(m, "%c %3d %5d %5d %10u\n",
       priv->authenticated ? 'y' : 'n',
       priv->minor->index,
       pid_vnr(priv->pid),
       from_kuid_munged(seq_user_ns(m), priv->uid),
-      priv->magic, priv->ioctl_count);
+      priv->magic);
  }
  mutex_unlock(&dev->struct_mutex);
  return 0;
@@ -234,14 +234,18 @@ int drm_vma_info(struct seq_file *m, void *data)
  struct drm_device *dev = node->minor->dev;
  struct drm_vma_entry *pt;
  struct vm_area_struct *vma;
+ unsigned long vma_count = 0;
 #if defined(__i386__)
  unsigned int pgprot;
 #endif
 
  mutex_lock(&dev->struct_mutex);
- seq_printf(m, "vma use count: %d, high_memory = %pK, 0x%pK\n",
-     atomic_read(&dev->vma_count),
-     high_memory, (void *)(unsigned long)virt_to_phys(high_memory));
+ list_for_each_entry(pt, &dev->vmalist, head)
+  vma_count++;
+
+ seq_printf(m, "vma use count: %lu, high_memory = %pK, 0x%pK\n",
+     vma_count, high_memory,
+     (void *)(unsigned long)virt_to_phys(high_memory));
 
  list_for_each_entry(pt, &dev->vmalist, head) {
   vma = pt->vma;
diff --git a/drivers/gpu/drm/drm_ioctl.c b/drivers/gpu/drm/drm_ioctl.c
index dffc836..f4dc9b7 100644
--- a/drivers/gpu/drm/drm_ioctl.c
+++ b/drivers/gpu/drm/drm_ioctl.c
@@ -296,6 +296,18 @@ int drm_getcap(struct drm_device *dev, void *data, struct drm_file *file_priv)
  case DRM_CAP_ASYNC_PAGE_FLIP:
   req->value = dev->mode_config.async_page_flip;
   break;
+ case DRM_CAP_CURSOR_WIDTH:
+  if (dev->mode_config.cursor_width)
+   req->value = dev->mode_config.cursor_width;
+  else
+   req->value = 64;
+  break;
+ case DRM_CAP_CURSOR_HEIGHT:
+  if (dev->mode_config.cursor_height)
+   req->value = dev->mode_config.cursor_height;
+  else
+   req->value = 64;
+  break;
  default:
   return -EINVAL;
  }
diff --git a/drivers/gpu/drm/drm_irq.c b/drivers/gpu/drm/drm_irq.c
index 64c34d5..c2676b5 100644
--- a/drivers/gpu/drm/drm_irq.c
+++ b/drivers/gpu/drm/drm_irq.c
@@ -368,7 +368,7 @@ int drm_irq_uninstall(struct drm_device *dev)
  if (dev->num_crtcs) {
   spin_lock_irqsave(&dev->vbl_lock, irqflags);
   for (i = 0; i < dev->num_crtcs; i++) {
-   DRM_WAKEUP(&dev->vblank[i].queue);
+   wake_up(&dev->vblank[i].queue);
    dev->vblank[i].enabled = false;
    dev->vblank[i].last =
     dev->driver->get_vblank_counter(dev, i);
@@ -436,45 +436,41 @@ int drm_control(struct drm_device *dev, void *data,
 }
 
 /**
- * drm_calc_timestamping_constants - Calculate and
- * store various constants which are later needed by
- * vblank and swap-completion timestamping, e.g, by
- * drm_calc_vbltimestamp_from_scanoutpos().
- * They are derived from crtc's true scanout timing,
- * so they take things like panel scaling or other
- * adjustments into account.
+ * drm_calc_timestamping_constants - Calculate vblank timestamp constants
  *
  * @crtc drm_crtc whose timestamp constants should be updated.
+ * @mode display mode containing the scanout timings
  *
+ * Calculate and store various constants which are later
+ * needed by vblank and swap-completion timestamping, e.g,
+ * by drm_calc_vbltimestamp_from_scanoutpos(). They are
+ * derived from crtc's true scanout timing, so they take
+ * things like panel scaling or other adjustments into account.
  */
-void drm_calc_timestamping_constants(struct drm_crtc *crtc)
+void drm_calc_timestamping_constants(struct drm_crtc *crtc,
+         const struct drm_display_mode *mode)
 {
- s64 linedur_ns = 0, pixeldur_ns = 0, framedur_ns = 0;
- u64 dotclock;
-
- /* Dot clock in Hz: */
- dotclock = (u64) crtc->hwmode.clock * 1000;
-
- /* Fields of interlaced scanout modes are only half a frame duration.
-  * Double the dotclock to get half the frame-/line-/pixelduration.
-  */
- if (crtc->hwmode.flags & DRM_MODE_FLAG_INTERLACE)
-  dotclock *= 2;
+ int linedur_ns = 0, pixeldur_ns = 0, framedur_ns = 0;
+ int dotclock = mode->crtc_clock;
 
  /* Valid dotclock? */
  if (dotclock > 0) {
-  int frame_size;
-  /* Convert scanline length in pixels and video dot clock to
-   * line duration, frame duration and pixel duration in
-   * nanoseconds:
+  int frame_size = mode->crtc_htotal * mode->crtc_vtotal;
+
+  /*
+   * Convert scanline length in pixels and video
+   * dot clock to line duration, frame duration
+   * and pixel duration in nanoseconds:
    */
-  pixeldur_ns = (s64) div64_u64(1000000000, dotclock);
-  linedur_ns  = (s64) div64_u64(((u64) crtc->hwmode.crtc_htotal *
-           1000000000), dotclock);
-  frame_size = crtc->hwmode.crtc_htotal *
-    crtc->hwmode.crtc_vtotal;
-  framedur_ns = (s64) div64_u64((u64) frame_size * 1000000000,
-           dotclock);
+  pixeldur_ns = 1000000 / dotclock;
+  linedur_ns  = div_u64((u64) mode->crtc_htotal * 1000000, dotclock);
+  framedur_ns = div_u64((u64) frame_size * 1000000, dotclock);
+
+  /*
+   * Fields of interlaced scanout modes are only half a frame duration.
+   */
+  if (mode->flags & DRM_MODE_FLAG_INTERLACE)
+   framedur_ns /= 2;
  } else
   DRM_ERROR("crtc %d: Can't calculate constants, dotclock = 0!\n",
      crtc->base.id);
@@ -484,11 +480,11 @@ void drm_calc_timestamping_constants(struct drm_crtc *crtc)
  crtc->framedur_ns = framedur_ns;
 
  DRM_DEBUG("crtc %d: hwmode: htotal %d, vtotal %d, vdisplay %d\n",
-    crtc->base.id, crtc->hwmode.crtc_htotal,
-    crtc->hwmode.crtc_vtotal, crtc->hwmode.crtc_vdisplay);
+    crtc->base.id, mode->crtc_htotal,
+    mode->crtc_vtotal, mode->crtc_vdisplay);
  DRM_DEBUG("crtc %d: clock %d kHz framedur %d linedur %d, pixeldur %d\n",
-    crtc->base.id, (int) dotclock/1000, (int) framedur_ns,
-    (int) linedur_ns, (int) pixeldur_ns);
+    crtc->base.id, dotclock, framedur_ns,
+    linedur_ns, pixeldur_ns);
 }
 EXPORT_SYMBOL(drm_calc_timestamping_constants);
 
@@ -521,6 +517,7 @@ EXPORT_SYMBOL(drm_calc_timestamping_constants);
  *         0 = Default.
  *         DRM_CALLED_FROM_VBLIRQ = If function is called from vbl irq handler.
  * @refcrtc: drm_crtc* of crtc which defines scanout timing.
+ * @mode: mode which defines the scanout timings
  *
  * Returns negative value on error, failure or if not supported in current
  * video mode:
@@ -540,14 +537,14 @@ int drm_calc_vbltimestamp_from_scanoutpos(struct drm_device *dev, int crtc,
        int *max_error,
        struct timeval *vblank_time,
        unsigned flags,
-       struct drm_crtc *refcrtc)
+       const struct drm_crtc *refcrtc,
+       const struct drm_display_mode *mode)
 {
  ktime_t stime, etime, mono_time_offset;
  struct timeval tv_etime;
- struct drm_display_mode *mode;
- int vbl_status, vtotal, vdisplay;
+ int vbl_status;
  int vpos, hpos, i;
- s64 framedur_ns, linedur_ns, pixeldur_ns, delta_ns, duration_ns;
+ int framedur_ns, linedur_ns, pixeldur_ns, delta_ns, duration_ns;
  bool invbl;
 
  if (crtc < 0 || crtc >= dev->num_crtcs) {
@@ -561,10 +558,6 @@ int drm_calc_vbltimestamp_from_scanoutpos(struct drm_device *dev, int crtc,
   return -EIO;
  }
 
- mode = &refcrtc->hwmode;
- vtotal = mode->crtc_vtotal;
- vdisplay = mode->crtc_vdisplay;
-
  /* Durations of frames, lines, pixels in nanoseconds. */
  framedur_ns = refcrtc->framedur_ns;
  linedur_ns  = refcrtc->linedur_ns;
@@ -573,7 +566,7 @@ int drm_calc_vbltimestamp_from_scanoutpos(struct drm_device *dev, int crtc,
  /* If mode timing undefined, just return as no-op:
   * Happens during initial modesetting of a crtc.
   */
- if (vtotal <= 0 || vdisplay <= 0 || framedur_ns == 0) {
+ if (framedur_ns == 0) {
   DRM_DEBUG("crtc %d: Noop due to uninitialized mode.\n", crtc);
   return -EAGAIN;
  }
@@ -590,7 +583,7 @@ int drm_calc_vbltimestamp_from_scanoutpos(struct drm_device *dev, int crtc,
    * Get vertical and horizontal scanout position vpos, hpos,
    * and bounding timestamps stime, etime, pre/post query.
    */
-  vbl_status = dev->driver->get_scanout_position(dev, crtc, &vpos,
+  vbl_status = dev->driver->get_scanout_position(dev, crtc, flags, &vpos,
               &hpos, &stime, &etime);
 
   /*
@@ -611,18 +604,18 @@ int drm_calc_vbltimestamp_from_scanoutpos(struct drm_device *dev, int crtc,
   duration_ns = ktime_to_ns(etime) - ktime_to_ns(stime);
 
   /* Accept result with <  max_error nsecs timing uncertainty. */
-  if (duration_ns <= (s64) *max_error)
+  if (duration_ns <= *max_error)
    break;
  }
 
  /* Noisy system timing? */
  if (i == DRM_TIMESTAMP_MAXRETRIES) {
   DRM_DEBUG("crtc %d: Noisy timestamp %d us > %d us [%d reps].\n",
-     crtc, (int) duration_ns/1000, *max_error/1000, i);
+     crtc, duration_ns/1000, *max_error/1000, i);
  }
 
  /* Return upper bound of timestamp precision error. */
- *max_error = (int) duration_ns;
+ *max_error = duration_ns;
 
  /* Check if in vblank area:
   * vpos is >=0 in video scanout area, but negative
@@ -635,25 +628,7 @@ int drm_calc_vbltimestamp_from_scanoutpos(struct drm_device *dev, int crtc,
   * since start of scanout at first display scanline. delta_ns
   * can be negative if start of scanout hasn't happened yet.
   */
- delta_ns = (s64) vpos * linedur_ns + (s64) hpos * pixeldur_ns;
-
- /* Is vpos outside nominal vblank area, but less than
-  * 1/100 of a frame height away from start of vblank?
-  * If so, assume this isn't a massively delayed vblank
-  * interrupt, but a vblank interrupt that fired a few
-  * microseconds before true start of vblank. Compensate
-  * by adding a full frame duration to the final timestamp.
-  * Happens, e.g., on ATI R500, R600.
-  *
-  * We only do this if DRM_CALLED_FROM_VBLIRQ.
-  */
- if ((flags & DRM_CALLED_FROM_VBLIRQ) && !invbl &&
-     ((vdisplay - vpos) < vtotal / 100)) {
-  delta_ns = delta_ns - framedur_ns;
-
-  /* Signal this correction as "applied". */
-  vbl_status |= 0x8;
- }
+ delta_ns = vpos * linedur_ns + hpos * pixeldur_ns;
 
  if (!drm_timestamp_monotonic)
   etime = ktime_sub(etime, mono_time_offset);
@@ -673,7 +648,7 @@ int drm_calc_vbltimestamp_from_scanoutpos(struct drm_device *dev, int crtc,
     crtc, (int)vbl_status, hpos, vpos,
     (long)tv_etime.tv_sec, (long)tv_etime.tv_usec,
     (long)vblank_time->tv_sec, (long)vblank_time->tv_usec,
-    (int)duration_ns/1000, i);
+    duration_ns/1000, i);
 
  vbl_status = DRM_VBLANKTIME_SCANOUTPOS_METHOD;
  if (invbl)
@@ -960,7 +935,7 @@ void drm_vblank_put(struct drm_device *dev, int crtc)
  if (atomic_dec_and_test(&dev->vblank[crtc].refcount) &&
      (drm_vblank_offdelay > 0))
   mod_timer(&dev->vblank_disable_timer,
-     jiffies + ((drm_vblank_offdelay * DRM_HZ)/1000));
+     jiffies + ((drm_vblank_offdelay * HZ)/1000));
 }
 EXPORT_SYMBOL(drm_vblank_put);
 
@@ -980,7 +955,7 @@ void drm_vblank_off(struct drm_device *dev, int crtc)
 
  spin_lock_irqsave(&dev->vbl_lock, irqflags);
  vblank_disable_and_save(dev, crtc);
- DRM_WAKEUP(&dev->vblank[crtc].queue);
+ wake_up(&dev->vblank[crtc].queue);
 
  /* Send any queued vblank events, lest the natives grow disquiet */
  seq = drm_vblank_count_and_time(dev, crtc, &now);
@@ -1244,7 +1219,7 @@ int drm_wait_vblank(struct drm_device *dev, void *data,
  DRM_DEBUG("waiting on vblank count %d, crtc %d\n",
     vblwait->request.sequence, crtc);
  dev->vblank[crtc].last_wait = vblwait->request.sequence;
- DRM_WAIT_ON(ret, dev->vblank[crtc].queue, 3 * DRM_HZ,
+ DRM_WAIT_ON(ret, dev->vblank[crtc].queue, 3 * HZ,
       (((drm_vblank_count(dev, crtc) -
          vblwait->request.sequence) <= (1 << 23)) ||
        !dev->irq_enabled));
@@ -1363,7 +1338,7 @@ bool drm_handle_vblank(struct drm_device *dev, int crtc)
      crtc, (int) diff_ns);
  }
 
- DRM_WAKEUP(&dev->vblank[crtc].queue);
+ wake_up(&dev->vblank[crtc].queue);
  drm_handle_vblank_events(dev, crtc);
 
  spin_unlock_irqrestore(&dev->vblank_time_lock, irqflags);
diff --git a/drivers/gpu/drm/drm_memory.c b/drivers/gpu/drm/drm_memory.c
index 64e44fa..00c67c0 100644
--- a/drivers/gpu/drm/drm_memory.c
+++ b/drivers/gpu/drm/drm_memory.c
@@ -82,19 +82,19 @@ static void *agp_remap(unsigned long offset, unsigned long size,
 }
 
 /** Wrapper around agp_free_memory() */
-void drm_free_agp(DRM_AGP_MEM * handle, int pages)
+void drm_free_agp(struct agp_memory * handle, int pages)
 {
  agp_free_memory(handle);
 }
 
 /** Wrapper around agp_bind_memory() */
-int drm_bind_agp(DRM_AGP_MEM * handle, unsigned int start)
+int drm_bind_agp(struct agp_memory * handle, unsigned int start)
 {
  return agp_bind_memory(handle, start);
 }
 
 /** Wrapper around agp_unbind_memory() */
-int drm_unbind_agp(DRM_AGP_MEM * handle)
+int drm_unbind_agp(struct agp_memory * handle)
 {
  return agp_unbind_memory(handle);
 }
@@ -110,8 +110,7 @@ static inline void *agp_remap(unsigned long offset, unsigned long size,
 
 void drm_core_ioremap(struct drm_local_map *map, struct drm_device *dev)
 {
- if (drm_core_has_AGP(dev) &&
-     dev->agp && dev->agp->cant_use_aperture && map->type == _DRM_AGP)
+ if (dev->agp && dev->agp->cant_use_aperture && map->type == _DRM_AGP)
   map->handle = agp_remap(map->offset, map->size, dev);
  else
   map->handle = ioremap(map->offset, map->size);
@@ -120,8 +119,7 @@ EXPORT_SYMBOL(drm_core_ioremap);
 
 void drm_core_ioremap_wc(struct drm_local_map *map, struct drm_device *dev)
 {
- if (drm_core_has_AGP(dev) &&
-     dev->agp && dev->agp->cant_use_aperture && map->type == _DRM_AGP)
+ if (dev->agp && dev->agp->cant_use_aperture && map->type == _DRM_AGP)
   map->handle = agp_remap(map->offset, map->size, dev);
  else
   map->handle = ioremap_wc(map->offset, map->size);
@@ -133,8 +131,7 @@ void drm_core_ioremapfree(struct drm_local_map *map, struct drm_device *dev)
  if (!map->handle || !map->size)
   return;
 
- if (drm_core_has_AGP(dev) &&
-     dev->agp && dev->agp->cant_use_aperture && map->type == _DRM_AGP)
+ if (dev->agp && dev->agp->cant_use_aperture && map->type == _DRM_AGP)
   vunmap(map->handle);
  else
   iounmap(map->handle);
diff --git a/drivers/gpu/drm/drm_mipi_dsi.c b/drivers/gpu/drm/drm_mipi_dsi.c
new file mode 100644
index 0000000..b155ee2
--- /dev/null
+++ b/drivers/gpu/drm/drm_mipi_dsi.c
@@ -0,0 +1,315 @@
+/*
+ * MIPI DSI Bus
+ *
+ * Copyright (C) 2012-2013, Samsung Electronics, Co., Ltd.
+ * Andrzej Hajda <a.hajda@samsung.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDERS, AUTHORS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM,
+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
+ * USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include <drm/drm_mipi_dsi.h>
+
+#include <linux/device.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/slab.h>
+
+#include <video/mipi_display.h>
+
+static int mipi_dsi_device_match(struct device *dev, struct device_driver *drv)
+{
+ return of_driver_match_device(dev, drv);
+}
+
+static const struct dev_pm_ops mipi_dsi_device_pm_ops = {
+ .runtime_suspend = pm_generic_runtime_suspend,
+ .runtime_resume = pm_generic_runtime_resume,
+ .suspend = pm_generic_suspend,
+ .resume = pm_generic_resume,
+ .freeze = pm_generic_freeze,
+ .thaw = pm_generic_thaw,
+ .poweroff = pm_generic_poweroff,
+ .restore = pm_generic_restore,
+};
+
+static struct bus_type mipi_dsi_bus_type = {
+ .name = "mipi-dsi",
+ .match = mipi_dsi_device_match,
+ .pm = &mipi_dsi_device_pm_ops,
+};
+
+static void mipi_dsi_dev_release(struct device *dev)
+{
+ struct mipi_dsi_device *dsi = to_mipi_dsi_device(dev);
+
+ of_node_put(dev->of_node);
+ kfree(dsi);
+}
+
+static const struct device_type mipi_dsi_device_type = {
+ .release = mipi_dsi_dev_release,
+};
+
+static struct mipi_dsi_device *mipi_dsi_device_alloc(struct mipi_dsi_host *host)
+{
+ struct mipi_dsi_device *dsi;
+
+ dsi = kzalloc(sizeof(*dsi), GFP_KERNEL);
+ if (!dsi)
+  return ERR_PTR(-ENOMEM);
+
+ dsi->host = host;
+ dsi->dev.bus = &mipi_dsi_bus_type;
+ dsi->dev.parent = host->dev;
+ dsi->dev.type = &mipi_dsi_device_type;
+
+ device_initialize(&dsi->dev);
+
+ return dsi;
+}
+
+static int mipi_dsi_device_add(struct mipi_dsi_device *dsi)
+{
+ struct mipi_dsi_host *host = dsi->host;
+
+ dev_set_name(&dsi->dev, "%s.%d", dev_name(host->dev),  dsi->channel);
+
+ return device_add(&dsi->dev);
+}
+
+static struct mipi_dsi_device *
+of_mipi_dsi_device_add(struct mipi_dsi_host *host, struct device_node *node)
+{
+ struct mipi_dsi_device *dsi;
+ struct device *dev = host->dev;
+ int ret;
+ u32 reg;
+
+ ret = of_property_read_u32(node, "reg", &reg);
+ if (ret) {
+  dev_err(dev, "device node %s has no valid reg property: %d\n",
+   node->full_name, ret);
+  return ERR_PTR(-EINVAL);
+ }
+
+ if (reg > 3) {
+  dev_err(dev, "device node %s has invalid reg property: %u\n",
+   node->full_name, reg);
+  return ERR_PTR(-EINVAL);
+ }
+
+ dsi = mipi_dsi_device_alloc(host);
+ if (IS_ERR(dsi)) {
+  dev_err(dev, "failed to allocate DSI device %s: %ld\n",
+   node->full_name, PTR_ERR(dsi));
+  return dsi;
+ }
+
+ dsi->dev.of_node = of_node_get(node);
+ dsi->channel = reg;
+
+ ret = mipi_dsi_device_add(dsi);
+ if (ret) {
+  dev_err(dev, "failed to add DSI device %s: %d\n",
+   node->full_name, ret);
+  kfree(dsi);
+  return ERR_PTR(ret);
+ }
+
+ return dsi;
+}
+
+int mipi_dsi_host_register(struct mipi_dsi_host *host)
+{
+ struct device_node *node;
+
+ for_each_available_child_of_node(host->dev->of_node, node)
+  of_mipi_dsi_device_add(host, node);
+
+ return 0;
+}
+EXPORT_SYMBOL(mipi_dsi_host_register);
+
+static int mipi_dsi_remove_device_fn(struct device *dev, void *priv)
+{
+ struct mipi_dsi_device *dsi = to_mipi_dsi_device(dev);
+
+ device_unregister(&dsi->dev);
+
+ return 0;
+}
+
+void mipi_dsi_host_unregister(struct mipi_dsi_host *host)
+{
+ device_for_each_child(host->dev, NULL, mipi_dsi_remove_device_fn);
+}
+EXPORT_SYMBOL(mipi_dsi_host_unregister);
+
+/**
+ * mipi_dsi_attach - attach a DSI device to its DSI host
+ * @dsi: DSI peripheral
+ */
+int mipi_dsi_attach(struct mipi_dsi_device *dsi)
+{
+ const struct mipi_dsi_host_ops *ops = dsi->host->ops;
+
+ if (!ops || !ops->attach)
+  return -ENOSYS;
+
+ return ops->attach(dsi->host, dsi);
+}
+EXPORT_SYMBOL(mipi_dsi_attach);
+
+/**
+ * mipi_dsi_detach - detach a DSI device from its DSI host
+ * @dsi: DSI peripheral
+ */
+int mipi_dsi_detach(struct mipi_dsi_device *dsi)
+{
+ const struct mipi_dsi_host_ops *ops = dsi->host->ops;
+
+ if (!ops || !ops->detach)
+  return -ENOSYS;
+
+ return ops->detach(dsi->host, dsi);
+}
+EXPORT_SYMBOL(mipi_dsi_detach);
+
+/**
+ * mipi_dsi_dcs_write - send DCS write command
+ * @dsi: DSI device
+ * @channel: virtual channel
+ * @data: pointer to the command followed by parameters
+ * @len: length of @data
+ */
+int mipi_dsi_dcs_write(struct mipi_dsi_device *dsi, unsigned int channel,
+         const void *data, size_t len)
+{
+ const struct mipi_dsi_host_ops *ops = dsi->host->ops;
+ struct mipi_dsi_msg msg = {
+  .channel = channel,
+  .tx_buf = data,
+  .tx_len = len
+ };
+
+ if (!ops || !ops->transfer)
+  return -ENOSYS;
+
+ switch (len) {
+ case 0:
+  return -EINVAL;
+ case 1:
+  msg.type = MIPI_DSI_DCS_SHORT_WRITE;
+  break;
+ case 2:
+  msg.type = MIPI_DSI_DCS_SHORT_WRITE_PARAM;
+  break;
+ default:
+  msg.type = MIPI_DSI_DCS_LONG_WRITE;
+  break;
+ }
+
+ return ops->transfer(dsi->host, &msg);
+}
+EXPORT_SYMBOL(mipi_dsi_dcs_write);
+
+/**
+ * mipi_dsi_dcs_read - send DCS read request command
+ * @dsi: DSI device
+ * @channel: virtual channel
+ * @cmd: DCS read command
+ * @data: pointer to read buffer
+ * @len: length of @data
+ *
+ * Function returns number of read bytes or error code.
+ */
+ssize_t mipi_dsi_dcs_read(struct mipi_dsi_device *dsi, unsigned int channel,
+     u8 cmd, void *data, size_t len)
+{
+ const struct mipi_dsi_host_ops *ops = dsi->host->ops;
+ struct mipi_dsi_msg msg = {
+  .channel = channel,
+  .type = MIPI_DSI_DCS_READ,
+  .tx_buf = &cmd,
+  .tx_len = 1,
+  .rx_buf = data,
+  .rx_len = len
+ };
+
+ if (!ops || !ops->transfer)
+  return -ENOSYS;
+
+ return ops->transfer(dsi->host, &msg);
+}
+EXPORT_SYMBOL(mipi_dsi_dcs_read);
+
+static int mipi_dsi_drv_probe(struct device *dev)
+{
+ struct mipi_dsi_driver *drv = to_mipi_dsi_driver(dev->driver);
+ struct mipi_dsi_device *dsi = to_mipi_dsi_device(dev);
+
+ return drv->probe(dsi);
+}
+
+static int mipi_dsi_drv_remove(struct device *dev)
+{
+ struct mipi_dsi_driver *drv = to_mipi_dsi_driver(dev->driver);
+ struct mipi_dsi_device *dsi = to_mipi_dsi_device(dev);
+
+ return drv->remove(dsi);
+}
+
+/**
+ * mipi_dsi_driver_register - register a driver for DSI devices
+ * @drv: DSI driver structure
+ */
+int mipi_dsi_driver_register(struct mipi_dsi_driver *drv)
+{
+ drv->driver.bus = &mipi_dsi_bus_type;
+ if (drv->probe)
+  drv->driver.probe = mipi_dsi_drv_probe;
+ if (drv->remove)
+  drv->driver.remove = mipi_dsi_drv_remove;
+
+ return driver_register(&drv->driver);
+}
+EXPORT_SYMBOL(mipi_dsi_driver_register);
+
+/**
+ * mipi_dsi_driver_unregister - unregister a driver for DSI devices
+ * @drv: DSI driver structure
+ */
+void mipi_dsi_driver_unregister(struct mipi_dsi_driver *drv)
+{
+ driver_unregister(&drv->driver);
+}
+EXPORT_SYMBOL(mipi_dsi_driver_unregister);
+
+static int __init mipi_dsi_bus_init(void)
+{
+ return bus_register(&mipi_dsi_bus_type);
+}
+postcore_initcall(mipi_dsi_bus_init);
+
+MODULE_AUTHOR("Andrzej Hajda <a.hajda@samsung.com>");
+MODULE_DESCRIPTION("MIPI DSI Bus");
+MODULE_LICENSE("GPL and additional rights");
diff --git a/drivers/gpu/drm/drm_panel.c b/drivers/gpu/drm/drm_panel.c
new file mode 100644
index 0000000..2ef988e
--- /dev/null
+++ b/drivers/gpu/drm/drm_panel.c
@@ -0,0 +1,100 @@
+/*
+ * Copyright (C) 2013, NVIDIA Corporation.  All rights reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sub license,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include <linux/err.h>
+#include <linux/module.h>
+
+#include <drm/drm_crtc.h>
+#include <drm/drm_panel.h>
+
+static DEFINE_MUTEX(panel_lock);
+static LIST_HEAD(panel_list);
+
+void drm_panel_init(struct drm_panel *panel)
+{
+ INIT_LIST_HEAD(&panel->list);
+}
+EXPORT_SYMBOL(drm_panel_init);
+
+int drm_panel_add(struct drm_panel *panel)
+{
+ mutex_lock(&panel_lock);
+ list_add_tail(&panel->list, &panel_list);
+ mutex_unlock(&panel_lock);
+
+ return 0;
+}
+EXPORT_SYMBOL(drm_panel_add);
+
+void drm_panel_remove(struct drm_panel *panel)
+{
+ mutex_lock(&panel_lock);
+ list_del_init(&panel->list);
+ mutex_unlock(&panel_lock);
+}
+EXPORT_SYMBOL(drm_panel_remove);
+
+int drm_panel_attach(struct drm_panel *panel, struct drm_connector *connector)
+{
+ if (panel->connector)
+  return -EBUSY;
+
+ panel->connector = connector;
+ panel->drm = connector->dev;
+
+ return 0;
+}
+EXPORT_SYMBOL(drm_panel_attach);
+
+int drm_panel_detach(struct drm_panel *panel)
+{
+ panel->connector = NULL;
+ panel->drm = NULL;
+
+ return 0;
+}
+EXPORT_SYMBOL(drm_panel_detach);
+
+#ifdef CONFIG_OF
+struct drm_panel *of_drm_find_panel(struct device_node *np)
+{
+ struct drm_panel *panel;
+
+ mutex_lock(&panel_lock);
+
+ list_for_each_entry(panel, &panel_list, list) {
+  if (panel->dev->of_node == np) {
+   mutex_unlock(&panel_lock);
+   return panel;
+  }
+ }
+
+ mutex_unlock(&panel_lock);
+ return NULL;
+}
+EXPORT_SYMBOL(of_drm_find_panel);
+#endif
+
+MODULE_AUTHOR("Thierry Reding <treding@nvidia.com>");
+MODULE_DESCRIPTION("DRM panel infrastructure");
+MODULE_LICENSE("GPL and additional rights");
diff --git a/drivers/gpu/drm/drm_pci.c b/drivers/gpu/drm/drm_pci.c
index 0267979..f7af69b 100644
--- a/drivers/gpu/drm/drm_pci.c
+++ b/drivers/gpu/drm/drm_pci.c
@@ -262,16 +262,11 @@ static int drm_pci_irq_by_busid(struct drm_device *dev, struct drm_irq_busid *p)
  return 0;
 }
 
-static int drm_pci_agp_init(struct drm_device *dev)
+static void drm_pci_agp_init(struct drm_device *dev)
 {
- if (drm_core_has_AGP(dev)) {
+ if (drm_core_check_feature(dev, DRIVER_USE_AGP)) {
   if (drm_pci_device_is_agp(dev))
    dev->agp = drm_agp_init(dev);
-  if (drm_core_check_feature(dev, DRIVER_REQUIRE_AGP)
-      && (dev->agp == NULL)) {
-   DRM_ERROR("Cannot initialize the agpgart module.\n");
-   return -EINVAL;
-  }
   if (dev->agp) {
    dev->agp->agp_mtrr = arch_phys_wc_add(
     dev->agp->agp_info.aper_base,
@@ -279,15 +274,14 @@ static int drm_pci_agp_init(struct drm_device *dev)
     1024 * 1024);
   }
  }
- return 0;
 }
 
-static void drm_pci_agp_destroy(struct drm_device *dev)
+void drm_pci_agp_destroy(struct drm_device *dev)
 {
- if (drm_core_has_AGP(dev) && dev->agp) {
+ if (dev->agp) {
   arch_phys_wc_del(dev->agp->agp_mtrr);
   drm_agp_clear(dev);
-  drm_agp_destroy(dev->agp);
+  kfree(dev->agp);
   dev->agp = NULL;
  }
 }
@@ -299,8 +293,6 @@ static struct drm_bus drm_pci_bus = {
  .set_busid = drm_pci_set_busid,
  .set_unique = drm_pci_set_unique,
  .irq_by_busid = drm_pci_irq_by_busid,
- .agp_init = drm_pci_agp_init,
- .agp_destroy = drm_pci_agp_destroy,
 };
 
 /**
@@ -338,17 +330,25 @@ int drm_get_pci_dev(struct pci_dev *pdev, const struct pci_device_id *ent,
  if (drm_core_check_feature(dev, DRIVER_MODESET))
   pci_set_drvdata(pdev, dev);
 
+ drm_pci_agp_init(dev);
+
  ret = drm_dev_register(dev, ent->driver_data);
  if (ret)
-  goto err_pci;
+  goto err_agp;
 
  DRM_INFO("Initialized %s %d.%d.%d %s for %s on minor %d\n",
    driver->name, driver->major, driver->minor, driver->patchlevel,
    driver->date, pci_name(pdev), dev->primary->index);
 
+ /* No locking needed since shadow-attach is single-threaded since it may
+  * only be called from the per-driver module init hook. */
+ if (!drm_core_check_feature(dev, DRIVER_MODESET))
+  list_add_tail(&dev->legacy_dev_list, &driver->legacy_dev_list);
+
  return 0;
 
-err_pci:
+err_agp:
+ drm_pci_agp_destroy(dev);
  pci_disable_device(pdev);
 err_free:
  drm_dev_free(dev);
@@ -375,7 +375,6 @@ int drm_pci_init(struct drm_driver *driver, struct pci_driver *pdriver)
 
  DRM_DEBUG("\n");
 
- INIT_LIST_HEAD(&driver->device_list);
  driver->kdriver.pci = pdriver;
  driver->bus = &drm_pci_bus;
 
@@ -383,6 +382,7 @@ int drm_pci_init(struct drm_driver *driver, struct pci_driver *pdriver)
   return pci_register_driver(pdriver);
 
  /* If not using KMS, fall back to stealth mode manual scanning. */
+ INIT_LIST_HEAD(&driver->legacy_dev_list);
  for (i = 0; pdriver->id_table[i].vendor != 0; i++) {
   pid = &pdriver->id_table[i];
 
@@ -452,6 +452,7 @@ int drm_pci_init(struct drm_driver *driver, struct pci_driver *pdriver)
  return -1;
 }
 
+void drm_pci_agp_destroy(struct drm_device *dev) {}
 #endif
 
 EXPORT_SYMBOL(drm_pci_init);
@@ -465,8 +466,11 @@ void drm_pci_exit(struct drm_driver *driver, struct pci_driver *pdriver)
  if (driver->driver_features & DRIVER_MODESET) {
   pci_unregister_driver(pdriver);
  } else {
-  list_for_each_entry_safe(dev, tmp, &driver->device_list, driver_item)
+  list_for_each_entry_safe(dev, tmp, &driver->legacy_dev_list,
+      legacy_dev_list) {
+   list_del(&dev->legacy_dev_list);
    drm_put_dev(dev);
+  }
  }
  DRM_INFO("Module unloaded\n");
 }
diff --git a/drivers/gpu/drm/drm_platform.c b/drivers/gpu/drm/drm_platform.c
index fc24fee..21fc820 100644
--- a/drivers/gpu/drm/drm_platform.c
+++ b/drivers/gpu/drm/drm_platform.c
@@ -147,18 +147,6 @@ int drm_platform_init(struct drm_driver *driver, struct platform_device *platfor
 
  driver->kdriver.platform_device = platform_device;
  driver->bus = &drm_platform_bus;
- INIT_LIST_HEAD(&driver->device_list);
  return drm_get_platform_dev(platform_device, driver);
 }
 EXPORT_SYMBOL(drm_platform_init);
-
-void drm_platform_exit(struct drm_driver *driver, struct platform_device *platform_device)
-{
- struct drm_device *dev, *tmp;
- DRM_DEBUG("\n");
-
- list_for_each_entry_safe(dev, tmp, &driver->device_list, driver_item)
-  drm_put_dev(dev);
- DRM_INFO("Module unloaded\n");
-}
-EXPORT_SYMBOL(drm_platform_exit);
diff --git a/drivers/gpu/drm/drm_stub.c b/drivers/gpu/drm/drm_stub.c
index 66dd3a0..98a33c5 100644
--- a/drivers/gpu/drm/drm_stub.c
+++ b/drivers/gpu/drm/drm_stub.c
@@ -99,13 +99,19 @@ void drm_ut_debug_printk(unsigned int request_level,
     const char *function_name,
     const char *format, ...)
 {
+ struct va_format vaf;
  va_list args;
 
  if (drm_debug & request_level) {
-  if (function_name)
-   printk(KERN_DEBUG "[%s:%s], ", prefix, function_name);
   va_start(args, format);
-  vprintk(format, args);
+  vaf.fmt = format;
+  vaf.va = &args;
+
+  if (function_name)
+   printk(KERN_DEBUG "[%s:%s], %pV", prefix,
+          function_name, &vaf);
+  else
+   printk(KERN_DEBUG "%pV", &vaf);
   va_end(args);
  }
 }
@@ -521,16 +527,10 @@ int drm_dev_register(struct drm_device *dev, unsigned long flags)
 
  mutex_lock(&drm_global_mutex);
 
- if (dev->driver->bus->agp_init) {
-  ret = dev->driver->bus->agp_init(dev);
-  if (ret)
-   goto out_unlock;
- }
-
  if (drm_core_check_feature(dev, DRIVER_MODESET)) {
   ret = drm_get_minor(dev, &dev->control, DRM_MINOR_CONTROL);
   if (ret)
-   goto err_agp;
+   goto out_unlock;
  }
 
  if (drm_core_check_feature(dev, DRIVER_RENDER) && drm_rnodes) {
@@ -557,8 +557,6 @@ int drm_dev_register(struct drm_device *dev, unsigned long flags)
    goto err_unload;
  }
 
- list_add_tail(&dev->driver_item, &dev->driver->device_list);
-
  ret = 0;
  goto out_unlock;
 
@@ -571,9 +569,6 @@ err_render_node:
  drm_unplug_minor(dev->render);
 err_control_node:
  drm_unplug_minor(dev->control);
-err_agp:
- if (dev->driver->bus->agp_destroy)
-  dev->driver->bus->agp_destroy(dev);
 out_unlock:
  mutex_unlock(&drm_global_mutex);
  return ret;
@@ -597,8 +592,8 @@ void drm_dev_unregister(struct drm_device *dev)
  if (dev->driver->unload)
   dev->driver->unload(dev);
 
- if (dev->driver->bus->agp_destroy)
-  dev->driver->bus->agp_destroy(dev);
+ if (dev->agp)
+  drm_pci_agp_destroy(dev);
 
  drm_vblank_cleanup(dev);
 
@@ -608,7 +603,5 @@ void drm_dev_unregister(struct drm_device *dev)
  drm_unplug_minor(dev->control);
  drm_unplug_minor(dev->render);
  drm_unplug_minor(dev->primary);
-
- list_del(&dev->driver_item);
 }
 EXPORT_SYMBOL(drm_dev_unregister);
diff --git a/drivers/gpu/drm/drm_usb.c b/drivers/gpu/drm/drm_usb.c
index b179b70..0f8cb1a 100644
--- a/drivers/gpu/drm/drm_usb.c
+++ b/drivers/gpu/drm/drm_usb.c
@@ -1,4 +1,5 @@
 #include <drm/drmP.h>
+#include <drm/drm_usb.h>
 #include <linux/usb.h>
 #include <linux/module.h>
 
@@ -63,7 +64,6 @@ int drm_usb_init(struct drm_driver *driver, struct usb_driver *udriver)
  int res;
  DRM_DEBUG("\n");
 
- INIT_LIST_HEAD(&driver->device_list);
  driver->kdriver.usb = udriver;
  driver->bus = &drm_usb_bus;
 
diff --git a/drivers/gpu/drm/drm_vm.c b/drivers/gpu/drm/drm_vm.c
index 93e95d7..24e045c 100644
--- a/drivers/gpu/drm/drm_vm.c
+++ b/drivers/gpu/drm/drm_vm.c
@@ -101,7 +101,7 @@ static int drm_do_vm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
  /*
   * Find the right map
   */
- if (!drm_core_has_AGP(dev))
+ if (!dev->agp)
   goto vm_fault_error;
 
  if (!dev->agp || !dev->agp->cant_use_aperture)
@@ -220,7 +220,6 @@ static void drm_vm_shm_close(struct vm_area_struct *vma)
 
  DRM_DEBUG("0x%08lx,0x%08lx\n",
     vma->vm_start, vma->vm_end - vma->vm_start);
- atomic_dec(&dev->vma_count);
 
  map = vma->vm_private_data;
 
@@ -266,9 +265,6 @@ static void drm_vm_shm_close(struct vm_area_struct *vma)
     dmah.size = map->size;
     __drm_pci_free(dev, &dmah);
     break;
-   case _DRM_GEM:
-    DRM_ERROR("tried to rmmap GEM object\n");
-    break;
    }
    kfree(map);
   }
@@ -408,7 +404,6 @@ void drm_vm_open_locked(struct drm_device *dev,
 
  DRM_DEBUG("0x%08lx,0x%08lx\n",
     vma->vm_start, vma->vm_end - vma->vm_start);
- atomic_inc(&dev->vma_count);
 
  vma_entry = kmalloc(sizeof(*vma_entry), GFP_KERNEL);
  if (vma_entry) {
@@ -436,7 +431,6 @@ void drm_vm_close_locked(struct drm_device *dev,
 
  DRM_DEBUG("0x%08lx,0x%08lx\n",
     vma->vm_start, vma->vm_end - vma->vm_start);
- atomic_dec(&dev->vma_count);
 
  list_for_each_entry_safe(pt, temp, &dev->vmalist, head) {
   if (pt->vma == vma) {
@@ -595,7 +589,7 @@ int drm_mmap_locked(struct file *filp, struct vm_area_struct *vma)
  switch (map->type) {
 #if !defined(__arm__)
  case _DRM_AGP:
-  if (drm_core_has_AGP(dev) && dev->agp->cant_use_aperture) {
+  if (dev->agp && dev->agp->cant_use_aperture) {
    /*
     * On some platforms we can't talk to bus dma address from the CPU, so for
     * memory of type DRM_AGP, we'll deal with sorting out the real physical
diff --git a/drivers/gpu/drm/gma500/accel_2d.c b/drivers/gpu/drm/gma500/accel_2d.c
index d5ef1a5..de6f62a 100644
--- a/drivers/gpu/drm/gma500/accel_2d.c
+++ b/drivers/gpu/drm/gma500/accel_2d.c
@@ -326,7 +326,7 @@ int psbfb_sync(struct fb_info *info)
  struct psb_framebuffer *psbfb = &fbdev->pfb;
  struct drm_device *dev = psbfb->base.dev;
  struct drm_psb_private *dev_priv = dev->dev_private;
- unsigned long _end = jiffies + DRM_HZ;
+ unsigned long _end = jiffies + HZ;
  int busy = 0;
  unsigned long flags;
 
diff --git a/drivers/gpu/drm/gma500/backlight.c b/drivers/gpu/drm/gma500/backlight.c
index 143eba3..ea7dfc5 100644
--- a/drivers/gpu/drm/gma500/backlight.c
+++ b/drivers/gpu/drm/gma500/backlight.c
@@ -26,13 +26,13 @@
 #include "intel_bios.h"
 #include "power.h"
 
+#ifdef CONFIG_BACKLIGHT_CLASS_DEVICE
 static void do_gma_backlight_set(struct drm_device *dev)
 {
-#ifdef CONFIG_BACKLIGHT_CLASS_DEVICE
  struct drm_psb_private *dev_priv = dev->dev_private;
  backlight_update_status(dev_priv->backlight_device);
-#endif 
 }
+#endif
 
 void gma_backlight_enable(struct drm_device *dev)
 {
diff --git a/drivers/gpu/drm/gma500/cdv_intel_dp.c b/drivers/gpu/drm/gma500/cdv_intel_dp.c
index f88a181..0490ce3 100644
--- a/drivers/gpu/drm/gma500/cdv_intel_dp.c
+++ b/drivers/gpu/drm/gma500/cdv_intel_dp.c
@@ -483,7 +483,7 @@ cdv_intel_dp_aux_native_write(struct gma_encoder *encoder,
 
  if (send_bytes > 16)
   return -1;
- msg[0] = AUX_NATIVE_WRITE << 4;
+ msg[0] = DP_AUX_NATIVE_WRITE << 4;
  msg[1] = address >> 8;
  msg[2] = address & 0xff;
  msg[3] = send_bytes - 1;
@@ -493,9 +493,10 @@ cdv_intel_dp_aux_native_write(struct gma_encoder *encoder,
   ret = cdv_intel_dp_aux_ch(encoder, msg, msg_bytes, &ack, 1);
   if (ret < 0)
    return ret;
-  if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_ACK)
+  ack >>= 4;
+  if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_ACK)
    break;
-  else if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_DEFER)
+  else if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_DEFER)
    udelay(100);
   else
    return -EIO;
@@ -523,7 +524,7 @@ cdv_intel_dp_aux_native_read(struct gma_encoder *encoder,
  uint8_t ack;
  int ret;
 
- msg[0] = AUX_NATIVE_READ << 4;
+ msg[0] = DP_AUX_NATIVE_READ << 4;
  msg[1] = address >> 8;
  msg[2] = address & 0xff;
  msg[3] = recv_bytes - 1;
@@ -538,12 +539,12 @@ cdv_intel_dp_aux_native_read(struct gma_encoder *encoder,
    return -EPROTO;
   if (ret < 0)
    return ret;
-  ack = reply[0];
-  if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_ACK) {
+  ack = reply[0] >> 4;
+  if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_ACK) {
    memcpy(recv, reply + 1, ret - 1);
    return ret - 1;
   }
-  else if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_DEFER)
+  else if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_DEFER)
    udelay(100);
   else
    return -EIO;
@@ -569,12 +570,12 @@ cdv_intel_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
 
  /* Set up the command byte */
  if (mode & MODE_I2C_READ)
-  msg[0] = AUX_I2C_READ << 4;
+  msg[0] = DP_AUX_I2C_READ << 4;
  else
-  msg[0] = AUX_I2C_WRITE << 4;
+  msg[0] = DP_AUX_I2C_WRITE << 4;
 
  if (!(mode & MODE_I2C_STOP))
-  msg[0] |= AUX_I2C_MOT << 4;
+  msg[0] |= DP_AUX_I2C_MOT << 4;
 
  msg[1] = address >> 8;
  msg[2] = address;
@@ -606,16 +607,16 @@ cdv_intel_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
    return ret;
   }
 
-  switch (reply[0] & AUX_NATIVE_REPLY_MASK) {
-  case AUX_NATIVE_REPLY_ACK:
+  switch ((reply[0] >> 4) & DP_AUX_NATIVE_REPLY_MASK) {
+  case DP_AUX_NATIVE_REPLY_ACK:
    /* I2C-over-AUX Reply field is only valid
     * when paired with AUX ACK.
     */
    break;
-  case AUX_NATIVE_REPLY_NACK:
+  case DP_AUX_NATIVE_REPLY_NACK:
    DRM_DEBUG_KMS("aux_ch native nack\n");
    return -EREMOTEIO;
-  case AUX_NATIVE_REPLY_DEFER:
+  case DP_AUX_NATIVE_REPLY_DEFER:
    udelay(100);
    continue;
   default:
@@ -624,16 +625,16 @@ cdv_intel_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
    return -EREMOTEIO;
   }
 
-  switch (reply[0] & AUX_I2C_REPLY_MASK) {
-  case AUX_I2C_REPLY_ACK:
+  switch ((reply[0] >> 4) & DP_AUX_I2C_REPLY_MASK) {
+  case DP_AUX_I2C_REPLY_ACK:
    if (mode == MODE_I2C_READ) {
     *read_byte = reply[1];
    }
    return reply_bytes - 1;
-  case AUX_I2C_REPLY_NACK:
+  case DP_AUX_I2C_REPLY_NACK:
    DRM_DEBUG_KMS("aux_i2c nack\n");
    return -EREMOTEIO;
-  case AUX_I2C_REPLY_DEFER:
+  case DP_AUX_I2C_REPLY_DEFER:
    DRM_DEBUG_KMS("aux_i2c defer\n");
    udelay(100);
    break;
@@ -677,7 +678,7 @@ cdv_intel_dp_i2c_init(struct gma_connector *connector,
  return ret;
 }
 
-void cdv_intel_fixed_panel_mode(struct drm_display_mode *fixed_mode,
+static void cdv_intel_fixed_panel_mode(struct drm_display_mode *fixed_mode,
  struct drm_display_mode *adjusted_mode)
 {
  adjusted_mode->hdisplay = fixed_mode->hdisplay;
diff --git a/drivers/gpu/drm/gma500/psb_drv.h b/drivers/gpu/drm/gma500/psb_drv.h
index b59e658..5ad6a03 100644
--- a/drivers/gpu/drm/gma500/psb_drv.h
+++ b/drivers/gpu/drm/gma500/psb_drv.h
@@ -212,8 +212,8 @@ enum {
 #define PSB_HIGH_REG_OFFS 0x0600
 
 #define PSB_NUM_VBLANKS 2
-#define PSB_WATCHDOG_DELAY (DRM_HZ * 2)
-#define PSB_LID_DELAY (DRM_HZ / 10)
+#define PSB_WATCHDOG_DELAY (HZ * 2)
+#define PSB_LID_DELAY (HZ / 10)
 
 #define MDFLD_PNW_B0 0x04
 #define MDFLD_PNW_C0 0x08
@@ -232,7 +232,7 @@ enum {
 #define MDFLD_DSR_RR  45
 #define MDFLD_DPU_ENABLE  (1 << 31)
 #define MDFLD_DSR_FULLSCREEN  (1 << 30)
-#define MDFLD_DSR_DELAY  (DRM_HZ / MDFLD_DSR_RR)
+#define MDFLD_DSR_DELAY  (HZ / MDFLD_DSR_RR)
 
 #define PSB_PWR_STATE_ON  1
 #define PSB_PWR_STATE_OFF  2
@@ -769,7 +769,7 @@ extern void psb_mmu_remove_pages(struct psb_mmu_pd *pd,
  *psb_irq.c
  */
 
-extern irqreturn_t psb_irq_handler(DRM_IRQ_ARGS);
+extern irqreturn_t psb_irq_handler(int irq, void *arg);
 extern int psb_irq_enable_dpst(struct drm_device *dev);
 extern int psb_irq_disable_dpst(struct drm_device *dev);
 extern void psb_irq_preinstall(struct drm_device *dev);
diff --git a/drivers/gpu/drm/gma500/psb_intel_drv.h b/drivers/gpu/drm/gma500/psb_intel_drv.h
index bde27fd..dc2c8eb 100644
--- a/drivers/gpu/drm/gma500/psb_intel_drv.h
+++ b/drivers/gpu/drm/gma500/psb_intel_drv.h
@@ -250,11 +250,6 @@ extern void psb_intel_sdvo_set_hotplug(struct drm_connector *connector,
 extern int intelfb_probe(struct drm_device *dev);
 extern int intelfb_remove(struct drm_device *dev,
      struct drm_framebuffer *fb);
-extern struct drm_framebuffer *psb_intel_framebuffer_create(struct drm_device
-       *dev, struct
-       drm_mode_fb_cmd
-       *mode_cmd,
-       void *mm_private);
 extern bool psb_intel_lvds_mode_fixup(struct drm_encoder *encoder,
           const struct drm_display_mode *mode,
           struct drm_display_mode *adjusted_mode);
diff --git a/drivers/gpu/drm/gma500/psb_irq.c b/drivers/gpu/drm/gma500/psb_irq.c
index ba48303..f883f9e 100644
--- a/drivers/gpu/drm/gma500/psb_irq.c
+++ b/drivers/gpu/drm/gma500/psb_irq.c
@@ -200,7 +200,7 @@ static void psb_vdc_interrupt(struct drm_device *dev, uint32_t vdc_stat)
   mid_pipe_event_handler(dev, 1);
 }
 
-irqreturn_t psb_irq_handler(DRM_IRQ_ARGS)
+irqreturn_t psb_irq_handler(int irq, void *arg)
 {
  struct drm_device *dev = arg;
  struct drm_psb_private *dev_priv = dev->dev_private;
@@ -253,7 +253,7 @@ irqreturn_t psb_irq_handler(DRM_IRQ_ARGS)
 
  PSB_WVDC32(vdc_stat, PSB_INT_IDENTITY_R);
  (void) PSB_RVDC32(PSB_INT_IDENTITY_R);
- DRM_READMEMORYBARRIER();
+ rmb();
 
  if (!handled)
   return IRQ_NONE;
@@ -450,21 +450,6 @@ int psb_irq_disable_dpst(struct drm_device *dev)
  return 0;
 }
 
-#ifdef PSB_FIXME
-static int psb_vblank_do_wait(struct drm_device *dev,
-         unsigned int *sequence, atomic_t *counter)
-{
- unsigned int cur_vblank;
- int ret = 0;
- DRM_WAIT_ON(ret, dev->vblank.queue, 3 * DRM_HZ,
-      (((cur_vblank = atomic_read(counter))
-        - *sequence) <= (1 << 23)));
- *sequence = cur_vblank;
-
- return ret;
-}
-#endif
-
 /*
  * It is used to enable VBLANK interrupt
  */
diff --git a/drivers/gpu/drm/gma500/psb_irq.h b/drivers/gpu/drm/gma500/psb_irq.h
index debb7f1..d0b45ff 100644
--- a/drivers/gpu/drm/gma500/psb_irq.h
+++ b/drivers/gpu/drm/gma500/psb_irq.h
@@ -32,7 +32,7 @@ void sysirq_uninit(struct drm_device *dev);
 void psb_irq_preinstall(struct drm_device *dev);
 int  psb_irq_postinstall(struct drm_device *dev);
 void psb_irq_uninstall(struct drm_device *dev);
-irqreturn_t psb_irq_handler(DRM_IRQ_ARGS);
+irqreturn_t psb_irq_handler(int irq, void *arg);
 
 int psb_irq_enable_dpst(struct drm_device *dev);
 int psb_irq_disable_dpst(struct drm_device *dev);
diff --git a/drivers/gpu/drm/i2c/tda998x_drv.c b/drivers/gpu/drm/i2c/tda998x_drv.c
index 400b0c4..faa77f5 100644
--- a/drivers/gpu/drm/i2c/tda998x_drv.c
+++ b/drivers/gpu/drm/i2c/tda998x_drv.c
@@ -208,7 +208,7 @@ struct tda998x_priv {
 # define PLL_SERIAL_1_SRL_IZ(x)   (((x) & 3) << 1)
 # define PLL_SERIAL_1_SRL_MAN_IZ  (1 << 6)
 #define REG_PLL_SERIAL_2          REG(0x02, 0x01)     /* read/write */
-# define PLL_SERIAL_2_SRL_NOSC(x) (((x) & 3) << 0)
+# define PLL_SERIAL_2_SRL_NOSC(x) ((x) << 0)
 # define PLL_SERIAL_2_SRL_PR(x)   (((x) & 0xf) << 4)
 #define REG_PLL_SERIAL_3          REG(0x02, 0x02)     /* read/write */
 # define PLL_SERIAL_3_SRL_CCIR    (1 << 0)
@@ -528,10 +528,10 @@ tda998x_write_aif(struct drm_encoder *encoder, struct tda998x_encoder_params *p)
 {
  uint8_t buf[PB(5) + 1];
 
+ memset(buf, 0, sizeof(buf));
  buf[HB(0)] = 0x84;
  buf[HB(1)] = 0x01;
  buf[HB(2)] = 10;
- buf[PB(0)] = 0;
  buf[PB(1)] = p->audio_frame[1] & 0x07; /* CC */
  buf[PB(2)] = p->audio_frame[2] & 0x1c; /* SF */
  buf[PB(4)] = p->audio_frame[4];
@@ -824,6 +824,11 @@ tda998x_encoder_mode_set(struct drm_encoder *encoder,
  }
 
  div = 148500 / mode->clock;
+ if (div != 0) {
+  div--;
+  if (div > 3)
+   div = 3;
+ }
 
  /* mute the audio FIFO: */
  reg_set(encoder, REG_AIP_CNTRL_0, AIP_CNTRL_0_RST_FIFO);
@@ -913,7 +918,7 @@ tda998x_encoder_mode_set(struct drm_encoder *encoder,
 
  if (priv->rev == TDA19988) {
   /* let incoming pixels fill the active space (if any) */
-  reg_write(encoder, REG_ENABLE_SPACE, 0x01);
+  reg_write(encoder, REG_ENABLE_SPACE, 0x00);
  }
 
  /* must be last register set: */
@@ -1094,6 +1099,8 @@ tda998x_encoder_destroy(struct drm_encoder *encoder)
 {
  struct tda998x_priv *priv = to_tda998x_priv(encoder);
  drm_i2c_encoder_destroy(encoder);
+ if (priv->cec)
+  i2c_unregister_device(priv->cec);
  kfree(priv);
 }
 
@@ -1142,8 +1149,12 @@ tda998x_encoder_init(struct i2c_client *client,
  priv->vip_cntrl_1 = VIP_CNTRL_1_SWAP_C(0) | VIP_CNTRL_1_SWAP_D(1);
  priv->vip_cntrl_2 = VIP_CNTRL_2_SWAP_E(4) | VIP_CNTRL_2_SWAP_F(5);
 
- priv->current_page = 0;
+ priv->current_page = 0xff;
  priv->cec = i2c_new_dummy(client->adapter, 0x34);
+ if (!priv->cec) {
+  kfree(priv);
+  return -ENODEV;
+ }
  priv->dpms = DRM_MODE_DPMS_OFF;
 
  encoder_slave->slave_priv = priv;
diff --git a/drivers/gpu/drm/i810/i810_dma.c b/drivers/gpu/drm/i810/i810_dma.c
index 249fdff..aeace37 100644
--- a/drivers/gpu/drm/i810/i810_dma.c
+++ b/drivers/gpu/drm/i810/i810_dma.c
@@ -1193,6 +1193,10 @@ static int i810_flip_bufs(struct drm_device *dev, void *data,
 
 int i810_driver_load(struct drm_device *dev, unsigned long flags)
 {
+ /* Our userspace depends upon the agp mapping support. */
+ if (!dev->agp)
+  return -EINVAL;
+
  pci_set_master(dev->pdev);
 
  return 0;
diff --git a/drivers/gpu/drm/i810/i810_drv.c b/drivers/gpu/drm/i810/i810_drv.c
index d8180d2..441ccf8 100644
--- a/drivers/gpu/drm/i810/i810_drv.c
+++ b/drivers/gpu/drm/i810/i810_drv.c
@@ -57,7 +57,7 @@ static const struct file_operations i810_driver_fops = {
 
 static struct drm_driver driver = {
  .driver_features =
-     DRIVER_USE_AGP | DRIVER_REQUIRE_AGP |
+     DRIVER_USE_AGP |
      DRIVER_HAVE_DMA,
  .dev_priv_size = sizeof(drm_i810_buf_priv_t),
  .load = i810_driver_load,
diff --git a/drivers/gpu/drm/i915/Kconfig b/drivers/gpu/drm/i915/Kconfig
index 6199d0b..73ed59e 100644
--- a/drivers/gpu/drm/i915/Kconfig
+++ b/drivers/gpu/drm/i915/Kconfig
@@ -1,8 +1,10 @@
 config DRM_I915
  tristate "Intel 8xx/9xx/G3x/G4x/HD Graphics"
  depends on DRM
- depends on AGP
- depends on AGP_INTEL
+ depends on X86 && PCI
+ depends on (AGP || AGP=n)
+ select INTEL_GTT
+ select AGP_INTEL if AGP
  # we need shmfs for the swappable backing store, and in particular
  # the shmem_readpage() which depends upon tmpfs
  select SHMEM
@@ -35,15 +37,14 @@ config DRM_I915
 config DRM_I915_KMS
  bool "Enable modesetting on intel by default"
  depends on DRM_I915
+ default y
  help
-   Choose this option if you want kernel modesetting enabled by default,
-   and you have a new enough userspace to support this. Running old
-   userspaces with this enabled will cause pain.  Note that this causes
-   the driver to bind to PCI devices, which precludes loading things
-   like intelfb.
+   Choose this option if you want kernel modesetting enabled by default.
+
+   If in doubt, say "Y".
 
 config DRM_I915_FBDEV
- bool "Enable legacy fbdev support for the modesettting intel driver"
+ bool "Enable legacy fbdev support for the modesetting intel driver"
  depends on DRM_I915
  select DRM_KMS_FB_HELPER
  select FB_CFB_FILLRECT
@@ -55,9 +56,12 @@ config DRM_I915_FBDEV
    support. Note that this support also provide the linux console
    support on top of the intel modesetting driver.
 
+   If in doubt, say "Y".
+
 config DRM_I915_PRELIMINARY_HW_SUPPORT
  bool "Enable preliminary support for prerelease Intel hardware by default"
  depends on DRM_I915
+ default n
  help
    Choose this option if you have prerelease Intel hardware and want the
    i915 driver to support it by default.  You can enable such support at
@@ -65,3 +69,15 @@ config DRM_I915_PRELIMINARY_HW_SUPPORT
    option changes the default for that module option.
 
    If in doubt, say "N".
+
+config DRM_I915_UMS
+ bool "Enable userspace modesetting on Intel hardware (DEPRECATED)"
+ depends on DRM_I915
+ default n
+ help
+   Choose this option if you still need userspace modesetting.
+
+   Userspace modesetting is deprecated for quite some time now, so
+   enable this only if you have ancient versions of the DDX drivers.
+
+   If in doubt, say "N".
diff --git a/drivers/gpu/drm/i915/Makefile b/drivers/gpu/drm/i915/Makefile
index 41838ea..9fd44f5 100644
--- a/drivers/gpu/drm/i915/Makefile
+++ b/drivers/gpu/drm/i915/Makefile
@@ -4,7 +4,6 @@
 
 ccflags-y := -Iinclude/drm
 i915-y := i915_drv.o i915_dma.o i915_irq.o \
-   i915_debugfs.o \
    i915_gpu_error.o \
           i915_suspend.o \
    i915_gem.o \
@@ -38,7 +37,6 @@ i915-y := i915_drv.o i915_dma.o i915_irq.o \
    intel_ringbuffer.o \
    intel_overlay.o \
    intel_sprite.o \
-   intel_opregion.o \
    intel_sideband.o \
    intel_uncore.o \
    dvo_ch7xxx.o \
@@ -51,10 +49,12 @@ i915-y := i915_drv.o i915_dma.o i915_irq.o \
 
 i915-$(CONFIG_COMPAT)   += i915_ioc32.o
 
-i915-$(CONFIG_ACPI) += intel_acpi.o
+i915-$(CONFIG_ACPI) += intel_acpi.o intel_opregion.o
 
 i915-$(CONFIG_DRM_I915_FBDEV) += intel_fbdev.o
 
+i915-$(CONFIG_DEBUG_FS) += i915_debugfs.o
+
 obj-$(CONFIG_DRM_I915)  += i915.o
 
 CFLAGS_i915_trace_points.o := -I$(src)
diff --git a/drivers/gpu/drm/i915/dvo_ns2501.c b/drivers/gpu/drm/i915/dvo_ns2501.c
index c4a255b..954acb2 100644
--- a/drivers/gpu/drm/i915/dvo_ns2501.c
+++ b/drivers/gpu/drm/i915/dvo_ns2501.c
@@ -87,49 +87,6 @@ struct ns2501_priv {
  * when switching the resolution.
  */
 
-static void enable_dvo(struct intel_dvo_device *dvo)
-{
- struct ns2501_priv *ns = (struct ns2501_priv *)(dvo->dev_priv);
- struct i2c_adapter *adapter = dvo->i2c_bus;
- struct intel_gmbus *bus = container_of(adapter,
-            struct intel_gmbus,
-            adapter);
- struct drm_i915_private *dev_priv = bus->dev_priv;
-
- DRM_DEBUG_KMS("%s: Trying to re-enable the DVO\n", __FUNCTION__);
-
- ns->dvoc = I915_READ(DVO_C);
- ns->pll_a = I915_READ(_DPLL_A);
- ns->srcdim = I915_READ(DVOC_SRCDIM);
- ns->fw_blc = I915_READ(FW_BLC);
-
- I915_WRITE(DVOC, 0x10004084);
- I915_WRITE(_DPLL_A, 0xd0820000);
- I915_WRITE(DVOC_SRCDIM, 0x400300); // 1024x768
- I915_WRITE(FW_BLC, 0x1080304);
-
- I915_WRITE(DVOC, 0x90004084);
-}
-
-/*
- * Restore the I915 registers modified by the above
- * trigger function.
- */
-static void restore_dvo(struct intel_dvo_device *dvo)
-{
- struct i2c_adapter *adapter = dvo->i2c_bus;
- struct intel_gmbus *bus = container_of(adapter,
-            struct intel_gmbus,
-            adapter);
- struct drm_i915_private *dev_priv = bus->dev_priv;
- struct ns2501_priv *ns = (struct ns2501_priv *)(dvo->dev_priv);
-
- I915_WRITE(DVOC, ns->dvoc);
- I915_WRITE(_DPLL_A, ns->pll_a);
- I915_WRITE(DVOC_SRCDIM, ns->srcdim);
- I915_WRITE(FW_BLC, ns->fw_blc);
-}
-
 /*
 ** Read a register from the ns2501.
 ** Returns true if successful, false otherwise.
@@ -300,7 +257,7 @@ static void ns2501_mode_set(struct intel_dvo_device *dvo,
        struct drm_display_mode *adjusted_mode)
 {
  bool ok;
- bool restore = false;
+ int retries = 10;
  struct ns2501_priv *ns = (struct ns2501_priv *)(dvo->dev_priv);
 
  DRM_DEBUG_KMS
@@ -476,20 +433,7 @@ static void ns2501_mode_set(struct intel_dvo_device *dvo,
    ns->reg_8_shadow |= NS2501_8_BPAS;
   }
   ok &= ns2501_writeb(dvo, NS2501_REG8, ns->reg_8_shadow);
-
-  if (!ok) {
-   if (restore)
-    restore_dvo(dvo);
-   enable_dvo(dvo);
-   restore = true;
-  }
- } while (!ok);
- /*
-  * Restore the old i915 registers before
-  * forcing the ns2501 on.
-  */
- if (restore)
-  restore_dvo(dvo);
+ } while (!ok && retries--);
 }
 
 /* set the NS2501 power state */
@@ -510,7 +454,7 @@ static bool ns2501_get_hw_state(struct intel_dvo_device *dvo)
 static void ns2501_dpms(struct intel_dvo_device *dvo, bool enable)
 {
  bool ok;
- bool restore = false;
+ int retries = 10;
  struct ns2501_priv *ns = (struct ns2501_priv *)(dvo->dev_priv);
  unsigned char ch;
 
@@ -537,16 +481,7 @@ static void ns2501_dpms(struct intel_dvo_device *dvo, bool enable)
    ok &=
        ns2501_writeb(dvo, 0x35,
        enable ? 0xff : 0x00);
-   if (!ok) {
-    if (restore)
-     restore_dvo(dvo);
-    enable_dvo(dvo);
-    restore = true;
-   }
-  } while (!ok);
-
-  if (restore)
-   restore_dvo(dvo);
+  } while (!ok && retries--);
  }
 }
 
diff --git a/drivers/gpu/drm/i915/i915_debugfs.c b/drivers/gpu/drm/i915/i915_debugfs.c
index 6ed45a9..b2b46c5 100644
--- a/drivers/gpu/drm/i915/i915_debugfs.c
+++ b/drivers/gpu/drm/i915/i915_debugfs.c
@@ -40,8 +40,6 @@
 #include <drm/i915_drm.h>
 #include "i915_drv.h"
 
-#if defined(CONFIG_DEBUG_FS)
-
 enum {
  ACTIVE_LIST,
  INACTIVE_LIST,
@@ -406,16 +404,26 @@ static int i915_gem_object_info(struct seq_file *m, void* data)
  seq_putc(m, '\n');
  list_for_each_entry_reverse(file, &dev->filelist, lhead) {
   struct file_stats stats;
+  struct task_struct *task;
 
   memset(&stats, 0, sizeof(stats));
   idr_for_each(&file->object_idr, per_file_stats, &stats);
+  /*
+   * Although we have a valid reference on file->pid, that does
+   * not guarantee that the task_struct who called get_pid() is
+   * still alive (e.g. get_pid(current) => fork() => exit()).
+   * Therefore, we need to protect this ->comm access using RCU.
+   */
+  rcu_read_lock();
+  task = pid_task(file->pid, PIDTYPE_PID);
   seq_printf(m, "%s: %u objects, %zu bytes (%zu active, %zu inactive, %zu unbound)\n",
-      get_pid_task(file->pid, PIDTYPE_PID)->comm,
+      task ? task->comm : "<unknown>",
       stats.count,
       stats.total,
       stats.active,
       stats.inactive,
       stats.unbound);
+  rcu_read_unlock();
  }
 
  mutex_unlock(&dev->struct_mutex);
@@ -564,10 +572,12 @@ static int i915_gem_seqno_info(struct seq_file *m, void *data)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  for_each_ring(ring, dev_priv, i)
   i915_ring_seqno_info(m, ring);
 
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev->struct_mutex);
 
  return 0;
@@ -585,6 +595,7 @@ static int i915_interrupt_info(struct seq_file *m, void *data)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  if (INTEL_INFO(dev)->gen >= 8) {
   int i;
@@ -711,6 +722,7 @@ static int i915_interrupt_info(struct seq_file *m, void *data)
   }
   i915_ring_seqno_info(m, ring);
  }
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev->struct_mutex);
 
  return 0;
@@ -904,9 +916,11 @@ static int i915_rstdby_delays(struct seq_file *m, void *unused)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  crstanddelay = I915_READ16(CRSTANDVID);
 
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev->struct_mutex);
 
  seq_printf(m, "w/ctx: %d, w/o ctx: %d\n", (crstanddelay >> 8) & 0x3f, (crstanddelay & 0x3f));
@@ -919,7 +933,9 @@ static int i915_cur_delayinfo(struct seq_file *m, void *unused)
  struct drm_info_node *node = (struct drm_info_node *) m->private;
  struct drm_device *dev = node->minor->dev;
  drm_i915_private_t *dev_priv = dev->dev_private;
- int ret;
+ int ret = 0;
+
+ intel_runtime_pm_get(dev_priv);
 
  flush_delayed_work(&dev_priv->rps.delayed_resume_work);
 
@@ -945,9 +961,9 @@ static int i915_cur_delayinfo(struct seq_file *m, void *unused)
   /* RPSTAT1 is in the GT power well */
   ret = mutex_lock_interruptible(&dev->struct_mutex);
   if (ret)
-   return ret;
+   goto out;
 
-  gen6_gt_force_wake_get(dev_priv);
+  gen6_gt_force_wake_get(dev_priv, FORCEWAKE_ALL);
 
   reqf = I915_READ(GEN6_RPNSWREQ);
   reqf &= ~GEN6_TURBO_DISABLE;
@@ -970,7 +986,7 @@ static int i915_cur_delayinfo(struct seq_file *m, void *unused)
    cagf = (rpstat & GEN6_CAGF_MASK) >> GEN6_CAGF_SHIFT;
   cagf *= GT_FREQUENCY_MULTIPLIER;
 
-  gen6_gt_force_wake_put(dev_priv);
+  gen6_gt_force_wake_put(dev_priv, FORCEWAKE_ALL);
   mutex_unlock(&dev->struct_mutex);
 
   seq_printf(m, "GT_PERF_STATUS: 0x%08x\n", gt_perf_status);
@@ -1018,23 +1034,24 @@ static int i915_cur_delayinfo(struct seq_file *m, void *unused)
   seq_printf(m, "PUNIT_REG_GPU_FREQ_STS: 0x%08x\n", freq_sts);
   seq_printf(m, "DDR freq: %d MHz\n", dev_priv->mem_freq);
 
-  val = vlv_punit_read(dev_priv, PUNIT_FUSE_BUS1);
+  val = valleyview_rps_max_freq(dev_priv);
   seq_printf(m, "max GPU freq: %d MHz\n",
-      vlv_gpu_freq(dev_priv->mem_freq, val));
+      vlv_gpu_freq(dev_priv, val));
 
-  val = vlv_punit_read(dev_priv, PUNIT_REG_GPU_LFM);
+  val = valleyview_rps_min_freq(dev_priv);
   seq_printf(m, "min GPU freq: %d MHz\n",
-      vlv_gpu_freq(dev_priv->mem_freq, val));
+      vlv_gpu_freq(dev_priv, val));
 
   seq_printf(m, "current GPU freq: %d MHz\n",
-      vlv_gpu_freq(dev_priv->mem_freq,
-     (freq_sts >> 8) & 0xff));
+      vlv_gpu_freq(dev_priv, (freq_sts >> 8) & 0xff));
   mutex_unlock(&dev_priv->rps.hw_lock);
  } else {
   seq_puts(m, "no P-state info available\n");
  }
 
- return 0;
+out:
+ intel_runtime_pm_put(dev_priv);
+ return ret;
 }
 
 static int i915_delayfreq_table(struct seq_file *m, void *unused)
@@ -1048,6 +1065,7 @@ static int i915_delayfreq_table(struct seq_file *m, void *unused)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  for (i = 0; i < 16; i++) {
   delayfreq = I915_READ(PXVFREQ_BASE + i * 4);
@@ -1055,6 +1073,8 @@ static int i915_delayfreq_table(struct seq_file *m, void *unused)
       (delayfreq & PXVFREQ_PX_MASK) >> PXVFREQ_PX_SHIFT);
  }
 
+ intel_runtime_pm_put(dev_priv);
+
  mutex_unlock(&dev->struct_mutex);
 
  return 0;
@@ -1076,12 +1096,14 @@ static int i915_inttoext_table(struct seq_file *m, void *unused)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  for (i = 1; i <= 32; i++) {
   inttoext = I915_READ(INTTOEXT_BASE_ILK + i * 4);
   seq_printf(m, "INTTOEXT%02d: 0x%08x\n", i, inttoext);
  }
 
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev->struct_mutex);
 
  return 0;
@@ -1099,11 +1121,13 @@ static int ironlake_drpc_info(struct seq_file *m)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  rgvmodectl = I915_READ(MEMMODECTL);
  rstdbyctl = I915_READ(RSTDBYCTL);
  crstandvid = I915_READ16(CRSTANDVID);
 
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev->struct_mutex);
 
  seq_printf(m, "HD boost: %s\n", (rgvmodectl & MEMMODE_BOOST_EN) ?
@@ -1154,6 +1178,50 @@ static int ironlake_drpc_info(struct seq_file *m)
  return 0;
 }
 
+static int vlv_drpc_info(struct seq_file *m)
+{
+
+ struct drm_info_node *node = (struct drm_info_node *) m->private;
+ struct drm_device *dev = node->minor->dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ u32 rpmodectl1, rcctl1;
+ unsigned fw_rendercount = 0, fw_mediacount = 0;
+
+ rpmodectl1 = I915_READ(GEN6_RP_CONTROL);
+ rcctl1 = I915_READ(GEN6_RC_CONTROL);
+
+ seq_printf(m, "Video Turbo Mode: %s\n",
+     yesno(rpmodectl1 & GEN6_RP_MEDIA_TURBO));
+ seq_printf(m, "Turbo enabled: %s\n",
+     yesno(rpmodectl1 & GEN6_RP_ENABLE));
+ seq_printf(m, "HW control enabled: %s\n",
+     yesno(rpmodectl1 & GEN6_RP_ENABLE));
+ seq_printf(m, "SW control enabled: %s\n",
+     yesno((rpmodectl1 & GEN6_RP_MEDIA_MODE_MASK) ==
+     GEN6_RP_MEDIA_SW_MODE));
+ seq_printf(m, "RC6 Enabled: %s\n",
+     yesno(rcctl1 & (GEN7_RC_CTL_TO_MODE |
+     GEN6_RC_CTL_EI_MODE(1))));
+ seq_printf(m, "Render Power Well: %s\n",
+   (I915_READ(VLV_GTLC_PW_STATUS) &
+    VLV_GTLC_PW_RENDER_STATUS_MASK) ? "Up" : "Down");
+ seq_printf(m, "Media Power Well: %s\n",
+   (I915_READ(VLV_GTLC_PW_STATUS) &
+    VLV_GTLC_PW_MEDIA_STATUS_MASK) ? "Up" : "Down");
+
+ spin_lock_irq(&dev_priv->uncore.lock);
+ fw_rendercount = dev_priv->uncore.fw_rendercount;
+ fw_mediacount = dev_priv->uncore.fw_mediacount;
+ spin_unlock_irq(&dev_priv->uncore.lock);
+
+ seq_printf(m, "Forcewake Render Count = %u\n", fw_rendercount);
+ seq_printf(m, "Forcewake Media Count = %u\n", fw_mediacount);
+
+
+ return 0;
+}
+
+
 static int gen6_drpc_info(struct seq_file *m)
 {
 
@@ -1167,6 +1235,7 @@ static int gen6_drpc_info(struct seq_file *m)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  spin_lock_irq(&dev_priv->uncore.lock);
  forcewake_count = dev_priv->uncore.forcewake_count;
@@ -1192,6 +1261,8 @@ static int gen6_drpc_info(struct seq_file *m)
  sandybridge_pcode_read(dev_priv, GEN6_PCODE_READ_RC6VIDS, &rc6vids);
  mutex_unlock(&dev_priv->rps.hw_lock);
 
+ intel_runtime_pm_put(dev_priv);
+
  seq_printf(m, "Video Turbo Mode: %s\n",
      yesno(rpmodectl1 & GEN6_RP_MEDIA_TURBO));
  seq_printf(m, "HW control enabled: %s\n",
@@ -1256,7 +1327,9 @@ static int i915_drpc_info(struct seq_file *m, void *unused)
  struct drm_info_node *node = (struct drm_info_node *) m->private;
  struct drm_device *dev = node->minor->dev;
 
- if (IS_GEN6(dev) || IS_GEN7(dev))
+ if (IS_VALLEYVIEW(dev))
+  return vlv_drpc_info(m);
+ else if (IS_GEN6(dev) || IS_GEN7(dev))
   return gen6_drpc_info(m);
  else
   return ironlake_drpc_info(m);
@@ -1268,7 +1341,7 @@ static int i915_fbc_status(struct seq_file *m, void *unused)
  struct drm_device *dev = node->minor->dev;
  drm_i915_private_t *dev_priv = dev->dev_private;
 
- if (!I915_HAS_FBC(dev)) {
+ if (!HAS_FBC(dev)) {
   seq_puts(m, "FBC unsupported on this chipset\n");
   return 0;
  }
@@ -1330,7 +1403,7 @@ static int i915_ips_status(struct seq_file *m, void *unused)
   return 0;
  }
 
- if (I915_READ(IPS_CTL) & IPS_ENABLE)
+ if (IS_BROADWELL(dev) || I915_READ(IPS_CTL) & IPS_ENABLE)
   seq_puts(m, "enabled\n");
  else
   seq_puts(m, "disabled\n");
@@ -1406,6 +1479,7 @@ static int i915_ring_freq_table(struct seq_file *m, void *unused)
  ret = mutex_lock_interruptible(&dev_priv->rps.hw_lock);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  seq_puts(m, "GPU freq (MHz)\tEffective CPU freq (MHz)\tEffective Ring freq (MHz)\n");
 
@@ -1422,6 +1496,7 @@ static int i915_ring_freq_table(struct seq_file *m, void *unused)
       ((ia_freq >> 8) & 0xff) * 100);
  }
 
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev_priv->rps.hw_lock);
 
  return 0;
@@ -1437,8 +1512,10 @@ static int i915_gfxec(struct seq_file *m, void *unused)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  seq_printf(m, "GFXEC: %ld\n", (unsigned long)I915_READ(0x112f4));
+ intel_runtime_pm_put(dev_priv);
 
  mutex_unlock(&dev->struct_mutex);
 
@@ -1565,13 +1642,21 @@ static int i915_gen6_forcewake_count_info(struct seq_file *m, void *data)
  struct drm_info_node *node = (struct drm_info_node *) m->private;
  struct drm_device *dev = node->minor->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
- unsigned forcewake_count;
+ unsigned forcewake_count = 0, fw_rendercount = 0, fw_mediacount = 0;
 
  spin_lock_irq(&dev_priv->uncore.lock);
- forcewake_count = dev_priv->uncore.forcewake_count;
+ if (IS_VALLEYVIEW(dev)) {
+  fw_rendercount = dev_priv->uncore.fw_rendercount;
+  fw_mediacount = dev_priv->uncore.fw_mediacount;
+ } else
+  forcewake_count = dev_priv->uncore.forcewake_count;
  spin_unlock_irq(&dev_priv->uncore.lock);
 
- seq_printf(m, "forcewake count = %u\n", forcewake_count);
+ if (IS_VALLEYVIEW(dev)) {
+  seq_printf(m, "fw_rendercount = %u\n", fw_rendercount);
+  seq_printf(m, "fw_mediacount = %u\n", fw_mediacount);
+ } else
+  seq_printf(m, "forcewake count = %u\n", forcewake_count);
 
  return 0;
 }
@@ -1610,6 +1695,7 @@ static int i915_swizzle_info(struct seq_file *m, void *data)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  seq_printf(m, "bit6 swizzle for X-tiling = %s\n",
      swizzle_string(dev_priv->mm.bit_6_swizzle_x));
@@ -1641,6 +1727,7 @@ static int i915_swizzle_info(struct seq_file *m, void *data)
   seq_printf(m, "DISP_ARB_CTL = 0x%08x\n",
       I915_READ(DISP_ARB_CTL));
  }
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev->struct_mutex);
 
  return 0;
@@ -1701,16 +1788,19 @@ static int i915_ppgtt_info(struct seq_file *m, void *data)
 {
  struct drm_info_node *node = (struct drm_info_node *) m->private;
  struct drm_device *dev = node->minor->dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
 
  int ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  if (INTEL_INFO(dev)->gen >= 8)
   gen8_ppgtt_info(m, dev);
  else if (INTEL_INFO(dev)->gen >= 6)
   gen6_ppgtt_info(m, dev);
 
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev->struct_mutex);
 
  return 0;
@@ -1735,28 +1825,28 @@ static int i915_dpio_info(struct seq_file *m, void *data)
 
  seq_printf(m, "DPIO_CTL: 0x%08x\n", I915_READ(DPIO_CTL));
 
- seq_printf(m, "DPIO_DIV_A: 0x%08x\n",
-     vlv_dpio_read(dev_priv, PIPE_A, _DPIO_DIV_A));
- seq_printf(m, "DPIO_DIV_B: 0x%08x\n",
-     vlv_dpio_read(dev_priv, PIPE_A, _DPIO_DIV_B));
+ seq_printf(m, "DPIO PLL DW3 CH0 : 0x%08x\n",
+     vlv_dpio_read(dev_priv, PIPE_A, VLV_PLL_DW3(0)));
+ seq_printf(m, "DPIO PLL DW3 CH1: 0x%08x\n",
+     vlv_dpio_read(dev_priv, PIPE_A, VLV_PLL_DW3(1)));
 
- seq_printf(m, "DPIO_REFSFR_A: 0x%08x\n",
-     vlv_dpio_read(dev_priv, PIPE_A, _DPIO_REFSFR_A));
- seq_printf(m, "DPIO_REFSFR_B: 0x%08x\n",
-     vlv_dpio_read(dev_priv, PIPE_A, _DPIO_REFSFR_B));
+ seq_printf(m, "DPIO PLL DW5 CH0: 0x%08x\n",
+     vlv_dpio_read(dev_priv, PIPE_A, VLV_PLL_DW5(0)));
+ seq_printf(m, "DPIO PLL DW5 CH1: 0x%08x\n",
+     vlv_dpio_read(dev_priv, PIPE_A, VLV_PLL_DW5(1)));
 
- seq_printf(m, "DPIO_CORE_CLK_A: 0x%08x\n",
-     vlv_dpio_read(dev_priv, PIPE_A, _DPIO_CORE_CLK_A));
- seq_printf(m, "DPIO_CORE_CLK_B: 0x%08x\n",
-     vlv_dpio_read(dev_priv, PIPE_A, _DPIO_CORE_CLK_B));
+ seq_printf(m, "DPIO PLL DW7 CH0: 0x%08x\n",
+     vlv_dpio_read(dev_priv, PIPE_A, VLV_PLL_DW7(0)));
+ seq_printf(m, "DPIO PLL DW7 CH1: 0x%08x\n",
+     vlv_dpio_read(dev_priv, PIPE_A, VLV_PLL_DW7(1)));
 
- seq_printf(m, "DPIO_LPF_COEFF_A: 0x%08x\n",
-     vlv_dpio_read(dev_priv, PIPE_A, _DPIO_LPF_COEFF_A));
- seq_printf(m, "DPIO_LPF_COEFF_B: 0x%08x\n",
-     vlv_dpio_read(dev_priv, PIPE_A, _DPIO_LPF_COEFF_B));
+ seq_printf(m, "DPIO PLL DW10 CH0: 0x%08x\n",
+     vlv_dpio_read(dev_priv, PIPE_A, VLV_PLL_DW10(0)));
+ seq_printf(m, "DPIO PLL DW10 CH1: 0x%08x\n",
+     vlv_dpio_read(dev_priv, PIPE_A, VLV_PLL_DW10(1)));
 
  seq_printf(m, "DPIO_FASTCLK_DISABLE: 0x%08x\n",
-     vlv_dpio_read(dev_priv, PIPE_A, DPIO_FASTCLK_DISABLE));
+     vlv_dpio_read(dev_priv, PIPE_A, VLV_CMN_DW0));
 
  mutex_unlock(&dev_priv->dpio_lock);
 
@@ -1784,6 +1874,8 @@ static int i915_edp_psr_status(struct seq_file *m, void *data)
  u32 psrperf = 0;
  bool enabled = false;
 
+ intel_runtime_pm_get(dev_priv);
+
  seq_printf(m, "Sink_Support: %s\n", yesno(dev_priv->psr.sink_support));
  seq_printf(m, "Source_OK: %s\n", yesno(dev_priv->psr.source_ok));
 
@@ -1796,6 +1888,7 @@ static int i915_edp_psr_status(struct seq_file *m, void *data)
    EDP_PSR_PERF_CNT_MASK;
  seq_printf(m, "Performance_Counter: %u\n", psrperf);
 
+ intel_runtime_pm_put(dev_priv);
  return 0;
 }
 
@@ -1845,6 +1938,76 @@ static int i915_pc8_status(struct seq_file *m, void *unused)
  return 0;
 }
 
+static const char *power_domain_str(enum intel_display_power_domain domain)
+{
+ switch (domain) {
+ case POWER_DOMAIN_PIPE_A:
+  return "PIPE_A";
+ case POWER_DOMAIN_PIPE_B:
+  return "PIPE_B";
+ case POWER_DOMAIN_PIPE_C:
+  return "PIPE_C";
+ case POWER_DOMAIN_PIPE_A_PANEL_FITTER:
+  return "PIPE_A_PANEL_FITTER";
+ case POWER_DOMAIN_PIPE_B_PANEL_FITTER:
+  return "PIPE_B_PANEL_FITTER";
+ case POWER_DOMAIN_PIPE_C_PANEL_FITTER:
+  return "PIPE_C_PANEL_FITTER";
+ case POWER_DOMAIN_TRANSCODER_A:
+  return "TRANSCODER_A";
+ case POWER_DOMAIN_TRANSCODER_B:
+  return "TRANSCODER_B";
+ case POWER_DOMAIN_TRANSCODER_C:
+  return "TRANSCODER_C";
+ case POWER_DOMAIN_TRANSCODER_EDP:
+  return "TRANSCODER_EDP";
+ case POWER_DOMAIN_VGA:
+  return "VGA";
+ case POWER_DOMAIN_AUDIO:
+  return "AUDIO";
+ case POWER_DOMAIN_INIT:
+  return "INIT";
+ default:
+  WARN_ON(1);
+  return "?";
+ }
+}
+
+static int i915_power_domain_info(struct seq_file *m, void *unused)
+{
+ struct drm_info_node *node = (struct drm_info_node *) m->private;
+ struct drm_device *dev = node->minor->dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct i915_power_domains *power_domains = &dev_priv->power_domains;
+ int i;
+
+ mutex_lock(&power_domains->lock);
+
+ seq_printf(m, "%-25s %s\n", "Power well/domain", "Use count");
+ for (i = 0; i < power_domains->power_well_count; i++) {
+  struct i915_power_well *power_well;
+  enum intel_display_power_domain power_domain;
+
+  power_well = &power_domains->power_wells[i];
+  seq_printf(m, "%-25s %d\n", power_well->name,
+      power_well->count);
+
+  for (power_domain = 0; power_domain < POWER_DOMAIN_NUM;
+       power_domain++) {
+   if (!(BIT(power_domain) & power_well->domains))
+    continue;
+
+   seq_printf(m, "  %-23s %d\n",
+     power_domain_str(power_domain),
+     power_domains->domain_use_count[power_domain]);
+  }
+ }
+
+ mutex_unlock(&power_domains->lock);
+
+ return 0;
+}
+
 struct pipe_crc_info {
  const char *name;
  struct drm_device *dev;
@@ -1857,6 +2020,9 @@ static int i915_pipe_crc_open(struct inode *inode, struct file *filep)
  struct drm_i915_private *dev_priv = info->dev->dev_private;
  struct intel_pipe_crc *pipe_crc = &dev_priv->pipe_crc[info->pipe];
 
+ if (info->pipe >= INTEL_INFO(info->dev)->num_pipes)
+  return -ENODEV;
+
  spin_lock_irq(&pipe_crc->lock);
 
  if (pipe_crc->opened) {
@@ -2005,8 +2171,8 @@ static int i915_pipe_crc_create(struct dentry *root, struct drm_minor *minor,
  info->dev = dev;
  ent = debugfs_create_file(info->name, S_IRUGO, root, info,
       &i915_pipe_crc_fops);
- if (IS_ERR(ent))
-  return PTR_ERR(ent);
+ if (!ent)
+  return -ENOMEM;
 
  return drm_add_fake_info_node(minor, ent, info);
 }
@@ -2347,7 +2513,7 @@ static int pipe_crc_set_source(struct drm_device *dev, enum pipe pipe,
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_pipe_crc *pipe_crc = &dev_priv->pipe_crc[pipe];
- u32 val;
+ u32 val = 0; /* shut up gcc */
  int ret;
 
  if (pipe_crc->source == source)
@@ -2742,7 +2908,7 @@ i915_drop_caches_set(void *data, u64 val)
  struct i915_vma *vma, *x;
  int ret;
 
- DRM_DEBUG_DRIVER("Dropping caches: 0x%08llx\n", val);
+ DRM_DEBUG("Dropping caches: 0x%08llx\n", val);
 
  /* No need to check and wait for gpu resets, only libdrm auto-restarts
   * on ioctls on -EAGAIN. */
@@ -2810,8 +2976,7 @@ i915_max_freq_get(void *data, u64 *val)
   return ret;
 
  if (IS_VALLEYVIEW(dev))
-  *val = vlv_gpu_freq(dev_priv->mem_freq,
-        dev_priv->rps.max_delay);
+  *val = vlv_gpu_freq(dev_priv, dev_priv->rps.max_delay);
  else
   *val = dev_priv->rps.max_delay * GT_FREQUENCY_MULTIPLIER;
  mutex_unlock(&dev_priv->rps.hw_lock);
@@ -2841,9 +3006,9 @@ i915_max_freq_set(void *data, u64 val)
   * Turbo will still be enabled, but won't go above the set value.
   */
  if (IS_VALLEYVIEW(dev)) {
-  val = vlv_freq_opcode(dev_priv->mem_freq, val);
+  val = vlv_freq_opcode(dev_priv, val);
   dev_priv->rps.max_delay = val;
-  gen6_set_rps(dev, val);
+  valleyview_set_rps(dev, val);
  } else {
   do_div(val, GT_FREQUENCY_MULTIPLIER);
   dev_priv->rps.max_delay = val;
@@ -2876,8 +3041,7 @@ i915_min_freq_get(void *data, u64 *val)
   return ret;
 
  if (IS_VALLEYVIEW(dev))
-  *val = vlv_gpu_freq(dev_priv->mem_freq,
-        dev_priv->rps.min_delay);
+  *val = vlv_gpu_freq(dev_priv, dev_priv->rps.min_delay);
  else
   *val = dev_priv->rps.min_delay * GT_FREQUENCY_MULTIPLIER;
  mutex_unlock(&dev_priv->rps.hw_lock);
@@ -2907,7 +3071,7 @@ i915_min_freq_set(void *data, u64 val)
   * Turbo will still be enabled, but won't go below the set value.
   */
  if (IS_VALLEYVIEW(dev)) {
-  val = vlv_freq_opcode(dev_priv->mem_freq, val);
+  val = vlv_freq_opcode(dev_priv, val);
   dev_priv->rps.min_delay = val;
   valleyview_set_rps(dev, val);
  } else {
@@ -2938,8 +3102,11 @@ i915_cache_sharing_get(void *data, u64 *val)
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
 
  snpcr = I915_READ(GEN6_MBCUNIT_SNPCR);
+
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev_priv->dev->struct_mutex);
 
  *val = (snpcr & GEN6_MBC_SNPCR_MASK) >> GEN6_MBC_SNPCR_SHIFT;
@@ -2960,6 +3127,7 @@ i915_cache_sharing_set(void *data, u64 val)
  if (val > 3)
   return -EINVAL;
 
+ intel_runtime_pm_get(dev_priv);
  DRM_DEBUG_DRIVER("Manually setting uncore sharing to %llu\n", val);
 
  /* Update the cache sharing policy here as well */
@@ -2968,6 +3136,7 @@ i915_cache_sharing_set(void *data, u64 val)
  snpcr |= (val << GEN6_MBC_SNPCR_SHIFT);
  I915_WRITE(GEN6_MBCUNIT_SNPCR, snpcr);
 
+ intel_runtime_pm_put(dev_priv);
  return 0;
 }
 
@@ -2983,7 +3152,8 @@ static int i915_forcewake_open(struct inode *inode, struct file *file)
  if (INTEL_INFO(dev)->gen < 6)
   return 0;
 
- gen6_gt_force_wake_get(dev_priv);
+ intel_runtime_pm_get(dev_priv);
+ gen6_gt_force_wake_get(dev_priv, FORCEWAKE_ALL);
 
  return 0;
 }
@@ -2996,7 +3166,8 @@ static int i915_forcewake_release(struct inode *inode, struct file *file)
  if (INTEL_INFO(dev)->gen < 6)
   return 0;
 
- gen6_gt_force_wake_put(dev_priv);
+ gen6_gt_force_wake_put(dev_priv, FORCEWAKE_ALL);
+ intel_runtime_pm_put(dev_priv);
 
  return 0;
 }
@@ -3016,8 +3187,8 @@ static int i915_forcewake_create(struct dentry *root, struct drm_minor *minor)
       S_IRUSR,
       root, dev,
       &i915_forcewake_fops);
- if (IS_ERR(ent))
-  return PTR_ERR(ent);
+ if (!ent)
+  return -ENOMEM;
 
  return drm_add_fake_info_node(minor, ent, &i915_forcewake_fops);
 }
@@ -3034,8 +3205,8 @@ static int i915_debugfs_create(struct dentry *root,
       S_IRUGO | S_IWUSR,
       root, dev,
       fops);
- if (IS_ERR(ent))
-  return PTR_ERR(ent);
+ if (!ent)
+  return -ENOMEM;
 
  return drm_add_fake_info_node(minor, ent, fops);
 }
@@ -3079,6 +3250,7 @@ static const struct drm_info_list i915_debugfs_list[] = {
  {"i915_edp_psr_status", i915_edp_psr_status, 0},
  {"i915_energy_uJ", i915_energy_uJ, 0},
  {"i915_pc8_status", i915_pc8_status, 0},
+ {"i915_power_domain_info", i915_power_domain_info, 0},
 };
 #define I915_DEBUGFS_ENTRIES ARRAY_SIZE(i915_debugfs_list)
 
@@ -3102,10 +3274,10 @@ static const struct i915_debugfs_files {
 void intel_display_crc_init(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
- int i;
+ enum pipe pipe;
 
- for (i = 0; i < INTEL_INFO(dev)->num_pipes; i++) {
-  struct intel_pipe_crc *pipe_crc = &dev_priv->pipe_crc[i];
+ for_each_pipe(pipe) {
+  struct intel_pipe_crc *pipe_crc = &dev_priv->pipe_crc[pipe];
 
   pipe_crc->opened = false;
   spin_lock_init(&pipe_crc->lock);
@@ -3164,5 +3336,3 @@ void i915_debugfs_cleanup(struct drm_minor *minor)
   drm_debugfs_remove_files(info_list, 1, minor);
  }
 }
-
-#endif /* CONFIG_DEBUG_FS */
diff --git a/drivers/gpu/drm/i915/i915_dma.c b/drivers/gpu/drm/i915/i915_dma.c
index 848ad59..d450ccc 100644
--- a/drivers/gpu/drm/i915/i915_dma.c
+++ b/drivers/gpu/drm/i915/i915_dma.c
@@ -42,6 +42,8 @@
 #include <linux/vga_switcheroo.h>
 #include <linux/slab.h>
 #include <acpi/video.h>
+#include <linux/pm.h>
+#include <linux/pm_runtime.h>
 
 #define LP_RING(d) (&((struct drm_i915_private *)(d))->ring[RCS])
 
@@ -791,7 +793,7 @@ static int i915_wait_irq(struct drm_device * dev, int irq_nr)
   master_priv->sarea_priv->perf_boxes |= I915_BOX_WAIT;
 
  if (ring->irq_get(ring)) {
-  DRM_WAIT_ON(ret, ring->irq_queue, 3 * DRM_HZ,
+  DRM_WAIT_ON(ret, ring->irq_queue, 3 * HZ,
        READ_BREADCRUMB(dev_priv) >= irq_nr);
   ring->irq_put(ring);
  } else if (wait_for(READ_BREADCRUMB(dev_priv) >= irq_nr, 3000))
@@ -828,7 +830,7 @@ static int i915_irq_emit(struct drm_device *dev, void *data,
  result = i915_emit_irq(dev);
  mutex_unlock(&dev->struct_mutex);
 
- if (DRM_COPY_TO_USER(emit->irq_seq, &result, sizeof(int))) {
+ if (copy_to_user(emit->irq_seq, &result, sizeof(int))) {
   DRM_ERROR("copy_to_user\n");
   return -EFAULT;
  }
@@ -1016,8 +1018,8 @@ static int i915_getparam(struct drm_device *dev, void *data,
   return -EINVAL;
  }
 
- if (DRM_COPY_TO_USER(param->value, &value, sizeof(int))) {
-  DRM_ERROR("DRM_COPY_TO_USER failed\n");
+ if (copy_to_user(param->value, &value, sizeof(int))) {
+  DRM_ERROR("copy_to_user failed\n");
   return -EFAULT;
  }
 
@@ -1411,7 +1413,7 @@ void i915_master_destroy(struct drm_device *dev, struct drm_master *master)
  master->driver_priv = NULL;
 }
 
-#ifdef CONFIG_DRM_I915_FBDEV
+#if IS_ENABLED(CONFIG_FB)
 static void i915_kick_out_firmware_fb(struct drm_i915_private *dev_priv)
 {
  struct apertures_struct *ap;
@@ -1484,6 +1486,10 @@ int i915_driver_load(struct drm_device *dev, unsigned long flags)
   return -ENODEV;
  }
 
+ /* UMS needs agp support. */
+ if (!drm_core_check_feature(dev, DRIVER_MODESET) && !dev->agp)
+  return -EINVAL;
+
  dev_priv = kzalloc(sizeof(*dev_priv), GFP_KERNEL);
  if (dev_priv == NULL)
   return -ENOMEM;
@@ -1494,7 +1500,7 @@ int i915_driver_load(struct drm_device *dev, unsigned long flags)
 
  spin_lock_init(&dev_priv->irq_lock);
  spin_lock_init(&dev_priv->gpu_error.lock);
- spin_lock_init(&dev_priv->backlight.lock);
+ spin_lock_init(&dev_priv->backlight_lock);
  spin_lock_init(&dev_priv->uncore.lock);
  spin_lock_init(&dev_priv->mm.object_stat_lock);
  mutex_init(&dev_priv->dpio_lock);
@@ -1639,8 +1645,7 @@ int i915_driver_load(struct drm_device *dev, unsigned long flags)
    goto out_gem_unload;
  }
 
- if (HAS_POWER_WELL(dev))
-  intel_power_domains_init(dev);
+ intel_power_domains_init(dev);
 
  if (drm_core_check_feature(dev, DRIVER_MODESET)) {
   ret = i915_load_modeset_init(dev);
@@ -1664,11 +1669,12 @@ int i915_driver_load(struct drm_device *dev, unsigned long flags)
  if (IS_GEN5(dev))
   intel_gpu_ips_init(dev_priv);
 
+ intel_init_runtime_pm(dev_priv);
+
  return 0;
 
 out_power_well:
- if (HAS_POWER_WELL(dev))
-  intel_power_domains_remove(dev);
+ intel_power_domains_remove(dev);
  drm_vblank_cleanup(dev);
 out_gem_unload:
  if (dev_priv->mm.inactive_shrinker.shrink)
@@ -1705,25 +1711,27 @@ int i915_driver_unload(struct drm_device *dev)
  struct drm_i915_private *dev_priv = dev->dev_private;
  int ret;
 
+ ret = i915_gem_suspend(dev);
+ if (ret) {
+  DRM_ERROR("failed to idle hardware: %d\n", ret);
+  return ret;
+ }
+
+ intel_fini_runtime_pm(dev_priv);
+
  intel_gpu_ips_teardown();
 
- if (HAS_POWER_WELL(dev)) {
-  /* The i915.ko module is still not prepared to be loaded when
-   * the power well is not enabled, so just enable it in case
-   * we're going to unload/reload. */
-  intel_display_set_init_power(dev, true);
-  intel_power_domains_remove(dev);
- }
+ /* The i915.ko module is still not prepared to be loaded when
+  * the power well is not enabled, so just enable it in case
+  * we're going to unload/reload. */
+ intel_display_set_init_power(dev, true);
+ intel_power_domains_remove(dev);
 
  i915_teardown_sysfs(dev);
 
  if (dev_priv->mm.inactive_shrinker.shrink)
   unregister_shrinker(&dev_priv->mm.inactive_shrinker);
 
- ret = i915_gem_suspend(dev);
- if (ret)
-  DRM_ERROR("failed to idle hardware: %d\n", ret);
-
  io_mapping_free(dev_priv->gtt.mappable);
  arch_phys_wc_del(dev_priv->gtt.mtrr);
 
@@ -1778,7 +1786,6 @@ int i915_driver_unload(struct drm_device *dev)
 
  list_del(&dev_priv->gtt.base.global_link);
  WARN_ON(!list_empty(&dev_priv->vm_list));
- drm_mm_takedown(&dev_priv->gtt.base.mm);
 
  drm_vblank_cleanup(dev);
 
@@ -1911,6 +1918,7 @@ const struct drm_ioctl_desc i915_ioctls[] = {
  DRM_IOCTL_DEF_DRV(I915_GEM_CONTEXT_CREATE, i915_gem_context_create_ioctl, DRM_UNLOCKED|DRM_RENDER_ALLOW),
  DRM_IOCTL_DEF_DRV(I915_GEM_CONTEXT_DESTROY, i915_gem_context_destroy_ioctl, DRM_UNLOCKED|DRM_RENDER_ALLOW),
  DRM_IOCTL_DEF_DRV(I915_REG_READ, i915_reg_read_ioctl, DRM_UNLOCKED|DRM_RENDER_ALLOW),
+ DRM_IOCTL_DEF_DRV(I915_GET_RESET_STATS, i915_get_reset_stats_ioctl, DRM_UNLOCKED|DRM_RENDER_ALLOW),
 };
 
 int i915_max_ioctl = DRM_ARRAY_SIZE(i915_ioctls);
diff --git a/drivers/gpu/drm/i915/i915_drv.c b/drivers/gpu/drm/i915/i915_drv.c
index 197bb83..ec7bb0f 100644
--- a/drivers/gpu/drm/i915/i915_drv.c
+++ b/drivers/gpu/drm/i915/i915_drv.c
@@ -59,7 +59,7 @@ MODULE_PARM_DESC(powersave,
   "Enable powersavings, fbc, downclocking, etc. (default: true)");
 
 int i915_semaphores __read_mostly = -1;
-module_param_named(semaphores, i915_semaphores, int, 0600);
+module_param_named(semaphores, i915_semaphores, int, 0400);
 MODULE_PARM_DESC(semaphores,
   "Use semaphores for inter-ring sync (default: -1 (use per-chip defaults))");
 
@@ -114,7 +114,7 @@ MODULE_PARM_DESC(enable_hangcheck,
   "(default: true)");
 
 int i915_enable_ppgtt __read_mostly = -1;
-module_param_named(i915_enable_ppgtt, i915_enable_ppgtt, int, 0600);
+module_param_named(i915_enable_ppgtt, i915_enable_ppgtt, int, 0400);
 MODULE_PARM_DESC(i915_enable_ppgtt,
   "Enable PPGTT (default: true)");
 
@@ -155,7 +155,6 @@ MODULE_PARM_DESC(prefault_disable,
   "Disable page prefaulting for pread/pwrite/reloc (default:false). For developers only.");
 
 static struct drm_driver driver;
-extern int intel_agp_enabled;
 
 static const struct intel_device_info intel_i830_info = {
  .gen = 2, .is_mobile = 1, .cursor_needs_physical = 1, .num_pipes = 2,
@@ -173,6 +172,7 @@ static const struct intel_device_info intel_i85x_info = {
  .gen = 2, .is_i85x = 1, .is_mobile = 1, .num_pipes = 2,
  .cursor_needs_physical = 1,
  .has_overlay = 1, .overlay_needs_physical = 1,
+ .has_fbc = 1,
  .ring_mask = RENDER_RING,
 };
 
@@ -192,6 +192,7 @@ static const struct intel_device_info intel_i915gm_info = {
  .cursor_needs_physical = 1,
  .has_overlay = 1, .overlay_needs_physical = 1,
  .supports_tv = 1,
+ .has_fbc = 1,
  .ring_mask = RENDER_RING,
 };
 static const struct intel_device_info intel_i945g_info = {
@@ -204,6 +205,7 @@ static const struct intel_device_info intel_i945gm_info = {
  .has_hotplug = 1, .cursor_needs_physical = 1,
  .has_overlay = 1, .overlay_needs_physical = 1,
  .supports_tv = 1,
+ .has_fbc = 1,
  .ring_mask = RENDER_RING,
 };
 
@@ -265,6 +267,7 @@ static const struct intel_device_info intel_ironlake_m_info = {
 static const struct intel_device_info intel_sandybridge_d_info = {
  .gen = 6, .num_pipes = 2,
  .need_gfx_hws = 1, .has_hotplug = 1,
+ .has_fbc = 1,
  .ring_mask = RENDER_RING | BSD_RING | BLT_RING,
  .has_llc = 1,
 };
@@ -280,6 +283,7 @@ static const struct intel_device_info intel_sandybridge_m_info = {
 #define GEN7_FEATURES  \
  .gen = 7, .num_pipes = 3, \
  .need_gfx_hws = 1, .has_hotplug = 1, \
+ .has_fbc = 1, \
  .ring_mask = RENDER_RING | BSD_RING | BLT_RING, \
  .has_llc = 1
 
@@ -292,7 +296,6 @@ static const struct intel_device_info intel_ivybridge_m_info = {
  GEN7_FEATURES,
  .is_ivybridge = 1,
  .is_mobile = 1,
- .has_fbc = 1,
 };
 
 static const struct intel_device_info intel_ivybridge_q_info = {
@@ -307,6 +310,7 @@ static const struct intel_device_info intel_valleyview_m_info = {
  .num_pipes = 2,
  .is_valleyview = 1,
  .display_mmio_offset = VLV_DISPLAY_BASE,
+ .has_fbc = 0, /* legal, last one wins */
  .has_llc = 0, /* legal, last one wins */
 };
 
@@ -315,6 +319,7 @@ static const struct intel_device_info intel_valleyview_d_info = {
  .num_pipes = 2,
  .is_valleyview = 1,
  .display_mmio_offset = VLV_DISPLAY_BASE,
+ .has_fbc = 0, /* legal, last one wins */
  .has_llc = 0, /* legal, last one wins */
 };
 
@@ -332,12 +337,10 @@ static const struct intel_device_info intel_haswell_m_info = {
  .is_mobile = 1,
  .has_ddi = 1,
  .has_fpga_dbg = 1,
- .has_fbc = 1,
  .ring_mask = RENDER_RING | BSD_RING | BLT_RING | VEBOX_RING,
 };
 
 static const struct intel_device_info intel_broadwell_d_info = {
- .is_preliminary = 1,
  .gen = 8, .num_pipes = 3,
  .need_gfx_hws = 1, .has_hotplug = 1,
  .ring_mask = RENDER_RING | BSD_RING | BLT_RING | VEBOX_RING,
@@ -346,7 +349,6 @@ static const struct intel_device_info intel_broadwell_d_info = {
 };
 
 static const struct intel_device_info intel_broadwell_m_info = {
- .is_preliminary = 1,
  .gen = 8, .is_mobile = 1, .num_pipes = 3,
  .need_gfx_hws = 1, .has_hotplug = 1,
  .ring_mask = RENDER_RING | BSD_RING | BLT_RING | VEBOX_RING,
@@ -471,12 +473,12 @@ void intel_detect_pch(struct drm_device *dev)
 bool i915_semaphore_is_enabled(struct drm_device *dev)
 {
  if (INTEL_INFO(dev)->gen < 6)
-  return 0;
+  return false;
 
  /* Until we get further testing... */
  if (IS_GEN8(dev)) {
   WARN_ON(!i915_preliminary_hw_support);
-  return 0;
+  return false;
  }
 
  if (i915_semaphores >= 0)
@@ -488,7 +490,7 @@ bool i915_semaphore_is_enabled(struct drm_device *dev)
   return false;
 #endif
 
- return 1;
+ return true;
 }
 
 static int i915_drm_freeze(struct drm_device *dev)
@@ -496,6 +498,8 @@ static int i915_drm_freeze(struct drm_device *dev)
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct drm_crtc *crtc;
 
+ intel_runtime_pm_get(dev_priv);
+
  /* ignore lid events during suspend */
  mutex_lock(&dev_priv->modeset_restore_lock);
  dev_priv->modeset_restore = MODESET_SUSPENDED;
@@ -683,6 +687,8 @@ static int __i915_drm_thaw(struct drm_device *dev, bool restore_gtt_mappings)
  mutex_lock(&dev_priv->modeset_restore_lock);
  dev_priv->modeset_restore = MODESET_DONE;
  mutex_unlock(&dev_priv->modeset_restore_lock);
+
+ intel_runtime_pm_put(dev_priv);
  return error;
 }
 
@@ -757,14 +763,14 @@ int i915_reset(struct drm_device *dev)
   DRM_INFO("Simulated gpu hang, resetting stop_rings\n");
   dev_priv->gpu_error.stop_rings = 0;
   if (ret == -ENODEV) {
-   DRM_ERROR("Reset not implemented, but ignoring "
-      "error for simulated gpu hangs\n");
+   DRM_INFO("Reset not implemented, but ignoring "
+     "error for simulated gpu hangs\n");
    ret = 0;
   }
  }
 
  if (ret) {
-  DRM_ERROR("Failed to reset chip.\n");
+  DRM_ERROR("Failed to reset chip: %i\n", ret);
   mutex_unlock(&dev->struct_mutex);
   return ret;
  }
@@ -785,12 +791,9 @@ int i915_reset(struct drm_device *dev)
   */
  if (drm_core_check_feature(dev, DRIVER_MODESET) ||
    !dev_priv->ums.mm_suspended) {
-  bool hw_contexts_disabled = dev_priv->hw_contexts_disabled;
   dev_priv->ums.mm_suspended = 0;
 
   ret = i915_gem_init_hw(dev);
-  if (!hw_contexts_disabled && dev_priv->hw_contexts_disabled)
-   DRM_ERROR("HW contexts didn't survive reset\n");
   mutex_unlock(&dev->struct_mutex);
   if (ret) {
    DRM_ERROR("Failed hw init on reset %d\n", ret);
@@ -826,17 +829,7 @@ static int i915_pci_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
  if (PCI_FUNC(pdev->devfn))
   return -ENODEV;
 
- /* We've managed to ship a kms-enabled ddx that shipped with an XvMC
-  * implementation for gen3 (and only gen3) that used legacy drm maps
-  * (gasp!) to share buffers between X and the client. Hence we need to
-  * keep around the fake agp stuff for gen3, even when kms is enabled. */
- if (intel_info->gen != 3) {
-  driver.driver_features &=
-   ~(DRIVER_USE_AGP | DRIVER_REQUIRE_AGP);
- } else if (!intel_agp_enabled) {
-  DRM_ERROR("drm/i915 can't work without intel_agp module!\n");
-  return -ENODEV;
- }
+ driver.driver_features &= ~(DRIVER_USE_AGP);
 
  return drm_get_pci_dev(pdev, ent, &driver);
 }
@@ -910,6 +903,49 @@ static int i915_pm_poweroff(struct device *dev)
  return i915_drm_freeze(drm_dev);
 }
 
+static int i915_runtime_suspend(struct device *device)
+{
+ struct pci_dev *pdev = to_pci_dev(device);
+ struct drm_device *dev = pci_get_drvdata(pdev);
+ struct drm_i915_private *dev_priv = dev->dev_private;
+
+ WARN_ON(!HAS_RUNTIME_PM(dev));
+
+ DRM_DEBUG_KMS("Suspending device\n");
+
+ i915_gem_release_all_mmaps(dev_priv);
+
+ del_timer_sync(&dev_priv->gpu_error.hangcheck_timer);
+ dev_priv->pm.suspended = true;
+
+ /*
+  * current versions of firmware which depend on this opregion
+  * notification have repurposed the D1 definition to mean
+  * "runtime suspended" vs. what you would normally expect (D3)
+  * to distinguish it from notifications that might be sent
+  * via the suspend path.
+  */
+ intel_opregion_notify_adapter(dev, PCI_D1);
+
+ return 0;
+}
+
+static int i915_runtime_resume(struct device *device)
+{
+ struct pci_dev *pdev = to_pci_dev(device);
+ struct drm_device *dev = pci_get_drvdata(pdev);
+ struct drm_i915_private *dev_priv = dev->dev_private;
+
+ WARN_ON(!HAS_RUNTIME_PM(dev));
+
+ DRM_DEBUG_KMS("Resuming device\n");
+
+ intel_opregion_notify_adapter(dev, PCI_D0);
+ dev_priv->pm.suspended = false;
+
+ return 0;
+}
+
 static const struct dev_pm_ops i915_pm_ops = {
  .suspend = i915_pm_suspend,
  .resume = i915_pm_resume,
@@ -917,6 +953,8 @@ static const struct dev_pm_ops i915_pm_ops = {
  .thaw = i915_pm_thaw,
  .poweroff = i915_pm_poweroff,
  .restore = i915_pm_resume,
+ .runtime_suspend = i915_runtime_suspend,
+ .runtime_resume = i915_runtime_resume,
 };
 
 static const struct vm_operations_struct i915_gem_vm_ops = {
@@ -944,7 +982,7 @@ static struct drm_driver driver = {
   * deal with them for Intel hardware.
   */
  .driver_features =
-     DRIVER_USE_AGP | DRIVER_REQUIRE_AGP |
+     DRIVER_USE_AGP |
      DRIVER_HAVE_IRQ | DRIVER_IRQ_SHARED | DRIVER_GEM | DRIVER_PRIME |
      DRIVER_RENDER,
  .load = i915_driver_load,
@@ -1019,14 +1057,24 @@ static int __init i915_init(void)
   driver.driver_features &= ~DRIVER_MODESET;
 #endif
 
- if (!(driver.driver_features & DRIVER_MODESET))
+ if (!(driver.driver_features & DRIVER_MODESET)) {
   driver.get_vblank_timestamp = NULL;
+#ifndef CONFIG_DRM_I915_UMS
+  /* Silently fail loading to not upset userspace. */
+  return 0;
+#endif
+ }
 
  return drm_pci_init(&driver, &i915_pci_driver);
 }
 
 static void __exit i915_exit(void)
 {
+#ifndef CONFIG_DRM_I915_UMS
+ if (!(driver.driver_features & DRIVER_MODESET))
+  return; /* Never loaded a driver. */
+#endif
+
  drm_pci_exit(&driver, &i915_pci_driver);
 }
 
diff --git a/drivers/gpu/drm/i915/i915_drv.h b/drivers/gpu/drm/i915/i915_drv.h
index 221ac62..df77e20 100644
--- a/drivers/gpu/drm/i915/i915_drv.h
+++ b/drivers/gpu/drm/i915/i915_drv.h
@@ -89,6 +89,18 @@ enum port {
 };
 #define port_name(p) ((p) + 'A')
 
+#define I915_NUM_PHYS_VLV 1
+
+enum dpio_channel {
+ DPIO_CH0,
+ DPIO_CH1
+};
+
+enum dpio_phy {
+ DPIO_PHY0,
+ DPIO_PHY1
+};
+
 enum intel_display_power_domain {
  POWER_DOMAIN_PIPE_A,
  POWER_DOMAIN_PIPE_B,
@@ -101,6 +113,7 @@ enum intel_display_power_domain {
  POWER_DOMAIN_TRANSCODER_C,
  POWER_DOMAIN_TRANSCODER_EDP,
  POWER_DOMAIN_VGA,
+ POWER_DOMAIN_AUDIO,
  POWER_DOMAIN_INIT,
 
  POWER_DOMAIN_NUM,
@@ -310,7 +323,7 @@ struct drm_i915_error_state {
  u32 instps[I915_NUM_RINGS];
  u32 extra_instdone[I915_NUM_INSTDONE_REG];
  u32 seqno[I915_NUM_RINGS];
- u64 bbaddr;
+ u64 bbaddr[I915_NUM_RINGS];
  u32 fault_reg[I915_NUM_RINGS];
  u32 done_reg;
  u32 faddr[I915_NUM_RINGS];
@@ -352,6 +365,7 @@ struct drm_i915_error_state {
  enum intel_ring_hangcheck_action hangcheck_action[I915_NUM_RINGS];
 };
 
+struct intel_connector;
 struct intel_crtc_config;
 struct intel_crtc;
 struct intel_limit;
@@ -359,7 +373,7 @@ struct dpll;
 
 struct drm_i915_display_funcs {
  bool (*fbc_enabled)(struct drm_device *dev);
- void (*enable_fbc)(struct drm_crtc *crtc, unsigned long interval);
+ void (*enable_fbc)(struct drm_crtc *crtc);
  void (*disable_fbc)(struct drm_device *dev);
  int (*get_display_clock_speed)(struct drm_device *dev);
  int (*get_fifo_size)(struct drm_device *dev, int plane);
@@ -414,11 +428,20 @@ struct drm_i915_display_funcs {
  /* render clock increase/decrease */
  /* display clock increase/decrease */
  /* pll clock increase/decrease */
+
+ int (*setup_backlight)(struct intel_connector *connector);
+ uint32_t (*get_backlight)(struct intel_connector *connector);
+ void (*set_backlight)(struct intel_connector *connector,
+         uint32_t level);
+ void (*disable_backlight)(struct intel_connector *connector);
+ void (*enable_backlight)(struct intel_connector *connector);
 };
 
 struct intel_uncore_funcs {
- void (*force_wake_get)(struct drm_i915_private *dev_priv);
- void (*force_wake_put)(struct drm_i915_private *dev_priv);
+ void (*force_wake_get)(struct drm_i915_private *dev_priv,
+       int fw_engine);
+ void (*force_wake_put)(struct drm_i915_private *dev_priv,
+       int fw_engine);
 
  uint8_t  (*mmio_readb)(struct drm_i915_private *dev_priv, off_t offset, bool trace);
  uint16_t (*mmio_readw)(struct drm_i915_private *dev_priv, off_t offset, bool trace);
@@ -443,6 +466,9 @@ struct intel_uncore {
  unsigned fifo_count;
  unsigned forcewake_count;
 
+ unsigned fw_rendercount;
+ unsigned fw_mediacount;
+
  struct delayed_work force_wake_work;
 };
 
@@ -670,7 +696,6 @@ struct i915_fbc {
   struct delayed_work work;
   struct drm_crtc *crtc;
   struct drm_framebuffer *fb;
-  int interval;
  } *fbc_work;
 
  enum no_fbc_reason {
@@ -709,7 +734,6 @@ enum intel_sbi_destination {
 #define QUIRK_PIPEA_FORCE (1<<0)
 #define QUIRK_LVDS_SSC_DISABLE (1<<1)
 #define QUIRK_INVERT_BRIGHTNESS (1<<2)
-#define QUIRK_NO_PCH_PWM_ENABLE (1<<3)
 
 struct intel_fbdev;
 struct intel_fbc_work;
@@ -762,8 +786,6 @@ struct i915_suspend_saved_registers {
  u32 saveBLC_PWM_CTL;
  u32 saveBLC_PWM_CTL2;
  u32 saveBLC_HIST_CTL_B;
- u32 saveBLC_PWM_CTL_B;
- u32 saveBLC_PWM_CTL2_B;
  u32 saveBLC_CPU_PWM_CTL;
  u32 saveBLC_CPU_PWM_CTL2;
  u32 saveFPB0;
@@ -933,21 +955,29 @@ struct intel_ilk_power_mgmt {
 
 /* Power well structure for haswell */
 struct i915_power_well {
+ const char *name;
+ bool always_on;
  /* power well enable/disable usage count */
  int count;
+ unsigned long domains;
+ void *data;
+ void (*set)(struct drm_device *dev, struct i915_power_well *power_well,
+      bool enable);
+ bool (*is_enabled)(struct drm_device *dev,
+      struct i915_power_well *power_well);
 };
 
-#define I915_MAX_POWER_WELLS 1
-
 struct i915_power_domains {
  /*
   * Power wells needed for initialization at driver init and suspend
   * time are on. They are kept on until after the first modeset.
   */
  bool init_power_on;
+ int power_well_count;
 
  struct mutex lock;
- struct i915_power_well power_wells[I915_MAX_POWER_WELLS];
+ int domain_use_count[POWER_DOMAIN_NUM];
+ struct i915_power_well *power_wells;
 };
 
 struct i915_dri1_state {
@@ -1078,34 +1108,30 @@ struct i915_gpu_error {
  unsigned long missed_irq_rings;
 
  /**
-  * State variable and reset counter controlling the reset flow
+  * State variable controlling the reset flow and count
   *
-  * Upper bits are for the reset counter.  This counter is used by the
-  * wait_seqno code to race-free noticed that a reset event happened and
-  * that it needs to restart the entire ioctl (since most likely the
-  * seqno it waited for won't ever signal anytime soon).
+  * This is a counter which gets incremented when reset is triggered,
+  * and again when reset has been handled. So odd values (lowest bit set)
+  * means that reset is in progress and even values that
+  * (reset_counter >> 1):th reset was successfully completed.
+  *
+  * If reset is not completed succesfully, the I915_WEDGE bit is
+  * set meaning that hardware is terminally sour and there is no
+  * recovery. All waiters on the reset_queue will be woken when
+  * that happens.
+  *
+  * This counter is used by the wait_seqno code to notice that reset
+  * event happened and it needs to restart the entire ioctl (since most
+  * likely the seqno it waited for won't ever signal anytime soon).
   *
   * This is important for lock-free wait paths, where no contended lock
   * naturally enforces the correct ordering between the bail-out of the
   * waiter and the gpu reset work code.
-  *
-  * Lowest bit controls the reset state machine: Set means a reset is in
-  * progress. This state will (presuming we don't have any bugs) decay
-  * into either unset (successful reset) or the special WEDGED value (hw
-  * terminally sour). All waiters on the reset_queue will be woken when
-  * that happens.
   */
  atomic_t reset_counter;
 
- /**
-  * Special values/flags for reset_counter
-  *
-  * Note that the code relies on
-  *  I915_WEDGED & I915_RESET_IN_PROGRESS_FLAG
-  * being true.
-  */
 #define I915_RESET_IN_PROGRESS_FLAG 1
-#define I915_WEDGED   0xffffffff
+#define I915_WEDGED   (1 << 31)
 
  /**
   * Waitqueue to signal when the reset has completed. Used by clients
@@ -1159,6 +1185,11 @@ struct intel_vbt_data {
  int edp_bpp;
  struct edp_power_seq edp_pps;
 
+ struct {
+  u16 pwm_freq_hz;
+  bool active_low_pwm;
+ } backlight;
+
  /* MIPI DSI */
  struct {
   u16 panel_id;
@@ -1185,7 +1216,7 @@ struct intel_wm_level {
  uint32_t fbc_val;
 };
 
-struct hsw_wm_values {
+struct ilk_wm_values {
  uint32_t wm_pipe[3];
  uint32_t wm_lp[3];
  uint32_t wm_lp_spr[3];
@@ -1263,6 +1294,10 @@ struct i915_package_c8 {
  } regsave;
 };
 
+struct i915_runtime_pm {
+ bool suspended;
+};
+
 enum intel_pipe_crc_source {
  INTEL_PIPE_CRC_SOURCE_NONE,
  INTEL_PIPE_CRC_SOURCE_PLANE1,
@@ -1367,15 +1402,9 @@ typedef struct drm_i915_private {
 
  /* overlay */
  struct intel_overlay *overlay;
- unsigned int sprite_scaling_enabled;
 
- /* backlight */
- struct {
-  int level;
-  bool enabled;
-  spinlock_t lock; /* bl registers and the above bl fields */
-  struct backlight_device *device;
- } backlight;
+ /* backlight registers and fields in struct intel_panel */
+ spinlock_t backlight_lock;
 
  /* LVDS info */
  bool no_aux_handshake;
@@ -1427,6 +1456,7 @@ typedef struct drm_i915_private {
  int num_shared_dpll;
  struct intel_shared_dpll shared_dplls[I915_NUM_PLLS];
  struct intel_ddi_plls ddi_plls;
+ int dpio_phy_iosf_port[I915_NUM_PHYS_VLV];
 
  /* Reclocking support */
  bool render_reclock_avail;
@@ -1471,7 +1501,6 @@ typedef struct drm_i915_private {
  struct drm_property *broadcast_rgb_property;
  struct drm_property *force_audio_property;
 
- bool hw_contexts_disabled;
  uint32_t hw_context_size;
  struct list_head context_list;
 
@@ -1493,11 +1522,13 @@ typedef struct drm_i915_private {
   uint16_t cur_latency[5];
 
   /* current hardware state */
-  struct hsw_wm_values hw;
+  struct ilk_wm_values hw;
  } wm;
 
  struct i915_package_c8 pc8;
 
+ struct i915_runtime_pm pm;
+
  /* Old dri1 support infrastructure, beware the dragons ya fools entering
   * here! */
  struct i915_dri1_state dri1;
@@ -1800,6 +1831,14 @@ struct drm_i915_file_private {
 
 /* Early gen2 have a totally busted CS tlb and require pinned batches. */
 #define HAS_BROKEN_CS_TLB(dev)  (IS_I830(dev) || IS_845G(dev))
+/*
+ * dp aux and gmbus irq on gen4 seems to be able to generate legacy interrupts
+ * even when in MSI mode. This results in spurious interrupt warnings if the
+ * legacy irq no. is shared with another device. The kernel then disables that
+ * interrupt source and so prevents the other device from working properly.
+ */
+#define HAS_AUX_IRQ(dev) (INTEL_INFO(dev)->gen >= 5)
+#define HAS_GMBUS_IRQ(dev) (INTEL_INFO(dev)->gen >= 5)
 
 /* With the 945 and later, Y tiling got adjusted so that it was 32 128-byte
  * rows, which changed the alignment requirements and fence programming.
@@ -1814,15 +1853,15 @@ struct drm_i915_file_private {
 
 #define HAS_FW_BLC(dev) (INTEL_INFO(dev)->gen > 2)
 #define HAS_PIPE_CXSR(dev) (INTEL_INFO(dev)->has_pipe_cxsr)
-#define I915_HAS_FBC(dev) (INTEL_INFO(dev)->has_fbc)
+#define HAS_FBC(dev) (INTEL_INFO(dev)->has_fbc)
 
 #define HAS_IPS(dev)  (IS_ULT(dev) || IS_BROADWELL(dev))
 
 #define HAS_DDI(dev)  (INTEL_INFO(dev)->has_ddi)
-#define HAS_POWER_WELL(dev) (IS_HASWELL(dev) || IS_BROADWELL(dev))
 #define HAS_FPGA_DBG_UNCLAIMED(dev) (INTEL_INFO(dev)->has_fpga_dbg)
 #define HAS_PSR(dev)  (IS_HASWELL(dev) || IS_BROADWELL(dev))
 #define HAS_PC8(dev)  (IS_HASWELL(dev)) /* XXX HSW:ULX */
+#define HAS_RUNTIME_PM(dev) (IS_HASWELL(dev))
 
 #define INTEL_PCH_DEVICE_ID_MASK  0xff00
 #define INTEL_PCH_IBX_DEVICE_ID_TYPE  0x3b00
@@ -1912,7 +1951,6 @@ extern void intel_hpd_init(struct drm_device *dev);
 extern void intel_uncore_sanitize(struct drm_device *dev);
 extern void intel_uncore_early_sanitize(struct drm_device *dev);
 extern void intel_uncore_init(struct drm_device *dev);
-extern void intel_uncore_clear_errors(struct drm_device *dev);
 extern void intel_uncore_check_errors(struct drm_device *dev);
 extern void intel_uncore_fini(struct drm_device *dev);
 
@@ -1988,6 +2026,7 @@ void i915_gem_object_unpin(struct drm_i915_gem_object *obj);
 int __must_check i915_vma_unbind(struct i915_vma *vma);
 int __must_check i915_gem_object_ggtt_unbind(struct drm_i915_gem_object *obj);
 int i915_gem_object_put_pages(struct drm_i915_gem_object *obj);
+void i915_gem_release_all_mmaps(struct drm_i915_private *dev_priv);
 void i915_gem_release_mmap(struct drm_i915_gem_object *obj);
 void i915_gem_lastclose(struct drm_device *dev);
 
@@ -2064,12 +2103,17 @@ int __must_check i915_gem_check_wedge(struct i915_gpu_error *error,
 static inline bool i915_reset_in_progress(struct i915_gpu_error *error)
 {
  return unlikely(atomic_read(&error->reset_counter)
-   & I915_RESET_IN_PROGRESS_FLAG);
+   & (I915_RESET_IN_PROGRESS_FLAG | I915_WEDGED));
 }
 
 static inline bool i915_terminally_wedged(struct i915_gpu_error *error)
 {
- return atomic_read(&error->reset_counter) == I915_WEDGED;
+ return atomic_read(&error->reset_counter) & I915_WEDGED;
+}
+
+static inline u32 i915_reset_count(struct i915_gpu_error *error)
+{
+ return ((atomic_read(&error->reset_counter) & ~I915_WEDGED) + 1) / 2;
 }
 
 void i915_gem_reset(struct drm_device *dev);
@@ -2181,7 +2225,7 @@ i915_gem_obj_ggtt_pin(struct drm_i915_gem_object *obj,
 }
 
 /* i915_gem_context.c */
-void i915_gem_context_init(struct drm_device *dev);
+int __must_check i915_gem_context_init(struct drm_device *dev);
 void i915_gem_context_fini(struct drm_device *dev);
 void i915_gem_context_close(struct drm_device *dev, struct drm_file *file);
 int i915_switch_context(struct intel_ring_buffer *ring,
@@ -2340,8 +2384,8 @@ extern void intel_i2c_reset(struct drm_device *dev);
 
 /* intel_opregion.c */
 struct intel_encoder;
-extern int intel_opregion_setup(struct drm_device *dev);
 #ifdef CONFIG_ACPI
+extern int intel_opregion_setup(struct drm_device *dev);
 extern void intel_opregion_init(struct drm_device *dev);
 extern void intel_opregion_fini(struct drm_device *dev);
 extern void intel_opregion_asle_intr(struct drm_device *dev);
@@ -2350,6 +2394,7 @@ extern int intel_opregion_notify_encoder(struct intel_encoder *intel_encoder,
 extern int intel_opregion_notify_adapter(struct drm_device *dev,
       pci_power_t state);
 #else
+static inline int intel_opregion_setup(struct drm_device *dev) { return 0; }
 static inline void intel_opregion_init(struct drm_device *dev) { return; }
 static inline void intel_opregion_fini(struct drm_device *dev) { return; }
 static inline void intel_opregion_asle_intr(struct drm_device *dev) { return; }
@@ -2399,6 +2444,8 @@ extern int intel_enable_rc6(const struct drm_device *dev);
 extern bool i915_semaphore_is_enabled(struct drm_device *dev);
 int i915_reg_read_ioctl(struct drm_device *dev, void *data,
    struct drm_file *file);
+int i915_get_reset_stats_ioctl(struct drm_device *dev, void *data,
+          struct drm_file *file);
 
 /* overlay */
 extern struct intel_overlay_error_state *intel_overlay_capture_error_state(struct drm_device *dev);
@@ -2414,8 +2461,8 @@ extern void intel_display_print_error_state(struct drm_i915_error_state_buf *e,
  * must be set to prevent GT core from power down and stale values being
  * returned.
  */
-void gen6_gt_force_wake_get(struct drm_i915_private *dev_priv);
-void gen6_gt_force_wake_put(struct drm_i915_private *dev_priv);
+void gen6_gt_force_wake_get(struct drm_i915_private *dev_priv, int fw_engine);
+void gen6_gt_force_wake_put(struct drm_i915_private *dev_priv, int fw_engine);
 
 int sandybridge_pcode_read(struct drm_i915_private *dev_priv, u8 mbox, u32 *val);
 int sandybridge_pcode_write(struct drm_i915_private *dev_priv, u8 mbox, u32 val);
@@ -2430,6 +2477,8 @@ u32 vlv_cck_read(struct drm_i915_private *dev_priv, u32 reg);
 void vlv_cck_write(struct drm_i915_private *dev_priv, u32 reg, u32 val);
 u32 vlv_ccu_read(struct drm_i915_private *dev_priv, u32 reg);
 void vlv_ccu_write(struct drm_i915_private *dev_priv, u32 reg, u32 val);
+u32 vlv_bunit_read(struct drm_i915_private *dev_priv, u32 reg);
+void vlv_bunit_write(struct drm_i915_private *dev_priv, u32 reg, u32 val);
 u32 vlv_gps_core_read(struct drm_i915_private *dev_priv, u32 reg);
 void vlv_gps_core_write(struct drm_i915_private *dev_priv, u32 reg, u32 val);
 u32 vlv_dpio_read(struct drm_i915_private *dev_priv, enum pipe pipe, int reg);
@@ -2438,9 +2487,30 @@ u32 intel_sbi_read(struct drm_i915_private *dev_priv, u16 reg,
      enum intel_sbi_destination destination);
 void intel_sbi_write(struct drm_i915_private *dev_priv, u16 reg, u32 value,
        enum intel_sbi_destination destination);
+u32 vlv_flisdsi_read(struct drm_i915_private *dev_priv, u32 reg);
+void vlv_flisdsi_write(struct drm_i915_private *dev_priv, u32 reg, u32 val);
+
+int vlv_gpu_freq(struct drm_i915_private *dev_priv, int val);
+int vlv_freq_opcode(struct drm_i915_private *dev_priv, int val);
+
+void vlv_force_wake_get(struct drm_i915_private *dev_priv, int fw_engine);
+void vlv_force_wake_put(struct drm_i915_private *dev_priv, int fw_engine);
+
+#define FORCEWAKE_VLV_RENDER_RANGE_OFFSET(reg) \
+ (((reg) >= 0x2000 && (reg) < 0x4000) ||\
+ ((reg) >= 0x5000 && (reg) < 0x8000) ||\
+ ((reg) >= 0xB000 && (reg) < 0x12000) ||\
+ ((reg) >= 0x2E000 && (reg) < 0x30000))
+
+#define FORCEWAKE_VLV_MEDIA_RANGE_OFFSET(reg)\
+ (((reg) >= 0x12000 && (reg) < 0x14000) ||\
+ ((reg) >= 0x22000 && (reg) < 0x24000) ||\
+ ((reg) >= 0x30000 && (reg) < 0x40000))
+
+#define FORCEWAKE_RENDER (1 << 0)
+#define FORCEWAKE_MEDIA  (1 << 1)
+#define FORCEWAKE_ALL  (FORCEWAKE_RENDER | FORCEWAKE_MEDIA)
 
-int vlv_gpu_freq(int ddr_freq, int val);
-int vlv_freq_opcode(int ddr_freq, int val);
 
 #define I915_READ8(reg)  dev_priv->uncore.funcs.mmio_readb(dev_priv, (reg), true)
 #define I915_WRITE8(reg, val) dev_priv->uncore.funcs.mmio_writeb(dev_priv, (reg), (val), true)
diff --git a/drivers/gpu/drm/i915/i915_gem.c b/drivers/gpu/drm/i915/i915_gem.c
index 30f75d2..9720346 100644
--- a/drivers/gpu/drm/i915/i915_gem.c
+++ b/drivers/gpu/drm/i915/i915_gem.c
@@ -1013,9 +1013,11 @@ static int __wait_seqno(struct intel_ring_buffer *ring, u32 seqno,
    struct drm_i915_file_private *file_priv)
 {
  drm_i915_private_t *dev_priv = ring->dev->dev_private;
+ const bool irq_test_in_progress =
+  ACCESS_ONCE(dev_priv->gpu_error.test_irq_rings) & intel_ring_flag(ring);
  struct timespec before, now;
  DEFINE_WAIT(wait);
- long timeout_jiffies;
+ unsigned long timeout_expire;
  int ret;
 
  WARN(dev_priv->pc8.irqs_disabled, "IRQs disabled\n");
@@ -1023,7 +1025,7 @@ static int __wait_seqno(struct intel_ring_buffer *ring, u32 seqno,
  if (i915_seqno_passed(ring->get_seqno(ring, true), seqno))
   return 0;
 
- timeout_jiffies = timeout ? timespec_to_jiffies_timeout(timeout) : 1;
+ timeout_expire = timeout ? jiffies + timespec_to_jiffies_timeout(timeout) : 0;
 
  if (dev_priv->info->gen >= 6 && can_wait_boost(file_priv)) {
   gen6_rps_boost(dev_priv);
@@ -1033,8 +1035,7 @@ static int __wait_seqno(struct intel_ring_buffer *ring, u32 seqno,
       msecs_to_jiffies(100));
  }
 
- if (!(dev_priv->gpu_error.test_irq_rings & intel_ring_flag(ring)) &&
-     WARN_ON(!ring->irq_get(ring)))
+ if (!irq_test_in_progress && WARN_ON(!ring->irq_get(ring)))
   return -ENODEV;
 
  /* Record current time in case interrupted by signal, or wedged */
@@ -1042,7 +1043,6 @@ static int __wait_seqno(struct intel_ring_buffer *ring, u32 seqno,
  getrawmonotonic(&before);
  for (;;) {
   struct timer_list timer;
-  unsigned long expire;
 
   prepare_to_wait(&ring->irq_queue, &wait,
     interruptible ? TASK_INTERRUPTIBLE : TASK_UNINTERRUPTIBLE);
@@ -1068,23 +1068,22 @@ static int __wait_seqno(struct intel_ring_buffer *ring, u32 seqno,
    break;
   }
 
-  if (timeout_jiffies <= 0) {
+  if (timeout && time_after_eq(jiffies, timeout_expire)) {
    ret = -ETIME;
    break;
   }
 
   timer.function = NULL;
   if (timeout || missed_irq(dev_priv, ring)) {
+   unsigned long expire;
+
    setup_timer_on_stack(&timer, fake_irq, (unsigned long)current);
-   expire = jiffies + (missed_irq(dev_priv, ring) ? 1: timeout_jiffies);
+   expire = missed_irq(dev_priv, ring) ? jiffies + 1 : timeout_expire;
    mod_timer(&timer, expire);
   }
 
   io_schedule();
 
-  if (timeout)
-   timeout_jiffies = expire - jiffies;
-
   if (timer.function) {
    del_singleshot_timer_sync(&timer);
    destroy_timer_on_stack(&timer);
@@ -1093,7 +1092,8 @@ static int __wait_seqno(struct intel_ring_buffer *ring, u32 seqno,
  getrawmonotonic(&now);
  trace_i915_gem_request_wait_end(ring, seqno);
 
- ring->irq_put(ring);
+ if (!irq_test_in_progress)
+  ring->irq_put(ring);
 
  finish_wait(&ring->irq_queue, &wait);
 
@@ -1378,6 +1378,8 @@ int i915_gem_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
  int ret = 0;
  bool write = !!(vmf->flags & FAULT_FLAG_WRITE);
 
+ intel_runtime_pm_get(dev_priv);
+
  /* We don't use vmf->pgoff since that has the fake offset */
  page_offset = ((unsigned long)vmf->virtual_address - vma->vm_start) >>
   PAGE_SHIFT;
@@ -1425,8 +1427,10 @@ out:
   /* If this -EIO is due to a gpu hang, give the reset code a
    * chance to clean up the mess. Otherwise return the proper
    * SIGBUS. */
-  if (i915_terminally_wedged(&dev_priv->gpu_error))
-   return VM_FAULT_SIGBUS;
+  if (i915_terminally_wedged(&dev_priv->gpu_error)) {
+   ret = VM_FAULT_SIGBUS;
+   break;
+  }
  case -EAGAIN:
   /*
    * EAGAIN means the gpu is hung and we'll wait for the error
@@ -1441,15 +1445,38 @@ out:
    * EBUSY is ok: this just means that another thread
    * already did the job.
    */
-  return VM_FAULT_NOPAGE;
+  ret = VM_FAULT_NOPAGE;
+  break;
  case -ENOMEM:
-  return VM_FAULT_OOM;
+  ret = VM_FAULT_OOM;
+  break;
  case -ENOSPC:
-  return VM_FAULT_SIGBUS;
+  ret = VM_FAULT_SIGBUS;
+  break;
  default:
   WARN_ONCE(ret, "unhandled error in i915_gem_fault: %i\n", ret);
-  return VM_FAULT_SIGBUS;
+  ret = VM_FAULT_SIGBUS;
+  break;
  }
+
+ intel_runtime_pm_put(dev_priv);
+ return ret;
+}
+
+void i915_gem_release_all_mmaps(struct drm_i915_private *dev_priv)
+{
+ struct i915_vma *vma;
+
+ /*
+  * Only the global gtt is relevant for gtt memory mappings, so restrict
+  * list traversal to objects bound into the global address space. Note
+  * that the active list should be empty, but better safe than sorry.
+  */
+ WARN_ON(!list_empty(&dev_priv->gtt.base.active_list));
+ list_for_each_entry(vma, &dev_priv->gtt.base.active_list, mm_list)
+  i915_gem_release_mmap(vma->obj);
+ list_for_each_entry(vma, &dev_priv->gtt.base.inactive_list, mm_list)
+  i915_gem_release_mmap(vma->obj);
 }
 
 /**
@@ -2297,7 +2324,7 @@ static void i915_set_reset_status(struct intel_ring_buffer *ring,
 
  if (ring->hangcheck.action != HANGCHECK_WAIT &&
      i915_request_guilty(request, acthd, &inside)) {
-  DRM_ERROR("%s hung %s bo (0x%lx ctx %d) at 0x%x\n",
+  DRM_DEBUG("%s hung %s bo (0x%lx ctx %d) at 0x%x\n",
      ring->name,
      inside ? "inside" : "flushing",
      offset,
@@ -2355,16 +2382,6 @@ static void i915_gem_reset_ring_status(struct drm_i915_private *dev_priv,
 static void i915_gem_reset_ring_cleanup(struct drm_i915_private *dev_priv,
      struct intel_ring_buffer *ring)
 {
- while (!list_empty(&ring->request_list)) {
-  struct drm_i915_gem_request *request;
-
-  request = list_first_entry(&ring->request_list,
-        struct drm_i915_gem_request,
-        list);
-
-  i915_gem_free_request(request);
- }
-
  while (!list_empty(&ring->active_list)) {
   struct drm_i915_gem_object *obj;
 
@@ -2374,6 +2391,23 @@ static void i915_gem_reset_ring_cleanup(struct drm_i915_private *dev_priv,
 
   i915_gem_object_move_to_inactive(obj);
  }
+
+ /*
+  * We must free the requests after all the corresponding objects have
+  * been moved off active lists. Which is the same order as the normal
+  * retire_requests function does. This is important if object hold
+  * implicit references on things like e.g. ppgtt address spaces through
+  * the request.
+  */
+ while (!list_empty(&ring->request_list)) {
+  struct drm_i915_gem_request *request;
+
+  request = list_first_entry(&ring->request_list,
+        struct drm_i915_gem_request,
+        list);
+
+  i915_gem_free_request(request);
+ }
 }
 
 void i915_gem_restore_fences(struct drm_device *dev)
@@ -2754,7 +2788,6 @@ int i915_vma_unbind(struct i915_vma *vma)
   obj->has_aliasing_ppgtt_mapping = 0;
  }
  i915_gem_gtt_finish_object(obj);
- i915_gem_object_unpin_pages(obj);
 
  list_del(&vma->mm_list);
  /* Avoid an unnecessary call to unbind on rebind. */
@@ -2762,7 +2795,6 @@ int i915_vma_unbind(struct i915_vma *vma)
   obj->map_and_fenceable = true;
 
  drm_mm_remove_node(&vma->node);
-
  i915_gem_vma_destroy(vma);
 
  /* Since the unbound list is global, only move to that list if
@@ -2770,6 +2802,12 @@ int i915_vma_unbind(struct i915_vma *vma)
  if (list_empty(&obj->vma_list))
   list_move_tail(&obj->global_list, &dev_priv->mm.unbound_list);
 
+ /* And finally now the object is completely decoupled from this vma,
+  * we can drop its hold on the backing storage and allow it to be
+  * reaped by the shrinker.
+  */
+ i915_gem_object_unpin_pages(obj);
+
  return 0;
 }
 
@@ -3062,7 +3100,7 @@ i915_find_fence_reg(struct drm_device *dev)
  }
 
  if (avail == NULL)
-  return NULL;
+  goto deadlock;
 
  /* None available, try to steal one or wait for a user to finish */
  list_for_each_entry(reg, &dev_priv->mm.fence_list, lru_list) {
@@ -3072,7 +3110,12 @@ i915_find_fence_reg(struct drm_device *dev)
   return reg;
  }
 
- return NULL;
+deadlock:
+ /* Wait for completion of pending flips which consume fences */
+ if (intel_has_pending_fb_unpin(dev))
+  return ERR_PTR(-EAGAIN);
+
+ return ERR_PTR(-EDEADLK);
 }
 
 /**
@@ -3117,8 +3160,8 @@ i915_gem_object_get_fence(struct drm_i915_gem_object *obj)
   }
  } else if (enable) {
   reg = i915_find_fence_reg(dev);
-  if (reg == NULL)
-   return -EDEADLK;
+  if (IS_ERR(reg))
+   return PTR_ERR(reg);
 
   if (reg->obj) {
    struct drm_i915_gem_object *old = reg->obj;
@@ -4173,6 +4216,8 @@ void i915_gem_free_object(struct drm_gem_object *gem_obj)
  drm_i915_private_t *dev_priv = dev->dev_private;
  struct i915_vma *vma, *next;
 
+ intel_runtime_pm_get(dev_priv);
+
  trace_i915_gem_object_destroy(obj);
 
  if (obj->phys_obj)
@@ -4217,6 +4262,8 @@ void i915_gem_free_object(struct drm_gem_object *gem_obj)
 
  kfree(obj->bit_17);
  i915_gem_object_free(obj);
+
+ intel_runtime_pm_put(dev_priv);
 }
 
 struct i915_vma *i915_gem_obj_to_vma(struct drm_i915_gem_object *obj,
@@ -4473,7 +4520,13 @@ i915_gem_init_hw(struct drm_device *dev)
   * XXX: There was some w/a described somewhere suggesting loading
   * contexts before PPGTT.
   */
- i915_gem_context_init(dev);
+ ret = i915_gem_context_init(dev);
+ if (ret) {
+  i915_gem_cleanup_ringbuffer(dev);
+  DRM_ERROR("Context initialization failed %d\n", ret);
+  return ret;
+ }
+
  if (dev_priv->mm.aliasing_ppgtt) {
   ret = dev_priv->mm.aliasing_ppgtt->enable(dev);
   if (ret) {
diff --git a/drivers/gpu/drm/i915/i915_gem_context.c b/drivers/gpu/drm/i915/i915_gem_context.c
index b0f42b9..e08acab 100644
--- a/drivers/gpu/drm/i915/i915_gem_context.c
+++ b/drivers/gpu/drm/i915/i915_gem_context.c
@@ -247,36 +247,34 @@ err_destroy:
  return ret;
 }
 
-void i915_gem_context_init(struct drm_device *dev)
+int i915_gem_context_init(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
+ int ret;
 
- if (!HAS_HW_CONTEXTS(dev)) {
-  dev_priv->hw_contexts_disabled = true;
-  DRM_DEBUG_DRIVER("Disabling HW Contexts; old hardware\n");
-  return;
- }
+ if (!HAS_HW_CONTEXTS(dev))
+  return 0;
 
  /* If called from reset, or thaw... we've been here already */
- if (dev_priv->hw_contexts_disabled ||
-     dev_priv->ring[RCS].default_context)
-  return;
+ if (dev_priv->ring[RCS].default_context)
+  return 0;
 
  dev_priv->hw_context_size = round_up(get_context_size(dev), 4096);
 
  if (dev_priv->hw_context_size > (1<<20)) {
-  dev_priv->hw_contexts_disabled = true;
   DRM_DEBUG_DRIVER("Disabling HW Contexts; invalid size\n");
-  return;
+  return -E2BIG;
  }
 
- if (create_default_context(dev_priv)) {
-  dev_priv->hw_contexts_disabled = true;
-  DRM_DEBUG_DRIVER("Disabling HW Contexts; create failed\n");
-  return;
+ ret = create_default_context(dev_priv);
+ if (ret) {
+  DRM_DEBUG_DRIVER("Disabling HW Contexts; create failed %d\n",
+     ret);
+  return ret;
  }
 
  DRM_DEBUG_DRIVER("HW context support initialized\n");
+ return 0;
 }
 
 void i915_gem_context_fini(struct drm_device *dev)
@@ -284,7 +282,7 @@ void i915_gem_context_fini(struct drm_device *dev)
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct i915_hw_context *dctx = dev_priv->ring[RCS].default_context;
 
- if (dev_priv->hw_contexts_disabled)
+ if (!HAS_HW_CONTEXTS(dev))
   return;
 
  /* The only known way to stop the gpu from accessing the hw context is
@@ -327,16 +325,16 @@ i915_gem_context_get_hang_stats(struct drm_device *dev,
     struct drm_file *file,
     u32 id)
 {
- struct drm_i915_private *dev_priv = dev->dev_private;
  struct drm_i915_file_private *file_priv = file->driver_priv;
  struct i915_hw_context *ctx;
 
  if (id == DEFAULT_CONTEXT_ID)
   return &file_priv->hang_stats;
 
- ctx = NULL;
- if (!dev_priv->hw_contexts_disabled)
-  ctx = i915_gem_context_get(file->driver_priv, id);
+ if (!HAS_HW_CONTEXTS(dev))
+  return ERR_PTR(-ENOENT);
+
+ ctx = i915_gem_context_get(file->driver_priv, id);
  if (ctx == NULL)
   return ERR_PTR(-ENOENT);
 
@@ -502,8 +500,6 @@ static int do_switch(struct i915_hw_context *to)
  * @ring: ring for which we'll execute the context switch
  * @file_priv: file_priv associated with the context, may be NULL
  * @id: context id number
- * @seqno: sequence number by which the new context will be switched to
- * @flags:
  *
  * The context life cycle is simple. The context refcount is incremented and
  * decremented by 1 and create and destroy. If the context is in use by the GPU,
@@ -517,7 +513,7 @@ int i915_switch_context(struct intel_ring_buffer *ring,
  struct drm_i915_private *dev_priv = ring->dev->dev_private;
  struct i915_hw_context *to;
 
- if (dev_priv->hw_contexts_disabled)
+ if (!HAS_HW_CONTEXTS(ring->dev))
   return 0;
 
  WARN_ON(!mutex_is_locked(&dev_priv->dev->struct_mutex));
@@ -542,7 +538,6 @@ int i915_switch_context(struct intel_ring_buffer *ring,
 int i915_gem_context_create_ioctl(struct drm_device *dev, void *data,
       struct drm_file *file)
 {
- struct drm_i915_private *dev_priv = dev->dev_private;
  struct drm_i915_gem_context_create *args = data;
  struct drm_i915_file_private *file_priv = file->driver_priv;
  struct i915_hw_context *ctx;
@@ -551,7 +546,7 @@ int i915_gem_context_create_ioctl(struct drm_device *dev, void *data,
  if (!(dev->driver->driver_features & DRIVER_GEM))
   return -ENODEV;
 
- if (dev_priv->hw_contexts_disabled)
+ if (!HAS_HW_CONTEXTS(dev))
   return -ENODEV;
 
  ret = i915_mutex_lock_interruptible(dev);
diff --git a/drivers/gpu/drm/i915/i915_gem_evict.c b/drivers/gpu/drm/i915/i915_gem_evict.c
index 8f3adc7..2ca280f 100644
--- a/drivers/gpu/drm/i915/i915_gem_evict.c
+++ b/drivers/gpu/drm/i915/i915_gem_evict.c
@@ -27,8 +27,10 @@
  */
 
 #include <drm/drmP.h>
-#include "i915_drv.h"
 #include <drm/i915_drm.h>
+
+#include "i915_drv.h"
+#include "intel_drv.h"
 #include "i915_trace.h"
 
 static bool
@@ -53,6 +55,7 @@ i915_gem_evict_something(struct drm_device *dev, struct i915_address_space *vm,
  struct list_head eviction_list, unwind_list;
  struct i915_vma *vma;
  int ret = 0;
+ int pass = 0;
 
  trace_i915_gem_evict(dev, min_size, alignment, mappable);
 
@@ -119,14 +122,24 @@ none:
  /* Can we unpin some objects such as idle hw contents,
   * or pending flips?
   */
- ret = nonblocking ? -ENOSPC : i915_gpu_idle(dev);
- if (ret)
-  return ret;
+ if (nonblocking)
+  return -ENOSPC;
 
  /* Only idle the GPU and repeat the search once */
- i915_gem_retire_requests(dev);
- nonblocking = true;
- goto search_again;
+ if (pass++ == 0) {
+  ret = i915_gpu_idle(dev);
+  if (ret)
+   return ret;
+
+  i915_gem_retire_requests(dev);
+  goto search_again;
+ }
+
+ /* If we still have pending pageflip completions, drop
+  * back to userspace to give our workqueues time to
+  * acquire our locks and unpin the old scanouts.
+  */
+ return intel_has_pending_fb_unpin(dev) ? -EAGAIN : -ENOSPC;
 
 found:
  /* drm_mm doesn't allow any other other operations while
diff --git a/drivers/gpu/drm/i915/i915_gem_execbuffer.c b/drivers/gpu/drm/i915/i915_gem_execbuffer.c
index a3ba9a8..d269ecf 100644
--- a/drivers/gpu/drm/i915/i915_gem_execbuffer.c
+++ b/drivers/gpu/drm/i915/i915_gem_execbuffer.c
@@ -46,7 +46,7 @@ struct eb_vmas {
 };
 
 static struct eb_vmas *
-eb_create(struct drm_i915_gem_execbuffer2 *args, struct i915_address_space *vm)
+eb_create(struct drm_i915_gem_execbuffer2 *args)
 {
  struct eb_vmas *eb = NULL;
 
@@ -252,7 +252,7 @@ relocate_entry_cpu(struct drm_i915_gem_object *obj,
  struct drm_device *dev = obj->base.dev;
  uint32_t page_offset = offset_in_page(reloc->offset);
  char *vaddr;
- int ret = -EINVAL;
+ int ret;
 
  ret = i915_gem_object_set_to_cpu_domain(obj, true);
  if (ret)
@@ -287,7 +287,7 @@ relocate_entry_gtt(struct drm_i915_gem_object *obj,
  struct drm_i915_private *dev_priv = dev->dev_private;
  uint32_t __iomem *reloc_entry;
  void __iomem *reloc_page;
- int ret = -EINVAL;
+ int ret;
 
  ret = i915_gem_object_set_to_gtt_domain(obj, true);
  if (ret)
@@ -335,7 +335,7 @@ i915_gem_execbuffer_relocate_entry(struct drm_i915_gem_object *obj,
  struct drm_i915_gem_object *target_i915_obj;
  struct i915_vma *target_vma;
  uint32_t target_offset;
- int ret = -EINVAL;
+ int ret;
 
  /* we've already hold a reference to all valid objects */
  target_vma = eb_get_vma(eb, reloc->target_handle);
@@ -344,7 +344,7 @@ i915_gem_execbuffer_relocate_entry(struct drm_i915_gem_object *obj,
  target_i915_obj = target_vma->obj;
  target_obj = &target_vma->obj->base;
 
- target_offset = i915_gem_obj_ggtt_offset(target_i915_obj);
+ target_offset = target_vma->node.start;
 
  /* Sandybridge PPGTT errata: We need a global gtt mapping for MI and
   * pipe_control writes because the gpu doesn't properly redirect them
@@ -365,7 +365,7 @@ i915_gem_execbuffer_relocate_entry(struct drm_i915_gem_object *obj,
      (int) reloc->offset,
      reloc->read_domains,
      reloc->write_domain);
-  return ret;
+  return -EINVAL;
  }
  if (unlikely((reloc->write_domain | reloc->read_domains)
        & ~I915_GEM_GPU_DOMAINS)) {
@@ -376,7 +376,7 @@ i915_gem_execbuffer_relocate_entry(struct drm_i915_gem_object *obj,
      (int) reloc->offset,
      reloc->read_domains,
      reloc->write_domain);
-  return ret;
+  return -EINVAL;
  }
 
  target_obj->pending_read_domains |= reloc->read_domains;
@@ -396,14 +396,14 @@ i915_gem_execbuffer_relocate_entry(struct drm_i915_gem_object *obj,
      obj, reloc->target_handle,
      (int) reloc->offset,
      (int) obj->base.size);
-  return ret;
+  return -EINVAL;
  }
  if (unlikely(reloc->offset & 3)) {
   DRM_DEBUG("Relocation not 4-byte aligned: "
      "obj %p target %d offset %d.\n",
      obj, reloc->target_handle,
      (int) reloc->offset);
-  return ret;
+  return -EINVAL;
  }
 
  /* We can't wait for rendering with pagefaults disabled */
@@ -491,8 +491,7 @@ i915_gem_execbuffer_relocate_vma_slow(struct i915_vma *vma,
 }
 
 static int
-i915_gem_execbuffer_relocate(struct eb_vmas *eb,
-        struct i915_address_space *vm)
+i915_gem_execbuffer_relocate(struct eb_vmas *eb)
 {
  struct i915_vma *vma;
  int ret = 0;
@@ -901,6 +900,24 @@ validate_exec_list(struct drm_i915_gem_exec_object2 *exec,
  return 0;
 }
 
+static int
+i915_gem_validate_context(struct drm_device *dev, struct drm_file *file,
+     const u32 ctx_id)
+{
+ struct i915_ctx_hang_stats *hs;
+
+ hs = i915_gem_context_get_hang_stats(dev, file, ctx_id);
+ if (IS_ERR(hs))
+  return PTR_ERR(hs);
+
+ if (hs->banned) {
+  DRM_DEBUG("Context %u tried to submit while banned\n", ctx_id);
+  return -EIO;
+ }
+
+ return 0;
+}
+
 static void
 i915_gem_execbuffer_move_to_active(struct list_head *vmas,
        struct intel_ring_buffer *ring)
@@ -980,8 +997,7 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
  struct drm_i915_gem_object *batch_obj;
  struct drm_clip_rect *cliprects = NULL;
  struct intel_ring_buffer *ring;
- struct i915_ctx_hang_stats *hs;
- u32 ctx_id = i915_execbuffer2_get_context_id(*args);
+ const u32 ctx_id = i915_execbuffer2_get_context_id(*args);
  u32 exec_start, exec_len;
  u32 mask, flags;
  int ret, mode, i;
@@ -1108,6 +1124,8 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
   }
  }
 
+ intel_runtime_pm_get(dev_priv);
+
  ret = i915_mutex_lock_interruptible(dev);
  if (ret)
   goto pre_mutex_err;
@@ -1118,7 +1136,13 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
   goto pre_mutex_err;
  }
 
- eb = eb_create(args, vm);
+ ret = i915_gem_validate_context(dev, file, ctx_id);
+ if (ret) {
+  mutex_unlock(&dev->struct_mutex);
+  goto pre_mutex_err;
+ }
+
+ eb = eb_create(args);
  if (eb == NULL) {
   mutex_unlock(&dev->struct_mutex);
   ret = -ENOMEM;
@@ -1141,7 +1165,7 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
 
  /* The objects are in their final locations, apply the relocations. */
  if (need_relocs)
-  ret = i915_gem_execbuffer_relocate(eb, vm);
+  ret = i915_gem_execbuffer_relocate(eb);
  if (ret) {
   if (ret == -EFAULT) {
    ret = i915_gem_execbuffer_relocate_slow(dev, args, file, ring,
@@ -1170,17 +1194,6 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
  if (ret)
   goto err;
 
- hs = i915_gem_context_get_hang_stats(dev, file, ctx_id);
- if (IS_ERR(hs)) {
-  ret = PTR_ERR(hs);
-  goto err;
- }
-
- if (hs->banned) {
-  ret = -EIO;
-  goto err;
- }
-
  ret = i915_switch_context(ring, file, ctx_id);
  if (ret)
   goto err;
@@ -1242,6 +1255,10 @@ err:
 
 pre_mutex_err:
  kfree(cliprects);
+
+ /* intel_gpu_busy should also get a ref, so it will free when the device
+  * is really idle. */
+ intel_runtime_pm_put(dev_priv);
  return ret;
 }
 
diff --git a/drivers/gpu/drm/i915/i915_gem_gtt.c b/drivers/gpu/drm/i915/i915_gem_gtt.c
index e79720d..d278be1 100644
--- a/drivers/gpu/drm/i915/i915_gem_gtt.c
+++ b/drivers/gpu/drm/i915/i915_gem_gtt.c
@@ -240,10 +240,16 @@ static int gen8_ppgtt_enable(struct drm_device *dev)
   for_each_ring(ring, dev_priv, j) {
    ret = gen8_write_pdp(ring, i, addr);
    if (ret)
-    return ret;
+    goto err_out;
   }
  }
  return 0;
+
+err_out:
+ for_each_ring(ring, dev_priv, j)
+  I915_WRITE(RING_MODE_GEN7(ring),
+      _MASKED_BIT_DISABLE(GFX_PPGTT_ENABLE));
+ return ret;
 }
 
 static void gen8_ppgtt_clear_range(struct i915_address_space *vm,
@@ -293,23 +299,23 @@ static void gen8_ppgtt_insert_entries(struct i915_address_space *vm,
  unsigned act_pte = first_entry % GEN8_PTES_PER_PAGE;
  struct sg_page_iter sg_iter;
 
- pt_vaddr = kmap_atomic(&ppgtt->gen8_pt_pages[act_pt]);
+ pt_vaddr = NULL;
  for_each_sg_page(pages->sgl, &sg_iter, pages->nents, 0) {
-  dma_addr_t page_addr;
+  if (pt_vaddr == NULL)
+   pt_vaddr = kmap_atomic(&ppgtt->gen8_pt_pages[act_pt]);
 
-  page_addr = sg_dma_address(sg_iter.sg) +
-    (sg_iter.sg_pgoffset << PAGE_SHIFT);
-  pt_vaddr[act_pte] = gen8_pte_encode(page_addr, cache_level,
-          true);
+  pt_vaddr[act_pte] =
+   gen8_pte_encode(sg_page_iter_dma_address(&sg_iter),
+     cache_level, true);
   if (++act_pte == GEN8_PTES_PER_PAGE) {
    kunmap_atomic(pt_vaddr);
+   pt_vaddr = NULL;
    act_pt++;
-   pt_vaddr = kmap_atomic(&ppgtt->gen8_pt_pages[act_pt]);
    act_pte = 0;
-
   }
  }
- kunmap_atomic(pt_vaddr);
+ if (pt_vaddr)
+  kunmap_atomic(pt_vaddr);
 }
 
 static void gen8_ppgtt_cleanup(struct i915_address_space *vm)
@@ -318,6 +324,8 @@ static void gen8_ppgtt_cleanup(struct i915_address_space *vm)
   container_of(vm, struct i915_hw_ppgtt, base);
  int i, j;
 
+ drm_mm_takedown(&vm->mm);
+
  for (i = 0; i < ppgtt->num_pd_pages ; i++) {
   if (ppgtt->pd_dma_addr[i]) {
    pci_unmap_page(ppgtt->base.dev->pdev,
@@ -381,6 +389,8 @@ static int gen8_ppgtt_init(struct i915_hw_ppgtt *ppgtt, uint64_t size)
  ppgtt->base.clear_range = gen8_ppgtt_clear_range;
  ppgtt->base.insert_entries = gen8_ppgtt_insert_entries;
  ppgtt->base.cleanup = gen8_ppgtt_cleanup;
+ ppgtt->base.start = 0;
+ ppgtt->base.total = ppgtt->num_pt_pages * GEN8_PTES_PER_PAGE * PAGE_SIZE;
 
  BUG_ON(ppgtt->num_pd_pages > GEN8_LEGACY_PDPS);
 
@@ -573,21 +583,23 @@ static void gen6_ppgtt_insert_entries(struct i915_address_space *vm,
  unsigned act_pte = first_entry % I915_PPGTT_PT_ENTRIES;
  struct sg_page_iter sg_iter;
 
- pt_vaddr = kmap_atomic(ppgtt->pt_pages[act_pt]);
+ pt_vaddr = NULL;
  for_each_sg_page(pages->sgl, &sg_iter, pages->nents, 0) {
-  dma_addr_t page_addr;
+  if (pt_vaddr == NULL)
+   pt_vaddr = kmap_atomic(ppgtt->pt_pages[act_pt]);
 
-  page_addr = sg_page_iter_dma_address(&sg_iter);
-  pt_vaddr[act_pte] = vm->pte_encode(page_addr, cache_level, true);
+  pt_vaddr[act_pte] =
+   vm->pte_encode(sg_page_iter_dma_address(&sg_iter),
+           cache_level, true);
   if (++act_pte == I915_PPGTT_PT_ENTRIES) {
    kunmap_atomic(pt_vaddr);
+   pt_vaddr = NULL;
    act_pt++;
-   pt_vaddr = kmap_atomic(ppgtt->pt_pages[act_pt]);
    act_pte = 0;
-
   }
  }
- kunmap_atomic(pt_vaddr);
+ if (pt_vaddr)
+  kunmap_atomic(pt_vaddr);
 }
 
 static void gen6_ppgtt_cleanup(struct i915_address_space *vm)
@@ -632,6 +644,8 @@ static int gen6_ppgtt_init(struct i915_hw_ppgtt *ppgtt)
  ppgtt->base.insert_entries = gen6_ppgtt_insert_entries;
  ppgtt->base.cleanup = gen6_ppgtt_cleanup;
  ppgtt->base.scratch = dev_priv->gtt.base.scratch;
+ ppgtt->base.start = 0;
+ ppgtt->base.total = GEN6_PPGTT_PD_ENTRIES * I915_PPGTT_PT_ENTRIES * PAGE_SIZE;
  ppgtt->pt_pages = kcalloc(ppgtt->num_pd_entries, sizeof(struct page *),
       GFP_KERNEL);
  if (!ppgtt->pt_pages)
@@ -1124,7 +1138,6 @@ void i915_gem_setup_global_gtt(struct drm_device *dev,
   if (ret)
    DRM_DEBUG_KMS("Reservation failed\n");
   obj->has_global_gtt_mapping = 1;
-  list_add(&vma->vma_link, &obj->vma_list);
  }
 
  dev_priv->gtt.base.start = start;
@@ -1265,14 +1278,14 @@ static int ggtt_probe_common(struct drm_device *dev,
         size_t gtt_size)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
- phys_addr_t gtt_bus_addr;
+ phys_addr_t gtt_phys_addr;
  int ret;
 
  /* For Modern GENs the PTEs and register space are split in the BAR */
- gtt_bus_addr = pci_resource_start(dev->pdev, 0) +
+ gtt_phys_addr = pci_resource_start(dev->pdev, 0) +
   (pci_resource_len(dev->pdev, 0) / 2);
 
- dev_priv->gtt.gsm = ioremap_wc(gtt_bus_addr, gtt_size);
+ dev_priv->gtt.gsm = ioremap_wc(gtt_phys_addr, gtt_size);
  if (!dev_priv->gtt.gsm) {
   DRM_ERROR("Failed to map the gtt page table\n");
   return -ENOMEM;
@@ -1400,6 +1413,8 @@ static void gen6_gmch_remove(struct i915_address_space *vm)
 {
 
  struct i915_gtt *gtt = container_of(vm, struct i915_gtt, base);
+
+ drm_mm_takedown(&vm->mm);
  iounmap(gtt->gsm);
  teardown_scratch_page(vm->dev);
 }
@@ -1425,6 +1440,9 @@ static int i915_gmch_probe(struct drm_device *dev,
  dev_priv->gtt.base.clear_range = i915_ggtt_clear_range;
  dev_priv->gtt.base.insert_entries = i915_ggtt_insert_entries;
 
+ if (unlikely(dev_priv->gtt.do_idle_maps))
+  DRM_INFO("applying Ironlake quirks for intel_iommu\n");
+
  return 0;
 }
 
diff --git a/drivers/gpu/drm/i915/i915_gem_stolen.c b/drivers/gpu/drm/i915/i915_gem_stolen.c
index 4a699d2..28d24ca 100644
--- a/drivers/gpu/drm/i915/i915_gem_stolen.c
+++ b/drivers/gpu/drm/i915/i915_gem_stolen.c
@@ -82,9 +82,22 @@ static unsigned long i915_stolen_to_physical(struct drm_device *dev)
  r = devm_request_mem_region(dev->dev, base, dev_priv->gtt.stolen_size,
         "Graphics Stolen Memory");
  if (r == NULL) {
-  DRM_ERROR("conflict detected with stolen region: [0x%08x - 0x%08x]\n",
-     base, base + (uint32_t)dev_priv->gtt.stolen_size);
-  base = 0;
+  /*
+   * One more attempt but this time requesting region from
+   * base + 1, as we have seen that this resolves the region
+   * conflict with the PCI Bus.
+   * This is a BIOS w/a: Some BIOS wrap stolen in the root
+   * PCI bus, but have an off-by-one error. Hence retry the
+   * reservation starting from 1 instead of 0.
+   */
+  r = devm_request_mem_region(dev->dev, base + 1,
+         dev_priv->gtt.stolen_size - 1,
+         "Graphics Stolen Memory");
+  if (r == NULL) {
+   DRM_ERROR("conflict detected with stolen region: [0x%08x - 0x%08x]\n",
+      base, base + (uint32_t)dev_priv->gtt.stolen_size);
+   base = 0;
+  }
  }
 
  return base;
@@ -427,6 +440,7 @@ i915_gem_object_create_stolen_for_preallocated(struct drm_device *dev,
 
  list_add_tail(&obj->global_list, &dev_priv->mm.bound_list);
  list_add_tail(&vma->mm_list, &ggtt->inactive_list);
+ i915_gem_object_pin_pages(obj);
 
  return obj;
 
diff --git a/drivers/gpu/drm/i915/i915_gpu_error.c b/drivers/gpu/drm/i915/i915_gpu_error.c
index a052ef9..990cf8f 100644
--- a/drivers/gpu/drm/i915/i915_gpu_error.c
+++ b/drivers/gpu/drm/i915/i915_gpu_error.c
@@ -253,12 +253,11 @@ static void i915_ring_error_state(struct drm_i915_error_state_buf *m,
  err_printf(m, "  IPEIR: 0x%08x\n", error->ipeir[ring]);
  err_printf(m, "  IPEHR: 0x%08x\n", error->ipehr[ring]);
  err_printf(m, "  INSTDONE: 0x%08x\n", error->instdone[ring]);
- if (ring == RCS && INTEL_INFO(dev)->gen >= 4)
-  err_printf(m, "  BBADDR: 0x%08llx\n", error->bbaddr);
- if (INTEL_INFO(dev)->gen >= 4)
+ if (INTEL_INFO(dev)->gen >= 4) {
+  err_printf(m, "  BBADDR: 0x%08llx\n", error->bbaddr[ring]);
   err_printf(m, "  BB_STATE: 0x%08x\n", error->bbstate[ring]);
- if (INTEL_INFO(dev)->gen >= 4)
   err_printf(m, "  INSTPS: 0x%08x\n", error->instps[ring]);
+ }
  err_printf(m, "  INSTPM: 0x%08x\n", error->instpm[ring]);
  err_printf(m, "  FADDR: 0x%08x\n", error->faddr[ring]);
  if (INTEL_INFO(dev)->gen >= 6) {
@@ -730,8 +729,9 @@ static void i915_record_ring_state(struct drm_device *dev,
   error->ipehr[ring->id] = I915_READ(RING_IPEHR(ring->mmio_base));
   error->instdone[ring->id] = I915_READ(RING_INSTDONE(ring->mmio_base));
   error->instps[ring->id] = I915_READ(RING_INSTPS(ring->mmio_base));
-  if (ring->id == RCS)
-   error->bbaddr = I915_READ64(BB_ADDR);
+  error->bbaddr[ring->id] = I915_READ(RING_BBADDR(ring->mmio_base));
+  if (INTEL_INFO(dev)->gen >= 8)
+   error->bbaddr[ring->id] |= (u64) I915_READ(RING_BBADDR_UDW(ring->mmio_base)) << 32;
   error->bbstate[ring->id] = I915_READ(RING_BBSTATE(ring->mmio_base));
  } else {
   error->faddr[ring->id] = I915_READ(DMA_FADD_I8XX);
diff --git a/drivers/gpu/drm/i915/i915_irq.c b/drivers/gpu/drm/i915/i915_irq.c
index 9702704..d554169 100644
--- a/drivers/gpu/drm/i915/i915_irq.c
+++ b/drivers/gpu/drm/i915/i915_irq.c
@@ -62,7 +62,7 @@ static const u32 hpd_mask_i915[] = {
  [HPD_PORT_D] = PORTD_HOTPLUG_INT_EN
 };
 
-static const u32 hpd_status_gen4[] = {
+static const u32 hpd_status_g4x[] = {
  [HPD_CRT] = CRT_HOTPLUG_INT_STATUS,
  [HPD_SDVO_B] = SDVOB_HOTPLUG_INT_STATUS_G4X,
  [HPD_SDVO_C] = SDVOC_HOTPLUG_INT_STATUS_G4X,
@@ -599,7 +599,7 @@ static u32 i915_get_vblank_counter(struct drm_device *dev, int pipe)
   * Cook up a vblank counter by also checking the pixel
   * counter against vblank start.
   */
- return ((high1 << 8) | low) + (pixel >= vbl_start);
+ return (((high1 << 8) | low) + (pixel >= vbl_start)) & 0xffffff;
 }
 
 static u32 gm45_get_vblank_counter(struct drm_device *dev, int pipe)
@@ -618,63 +618,30 @@ static u32 gm45_get_vblank_counter(struct drm_device *dev, int pipe)
 
 /* raw reads, only for fast reads of display block, no need for forcewake etc. */
 #define __raw_i915_read32(dev_priv__, reg__) readl((dev_priv__)->regs + (reg__))
-#define __raw_i915_read16(dev_priv__, reg__) readw((dev_priv__)->regs + (reg__))
 
-static bool intel_pipe_in_vblank_locked(struct drm_device *dev, enum pipe pipe)
+static bool ilk_pipe_in_vblank_locked(struct drm_device *dev, enum pipe pipe)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  uint32_t status;
  int reg;
 
- if (IS_VALLEYVIEW(dev)) {
-  status = pipe == PIPE_A ?
-   I915_DISPLAY_PIPE_A_VBLANK_INTERRUPT :
-   I915_DISPLAY_PIPE_B_VBLANK_INTERRUPT;
-
-  reg = VLV_ISR;
- } else if (IS_GEN2(dev)) {
-  status = pipe == PIPE_A ?
-   I915_DISPLAY_PIPE_A_VBLANK_INTERRUPT :
-   I915_DISPLAY_PIPE_B_VBLANK_INTERRUPT;
-
-  reg = ISR;
- } else if (INTEL_INFO(dev)->gen < 5) {
-  status = pipe == PIPE_A ?
-   I915_DISPLAY_PIPE_A_VBLANK_INTERRUPT :
-   I915_DISPLAY_PIPE_B_VBLANK_INTERRUPT;
-
-  reg = ISR;
- } else if (INTEL_INFO(dev)->gen < 7) {
-  status = pipe == PIPE_A ?
-   DE_PIPEA_VBLANK :
-   DE_PIPEB_VBLANK;
-
+ if (INTEL_INFO(dev)->gen >= 8) {
+  status = GEN8_PIPE_VBLANK;
+  reg = GEN8_DE_PIPE_ISR(pipe);
+ } else if (INTEL_INFO(dev)->gen >= 7) {
+  status = DE_PIPE_VBLANK_IVB(pipe);
   reg = DEISR;
  } else {
-  switch (pipe) {
-  default:
-  case PIPE_A:
-   status = DE_PIPEA_VBLANK_IVB;
-   break;
-  case PIPE_B:
-   status = DE_PIPEB_VBLANK_IVB;
-   break;
-  case PIPE_C:
-   status = DE_PIPEC_VBLANK_IVB;
-   break;
-  }
-
+  status = DE_PIPE_VBLANK(pipe);
   reg = DEISR;
  }
 
- if (IS_GEN2(dev))
-  return __raw_i915_read16(dev_priv, reg) & status;
- else
-  return __raw_i915_read32(dev_priv, reg) & status;
+ return __raw_i915_read32(dev_priv, reg) & status;
 }
 
 static int i915_get_crtc_scanoutpos(struct drm_device *dev, int pipe,
-        int *vpos, int *hpos, ktime_t *stime, ktime_t *etime)
+        unsigned int flags, int *vpos, int *hpos,
+        ktime_t *stime, ktime_t *etime)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct drm_crtc *crtc = dev_priv->pipe_to_crtc_mapping[pipe];
@@ -697,6 +664,12 @@ static int i915_get_crtc_scanoutpos(struct drm_device *dev, int pipe,
  vbl_start = mode->crtc_vblank_start;
  vbl_end = mode->crtc_vblank_end;
 
+ if (mode->flags & DRM_MODE_FLAG_INTERLACE) {
+  vbl_start = DIV_ROUND_UP(vbl_start, 2);
+  vbl_end /= 2;
+  vtotal /= 2;
+ }
+
  ret |= DRM_SCANOUTPOS_VALID | DRM_SCANOUTPOS_ACCURATE;
 
  /*
@@ -721,17 +694,63 @@ static int i915_get_crtc_scanoutpos(struct drm_device *dev, int pipe,
   else
    position = __raw_i915_read32(dev_priv, PIPEDSL(pipe)) & DSL_LINEMASK_GEN3;
 
-  /*
-   * The scanline counter increments at the leading edge
-   * of hsync, ie. it completely misses the active portion
-   * of the line. Fix up the counter at both edges of vblank
-   * to get a more accurate picture whether we're in vblank
-   * or not.
-   */
-  in_vbl = intel_pipe_in_vblank_locked(dev, pipe);
-  if ((in_vbl && position == vbl_start - 1) ||
-      (!in_vbl && position == vbl_end - 1))
-   position = (position + 1) % vtotal;
+  if (HAS_DDI(dev)) {
+   /*
+    * On HSW HDMI outputs there seems to be a 2 line
+    * difference, whereas eDP has the normal 1 line
+    * difference that earlier platforms have. External
+    * DP is unknown. For now just check for the 2 line
+    * difference case on all output types on HSW+.
+    *
+    * This might misinterpret the scanline counter being
+    * one line too far along on eDP, but that's less
+    * dangerous than the alternative since that would lead
+    * the vblank timestamp code astray when it sees a
+    * scanline count before vblank_start during a vblank
+    * interrupt.
+    */
+   in_vbl = ilk_pipe_in_vblank_locked(dev, pipe);
+   if ((in_vbl && (position == vbl_start - 2 ||
+     position == vbl_start - 1)) ||
+       (!in_vbl && (position == vbl_end - 2 ||
+      position == vbl_end - 1)))
+    position = (position + 2) % vtotal;
+  } else if (HAS_PCH_SPLIT(dev)) {
+   /*
+    * The scanline counter increments at the leading edge
+    * of hsync, ie. it completely misses the active portion
+    * of the line. Fix up the counter at both edges of vblank
+    * to get a more accurate picture whether we're in vblank
+    * or not.
+    */
+   in_vbl = ilk_pipe_in_vblank_locked(dev, pipe);
+   if ((in_vbl && position == vbl_start - 1) ||
+       (!in_vbl && position == vbl_end - 1))
+    position = (position + 1) % vtotal;
+  } else {
+   /*
+    * ISR vblank status bits don't work the way we'd want
+    * them to work on non-PCH platforms (for
+    * ilk_pipe_in_vblank_locked()), and there doesn't
+    * appear any other way to determine if we're currently
+    * in vblank.
+    *
+    * Instead let's assume that we're already in vblank if
+    * we got called from the vblank interrupt and the
+    * scanline counter value indicates that we're on the
+    * line just prior to vblank start. This should result
+    * in the correct answer, unless the vblank interrupt
+    * delivery really got delayed for almost exactly one
+    * full frame/field.
+    */
+   if (flags & DRM_CALLED_FROM_VBLIRQ &&
+       position == vbl_start - 1) {
+    position = (position + 1) % vtotal;
+
+    /* Signal this correction as "applied". */
+    ret |= 0x8;
+   }
+  }
  } else {
   /* Have access to pixelcount since start of frame.
    * We can split this into vertical and horizontal
@@ -808,7 +827,8 @@ static int i915_get_vblank_timestamp(struct drm_device *dev, int pipe,
  /* Helper routine in DRM core does all the work: */
  return drm_calc_vbltimestamp_from_scanoutpos(dev, pipe, max_error,
            vblank_time, flags,
-           crtc);
+           crtc,
+           &to_intel_crtc(crtc)->config.adjusted_mode);
 }
 
 static bool intel_hpd_irq_event(struct drm_device *dev,
@@ -1014,10 +1034,8 @@ static void gen6_pm_rps_work(struct work_struct *work)
  /* sysfs frequency interfaces may have snuck in while servicing the
   * interrupt
   */
- if (new_delay < (int)dev_priv->rps.min_delay)
-  new_delay = dev_priv->rps.min_delay;
- if (new_delay > (int)dev_priv->rps.max_delay)
-  new_delay = dev_priv->rps.max_delay;
+ new_delay = clamp_t(int, new_delay,
+       dev_priv->rps.min_delay, dev_priv->rps.max_delay);
  dev_priv->rps.last_adj = new_delay - dev_priv->rps.cur_delay;
 
  if (IS_VALLEYVIEW(dev_priv->dev))
@@ -1234,9 +1252,10 @@ static inline void intel_hpd_irq_handler(struct drm_device *dev,
  spin_lock(&dev_priv->irq_lock);
  for (i = 1; i < HPD_NUM_PINS; i++) {
 
-  WARN(((hpd[i] & hotplug_trigger) &&
-        dev_priv->hpd_stats[i].hpd_mark != HPD_ENABLED),
-       "Received HPD interrupt although disabled\n");
+  WARN_ONCE(hpd[i] & hotplug_trigger &&
+     dev_priv->hpd_stats[i].hpd_mark == HPD_DISABLED,
+     "Received HPD interrupt (0x%08x) on pin %d (0x%08x) although disabled\n",
+     hotplug_trigger, i, hpd[i]);
 
   if (!(hpd[i] & hotplug_trigger) ||
       dev_priv->hpd_stats[i].hpd_mark != HPD_ENABLED)
@@ -1473,6 +1492,9 @@ static irqreturn_t valleyview_irq_handler(int irq, void *arg)
 
    intel_hpd_irq_handler(dev, hotplug_trigger, hpd_status_i915);
 
+   if (hotplug_status & DP_AUX_CHANNEL_MASK_INT_STATUS_G4X)
+    dp_aux_irq_handler(dev);
+
    I915_WRITE(PORT_HOTPLUG_STAT, hotplug_status);
    I915_READ(PORT_HOTPLUG_STAT);
   }
@@ -1992,7 +2014,7 @@ static void i915_error_work_func(struct work_struct *work)
    kobject_uevent_env(&dev->primary->kdev->kobj,
         KOBJ_CHANGE, reset_done_event);
   } else {
-   atomic_set(&error->reset_counter, I915_WEDGED);
+   atomic_set_mask(I915_WEDGED, &error->reset_counter);
   }
 
   /*
@@ -3137,10 +3159,10 @@ static int i8xx_irq_postinstall(struct drm_device *dev)
  * Returns true when a page flip has completed.
  */
 static bool i8xx_handle_vblank(struct drm_device *dev,
-          int pipe, u16 iir)
+          int plane, int pipe, u32 iir)
 {
  drm_i915_private_t *dev_priv = dev->dev_private;
- u16 flip_pending = DISPLAY_PLANE_FLIP_PENDING(pipe);
+ u16 flip_pending = DISPLAY_PLANE_FLIP_PENDING(plane);
 
  if (!drm_handle_vblank(dev, pipe))
   return false;
@@ -3148,7 +3170,7 @@ static bool i8xx_handle_vblank(struct drm_device *dev,
  if ((iir & flip_pending) == 0)
   return false;
 
- intel_prepare_page_flip(dev, pipe);
+ intel_prepare_page_flip(dev, plane);
 
  /* We detect FlipDone by looking for the change in PendingFlip from '1'
   * to '0' on the following vblank, i.e. IIR has the Pendingflip
@@ -3217,9 +3239,13 @@ static irqreturn_t i8xx_irq_handler(int irq, void *arg)
    notify_ring(dev, &dev_priv->ring[RCS]);
 
   for_each_pipe(pipe) {
+   int plane = pipe;
+   if (HAS_FBC(dev))
+    plane = !plane;
+
    if (pipe_stats[pipe] & PIPE_VBLANK_INTERRUPT_STATUS &&
-       i8xx_handle_vblank(dev, pipe, iir))
-    flip_mask &= ~DISPLAY_PLANE_FLIP_PENDING(pipe);
+       i8xx_handle_vblank(dev, plane, pipe, iir))
+    flip_mask &= ~DISPLAY_PLANE_FLIP_PENDING(plane);
 
    if (pipe_stats[pipe] & PIPE_CRC_DONE_INTERRUPT_STATUS)
     i9xx_pipe_crc_irq_handler(dev, pipe);
@@ -3415,7 +3441,7 @@ static irqreturn_t i915_irq_handler(int irq, void *arg)
 
   for_each_pipe(pipe) {
    int plane = pipe;
-   if (IS_MOBILE(dev))
+   if (HAS_FBC(dev))
     plane = !plane;
 
    if (pipe_stats[pipe] & PIPE_VBLANK_INTERRUPT_STATUS &&
@@ -3652,7 +3678,11 @@ static irqreturn_t i965_irq_handler(int irq, void *arg)
       hotplug_status);
 
    intel_hpd_irq_handler(dev, hotplug_trigger,
-           IS_G4X(dev) ? hpd_status_gen4 : hpd_status_i915);
+           IS_G4X(dev) ? hpd_status_g4x : hpd_status_i915);
+
+   if (IS_G4X(dev) &&
+       (hotplug_status & DP_AUX_CHANNEL_MASK_INT_STATUS_G4X))
+    dp_aux_irq_handler(dev);
 
    I915_WRITE(PORT_HOTPLUG_STAT, hotplug_status);
    I915_READ(PORT_HOTPLUG_STAT);
@@ -3890,8 +3920,8 @@ void hsw_pc8_disable_interrupts(struct drm_device *dev)
  dev_priv->pc8.regsave.gtier = I915_READ(GTIER);
  dev_priv->pc8.regsave.gen6_pmimr = I915_READ(GEN6_PMIMR);
 
- ironlake_disable_display_irq(dev_priv, ~DE_PCH_EVENT_IVB);
- ibx_disable_display_interrupt(dev_priv, ~SDE_HOTPLUG_MASK_CPT);
+ ironlake_disable_display_irq(dev_priv, 0xffffffff);
+ ibx_disable_display_interrupt(dev_priv, 0xffffffff);
  ilk_disable_gt_irq(dev_priv, 0xffffffff);
  snb_disable_pm_irq(dev_priv, 0xffffffff);
 
@@ -3905,34 +3935,26 @@ void hsw_pc8_restore_interrupts(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  unsigned long irqflags;
- uint32_t val, expected;
+ uint32_t val;
 
  spin_lock_irqsave(&dev_priv->irq_lock, irqflags);
 
  val = I915_READ(DEIMR);
- expected = ~DE_PCH_EVENT_IVB;
- WARN(val != expected, "DEIMR is 0x%08x, not 0x%08x\n", val, expected);
+ WARN(val != 0xffffffff, "DEIMR is 0x%08x\n", val);
 
- val = I915_READ(SDEIMR) & ~SDE_HOTPLUG_MASK_CPT;
- expected = ~SDE_HOTPLUG_MASK_CPT;
- WARN(val != expected, "SDEIMR non-HPD bits are 0x%08x, not 0x%08x\n",
-      val, expected);
+ val = I915_READ(SDEIMR);
+ WARN(val != 0xffffffff, "SDEIMR is 0x%08x\n", val);
 
  val = I915_READ(GTIMR);
- expected = 0xffffffff;
- WARN(val != expected, "GTIMR is 0x%08x, not 0x%08x\n", val, expected);
+ WARN(val != 0xffffffff, "GTIMR is 0x%08x\n", val);
 
  val = I915_READ(GEN6_PMIMR);
- expected = 0xffffffff;
- WARN(val != expected, "GEN6_PMIMR is 0x%08x, not 0x%08x\n", val,
-      expected);
+ WARN(val != 0xffffffff, "GEN6_PMIMR is 0x%08x\n", val);
 
  dev_priv->pc8.irqs_disabled = false;
 
  ironlake_enable_display_irq(dev_priv, ~dev_priv->pc8.regsave.deimr);
- ibx_enable_display_interrupt(dev_priv,
-         ~dev_priv->pc8.regsave.sdeimr &
-         ~SDE_HOTPLUG_MASK_CPT);
+ ibx_enable_display_interrupt(dev_priv, ~dev_priv->pc8.regsave.sdeimr);
  ilk_enable_gt_irq(dev_priv, ~dev_priv->pc8.regsave.gtimr);
  snb_enable_pm_irq(dev_priv, ~dev_priv->pc8.regsave.gen6_pmimr);
  I915_WRITE(GTIER, dev_priv->pc8.regsave.gtier);
diff --git a/drivers/gpu/drm/i915/i915_reg.h b/drivers/gpu/drm/i915/i915_reg.h
index 9a1a96a..a48b7ca 100644
--- a/drivers/gpu/drm/i915/i915_reg.h
+++ b/drivers/gpu/drm/i915/i915_reg.h
@@ -193,10 +193,13 @@
 #define   MI_SCENE_COUNT (1 << 3) /* just increment scene count */
 #define   MI_END_SCENE  (1 << 4) /* flush binner and incr scene count */
 #define   MI_INVALIDATE_ISP (1 << 5) /* invalidate indirect state pointers */
+#define MI_REPORT_HEAD  MI_INSTR(0x07, 0)
+#define MI_ARB_ON_OFF  MI_INSTR(0x08, 0)
+#define   MI_ARB_ENABLE   (1<<0)
+#define   MI_ARB_DISABLE  (0<<0)
 #define MI_BATCH_BUFFER_END MI_INSTR(0x0a, 0)
 #define MI_SUSPEND_FLUSH MI_INSTR(0x0b, 0)
 #define   MI_SUSPEND_FLUSH_EN (1<<0)
-#define MI_REPORT_HEAD  MI_INSTR(0x07, 0)
 #define MI_OVERLAY_FLIP  MI_INSTR(0x11, 0)
 #define   MI_OVERLAY_CONTINUE (0x0<<21)
 #define   MI_OVERLAY_ON  (0x1<<21)
@@ -212,10 +215,24 @@
 #define   MI_DISPLAY_FLIP_IVB_SPRITE_B (3 << 19)
 #define   MI_DISPLAY_FLIP_IVB_PLANE_C  (4 << 19)
 #define   MI_DISPLAY_FLIP_IVB_SPRITE_C (5 << 19)
-#define MI_ARB_ON_OFF  MI_INSTR(0x08, 0)
-#define   MI_ARB_ENABLE   (1<<0)
-#define   MI_ARB_DISABLE  (0<<0)
-
+#define MI_SEMAPHORE_MBOX MI_INSTR(0x16, 1) /* gen6+ */
+#define   MI_SEMAPHORE_GLOBAL_GTT    (1<<22)
+#define   MI_SEMAPHORE_UPDATE     (1<<21)
+#define   MI_SEMAPHORE_COMPARE     (1<<20)
+#define   MI_SEMAPHORE_REGISTER     (1<<18)
+#define   MI_SEMAPHORE_SYNC_VR     (0<<16) /* RCS  wait for VCS  (RVSYNC) */
+#define   MI_SEMAPHORE_SYNC_VER     (1<<16) /* RCS  wait for VECS (RVESYNC) */
+#define   MI_SEMAPHORE_SYNC_BR     (2<<16) /* RCS  wait for BCS  (RBSYNC) */
+#define   MI_SEMAPHORE_SYNC_BV     (0<<16) /* VCS  wait for BCS  (VBSYNC) */
+#define   MI_SEMAPHORE_SYNC_VEV     (1<<16) /* VCS  wait for VECS (VVESYNC) */
+#define   MI_SEMAPHORE_SYNC_RV     (2<<16) /* VCS  wait for RCS  (VRSYNC) */
+#define   MI_SEMAPHORE_SYNC_RB     (0<<16) /* BCS  wait for RCS  (BRSYNC) */
+#define   MI_SEMAPHORE_SYNC_VEB     (1<<16) /* BCS  wait for VECS (BVESYNC) */
+#define   MI_SEMAPHORE_SYNC_VB     (2<<16) /* BCS  wait for VCS  (BVSYNC) */
+#define   MI_SEMAPHORE_SYNC_BVE     (0<<16) /* VECS wait for BCS  (VEBSYNC) */
+#define   MI_SEMAPHORE_SYNC_VVE     (1<<16) /* VECS wait for VCS  (VEVSYNC) */
+#define   MI_SEMAPHORE_SYNC_RVE     (2<<16) /* VECS wait for RCS  (VERSYNC) */
+#define   MI_SEMAPHORE_SYNC_INVALID  (3<<16)
 #define MI_SET_CONTEXT  MI_INSTR(0x18, 0)
 #define   MI_MM_SPACE_GTT  (1<<8)
 #define   MI_MM_SPACE_PHYSICAL  (0<<8)
@@ -235,7 +252,7 @@
  */
 #define MI_LOAD_REGISTER_IMM(x) MI_INSTR(0x22, 2*x-1)
 #define MI_STORE_REGISTER_MEM(x) MI_INSTR(0x24, 2*x-1)
-#define  MI_SRM_LRM_GLOBAL_GTT  (1<<22)
+#define   MI_SRM_LRM_GLOBAL_GTT  (1<<22)
 #define MI_FLUSH_DW  MI_INSTR(0x26, 1) /* for GEN6 */
 #define   MI_FLUSH_DW_STORE_INDEX (1<<21)
 #define   MI_INVALIDATE_TLB  (1<<18)
@@ -246,30 +263,13 @@
 #define MI_BATCH_BUFFER  MI_INSTR(0x30, 1)
 #define   MI_BATCH_NON_SECURE  (1)
 /* for snb/ivb/vlv this also means "batch in ppgtt" when ppgtt is enabled. */
-#define   MI_BATCH_NON_SECURE_I965  (1<<8)
+#define   MI_BATCH_NON_SECURE_I965 (1<<8)
 #define   MI_BATCH_PPGTT_HSW  (1<<8)
-#define   MI_BATCH_NON_SECURE_HSW  (1<<13)
+#define   MI_BATCH_NON_SECURE_HSW (1<<13)
 #define MI_BATCH_BUFFER_START MI_INSTR(0x31, 0)
 #define   MI_BATCH_GTT      (2<<6) /* aliased with (1<<7) on gen4 */
 #define MI_BATCH_BUFFER_START_GEN8 MI_INSTR(0x31, 1)
-#define MI_SEMAPHORE_MBOX MI_INSTR(0x16, 1) /* gen6+ */
-#define  MI_SEMAPHORE_GLOBAL_GTT    (1<<22)
-#define  MI_SEMAPHORE_UPDATE     (1<<21)
-#define  MI_SEMAPHORE_COMPARE     (1<<20)
-#define  MI_SEMAPHORE_REGISTER     (1<<18)
-#define  MI_SEMAPHORE_SYNC_VR     (0<<16) /* RCS  wait for VCS  (RVSYNC) */
-#define  MI_SEMAPHORE_SYNC_VER     (1<<16) /* RCS  wait for VECS (RVESYNC) */
-#define  MI_SEMAPHORE_SYNC_BR     (2<<16) /* RCS  wait for BCS  (RBSYNC) */
-#define  MI_SEMAPHORE_SYNC_BV     (0<<16) /* VCS  wait for BCS  (VBSYNC) */
-#define  MI_SEMAPHORE_SYNC_VEV     (1<<16) /* VCS  wait for VECS (VVESYNC) */
-#define  MI_SEMAPHORE_SYNC_RV     (2<<16) /* VCS  wait for RCS  (VRSYNC) */
-#define  MI_SEMAPHORE_SYNC_RB     (0<<16) /* BCS  wait for RCS  (BRSYNC) */
-#define  MI_SEMAPHORE_SYNC_VEB     (1<<16) /* BCS  wait for VECS (BVESYNC) */
-#define  MI_SEMAPHORE_SYNC_VB     (2<<16) /* BCS  wait for VCS  (BVSYNC) */
-#define  MI_SEMAPHORE_SYNC_BVE     (0<<16) /* VECS wait for BCS  (VEBSYNC) */
-#define  MI_SEMAPHORE_SYNC_VVE     (1<<16) /* VECS wait for VCS  (VEVSYNC) */
-#define  MI_SEMAPHORE_SYNC_RVE     (2<<16) /* VECS wait for RCS  (VERSYNC) */
-#define  MI_SEMAPHORE_SYNC_INVALID  (3<<16)
+
 
 #define MI_PREDICATE_RESULT_2 (0x2214)
 #define  LOWER_SLICE_ENABLED (1<<0)
@@ -354,6 +354,7 @@
 #define   IOSF_BYTE_ENABLES_SHIFT  4
 #define   IOSF_BAR_SHIFT   1
 #define   IOSF_SB_BUSY    (1<<0)
+#define   IOSF_PORT_BUNIT   0x3
 #define   IOSF_PORT_PUNIT   0x4
 #define   IOSF_PORT_NC    0x11
 #define   IOSF_PORT_DPIO   0x12
@@ -361,12 +362,21 @@
 #define   IOSF_PORT_CCK    0x14
 #define   IOSF_PORT_CCU    0xA9
 #define   IOSF_PORT_GPS_CORE   0x48
+#define   IOSF_PORT_FLISDSI   0x1B
 #define VLV_IOSF_DATA    (VLV_DISPLAY_BASE + 0x2104)
 #define VLV_IOSF_ADDR    (VLV_DISPLAY_BASE + 0x2108)
 
+/* See configdb bunit SB addr map */
+#define BUNIT_REG_BISOC    0x11
+
 #define PUNIT_OPCODE_REG_READ   6
 #define PUNIT_OPCODE_REG_WRITE   7
 
+#define PUNIT_REG_DSPFREQ   0x36
+#define   DSPFREQSTAT_SHIFT   30
+#define   DSPFREQSTAT_MASK   (0x3 << DSPFREQSTAT_SHIFT)
+#define   DSPFREQGUAR_SHIFT   14
+#define   DSPFREQGUAR_MASK   (0x3 << DSPFREQGUAR_SHIFT)
 #define PUNIT_REG_PWRGT_CTRL   0x60
 #define PUNIT_REG_PWRGT_STATUS   0x61
 #define   PUNIT_CLK_GATE   1
@@ -429,6 +439,7 @@
 #define  DSI_PLL_N1_DIV_MASK   (3 << 16)
 #define  DSI_PLL_M1_DIV_SHIFT   0
 #define  DSI_PLL_M1_DIV_MASK   (0x1ff << 0)
+#define CCK_DISPLAY_CLOCK_CONTROL  0x6b
 
 /*
  * DPIO - a special bus for various display related registers to hide behind
@@ -447,15 +458,13 @@
 #define  DPIO_SFR_BYPASS  (1<<1)
 #define  DPIO_CMNRST   (1<<0)
 
-#define _DPIO_TX3_SWING_CTL4_A  0x690
-#define _DPIO_TX3_SWING_CTL4_B  0x2a90
-#define DPIO_TX3_SWING_CTL4(pipe) _PIPE(pipe, _DPIO_TX3_SWING_CTL4_A, \
-     _DPIO_TX3_SWING_CTL4_B)
+#define DPIO_PHY(pipe)   ((pipe) >> 1)
+#define DPIO_PHY_IOSF_PORT(phy)  (dev_priv->dpio_phy_iosf_port[phy])
 
 /*
  * Per pipe/PLL DPIO regs
  */
-#define _DPIO_DIV_A   0x800c
+#define _VLV_PLL_DW3_CH0  0x800c
 #define   DPIO_POST_DIV_SHIFT  (28) /* 3 bits */
 #define   DPIO_POST_DIV_DAC  0
 #define   DPIO_POST_DIV_HDMIDP  1 /* DAC 225-400M rate */
@@ -468,10 +477,10 @@
 #define   DPIO_ENABLE_CALIBRATION (1<<11)
 #define   DPIO_M1DIV_SHIFT  (8) /* 3 bits */
 #define   DPIO_M2DIV_MASK  0xff
-#define _DPIO_DIV_B   0x802c
-#define DPIO_DIV(pipe) _PIPE(pipe, _DPIO_DIV_A, _DPIO_DIV_B)
+#define _VLV_PLL_DW3_CH1  0x802c
+#define VLV_PLL_DW3(ch) _PIPE(ch, _VLV_PLL_DW3_CH0, _VLV_PLL_DW3_CH1)
 
-#define _DPIO_REFSFR_A   0x8014
+#define _VLV_PLL_DW5_CH0  0x8014
 #define   DPIO_REFSEL_OVERRIDE  27
 #define   DPIO_PLL_MODESEL_SHIFT 24 /* 3 bits */
 #define   DPIO_BIAS_CURRENT_CTL_SHIFT 21 /* 3 bits, always 0x7 */
@@ -479,118 +488,112 @@
 #define   DPIO_PLL_REFCLK_SEL_MASK 3
 #define   DPIO_DRIVER_CTL_SHIFT  12 /* always set to 0x8 */
 #define   DPIO_CLK_BIAS_CTL_SHIFT 8 /* always set to 0x5 */
-#define _DPIO_REFSFR_B   0x8034
-#define DPIO_REFSFR(pipe) _PIPE(pipe, _DPIO_REFSFR_A, _DPIO_REFSFR_B)
+#define _VLV_PLL_DW5_CH1  0x8034
+#define VLV_PLL_DW5(ch) _PIPE(ch, _VLV_PLL_DW5_CH0, _VLV_PLL_DW5_CH1)
 
-#define _DPIO_CORE_CLK_A  0x801c
-#define _DPIO_CORE_CLK_B  0x803c
-#define DPIO_CORE_CLK(pipe) _PIPE(pipe, _DPIO_CORE_CLK_A, _DPIO_CORE_CLK_B)
+#define _VLV_PLL_DW7_CH0  0x801c
+#define _VLV_PLL_DW7_CH1  0x803c
+#define VLV_PLL_DW7(ch) _PIPE(ch, _VLV_PLL_DW7_CH0, _VLV_PLL_DW7_CH1)
 
-#define _DPIO_IREF_CTL_A  0x8040
-#define _DPIO_IREF_CTL_B  0x8060
-#define DPIO_IREF_CTL(pipe) _PIPE(pipe, _DPIO_IREF_CTL_A, _DPIO_IREF_CTL_B)
+#define _VLV_PLL_DW8_CH0  0x8040
+#define _VLV_PLL_DW8_CH1  0x8060
+#define VLV_PLL_DW8(ch) _PIPE(ch, _VLV_PLL_DW8_CH0, _VLV_PLL_DW8_CH1)
 
-#define DPIO_IREF_BCAST   0xc044
-#define _DPIO_IREF_A   0x8044
-#define _DPIO_IREF_B   0x8064
-#define DPIO_IREF(pipe) _PIPE(pipe, _DPIO_IREF_A, _DPIO_IREF_B)
+#define VLV_PLL_DW9_BCAST  0xc044
+#define _VLV_PLL_DW9_CH0  0x8044
+#define _VLV_PLL_DW9_CH1  0x8064
+#define VLV_PLL_DW9(ch) _PIPE(ch, _VLV_PLL_DW9_CH0, _VLV_PLL_DW9_CH1)
 
-#define _DPIO_PLL_CML_A   0x804c
-#define _DPIO_PLL_CML_B   0x806c
-#define DPIO_PLL_CML(pipe) _PIPE(pipe, _DPIO_PLL_CML_A, _DPIO_PLL_CML_B)
+#define _VLV_PLL_DW10_CH0  0x8048
+#define _VLV_PLL_DW10_CH1  0x8068
+#define VLV_PLL_DW10(ch) _PIPE(ch, _VLV_PLL_DW10_CH0, _VLV_PLL_DW10_CH1)
 
-#define _DPIO_LPF_COEFF_A  0x8048
-#define _DPIO_LPF_COEFF_B  0x8068
-#define DPIO_LPF_COEFF(pipe) _PIPE(pipe, _DPIO_LPF_COEFF_A, _DPIO_LPF_COEFF_B)
+#define _VLV_PLL_DW11_CH0  0x804c
+#define _VLV_PLL_DW11_CH1  0x806c
+#define VLV_PLL_DW11(ch) _PIPE(ch, _VLV_PLL_DW11_CH0, _VLV_PLL_DW11_CH1)
 
-#define DPIO_CALIBRATION  0x80ac
+/* Spec for ref block start counts at DW10 */
+#define VLV_REF_DW13   0x80ac
 
-#define DPIO_FASTCLK_DISABLE  0x8100
+#define VLV_CMN_DW0   0x8100
 
 /*
  * Per DDI channel DPIO regs
  */
 
-#define _DPIO_PCS_TX_0   0x8200
-#define _DPIO_PCS_TX_1   0x8400
+#define _VLV_PCS_DW0_CH0  0x8200
+#define _VLV_PCS_DW0_CH1  0x8400
 #define   DPIO_PCS_TX_LANE2_RESET (1<<16)
 #define   DPIO_PCS_TX_LANE1_RESET (1<<7)
-#define DPIO_PCS_TX(port) _PORT(port, _DPIO_PCS_TX_0, _DPIO_PCS_TX_1)
+#define VLV_PCS_DW0(ch) _PORT(ch, _VLV_PCS_DW0_CH0, _VLV_PCS_DW0_CH1)
 
-#define _DPIO_PCS_CLK_0   0x8204
-#define _DPIO_PCS_CLK_1   0x8404
+#define _VLV_PCS_DW1_CH0  0x8204
+#define _VLV_PCS_DW1_CH1  0x8404
 #define   DPIO_PCS_CLK_CRI_RXEB_EIOS_EN (1<<22)
 #define   DPIO_PCS_CLK_CRI_RXDIGFILTSG_EN (1<<21)
 #define   DPIO_PCS_CLK_DATAWIDTH_SHIFT (6)
 #define   DPIO_PCS_CLK_SOFT_RESET (1<<5)
-#define DPIO_PCS_CLK(port) _PORT(port, _DPIO_PCS_CLK_0, _DPIO_PCS_CLK_1)
-
-#define _DPIO_PCS_CTL_OVR1_A  0x8224
-#define _DPIO_PCS_CTL_OVR1_B  0x8424
-#define DPIO_PCS_CTL_OVER1(port) _PORT(port, _DPIO_PCS_CTL_OVR1_A, \
-           _DPIO_PCS_CTL_OVR1_B)
-
-#define _DPIO_PCS_STAGGER0_A  0x822c
-#define _DPIO_PCS_STAGGER0_B  0x842c
-#define DPIO_PCS_STAGGER0(port) _PORT(port, _DPIO_PCS_STAGGER0_A, \
-          _DPIO_PCS_STAGGER0_B)
-
-#define _DPIO_PCS_STAGGER1_A  0x8230
-#define _DPIO_PCS_STAGGER1_B  0x8430
-#define DPIO_PCS_STAGGER1(port) _PORT(port, _DPIO_PCS_STAGGER1_A, \
-          _DPIO_PCS_STAGGER1_B)
-
-#define _DPIO_PCS_CLOCKBUF0_A  0x8238
-#define _DPIO_PCS_CLOCKBUF0_B  0x8438
-#define DPIO_PCS_CLOCKBUF0(port) _PORT(port, _DPIO_PCS_CLOCKBUF0_A, \
-           _DPIO_PCS_CLOCKBUF0_B)
-
-#define _DPIO_PCS_CLOCKBUF8_A  0x825c
-#define _DPIO_PCS_CLOCKBUF8_B  0x845c
-#define DPIO_PCS_CLOCKBUF8(port) _PORT(port, _DPIO_PCS_CLOCKBUF8_A, \
-           _DPIO_PCS_CLOCKBUF8_B)
-
-#define _DPIO_TX_SWING_CTL2_A  0x8288
-#define _DPIO_TX_SWING_CTL2_B  0x8488
-#define DPIO_TX_SWING_CTL2(port) _PORT(port, _DPIO_TX_SWING_CTL2_A, \
-           _DPIO_TX_SWING_CTL2_B)
-
-#define _DPIO_TX_SWING_CTL3_A  0x828c
-#define _DPIO_TX_SWING_CTL3_B  0x848c
-#define DPIO_TX_SWING_CTL3(port) _PORT(port, _DPIO_TX_SWING_CTL3_A, \
-           _DPIO_TX_SWING_CTL3_B)
-
-#define _DPIO_TX_SWING_CTL4_A  0x8290
-#define _DPIO_TX_SWING_CTL4_B  0x8490
-#define DPIO_TX_SWING_CTL4(port) _PORT(port, _DPIO_TX_SWING_CTL4_A, \
-           _DPIO_TX_SWING_CTL4_B)
-
-#define _DPIO_TX_OCALINIT_0  0x8294
-#define _DPIO_TX_OCALINIT_1  0x8494
+#define VLV_PCS_DW1(ch) _PORT(ch, _VLV_PCS_DW1_CH0, _VLV_PCS_DW1_CH1)
+
+#define _VLV_PCS_DW8_CH0  0x8220
+#define _VLV_PCS_DW8_CH1  0x8420
+#define VLV_PCS_DW8(ch) _PORT(ch, _VLV_PCS_DW8_CH0, _VLV_PCS_DW8_CH1)
+
+#define _VLV_PCS01_DW8_CH0  0x0220
+#define _VLV_PCS23_DW8_CH0  0x0420
+#define _VLV_PCS01_DW8_CH1  0x2620
+#define _VLV_PCS23_DW8_CH1  0x2820
+#define VLV_PCS01_DW8(port) _PORT(port, _VLV_PCS01_DW8_CH0, _VLV_PCS01_DW8_CH1)
+#define VLV_PCS23_DW8(port) _PORT(port, _VLV_PCS23_DW8_CH0, _VLV_PCS23_DW8_CH1)
+
+#define _VLV_PCS_DW9_CH0  0x8224
+#define _VLV_PCS_DW9_CH1  0x8424
+#define VLV_PCS_DW9(ch) _PORT(ch, _VLV_PCS_DW9_CH0, _VLV_PCS_DW9_CH1)
+
+#define _VLV_PCS_DW11_CH0  0x822c
+#define _VLV_PCS_DW11_CH1  0x842c
+#define VLV_PCS_DW11(ch) _PORT(ch, _VLV_PCS_DW11_CH0, _VLV_PCS_DW11_CH1)
+
+#define _VLV_PCS_DW12_CH0  0x8230
+#define _VLV_PCS_DW12_CH1  0x8430
+#define VLV_PCS_DW12(ch) _PORT(ch, _VLV_PCS_DW12_CH0, _VLV_PCS_DW12_CH1)
+
+#define _VLV_PCS_DW14_CH0  0x8238
+#define _VLV_PCS_DW14_CH1  0x8438
+#define VLV_PCS_DW14(ch) _PORT(ch, _VLV_PCS_DW14_CH0, _VLV_PCS_DW14_CH1)
+
+#define _VLV_PCS_DW23_CH0  0x825c
+#define _VLV_PCS_DW23_CH1  0x845c
+#define VLV_PCS_DW23(ch) _PORT(ch, _VLV_PCS_DW23_CH0, _VLV_PCS_DW23_CH1)
+
+#define _VLV_TX_DW2_CH0   0x8288
+#define _VLV_TX_DW2_CH1   0x8488
+#define VLV_TX_DW2(ch) _PORT(ch, _VLV_TX_DW2_CH0, _VLV_TX_DW2_CH1)
+
+#define _VLV_TX_DW3_CH0   0x828c
+#define _VLV_TX_DW3_CH1   0x848c
+#define VLV_TX_DW3(ch) _PORT(ch, _VLV_TX_DW3_CH0, _VLV_TX_DW3_CH1)
+
+#define _VLV_TX_DW4_CH0   0x8290
+#define _VLV_TX_DW4_CH1   0x8490
+#define VLV_TX_DW4(ch) _PORT(ch, _VLV_TX_DW4_CH0, _VLV_TX_DW4_CH1)
+
+#define _VLV_TX3_DW4_CH0  0x690
+#define _VLV_TX3_DW4_CH1  0x2a90
+#define VLV_TX3_DW4(ch) _PORT(ch, _VLV_TX3_DW4_CH0, _VLV_TX3_DW4_CH1)
+
+#define _VLV_TX_DW5_CH0   0x8294
+#define _VLV_TX_DW5_CH1   0x8494
 #define   DPIO_TX_OCALINIT_EN  (1<<31)
-#define DPIO_TX_OCALINIT(port) _PORT(port, _DPIO_TX_OCALINIT_0, \
-         _DPIO_TX_OCALINIT_1)
-
-#define _DPIO_TX_CTL_0   0x82ac
-#define _DPIO_TX_CTL_1   0x84ac
-#define DPIO_TX_CTL(port) _PORT(port, _DPIO_TX_CTL_0, _DPIO_TX_CTL_1)
-
-#define _DPIO_TX_LANE_0   0x82b8
-#define _DPIO_TX_LANE_1   0x84b8
-#define DPIO_TX_LANE(port) _PORT(port, _DPIO_TX_LANE_0, _DPIO_TX_LANE_1)
-
-#define _DPIO_DATA_CHANNEL1  0x8220
-#define _DPIO_DATA_CHANNEL2  0x8420
-#define DPIO_DATA_CHANNEL(port) _PORT(port, _DPIO_DATA_CHANNEL1, _DPIO_DATA_CHANNEL2)
-
-#define _DPIO_PORT0_PCS0  0x0220
-#define _DPIO_PORT0_PCS1  0x0420
-#define _DPIO_PORT1_PCS2  0x2620
-#define _DPIO_PORT1_PCS3  0x2820
-#define DPIO_DATA_LANE_A(port) _PORT(port, _DPIO_PORT0_PCS0, _DPIO_PORT1_PCS2)
-#define DPIO_DATA_LANE_B(port) _PORT(port, _DPIO_PORT0_PCS1, _DPIO_PORT1_PCS3)
-#define DPIO_DATA_CHANNEL1              0x8220
-#define DPIO_DATA_CHANNEL2              0x8420
+#define VLV_TX_DW5(ch) _PORT(ch, _VLV_TX_DW5_CH0, _VLV_TX_DW5_CH1)
+
+#define _VLV_TX_DW11_CH0  0x82ac
+#define _VLV_TX_DW11_CH1  0x84ac
+#define VLV_TX_DW11(ch) _PORT(ch, _VLV_TX_DW11_CH0, _VLV_TX_DW11_CH1)
+
+#define _VLV_TX_DW14_CH0  0x82b8
+#define _VLV_TX_DW14_CH1  0x84b8
+#define VLV_TX_DW14(ch) _PORT(ch, _VLV_TX_DW14_CH0, _VLV_TX_DW14_CH1)
 
 /*
  * Fence registers
@@ -732,6 +735,8 @@
 #define HWSTAM  0x02098
 #define DMA_FADD_I8XX 0x020d0
 #define RING_BBSTATE(base) ((base)+0x110)
+#define RING_BBADDR(base) ((base)+0x140)
+#define RING_BBADDR_UDW(base) ((base)+0x168) /* gen8+ */
 
 #define ERROR_GEN6 0x040a0
 #define GEN7_ERR_INT 0x44040
@@ -922,7 +927,6 @@
 #define   CM0_COLOR_EVICT_DISABLE (1<<3)
 #define   CM0_DEPTH_WRITE_DISABLE (1<<1)
 #define   CM0_RC_OP_FLUSH_DISABLE (1<<0)
-#define BB_ADDR  0x02140 /* 8 bytes */
 #define GFX_FLSH_CNTL 0x02170 /* 915+ only */
 #define GFX_FLSH_CNTL_GEN6 0x101008
 #define   GFX_FLSH_CNTL_EN (1<<0)
@@ -999,6 +1003,7 @@
 
 #define GEN7_FF_THREAD_MODE  0x20a0
 #define   GEN7_FF_SCHED_MASK  0x0077070
+#define   GEN8_FF_DS_REF_CNT_FFME (1 << 19)
 #define   GEN7_FF_TS_SCHED_HS1  (0x5<<16)
 #define   GEN7_FF_TS_SCHED_HS0  (0x3<<16)
 #define   GEN7_FF_TS_SCHED_LOAD_BALANCE (0x1<<16)
@@ -1026,14 +1031,14 @@
 #define   FBC_CTL_UNCOMPRESSIBLE (1<<14)
 #define   FBC_CTL_C3_IDLE (1<<13)
 #define   FBC_CTL_STRIDE_SHIFT (5)
-#define   FBC_CTL_FENCENO (1<<0)
+#define   FBC_CTL_FENCENO_SHIFT (0)
 #define FBC_COMMAND  0x0320c
 #define   FBC_CMD_COMPRESS (1<<0)
 #define FBC_STATUS  0x03210
 #define   FBC_STAT_COMPRESSING (1<<31)
 #define   FBC_STAT_COMPRESSED (1<<30)
 #define   FBC_STAT_MODIFIED (1<<29)
-#define   FBC_STAT_CURRENT_LINE (1<<0)
+#define   FBC_STAT_CURRENT_LINE_SHIFT (0)
 #define FBC_CONTROL2  0x03214
 #define   FBC_CTL_FENCE_DBL (0<<4)
 #define   FBC_CTL_IDLE_IMM (0<<2)
@@ -2134,6 +2139,11 @@
 #define   CRT_HOTPLUG_MONITOR_COLOR  (3 << 8)
 #define   CRT_HOTPLUG_MONITOR_MONO  (2 << 8)
 #define   CRT_HOTPLUG_MONITOR_NONE  (0 << 8)
+#define   DP_AUX_CHANNEL_D_INT_STATUS_G4X (1 << 6)
+#define   DP_AUX_CHANNEL_C_INT_STATUS_G4X (1 << 5)
+#define   DP_AUX_CHANNEL_B_INT_STATUS_G4X (1 << 4)
+#define   DP_AUX_CHANNEL_MASK_INT_STATUS_G4X (7 << 4)
+
 /* SDVO is different across gen3/4 */
 #define   SDVOC_HOTPLUG_INT_STATUS_G4X  (1 << 3)
 #define   SDVOB_HOTPLUG_INT_STATUS_G4X  (1 << 2)
@@ -3425,42 +3435,6 @@
 /* the unit of memory self-refresh latency time is 0.5us */
 #define  ILK_SRLT_MASK  0x3f
 
-/* define the fifo size on Ironlake */
-#define ILK_DISPLAY_FIFO 128
-#define ILK_DISPLAY_MAXWM 64
-#define ILK_DISPLAY_DFTWM 8
-#define ILK_CURSOR_FIFO  32
-#define ILK_CURSOR_MAXWM 16
-#define ILK_CURSOR_DFTWM 8
-
-#define ILK_DISPLAY_SR_FIFO 512
-#define ILK_DISPLAY_MAX_SRWM 0x1ff
-#define ILK_DISPLAY_DFT_SRWM 0x3f
-#define ILK_CURSOR_SR_FIFO 64
-#define ILK_CURSOR_MAX_SRWM 0x3f
-#define ILK_CURSOR_DFT_SRWM 8
-
-#define ILK_FIFO_LINE_SIZE 64
-
-/* define the WM info on Sandybridge */
-#define SNB_DISPLAY_FIFO 128
-#define SNB_DISPLAY_MAXWM 0x7f /* bit 16:22 */
-#define SNB_DISPLAY_DFTWM 8
-#define SNB_CURSOR_FIFO  32
-#define SNB_CURSOR_MAXWM 0x1f /* bit 4:0 */
-#define SNB_CURSOR_DFTWM 8
-
-#define SNB_DISPLAY_SR_FIFO 512
-#define SNB_DISPLAY_MAX_SRWM 0x1ff /* bit 16:8 */
-#define SNB_DISPLAY_DFT_SRWM 0x3f
-#define SNB_CURSOR_SR_FIFO 64
-#define SNB_CURSOR_MAX_SRWM 0x3f /* bit 5:0 */
-#define SNB_CURSOR_DFT_SRWM 8
-
-#define SNB_FBC_MAX_SRWM 0xf /* bit 23:20 */
-
-#define SNB_FIFO_LINE_SIZE 64
-
 
 /* the address where we get all kinds of latency value */
 #define SSKPD   0x5d10
@@ -3604,8 +3578,6 @@
 #define DISP_BASEADDR_MASK (0xfffff000)
 #define I915_LO_DISPBASE(val) (val & ~DISP_BASEADDR_MASK)
 #define I915_HI_DISPBASE(val) (val & DISP_BASEADDR_MASK)
-#define I915_MODIFY_DISPBASE(reg, gfx_addr) \
-  (I915_WRITE((reg), (gfx_addr) | I915_LO_DISPBASE(I915_READ(reg))))
 
 /* VBIOS flags */
 #define SWF00   (dev_priv->info->display_mmio_offset + 0x71410)
@@ -3791,7 +3763,7 @@
 
 #define _SPACNTR  (VLV_DISPLAY_BASE + 0x72180)
 #define   SP_ENABLE   (1<<31)
-#define   SP_GEAMMA_ENABLE  (1<<30)
+#define   SP_GAMMA_ENABLE  (1<<30)
 #define   SP_PIXFORMAT_MASK  (0xf<<26)
 #define   SP_FORMAT_YUV422  (0<<26)
 #define   SP_FORMAT_BGR565  (5<<26)
@@ -4143,6 +4115,8 @@
 #define DISP_ARB_CTL 0x45000
 #define  DISP_TILE_SURFACE_SWIZZLING (1<<13)
 #define  DISP_FBC_WM_DIS  (1<<15)
+#define DISP_ARB_CTL2 0x45004
+#define  DISP_DATA_PARTITION_5_6 (1<<6)
 #define GEN7_MSG_CTL 0x45010
 #define  WAIT_FOR_PCH_RESET_ACK  (1<<1)
 #define  WAIT_FOR_PCH_FLR_ACK  (1<<0)
@@ -4163,6 +4137,10 @@
 #define GEN7_L3SQCREG4    0xb034
 #define  L3SQ_URB_READ_CAM_MATCH_DISABLE (1<<27)
 
+/* GEN8 chicken */
+#define HDC_CHICKEN0    0x7300
+#define  HDC_FORCE_NON_COHERENT   (1<<4)
+
 /* WaCatErrorRejectionIssue */
 #define GEN7_SQ_CHICKEN_MBCUNIT_CONFIG  0x9030
 #define  GEN7_SQ_CHICKEN_MBCUNIT_SQINTMOB (1<<11)
@@ -4847,6 +4825,8 @@
 #define  FORCEWAKE_ACK    0x130090
 #define  VLV_GTLC_WAKE_CTRL   0x130090
 #define  VLV_GTLC_PW_STATUS   0x130094
+#define VLV_GTLC_PW_RENDER_STATUS_MASK  0x80
+#define VLV_GTLC_PW_MEDIA_STATUS_MASK  0x20
 #define  FORCEWAKE_MT    0xa188 /* multi-threaded */
 #define   FORCEWAKE_KERNEL   0x1
 #define   FORCEWAKE_USER   0x2
@@ -4855,12 +4835,16 @@
 #define    FORCEWAKE_MT_ENABLE   (1<<5)
 
 #define  GTFIFODBG    0x120000
-#define    GT_FIFO_CPU_ERROR_MASK  7
+#define    GT_FIFO_SBDROPERR   (1<<6)
+#define    GT_FIFO_BLOBDROPERR   (1<<5)
+#define    GT_FIFO_SB_READ_ABORTERR  (1<<4)
+#define    GT_FIFO_DROPERR   (1<<3)
 #define    GT_FIFO_OVFERR   (1<<2)
 #define    GT_FIFO_IAWRERR   (1<<1)
 #define    GT_FIFO_IARDERR   (1<<0)
 
-#define  GT_FIFO_FREE_ENTRIES   0x120008
+#define  GTFIFOCTL    0x120008
+#define    GT_FIFO_FREE_ENTRIES_MASK  0x7f
 #define    GT_FIFO_NUM_RESERVED_ENTRIES  20
 
 #define  HSW_IDICR    0x9008
@@ -4894,6 +4878,7 @@
 #define   GEN6_RC_CTL_RC6_ENABLE  (1<<18)
 #define   GEN6_RC_CTL_RC1e_ENABLE  (1<<20)
 #define   GEN6_RC_CTL_RC7_ENABLE  (1<<22)
+#define   VLV_RC_CTL_CTX_RST_PARALLEL  (1<<24)
 #define   GEN7_RC_CTL_TO_MODE   (1<<28)
 #define   GEN6_RC_CTL_EI_MODE(x)  ((x)<<27)
 #define   GEN6_RC_CTL_HW_ENABLE   (1<<31)
diff --git a/drivers/gpu/drm/i915/i915_suspend.c b/drivers/gpu/drm/i915/i915_suspend.c
index 98790c7..8150fdc 100644
--- a/drivers/gpu/drm/i915/i915_suspend.c
+++ b/drivers/gpu/drm/i915/i915_suspend.c
@@ -192,7 +192,6 @@ static void i915_restore_vga(struct drm_device *dev)
 static void i915_save_display(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
- unsigned long flags;
 
  /* Display arbitration control */
  if (INTEL_INFO(dev)->gen <= 4)
@@ -203,46 +202,27 @@ static void i915_save_display(struct drm_device *dev)
  if (!drm_core_check_feature(dev, DRIVER_MODESET))
   i915_save_display_reg(dev);
 
- spin_lock_irqsave(&dev_priv->backlight.lock, flags);
-
  /* LVDS state */
  if (HAS_PCH_SPLIT(dev)) {
   dev_priv->regfile.savePP_CONTROL = I915_READ(PCH_PP_CONTROL);
-  dev_priv->regfile.saveBLC_PWM_CTL = I915_READ(BLC_PWM_PCH_CTL1);
-  dev_priv->regfile.saveBLC_PWM_CTL2 = I915_READ(BLC_PWM_PCH_CTL2);
-  dev_priv->regfile.saveBLC_CPU_PWM_CTL = I915_READ(BLC_PWM_CPU_CTL);
-  dev_priv->regfile.saveBLC_CPU_PWM_CTL2 = I915_READ(BLC_PWM_CPU_CTL2);
   if (HAS_PCH_IBX(dev) || HAS_PCH_CPT(dev))
    dev_priv->regfile.saveLVDS = I915_READ(PCH_LVDS);
  } else if (IS_VALLEYVIEW(dev)) {
   dev_priv->regfile.savePP_CONTROL = I915_READ(PP_CONTROL);
   dev_priv->regfile.savePFIT_PGM_RATIOS = I915_READ(PFIT_PGM_RATIOS);
 
-  dev_priv->regfile.saveBLC_PWM_CTL =
-   I915_READ(VLV_BLC_PWM_CTL(PIPE_A));
   dev_priv->regfile.saveBLC_HIST_CTL =
    I915_READ(VLV_BLC_HIST_CTL(PIPE_A));
-  dev_priv->regfile.saveBLC_PWM_CTL2 =
-   I915_READ(VLV_BLC_PWM_CTL2(PIPE_A));
-  dev_priv->regfile.saveBLC_PWM_CTL_B =
-   I915_READ(VLV_BLC_PWM_CTL(PIPE_B));
   dev_priv->regfile.saveBLC_HIST_CTL_B =
    I915_READ(VLV_BLC_HIST_CTL(PIPE_B));
-  dev_priv->regfile.saveBLC_PWM_CTL2_B =
-   I915_READ(VLV_BLC_PWM_CTL2(PIPE_B));
  } else {
   dev_priv->regfile.savePP_CONTROL = I915_READ(PP_CONTROL);
   dev_priv->regfile.savePFIT_PGM_RATIOS = I915_READ(PFIT_PGM_RATIOS);
-  dev_priv->regfile.saveBLC_PWM_CTL = I915_READ(BLC_PWM_CTL);
   dev_priv->regfile.saveBLC_HIST_CTL = I915_READ(BLC_HIST_CTL);
-  if (INTEL_INFO(dev)->gen >= 4)
-   dev_priv->regfile.saveBLC_PWM_CTL2 = I915_READ(BLC_PWM_CTL2);
   if (IS_MOBILE(dev) && !IS_I830(dev))
    dev_priv->regfile.saveLVDS = I915_READ(LVDS);
  }
 
- spin_unlock_irqrestore(&dev_priv->backlight.lock, flags);
-
  if (!IS_I830(dev) && !IS_845G(dev) && !HAS_PCH_SPLIT(dev))
   dev_priv->regfile.savePFIT_CONTROL = I915_READ(PFIT_CONTROL);
 
@@ -257,7 +237,7 @@ static void i915_save_display(struct drm_device *dev)
  }
 
  /* Only regfile.save FBC state on the platform that supports FBC */
- if (I915_HAS_FBC(dev)) {
+ if (HAS_FBC(dev)) {
   if (HAS_PCH_SPLIT(dev)) {
    dev_priv->regfile.saveDPFC_CB_BASE = I915_READ(ILK_DPFC_CB_BASE);
   } else if (IS_GM45(dev)) {
@@ -278,7 +258,6 @@ static void i915_restore_display(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  u32 mask = 0xffffffff;
- unsigned long flags;
 
  /* Display arbitration */
  if (INTEL_INFO(dev)->gen <= 4)
@@ -287,12 +266,6 @@ static void i915_restore_display(struct drm_device *dev)
  if (!drm_core_check_feature(dev, DRIVER_MODESET))
   i915_restore_display_reg(dev);
 
- spin_lock_irqsave(&dev_priv->backlight.lock, flags);
-
- /* LVDS state */
- if (INTEL_INFO(dev)->gen >= 4 && !HAS_PCH_SPLIT(dev))
-  I915_WRITE(BLC_PWM_CTL2, dev_priv->regfile.saveBLC_PWM_CTL2);
-
  if (drm_core_check_feature(dev, DRIVER_MODESET))
   mask = ~LVDS_PORT_EN;
 
@@ -305,13 +278,6 @@ static void i915_restore_display(struct drm_device *dev)
   I915_WRITE(PFIT_CONTROL, dev_priv->regfile.savePFIT_CONTROL);
 
  if (HAS_PCH_SPLIT(dev)) {
-  I915_WRITE(BLC_PWM_PCH_CTL1, dev_priv->regfile.saveBLC_PWM_CTL);
-  I915_WRITE(BLC_PWM_PCH_CTL2, dev_priv->regfile.saveBLC_PWM_CTL2);
-  /* NOTE: BLC_PWM_CPU_CTL must be written after BLC_PWM_CPU_CTL2;
-   * otherwise we get blank eDP screen after S3 on some machines
-   */
-  I915_WRITE(BLC_PWM_CPU_CTL2, dev_priv->regfile.saveBLC_CPU_PWM_CTL2);
-  I915_WRITE(BLC_PWM_CPU_CTL, dev_priv->regfile.saveBLC_CPU_PWM_CTL);
   I915_WRITE(PCH_PP_ON_DELAYS, dev_priv->regfile.savePP_ON_DELAYS);
   I915_WRITE(PCH_PP_OFF_DELAYS, dev_priv->regfile.savePP_OFF_DELAYS);
   I915_WRITE(PCH_PP_DIVISOR, dev_priv->regfile.savePP_DIVISOR);
@@ -319,21 +285,12 @@ static void i915_restore_display(struct drm_device *dev)
   I915_WRITE(RSTDBYCTL,
       dev_priv->regfile.saveMCHBAR_RENDER_STANDBY);
  } else if (IS_VALLEYVIEW(dev)) {
-  I915_WRITE(VLV_BLC_PWM_CTL(PIPE_A),
-      dev_priv->regfile.saveBLC_PWM_CTL);
   I915_WRITE(VLV_BLC_HIST_CTL(PIPE_A),
       dev_priv->regfile.saveBLC_HIST_CTL);
-  I915_WRITE(VLV_BLC_PWM_CTL2(PIPE_A),
-      dev_priv->regfile.saveBLC_PWM_CTL2);
-  I915_WRITE(VLV_BLC_PWM_CTL(PIPE_B),
-      dev_priv->regfile.saveBLC_PWM_CTL);
   I915_WRITE(VLV_BLC_HIST_CTL(PIPE_B),
       dev_priv->regfile.saveBLC_HIST_CTL);
-  I915_WRITE(VLV_BLC_PWM_CTL2(PIPE_B),
-      dev_priv->regfile.saveBLC_PWM_CTL2);
  } else {
   I915_WRITE(PFIT_PGM_RATIOS, dev_priv->regfile.savePFIT_PGM_RATIOS);
-  I915_WRITE(BLC_PWM_CTL, dev_priv->regfile.saveBLC_PWM_CTL);
   I915_WRITE(BLC_HIST_CTL, dev_priv->regfile.saveBLC_HIST_CTL);
   I915_WRITE(PP_ON_DELAYS, dev_priv->regfile.savePP_ON_DELAYS);
   I915_WRITE(PP_OFF_DELAYS, dev_priv->regfile.savePP_OFF_DELAYS);
@@ -341,11 +298,9 @@ static void i915_restore_display(struct drm_device *dev)
   I915_WRITE(PP_CONTROL, dev_priv->regfile.savePP_CONTROL);
  }
 
- spin_unlock_irqrestore(&dev_priv->backlight.lock, flags);
-
  /* only restore FBC info on the platform that supports FBC*/
  intel_disable_fbc(dev);
- if (I915_HAS_FBC(dev)) {
+ if (HAS_FBC(dev)) {
   if (HAS_PCH_SPLIT(dev)) {
    I915_WRITE(ILK_DPFC_CB_BASE, dev_priv->regfile.saveDPFC_CB_BASE);
   } else if (IS_GM45(dev)) {
diff --git a/drivers/gpu/drm/i915/i915_sysfs.c b/drivers/gpu/drm/i915/i915_sysfs.c
index cef38fd..33bcae3 100644
--- a/drivers/gpu/drm/i915/i915_sysfs.c
+++ b/drivers/gpu/drm/i915/i915_sysfs.c
@@ -40,10 +40,13 @@ static u32 calc_residency(struct drm_device *dev, const u32 reg)
  struct drm_i915_private *dev_priv = dev->dev_private;
  u64 raw_time; /* 32b value may overflow during fixed point math */
  u64 units = 128ULL, div = 100000ULL, bias = 100ULL;
+ u32 ret;
 
  if (!intel_enable_rc6(dev))
   return 0;
 
+ intel_runtime_pm_get(dev_priv);
+
  /* On VLV, residency time is in CZ units rather than 1.28us */
  if (IS_VALLEYVIEW(dev)) {
   u32 clkctl2;
@@ -52,7 +55,8 @@ static u32 calc_residency(struct drm_device *dev, const u32 reg)
    CLK_CTL2_CZCOUNT_30NS_SHIFT;
   if (!clkctl2) {
    WARN(!clkctl2, "bogus CZ count value");
-   return 0;
+   ret = 0;
+   goto out;
   }
   units = DIV_ROUND_UP_ULL(30ULL * bias, (u64)clkctl2);
   if (I915_READ(VLV_COUNTER_CONTROL) & VLV_COUNT_RANGE_HIGH)
@@ -62,7 +66,11 @@ static u32 calc_residency(struct drm_device *dev, const u32 reg)
  }
 
  raw_time = I915_READ(reg) * units;
- return DIV_ROUND_UP_ULL(raw_time, div);
+ ret = DIV_ROUND_UP_ULL(raw_time, div);
+
+out:
+ intel_runtime_pm_put(dev_priv);
+ return ret;
 }
 
 static ssize_t
@@ -183,13 +191,13 @@ i915_l3_write(struct file *filp, struct kobject *kobj,
  int slice = (int)(uintptr_t)attr->private;
  int ret;
 
+ if (!HAS_HW_CONTEXTS(drm_dev))
+  return -ENXIO;
+
  ret = l3_access_valid(drm_dev, offset);
  if (ret)
   return ret;
 
- if (dev_priv->hw_contexts_disabled)
-  return -ENXIO;
-
  ret = i915_mutex_lock_interruptible(drm_dev);
  if (ret)
   return ret;
@@ -259,7 +267,7 @@ static ssize_t gt_cur_freq_mhz_show(struct device *kdev,
  if (IS_VALLEYVIEW(dev_priv->dev)) {
   u32 freq;
   freq = vlv_punit_read(dev_priv, PUNIT_REG_GPU_FREQ_STS);
-  ret = vlv_gpu_freq(dev_priv->mem_freq, (freq >> 8) & 0xff);
+  ret = vlv_gpu_freq(dev_priv, (freq >> 8) & 0xff);
  } else {
   ret = dev_priv->rps.cur_delay * GT_FREQUENCY_MULTIPLIER;
  }
@@ -276,8 +284,7 @@ static ssize_t vlv_rpe_freq_mhz_show(struct device *kdev,
  struct drm_i915_private *dev_priv = dev->dev_private;
 
  return snprintf(buf, PAGE_SIZE, "%d\n",
-   vlv_gpu_freq(dev_priv->mem_freq,
-         dev_priv->rps.rpe_delay));
+   vlv_gpu_freq(dev_priv, dev_priv->rps.rpe_delay));
 }
 
 static ssize_t gt_max_freq_mhz_show(struct device *kdev, struct device_attribute *attr, char *buf)
@@ -291,7 +298,7 @@ static ssize_t gt_max_freq_mhz_show(struct device *kdev, struct device_attribute
 
  mutex_lock(&dev_priv->rps.hw_lock);
  if (IS_VALLEYVIEW(dev_priv->dev))
-  ret = vlv_gpu_freq(dev_priv->mem_freq, dev_priv->rps.max_delay);
+  ret = vlv_gpu_freq(dev_priv, dev_priv->rps.max_delay);
  else
   ret = dev_priv->rps.max_delay * GT_FREQUENCY_MULTIPLIER;
  mutex_unlock(&dev_priv->rps.hw_lock);
@@ -318,7 +325,7 @@ static ssize_t gt_max_freq_mhz_store(struct device *kdev,
  mutex_lock(&dev_priv->rps.hw_lock);
 
  if (IS_VALLEYVIEW(dev_priv->dev)) {
-  val = vlv_freq_opcode(dev_priv->mem_freq, val);
+  val = vlv_freq_opcode(dev_priv, val);
 
   hw_max = valleyview_rps_max_freq(dev_priv);
   hw_min = valleyview_rps_min_freq(dev_priv);
@@ -342,15 +349,15 @@ static ssize_t gt_max_freq_mhz_store(struct device *kdev,
   DRM_DEBUG("User requested overclocking to %d\n",
      val * GT_FREQUENCY_MULTIPLIER);
 
+ dev_priv->rps.max_delay = val;
+
  if (dev_priv->rps.cur_delay > val) {
-  if (IS_VALLEYVIEW(dev_priv->dev))
-   valleyview_set_rps(dev_priv->dev, val);
+  if (IS_VALLEYVIEW(dev))
+   valleyview_set_rps(dev, val);
   else
-   gen6_set_rps(dev_priv->dev, val);
+   gen6_set_rps(dev, val);
  }
 
- dev_priv->rps.max_delay = val;
-
  mutex_unlock(&dev_priv->rps.hw_lock);
 
  return count;
@@ -367,7 +374,7 @@ static ssize_t gt_min_freq_mhz_show(struct device *kdev, struct device_attribute
 
  mutex_lock(&dev_priv->rps.hw_lock);
  if (IS_VALLEYVIEW(dev_priv->dev))
-  ret = vlv_gpu_freq(dev_priv->mem_freq, dev_priv->rps.min_delay);
+  ret = vlv_gpu_freq(dev_priv, dev_priv->rps.min_delay);
  else
   ret = dev_priv->rps.min_delay * GT_FREQUENCY_MULTIPLIER;
  mutex_unlock(&dev_priv->rps.hw_lock);
@@ -394,7 +401,7 @@ static ssize_t gt_min_freq_mhz_store(struct device *kdev,
  mutex_lock(&dev_priv->rps.hw_lock);
 
  if (IS_VALLEYVIEW(dev)) {
-  val = vlv_freq_opcode(dev_priv->mem_freq, val);
+  val = vlv_freq_opcode(dev_priv, val);
 
   hw_max = valleyview_rps_max_freq(dev_priv);
   hw_min = valleyview_rps_min_freq(dev_priv);
@@ -411,15 +418,15 @@ static ssize_t gt_min_freq_mhz_store(struct device *kdev,
   return -EINVAL;
  }
 
+ dev_priv->rps.min_delay = val;
+
  if (dev_priv->rps.cur_delay < val) {
   if (IS_VALLEYVIEW(dev))
    valleyview_set_rps(dev, val);
   else
-   gen6_set_rps(dev_priv->dev, val);
+   gen6_set_rps(dev, val);
  }
 
- dev_priv->rps.min_delay = val;
-
  mutex_unlock(&dev_priv->rps.hw_lock);
 
  return count;
@@ -449,7 +456,9 @@ static ssize_t gt_rp_mhz_show(struct device *kdev, struct device_attribute *attr
  ret = mutex_lock_interruptible(&dev->struct_mutex);
  if (ret)
   return ret;
+ intel_runtime_pm_get(dev_priv);
  rp_state_cap = I915_READ(GEN6_RP_STATE_CAP);
+ intel_runtime_pm_put(dev_priv);
  mutex_unlock(&dev->struct_mutex);
 
  if (attr == &dev_attr_gt_RP0_freq_mhz) {
diff --git a/drivers/gpu/drm/i915/i915_ums.c b/drivers/gpu/drm/i915/i915_ums.c
index 967da47..caa18e8 100644
--- a/drivers/gpu/drm/i915/i915_ums.c
+++ b/drivers/gpu/drm/i915/i915_ums.c
@@ -270,6 +270,18 @@ void i915_save_display_reg(struct drm_device *dev)
  }
  /* FIXME: regfile.save TV & SDVO state */
 
+ /* Backlight */
+ if (HAS_PCH_SPLIT(dev)) {
+  dev_priv->regfile.saveBLC_PWM_CTL = I915_READ(BLC_PWM_PCH_CTL1);
+  dev_priv->regfile.saveBLC_PWM_CTL2 = I915_READ(BLC_PWM_PCH_CTL2);
+  dev_priv->regfile.saveBLC_CPU_PWM_CTL = I915_READ(BLC_PWM_CPU_CTL);
+  dev_priv->regfile.saveBLC_CPU_PWM_CTL2 = I915_READ(BLC_PWM_CPU_CTL2);
+ } else {
+  dev_priv->regfile.saveBLC_PWM_CTL = I915_READ(BLC_PWM_CTL);
+  if (INTEL_INFO(dev)->gen >= 4)
+   dev_priv->regfile.saveBLC_PWM_CTL2 = I915_READ(BLC_PWM_CTL2);
+ }
+
  return;
 }
 
@@ -280,6 +292,21 @@ void i915_restore_display_reg(struct drm_device *dev)
  int dpll_b_reg, fpb0_reg, fpb1_reg;
  int i;
 
+ /* Backlight */
+ if (HAS_PCH_SPLIT(dev)) {
+  I915_WRITE(BLC_PWM_PCH_CTL1, dev_priv->regfile.saveBLC_PWM_CTL);
+  I915_WRITE(BLC_PWM_PCH_CTL2, dev_priv->regfile.saveBLC_PWM_CTL2);
+  /* NOTE: BLC_PWM_CPU_CTL must be written after BLC_PWM_CPU_CTL2;
+   * otherwise we get blank eDP screen after S3 on some machines
+   */
+  I915_WRITE(BLC_PWM_CPU_CTL2, dev_priv->regfile.saveBLC_CPU_PWM_CTL2);
+  I915_WRITE(BLC_PWM_CPU_CTL, dev_priv->regfile.saveBLC_CPU_PWM_CTL);
+ } else {
+  if (INTEL_INFO(dev)->gen >= 4)
+   I915_WRITE(BLC_PWM_CTL2, dev_priv->regfile.saveBLC_PWM_CTL2);
+  I915_WRITE(BLC_PWM_CTL, dev_priv->regfile.saveBLC_PWM_CTL);
+ }
+
  /* Display port ratios (must be done before clock is set) */
  if (SUPPORTS_INTEGRATED_DP(dev)) {
   I915_WRITE(_PIPEA_DATA_M_G4X, dev_priv->regfile.savePIPEA_GMCH_DATA_M);
diff --git a/drivers/gpu/drm/i915/intel_bios.c b/drivers/gpu/drm/i915/intel_bios.c
index e4fba39..f220419 100644
--- a/drivers/gpu/drm/i915/intel_bios.c
+++ b/drivers/gpu/drm/i915/intel_bios.c
@@ -281,6 +281,34 @@ parse_lfp_panel_data(struct drm_i915_private *dev_priv,
  }
 }
 
+static void
+parse_lfp_backlight(struct drm_i915_private *dev_priv, struct bdb_header *bdb)
+{
+ const struct bdb_lfp_backlight_data *backlight_data;
+ const struct bdb_lfp_backlight_data_entry *entry;
+
+ backlight_data = find_section(bdb, BDB_LVDS_BACKLIGHT);
+ if (!backlight_data)
+  return;
+
+ if (backlight_data->entry_size != sizeof(backlight_data->data[0])) {
+  DRM_DEBUG_KMS("Unsupported backlight data entry size %u\n",
+         backlight_data->entry_size);
+  return;
+ }
+
+ entry = &backlight_data->data[panel_type];
+
+ dev_priv->vbt.backlight.pwm_freq_hz = entry->pwm_freq_hz;
+ dev_priv->vbt.backlight.active_low_pwm = entry->active_low_pwm;
+ DRM_DEBUG_KMS("VBT backlight PWM modulation frequency %u Hz, "
+        "active %s, min brightness %u, level %u\n",
+        dev_priv->vbt.backlight.pwm_freq_hz,
+        dev_priv->vbt.backlight.active_low_pwm ? "low" : "high",
+        entry->min_brightness,
+        backlight_data->level[panel_type]);
+}
+
 /* Try to find sdvo panel data */
 static void
 parse_sdvo_panel_data(struct drm_i915_private *dev_priv,
@@ -327,12 +355,12 @@ static int intel_bios_ssc_frequency(struct drm_device *dev,
 {
  switch (INTEL_INFO(dev)->gen) {
  case 2:
-  return alternate ? 66 : 48;
+  return alternate ? 66667 : 48000;
  case 3:
  case 4:
-  return alternate ? 100 : 96;
+  return alternate ? 100000 : 96000;
  default:
-  return alternate ? 100 : 120;
+  return alternate ? 100000 : 120000;
  }
 }
 
@@ -796,7 +824,7 @@ init_vbt_defaults(struct drm_i915_private *dev_priv)
   */
  dev_priv->vbt.lvds_ssc_freq = intel_bios_ssc_frequency(dev,
    !HAS_PCH_SPLIT(dev));
- DRM_DEBUG_KMS("Set default to SSC at %dMHz\n", dev_priv->vbt.lvds_ssc_freq);
+ DRM_DEBUG_KMS("Set default to SSC at %d kHz\n", dev_priv->vbt.lvds_ssc_freq);
 
  for (port = PORT_A; port < I915_MAX_PORTS; port++) {
   struct ddi_vbt_port_info *info =
@@ -894,6 +922,7 @@ intel_parse_bios(struct drm_device *dev)
  parse_general_features(dev_priv, bdb);
  parse_general_definitions(dev_priv, bdb);
  parse_lfp_panel_data(dev_priv, bdb);
+ parse_lfp_backlight(dev_priv, bdb);
  parse_sdvo_panel_data(dev_priv, bdb);
  parse_sdvo_device_mapping(dev_priv, bdb);
  parse_device_mapping(dev_priv, bdb);
diff --git a/drivers/gpu/drm/i915/intel_bios.h b/drivers/gpu/drm/i915/intel_bios.h
index f580a2b..282de5e 100644
--- a/drivers/gpu/drm/i915/intel_bios.h
+++ b/drivers/gpu/drm/i915/intel_bios.h
@@ -39,7 +39,7 @@ struct vbt_header {
  u8 reserved0;
  u32 bdb_offset;   /**< from beginning of VBT */
  u32 aim_offset[4];  /**< from beginning of VBT */
-} __attribute__((packed));
+} __packed;
 
 struct bdb_header {
  u8 signature[16];  /**< Always 'BIOS_DATA_BLOCK' */
@@ -65,7 +65,7 @@ struct vbios_data {
  u8 rsvd4; /* popup memory size */
  u8 resize_pci_bios;
  u8 rsvd5; /* is crt already on ddc2 */
-} __attribute__((packed));
+} __packed;
 
 /*
  * There are several types of BIOS data blocks (BDBs), each block has
@@ -142,7 +142,7 @@ struct bdb_general_features {
  u8 dp_ssc_enb:1; /* PCH attached eDP supports SSC */
  u8 dp_ssc_freq:1; /* SSC freq for PCH attached eDP */
  u8 rsvd11:3; /* finish byte */
-} __attribute__((packed));
+} __packed;
 
 /* pre-915 */
 #define GPIO_PIN_DVI_LVDS 0x03 /* "DVI/LVDS DDC GPIO pins" */
@@ -225,7 +225,7 @@ struct old_child_dev_config {
  u8  dvo2_wiring;
  u16 extended_type;
  u8  dvo_function;
-} __attribute__((packed));
+} __packed;
 
 /* This one contains field offsets that are known to be common for all BDB
  * versions. Notice that the meaning of the contents contents may still change,
@@ -238,7 +238,7 @@ struct common_child_dev_config {
  u8 not_common2[2];
  u8 ddc_pin;
  u16 edid_ptr;
-} __attribute__((packed));
+} __packed;
 
 /* This field changes depending on the BDB version, so the most reliable way to
  * read it is by checking the BDB version and reading the raw pointer. */
@@ -279,7 +279,7 @@ struct bdb_general_definitions {
   *      sizeof(child_device_config);
   */
  union child_device_config devices[0];
-} __attribute__((packed));
+} __packed;
 
 struct bdb_lvds_options {
  u8 panel_type;
@@ -293,7 +293,7 @@ struct bdb_lvds_options {
  u8 lvds_edid:1;
  u8 rsvd2:1;
  u8 rsvd4;
-} __attribute__((packed));
+} __packed;
 
 /* LFP pointer table contains entries to the struct below */
 struct bdb_lvds_lfp_data_ptr {
@@ -303,12 +303,12 @@ struct bdb_lvds_lfp_data_ptr {
  u8 dvo_table_size;
  u16 panel_pnp_id_offset;
  u8 pnp_table_size;
-} __attribute__((packed));
+} __packed;
 
 struct bdb_lvds_lfp_data_ptrs {
  u8 lvds_entries; /* followed by one or more lvds_data_ptr structs */
  struct bdb_lvds_lfp_data_ptr ptr[16];
-} __attribute__((packed));
+} __packed;
 
 /* LFP data has 3 blocks per entry */
 struct lvds_fp_timing {
@@ -325,7 +325,7 @@ struct lvds_fp_timing {
  u32 pfit_reg;
  u32 pfit_reg_val;
  u16 terminator;
-} __attribute__((packed));
+} __packed;
 
 struct lvds_dvo_timing {
  u16 clock;  /**< In 10khz */
@@ -353,7 +353,7 @@ struct lvds_dvo_timing {
  u8 vsync_positive:1;
  u8 hsync_positive:1;
  u8 rsvd2:1;
-} __attribute__((packed));
+} __packed;
 
 struct lvds_pnp_id {
  u16 mfg_name;
@@ -361,17 +361,33 @@ struct lvds_pnp_id {
  u32 serial;
  u8 mfg_week;
  u8 mfg_year;
-} __attribute__((packed));
+} __packed;
 
 struct bdb_lvds_lfp_data_entry {
  struct lvds_fp_timing fp_timing;
  struct lvds_dvo_timing dvo_timing;
  struct lvds_pnp_id pnp_id;
-} __attribute__((packed));
+} __packed;
 
 struct bdb_lvds_lfp_data {
  struct bdb_lvds_lfp_data_entry data[16];
-} __attribute__((packed));
+} __packed;
+
+struct bdb_lfp_backlight_data_entry {
+ u8 type:2;
+ u8 active_low_pwm:1;
+ u8 obsolete1:5;
+ u16 pwm_freq_hz;
+ u8 min_brightness;
+ u8 obsolete2;
+ u8 obsolete3;
+} __packed;
+
+struct bdb_lfp_backlight_data {
+ u8 entry_size;
+ struct bdb_lfp_backlight_data_entry data[16];
+ u8 level[16];
+} __packed;
 
 struct aimdb_header {
  char signature[16];
@@ -379,12 +395,12 @@ struct aimdb_header {
  u16 aimdb_version;
  u16 aimdb_header_size;
  u16 aimdb_size;
-} __attribute__((packed));
+} __packed;
 
 struct aimdb_block {
  u8 aimdb_id;
  u16 aimdb_size;
-} __attribute__((packed));
+} __packed;
 
 struct vch_panel_data {
  u16 fp_timing_offset;
@@ -395,12 +411,12 @@ struct vch_panel_data {
  u8 text_fitting_size;
  u16 graphics_fitting_offset;
  u8 graphics_fitting_size;
-} __attribute__((packed));
+} __packed;
 
 struct vch_bdb_22 {
  struct aimdb_block aimdb_block;
  struct vch_panel_data panels[16];
-} __attribute__((packed));
+} __packed;
 
 struct bdb_sdvo_lvds_options {
  u8 panel_backlight;
@@ -416,7 +432,7 @@ struct bdb_sdvo_lvds_options {
  u8 panel_misc_bits_2;
  u8 panel_misc_bits_3;
  u8 panel_misc_bits_4;
-} __attribute__((packed));
+} __packed;
 
 
 #define BDB_DRIVER_FEATURE_NO_LVDS  0
@@ -462,7 +478,7 @@ struct bdb_driver_features {
 
  u8 hdmi_termination;
  u8 custom_vbt_version;
-} __attribute__((packed));
+} __packed;
 
 #define EDP_18BPP 0
 #define EDP_24BPP 1
@@ -487,14 +503,14 @@ struct edp_power_seq {
  u16 t9;
  u16 t10;
  u16 t11_t12;
-} __attribute__ ((packed));
+} __packed;
 
 struct edp_link_params {
  u8 rate:4;
  u8 lanes:4;
  u8 preemphasis:4;
  u8 vswing:4;
-} __attribute__ ((packed));
+} __packed;
 
 struct bdb_edp {
  struct edp_power_seq power_seqs[16];
@@ -505,7 +521,7 @@ struct bdb_edp {
  /* ith bit indicates enabled/disabled for (i+1)th panel */
  u16 edp_s3d_feature;
  u16 edp_t3_optimization;
-} __attribute__ ((packed));
+} __packed;
 
 void intel_setup_bios(struct drm_device *dev);
 int intel_parse_bios(struct drm_device *dev);
@@ -733,6 +749,6 @@ struct bdb_mipi {
  u32 hl_switch_cnt;
  u32 lp_byte_clk;
  u32 clk_lane_switch_cnt;
-} __attribute__((packed));
+} __packed;
 
 #endif /* _I830_BIOS_H_ */
diff --git a/drivers/gpu/drm/i915/intel_crt.c b/drivers/gpu/drm/i915/intel_crt.c
index b5b1b9b..e2e39e6 100644
--- a/drivers/gpu/drm/i915/intel_crt.c
+++ b/drivers/gpu/drm/i915/intel_crt.c
@@ -222,8 +222,9 @@ static void intel_crt_dpms(struct drm_connector *connector, int mode)
  intel_modeset_check_state(connector->dev);
 }
 
-static int intel_crt_mode_valid(struct drm_connector *connector,
-    struct drm_display_mode *mode)
+static enum drm_mode_status
+intel_crt_mode_valid(struct drm_connector *connector,
+       struct drm_display_mode *mode)
 {
  struct drm_device *dev = connector->dev;
 
diff --git a/drivers/gpu/drm/i915/intel_ddi.c b/drivers/gpu/drm/i915/intel_ddi.c
index b69dc3e..234ac5f 100644
--- a/drivers/gpu/drm/i915/intel_ddi.c
+++ b/drivers/gpu/drm/i915/intel_ddi.c
@@ -73,7 +73,7 @@ static const u32 hsw_ddi_translations_hdmi[] = {
 };
 
 static const u32 bdw_ddi_translations_edp[] = {
- 0x00FFFFFF, 0x00000012,  /* DP parameters */
+ 0x00FFFFFF, 0x00000012,  /* eDP parameters */
  0x00EBAFFF, 0x00020011,
  0x00C71FFF, 0x0006000F,
  0x00FFFFFF, 0x00020011,
@@ -696,25 +696,25 @@ intel_ddi_calculate_wrpll(int clock /* in Hz */,
  *n2_out = best.n2;
  *p_out = best.p;
  *r2_out = best.r2;
-
- DRM_DEBUG_KMS("WRPLL: %dHz refresh rate with p=%d, n2=%d r2=%d\n",
-        clock, *p_out, *n2_out, *r2_out);
 }
 
-bool intel_ddi_pll_mode_set(struct drm_crtc *crtc)
+/*
+ * Tries to find a PLL for the CRTC. If it finds, it increases the refcount and
+ * stores it in intel_crtc->ddi_pll_sel, so other mode sets won't be able to
+ * steal the selected PLL. You need to call intel_ddi_pll_enable to actually
+ * enable the PLL.
+ */
+bool intel_ddi_pll_select(struct intel_crtc *intel_crtc)
 {
- struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
+ struct drm_crtc *crtc = &intel_crtc->base;
  struct intel_encoder *intel_encoder = intel_ddi_get_crtc_encoder(crtc);
  struct drm_encoder *encoder = &intel_encoder->base;
  struct drm_i915_private *dev_priv = crtc->dev->dev_private;
  struct intel_ddi_plls *plls = &dev_priv->ddi_plls;
  int type = intel_encoder->type;
  enum pipe pipe = intel_crtc->pipe;
- uint32_t reg, val;
  int clock = intel_crtc->config.port_clock;
 
- /* TODO: reuse PLLs when possible (compare values) */
-
  intel_ddi_put_crtc_pll(crtc);
 
  if (type == INTEL_OUTPUT_DISPLAYPORT || type == INTEL_OUTPUT_EDP) {
@@ -736,66 +736,145 @@ bool intel_ddi_pll_mode_set(struct drm_crtc *crtc)
    return false;
   }
 
-  /* We don't need to turn any PLL on because we'll use LCPLL. */
-  return true;
-
  } else if (type == INTEL_OUTPUT_HDMI) {
+  uint32_t reg, val;
   unsigned p, n2, r2;
 
-  if (plls->wrpll1_refcount == 0) {
+  intel_ddi_calculate_wrpll(clock * 1000, &r2, &n2, &p);
+
+  val = WRPLL_PLL_ENABLE | WRPLL_PLL_SELECT_LCPLL_2700 |
+        WRPLL_DIVIDER_REFERENCE(r2) | WRPLL_DIVIDER_FEEDBACK(n2) |
+        WRPLL_DIVIDER_POST(p);
+
+  if (val == I915_READ(WRPLL_CTL1)) {
+   DRM_DEBUG_KMS("Reusing WRPLL 1 on pipe %c\n",
+          pipe_name(pipe));
+   reg = WRPLL_CTL1;
+  } else if (val == I915_READ(WRPLL_CTL2)) {
+   DRM_DEBUG_KMS("Reusing WRPLL 2 on pipe %c\n",
+          pipe_name(pipe));
+   reg = WRPLL_CTL2;
+  } else if (plls->wrpll1_refcount == 0) {
    DRM_DEBUG_KMS("Using WRPLL 1 on pipe %c\n",
           pipe_name(pipe));
-   plls->wrpll1_refcount++;
    reg = WRPLL_CTL1;
-   intel_crtc->ddi_pll_sel = PORT_CLK_SEL_WRPLL1;
   } else if (plls->wrpll2_refcount == 0) {
    DRM_DEBUG_KMS("Using WRPLL 2 on pipe %c\n",
           pipe_name(pipe));
-   plls->wrpll2_refcount++;
    reg = WRPLL_CTL2;
-   intel_crtc->ddi_pll_sel = PORT_CLK_SEL_WRPLL2;
   } else {
    DRM_ERROR("No WRPLLs available!\n");
    return false;
   }
 
-  WARN(I915_READ(reg) & WRPLL_PLL_ENABLE,
-       "WRPLL already enabled\n");
-
-  intel_ddi_calculate_wrpll(clock * 1000, &r2, &n2, &p);
+  DRM_DEBUG_KMS("WRPLL: %dKHz refresh rate with p=%d, n2=%d r2=%d\n",
+         clock, p, n2, r2);
 
-  val = WRPLL_PLL_ENABLE | WRPLL_PLL_SELECT_LCPLL_2700 |
-        WRPLL_DIVIDER_REFERENCE(r2) | WRPLL_DIVIDER_FEEDBACK(n2) |
-        WRPLL_DIVIDER_POST(p);
+  if (reg == WRPLL_CTL1) {
+   plls->wrpll1_refcount++;
+   intel_crtc->ddi_pll_sel = PORT_CLK_SEL_WRPLL1;
+  } else {
+   plls->wrpll2_refcount++;
+   intel_crtc->ddi_pll_sel = PORT_CLK_SEL_WRPLL2;
+  }
 
  } else if (type == INTEL_OUTPUT_ANALOG) {
   if (plls->spll_refcount == 0) {
    DRM_DEBUG_KMS("Using SPLL on pipe %c\n",
           pipe_name(pipe));
    plls->spll_refcount++;
-   reg = SPLL_CTL;
    intel_crtc->ddi_pll_sel = PORT_CLK_SEL_SPLL;
   } else {
    DRM_ERROR("SPLL already in use\n");
    return false;
   }
 
-  WARN(I915_READ(reg) & SPLL_PLL_ENABLE,
-       "SPLL already enabled\n");
-
-  val = SPLL_PLL_ENABLE | SPLL_PLL_FREQ_1350MHz | SPLL_PLL_SSC;
-
  } else {
   WARN(1, "Invalid DDI encoder type %d\n", type);
   return false;
  }
 
- I915_WRITE(reg, val);
- udelay(20);
-
  return true;
 }
 
+/*
+ * To be called after intel_ddi_pll_select(). That one selects the PLL to be
+ * used, this one actually enables the PLL.
+ */
+void intel_ddi_pll_enable(struct intel_crtc *crtc)
+{
+ struct drm_device *dev = crtc->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_ddi_plls *plls = &dev_priv->ddi_plls;
+ int clock = crtc->config.port_clock;
+ uint32_t reg, cur_val, new_val;
+ int refcount;
+ const char *pll_name;
+ uint32_t enable_bit = (1 << 31);
+ unsigned int p, n2, r2;
+
+ BUILD_BUG_ON(enable_bit != SPLL_PLL_ENABLE);
+ BUILD_BUG_ON(enable_bit != WRPLL_PLL_ENABLE);
+
+ switch (crtc->ddi_pll_sel) {
+ case PORT_CLK_SEL_LCPLL_2700:
+ case PORT_CLK_SEL_LCPLL_1350:
+ case PORT_CLK_SEL_LCPLL_810:
+  /*
+   * LCPLL should always be enabled at this point of the mode set
+   * sequence, so nothing to do.
+   */
+  return;
+
+ case PORT_CLK_SEL_SPLL:
+  pll_name = "SPLL";
+  reg = SPLL_CTL;
+  refcount = plls->spll_refcount;
+  new_val = SPLL_PLL_ENABLE | SPLL_PLL_FREQ_1350MHz |
+     SPLL_PLL_SSC;
+  break;
+
+ case PORT_CLK_SEL_WRPLL1:
+ case PORT_CLK_SEL_WRPLL2:
+  if (crtc->ddi_pll_sel == PORT_CLK_SEL_WRPLL1) {
+   pll_name = "WRPLL1";
+   reg = WRPLL_CTL1;
+   refcount = plls->wrpll1_refcount;
+  } else {
+   pll_name = "WRPLL2";
+   reg = WRPLL_CTL2;
+   refcount = plls->wrpll2_refcount;
+  }
+
+  intel_ddi_calculate_wrpll(clock * 1000, &r2, &n2, &p);
+
+  new_val = WRPLL_PLL_ENABLE | WRPLL_PLL_SELECT_LCPLL_2700 |
+     WRPLL_DIVIDER_REFERENCE(r2) |
+     WRPLL_DIVIDER_FEEDBACK(n2) | WRPLL_DIVIDER_POST(p);
+
+  break;
+
+ case PORT_CLK_SEL_NONE:
+  WARN(1, "Bad selected pll: PORT_CLK_SEL_NONE\n");
+  return;
+ default:
+  WARN(1, "Bad selected pll: 0x%08x\n", crtc->ddi_pll_sel);
+  return;
+ }
+
+ cur_val = I915_READ(reg);
+
+ WARN(refcount < 1, "Bad %s refcount: %d\n", pll_name, refcount);
+ if (refcount == 1) {
+  WARN(cur_val & enable_bit, "%s already enabled\n", pll_name);
+  I915_WRITE(reg, new_val);
+  POSTING_READ(reg);
+  udelay(20);
+ } else {
+  WARN((cur_val & enable_bit) == 0, "%s disabled\n", pll_name);
+ }
+}
+
 void intel_ddi_set_pipe_settings(struct drm_crtc *crtc)
 {
  struct drm_i915_private *dev_priv = crtc->dev->dev_private;
@@ -1121,9 +1200,7 @@ static void intel_ddi_pre_enable(struct intel_encoder *intel_encoder)
 
  if (type == INTEL_OUTPUT_EDP) {
   struct intel_dp *intel_dp = enc_to_intel_dp(encoder);
-  ironlake_edp_panel_vdd_on(intel_dp);
   ironlake_edp_panel_on(intel_dp);
-  ironlake_edp_panel_vdd_off(intel_dp, true);
  }
 
  WARN_ON(intel_crtc->ddi_pll_sel == PORT_CLK_SEL_NONE);
@@ -1166,8 +1243,8 @@ static void intel_ddi_post_disable(struct intel_encoder *intel_encoder)
 
  if (type == INTEL_OUTPUT_DISPLAYPORT || type == INTEL_OUTPUT_EDP) {
   struct intel_dp *intel_dp = enc_to_intel_dp(encoder);
-  ironlake_edp_panel_vdd_on(intel_dp);
   intel_dp_sink_dpms(intel_dp, DRM_MODE_DPMS_OFF);
+  ironlake_edp_panel_vdd_on(intel_dp);
   ironlake_edp_panel_off(intel_dp);
  }
 
diff --git a/drivers/gpu/drm/i915/intel_display.c b/drivers/gpu/drm/i915/intel_display.c
index 3c5ff7a..9b8a7c7 100644
--- a/drivers/gpu/drm/i915/intel_display.c
+++ b/drivers/gpu/drm/i915/intel_display.c
@@ -90,8 +90,8 @@ intel_fdi_link_freq(struct drm_device *dev)
 
 static const intel_limit_t intel_limits_i8xx_dac = {
  .dot = { .min = 25000, .max = 350000 },
- .vco = { .min = 930000, .max = 1400000 },
- .n = { .min = 3, .max = 16 },
+ .vco = { .min = 908000, .max = 1512000 },
+ .n = { .min = 2, .max = 16 },
  .m = { .min = 96, .max = 140 },
  .m1 = { .min = 18, .max = 26 },
  .m2 = { .min = 6, .max = 16 },
@@ -103,8 +103,8 @@ static const intel_limit_t intel_limits_i8xx_dac = {
 
 static const intel_limit_t intel_limits_i8xx_dvo = {
  .dot = { .min = 25000, .max = 350000 },
- .vco = { .min = 930000, .max = 1400000 },
- .n = { .min = 3, .max = 16 },
+ .vco = { .min = 908000, .max = 1512000 },
+ .n = { .min = 2, .max = 16 },
  .m = { .min = 96, .max = 140 },
  .m1 = { .min = 18, .max = 26 },
  .m2 = { .min = 6, .max = 16 },
@@ -116,8 +116,8 @@ static const intel_limit_t intel_limits_i8xx_dvo = {
 
 static const intel_limit_t intel_limits_i8xx_lvds = {
  .dot = { .min = 25000, .max = 350000 },
- .vco = { .min = 930000, .max = 1400000 },
- .n = { .min = 3, .max = 16 },
+ .vco = { .min = 908000, .max = 1512000 },
+ .n = { .min = 2, .max = 16 },
  .m = { .min = 96, .max = 140 },
  .m1 = { .min = 18, .max = 26 },
  .m2 = { .min = 6, .max = 16 },
@@ -329,6 +329,8 @@ static void vlv_clock(int refclk, intel_clock_t *clock)
 {
  clock->m = clock->m1 * clock->m2;
  clock->p = clock->p1 * clock->p2;
+ if (WARN_ON(clock->n == 0 || clock->p == 0))
+  return;
  clock->vco = DIV_ROUND_CLOSEST(refclk * clock->m, clock->n);
  clock->dot = DIV_ROUND_CLOSEST(clock->vco, clock->p);
 }
@@ -430,6 +432,8 @@ static void pineview_clock(int refclk, intel_clock_t *clock)
 {
  clock->m = clock->m2 + 2;
  clock->p = clock->p1 * clock->p2;
+ if (WARN_ON(clock->n == 0 || clock->p == 0))
+  return;
  clock->vco = DIV_ROUND_CLOSEST(refclk * clock->m, clock->n);
  clock->dot = DIV_ROUND_CLOSEST(clock->vco, clock->p);
 }
@@ -443,6 +447,8 @@ static void i9xx_clock(int refclk, intel_clock_t *clock)
 {
  clock->m = i9xx_dpll_compute_m(clock);
  clock->p = clock->p1 * clock->p2;
+ if (WARN_ON(clock->n + 2 == 0 || clock->p == 0))
+  return;
  clock->vco = DIV_ROUND_CLOSEST(refclk * clock->m, clock->n + 2);
  clock->dot = DIV_ROUND_CLOSEST(clock->vco, clock->p);
 }
@@ -748,10 +754,10 @@ enum transcoder intel_pipe_to_cpu_transcoder(struct drm_i915_private *dev_priv,
  return intel_crtc->config.cpu_transcoder;
 }
 
-static void ironlake_wait_for_vblank(struct drm_device *dev, int pipe)
+static void g4x_wait_for_vblank(struct drm_device *dev, int pipe)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
- u32 frame, frame_reg = PIPEFRAME(pipe);
+ u32 frame, frame_reg = PIPE_FRMCOUNT_GM45(pipe);
 
  frame = I915_READ(frame_reg);
 
@@ -772,8 +778,8 @@ void intel_wait_for_vblank(struct drm_device *dev, int pipe)
  struct drm_i915_private *dev_priv = dev->dev_private;
  int pipestat_reg = PIPESTAT(pipe);
 
- if (INTEL_INFO(dev)->gen >= 5) {
-  ironlake_wait_for_vblank(dev, pipe);
+ if (IS_G4X(dev) || INTEL_INFO(dev)->gen >= 5) {
+  g4x_wait_for_vblank(dev, pipe);
   return;
  }
 
@@ -1086,12 +1092,12 @@ static void assert_cursor(struct drm_i915_private *dev_priv,
  struct drm_device *dev = dev_priv->dev;
  bool cur_state;
 
- if (IS_IVYBRIDGE(dev) || IS_HASWELL(dev))
-  cur_state = I915_READ(CURCNTR_IVB(pipe)) & CURSOR_MODE;
- else if (IS_845G(dev) || IS_I865G(dev))
+ if (IS_845G(dev) || IS_I865G(dev))
   cur_state = I915_READ(_CURACNTR) & CURSOR_ENABLE;
- else
+ else if (INTEL_INFO(dev)->gen <= 6 || IS_VALLEYVIEW(dev))
   cur_state = I915_READ(CURCNTR(pipe)) & CURSOR_MODE;
+ else
+  cur_state = I915_READ(CURCNTR_IVB(pipe)) & CURSOR_MODE;
 
  WARN(cur_state != state,
       "cursor on pipe %c assertion failure (expected %s, current %s)\n",
@@ -1205,15 +1211,12 @@ static void assert_sprites_disabled(struct drm_i915_private *dev_priv,
  }
 }
 
-static void assert_pch_refclk_enabled(struct drm_i915_private *dev_priv)
+static void ibx_assert_pch_refclk_enabled(struct drm_i915_private *dev_priv)
 {
  u32 val;
  bool enabled;
 
- if (HAS_PCH_LPT(dev_priv->dev)) {
-  DRM_DEBUG_DRIVER("LPT does not has PCH refclk, skipping check\n");
-  return;
- }
+ WARN_ON(!(HAS_PCH_IBX(dev_priv->dev) || HAS_PCH_CPT(dev_priv->dev)));
 
  val = I915_READ(PCH_DREF_CONTROL);
  enabled = !!(val & (DREF_SSC_SOURCE_MASK | DREF_NONSPREAD_SOURCE_MASK |
@@ -1361,6 +1364,24 @@ static void intel_init_dpio(struct drm_device *dev)
  if (!IS_VALLEYVIEW(dev))
   return;
 
+ DPIO_PHY_IOSF_PORT(DPIO_PHY0) = IOSF_PORT_DPIO;
+}
+
+static void intel_reset_dpio(struct drm_device *dev)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+
+ if (!IS_VALLEYVIEW(dev))
+  return;
+
+ /*
+  * Enable the CRI clock source so we can get at the display and the
+  * reference clock for VGA hotplug / manual detection.
+  */
+ I915_WRITE(DPLL(PIPE_B), I915_READ(DPLL(PIPE_B)) |
+     DPLL_REFA_CLK_ENABLE_VLV |
+     DPLL_INTEGRATED_CRI_CLK_VLV);
+
  /*
   * From VLV2A0_DP_eDP_DPIO_driver_vbios_notes_10.docx -
   *  6. De-assert cmn_reset/side_reset. Same as VLV X0.
@@ -1487,25 +1508,35 @@ static void vlv_disable_pll(struct drm_i915_private *dev_priv, enum pipe pipe)
  /* Make sure the pipe isn't still relying on us */
  assert_pipe_disabled(dev_priv, pipe);
 
- /* Leave integrated clock source enabled */
+ /*
+  * Leave integrated clock source and reference clock enabled for pipe B.
+  * The latter is needed for VGA hotplug / manual detection.
+  */
  if (pipe == PIPE_B)
-  val = DPLL_INTEGRATED_CRI_CLK_VLV;
+  val = DPLL_INTEGRATED_CRI_CLK_VLV | DPLL_REFA_CLK_ENABLE_VLV;
  I915_WRITE(DPLL(pipe), val);
  POSTING_READ(DPLL(pipe));
 }
 
-void vlv_wait_port_ready(struct drm_i915_private *dev_priv, int port)
+void vlv_wait_port_ready(struct drm_i915_private *dev_priv,
+  struct intel_digital_port *dport)
 {
  u32 port_mask;
 
- if (!port)
+ switch (dport->port) {
+ case PORT_B:
   port_mask = DPLL_PORTB_READY_MASK;
- else
+  break;
+ case PORT_C:
   port_mask = DPLL_PORTC_READY_MASK;
+  break;
+ default:
+  BUG();
+ }
 
  if (wait_for((I915_READ(DPLL(0)) & port_mask) == 0, 1000))
   WARN(1, "timed out waiting for port %c ready: 0x%08x\n",
-       'B' + port, I915_READ(DPLL(0)));
+       port_name(dport->port), I915_READ(DPLL(0)));
 }
 
 /**
@@ -2083,8 +2114,8 @@ static int i9xx_update_plane(struct drm_crtc *crtc, struct drm_framebuffer *fb,
         fb->pitches[0]);
  I915_WRITE(DSPSTRIDE(plane), fb->pitches[0]);
  if (INTEL_INFO(dev)->gen >= 4) {
-  I915_MODIFY_DISPBASE(DSPSURF(plane),
-         i915_gem_obj_ggtt_offset(obj) + intel_crtc->dspaddr_offset);
+  I915_WRITE(DSPSURF(plane),
+      i915_gem_obj_ggtt_offset(obj) + intel_crtc->dspaddr_offset);
   I915_WRITE(DSPTILEOFF(plane), (y << 16) | x);
   I915_WRITE(DSPLINOFF(plane), linear_offset);
  } else
@@ -2174,8 +2205,8 @@ static int ironlake_update_plane(struct drm_crtc *crtc,
         i915_gem_obj_ggtt_offset(obj), linear_offset, x, y,
         fb->pitches[0]);
  I915_WRITE(DSPSTRIDE(plane), fb->pitches[0]);
- I915_MODIFY_DISPBASE(DSPSURF(plane),
-        i915_gem_obj_ggtt_offset(obj) + intel_crtc->dspaddr_offset);
+ I915_WRITE(DSPSURF(plane),
+     i915_gem_obj_ggtt_offset(obj) + intel_crtc->dspaddr_offset);
  if (IS_HASWELL(dev) || IS_BROADWELL(dev)) {
   I915_WRITE(DSPOFFSET(plane), (y << 16) | x);
  } else {
@@ -2233,7 +2264,12 @@ void intel_display_handle_reset(struct drm_device *dev)
   struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 
   mutex_lock(&crtc->mutex);
-  if (intel_crtc->active)
+  /*
+   * FIXME: Once we have proper support for primary planes (and
+   * disabling them without disabling the entire crtc) allow again
+   * a NULL crtc->fb.
+   */
+  if (intel_crtc->active && crtc->fb)
    dev_priv->display.update_plane(crtc, crtc->fb,
              crtc->x, crtc->y);
   mutex_unlock(&crtc->mutex);
@@ -2350,6 +2386,8 @@ intel_pipe_set_base(struct drm_crtc *crtc, int x, int y,
    I915_WRITE(PF_WIN_POS(intel_crtc->pipe), 0);
    I915_WRITE(PF_WIN_SZ(intel_crtc->pipe), 0);
   }
+  intel_crtc->config.pipe_src_w = adjusted_mode->crtc_hdisplay;
+  intel_crtc->config.pipe_src_h = adjusted_mode->crtc_vdisplay;
  }
 
  ret = dev_priv->display.update_plane(crtc, fb, x, y);
@@ -2944,6 +2982,30 @@ static bool intel_crtc_has_pending_flip(struct drm_crtc *crtc)
  return pending;
 }
 
+bool intel_has_pending_fb_unpin(struct drm_device *dev)
+{
+ struct intel_crtc *crtc;
+
+ /* Note that we don't need to be called with mode_config.lock here
+  * as our list of CRTC objects is static for the lifetime of the
+  * device and so cannot disappear as we iterate. Similarly, we can
+  * happily treat the predicates as racy, atomic checks as userspace
+  * cannot claim and pin a new fb without at least acquring the
+  * struct_mutex and so serialising with us.
+  */
+ list_for_each_entry(crtc, &dev->mode_config.crtc_list, base.head) {
+  if (atomic_read(&crtc->unpin_work_count) == 0)
+   continue;
+
+  if (crtc->unpin_work)
+   intel_wait_for_vblank(dev, crtc->pipe);
+
+  return true;
+ }
+
+ return false;
+}
+
 static void intel_crtc_wait_for_pending_flips(struct drm_crtc *crtc)
 {
  struct drm_device *dev = crtc->dev;
@@ -3399,9 +3461,8 @@ void hsw_enable_ips(struct intel_crtc *crtc)
   mutex_unlock(&dev_priv->rps.hw_lock);
   /* Quoting Art Runyan: "its not safe to expect any particular
    * value in IPS_CTL bit 31 after enabling IPS through the
-   * mailbox." Therefore we need to defer waiting on the state
-   * change.
-   * TODO: need to fix this for state checker
+   * mailbox." Moreover, the mailbox may return a bogus state,
+   * so we need to just enable it and continue on.
    */
  } else {
   I915_WRITE(IPS_CTL, IPS_ENABLE);
@@ -3428,9 +3489,10 @@ void hsw_disable_ips(struct intel_crtc *crtc)
   mutex_lock(&dev_priv->rps.hw_lock);
   WARN_ON(sandybridge_pcode_write(dev_priv, DISPLAY_IPS_CONTROL, 0));
   mutex_unlock(&dev_priv->rps.hw_lock);
- } else
+ } else {
   I915_WRITE(IPS_CTL, 0);
- POSTING_READ(IPS_CTL);
+  POSTING_READ(IPS_CTL);
+ }
 
  /* We need to wait for a vblank before we can disable the plane. */
  intel_wait_for_vblank(dev, crtc->pipe);
@@ -3465,7 +3527,7 @@ static void intel_crtc_load_lut(struct drm_crtc *crtc)
  /* Workaround : Do not read or write the pipe palette/gamma data while
   * GAMMA_MODE is configured for split gamma and IPS_CTL has IPS enabled.
   */
- if (intel_crtc->config.ips_enabled &&
+ if (IS_HASWELL(dev) && intel_crtc->config.ips_enabled &&
      ((I915_READ(GAMMA_MODE(pipe)) & GAMMA_MODE_MODE_MASK) ==
       GAMMA_MODE_MODE_SPLIT)) {
   hsw_disable_ips(intel_crtc);
@@ -3910,6 +3972,174 @@ static void i9xx_pfit_enable(struct intel_crtc *crtc)
  I915_WRITE(BCLRPAT(crtc->pipe), 0);
 }
 
+int valleyview_get_vco(struct drm_i915_private *dev_priv)
+{
+ int hpll_freq, vco_freq[] = { 800, 1600, 2000, 2400 };
+
+ /* Obtain SKU information */
+ mutex_lock(&dev_priv->dpio_lock);
+ hpll_freq = vlv_cck_read(dev_priv, CCK_FUSE_REG) &
+  CCK_FUSE_HPLL_FREQ_MASK;
+ mutex_unlock(&dev_priv->dpio_lock);
+
+ return vco_freq[hpll_freq];
+}
+
+/* Adjust CDclk dividers to allow high res or save power if possible */
+static void valleyview_set_cdclk(struct drm_device *dev, int cdclk)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ u32 val, cmd;
+
+ if (cdclk >= 320) /* jump to highest voltage for 400MHz too */
+  cmd = 2;
+ else if (cdclk == 266)
+  cmd = 1;
+ else
+  cmd = 0;
+
+ mutex_lock(&dev_priv->rps.hw_lock);
+ val = vlv_punit_read(dev_priv, PUNIT_REG_DSPFREQ);
+ val &= ~DSPFREQGUAR_MASK;
+ val |= (cmd << DSPFREQGUAR_SHIFT);
+ vlv_punit_write(dev_priv, PUNIT_REG_DSPFREQ, val);
+ if (wait_for((vlv_punit_read(dev_priv, PUNIT_REG_DSPFREQ) &
+        DSPFREQSTAT_MASK) == (cmd << DSPFREQSTAT_SHIFT),
+       50)) {
+  DRM_ERROR("timed out waiting for CDclk change\n");
+ }
+ mutex_unlock(&dev_priv->rps.hw_lock);
+
+ if (cdclk == 400) {
+  u32 divider, vco;
+
+  vco = valleyview_get_vco(dev_priv);
+  divider = ((vco << 1) / cdclk) - 1;
+
+  mutex_lock(&dev_priv->dpio_lock);
+  /* adjust cdclk divider */
+  val = vlv_cck_read(dev_priv, CCK_DISPLAY_CLOCK_CONTROL);
+  val &= ~0xf;
+  val |= divider;
+  vlv_cck_write(dev_priv, CCK_DISPLAY_CLOCK_CONTROL, val);
+  mutex_unlock(&dev_priv->dpio_lock);
+ }
+
+ mutex_lock(&dev_priv->dpio_lock);
+ /* adjust self-refresh exit latency value */
+ val = vlv_bunit_read(dev_priv, BUNIT_REG_BISOC);
+ val &= ~0x7f;
+
+ /*
+  * For high bandwidth configs, we set a higher latency in the bunit
+  * so that the core display fetch happens in time to avoid underruns.
+  */
+ if (cdclk == 400)
+  val |= 4500 / 250; /* 4.5 usec */
+ else
+  val |= 3000 / 250; /* 3.0 usec */
+ vlv_bunit_write(dev_priv, BUNIT_REG_BISOC, val);
+ mutex_unlock(&dev_priv->dpio_lock);
+
+ /* Since we changed the CDclk, we need to update the GMBUSFREQ too */
+ intel_i2c_reset(dev);
+}
+
+static int valleyview_cur_cdclk(struct drm_i915_private *dev_priv)
+{
+ int cur_cdclk, vco;
+ int divider;
+
+ vco = valleyview_get_vco(dev_priv);
+
+ mutex_lock(&dev_priv->dpio_lock);
+ divider = vlv_cck_read(dev_priv, CCK_DISPLAY_CLOCK_CONTROL);
+ mutex_unlock(&dev_priv->dpio_lock);
+
+ divider &= 0xf;
+
+ cur_cdclk = (vco << 1) / (divider + 1);
+
+ return cur_cdclk;
+}
+
+static int valleyview_calc_cdclk(struct drm_i915_private *dev_priv,
+     int max_pixclk)
+{
+ int cur_cdclk;
+
+ cur_cdclk = valleyview_cur_cdclk(dev_priv);
+
+ /*
+  * Really only a few cases to deal with, as only 4 CDclks are supported:
+  *   200MHz
+  *   267MHz
+  *   320MHz
+  *   400MHz
+  * So we check to see whether we're above 90% of the lower bin and
+  * adjust if needed.
+  */
+ if (max_pixclk > 288000) {
+  return 400;
+ } else if (max_pixclk > 240000) {
+  return 320;
+ } else
+  return 266;
+ /* Looks like the 200MHz CDclk freq doesn't work on some configs */
+}
+
+static int intel_mode_max_pixclk(struct drm_i915_private *dev_priv,
+     unsigned modeset_pipes,
+     struct intel_crtc_config *pipe_config)
+{
+ struct drm_device *dev = dev_priv->dev;
+ struct intel_crtc *intel_crtc;
+ int max_pixclk = 0;
+
+ list_for_each_entry(intel_crtc, &dev->mode_config.crtc_list,
+       base.head) {
+  if (modeset_pipes & (1 << intel_crtc->pipe))
+   max_pixclk = max(max_pixclk,
+      pipe_config->adjusted_mode.crtc_clock);
+  else if (intel_crtc->base.enabled)
+   max_pixclk = max(max_pixclk,
+      intel_crtc->config.adjusted_mode.crtc_clock);
+ }
+
+ return max_pixclk;
+}
+
+static void valleyview_modeset_global_pipes(struct drm_device *dev,
+         unsigned *prepare_pipes,
+         unsigned modeset_pipes,
+         struct intel_crtc_config *pipe_config)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_crtc *intel_crtc;
+ int max_pixclk = intel_mode_max_pixclk(dev_priv, modeset_pipes,
+            pipe_config);
+ int cur_cdclk = valleyview_cur_cdclk(dev_priv);
+
+ if (valleyview_calc_cdclk(dev_priv, max_pixclk) == cur_cdclk)
+  return;
+
+ list_for_each_entry(intel_crtc, &dev->mode_config.crtc_list,
+       base.head)
+  if (intel_crtc->base.enabled)
+   *prepare_pipes |= (1 << intel_crtc->pipe);
+}
+
+static void valleyview_modeset_global_resources(struct drm_device *dev)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ int max_pixclk = intel_mode_max_pixclk(dev_priv, 0, NULL);
+ int cur_cdclk = valleyview_cur_cdclk(dev_priv);
+ int req_cdclk = valleyview_calc_cdclk(dev_priv, max_pixclk);
+
+ if (req_cdclk != cur_cdclk)
+  valleyview_set_cdclk(dev, req_cdclk);
+}
+
 static void valleyview_crtc_enable(struct drm_crtc *crtc)
 {
  struct drm_device *dev = crtc->dev;
@@ -4570,9 +4800,8 @@ static int i9xx_get_refclk(struct drm_crtc *crtc, int num_connectors)
   refclk = 100000;
  } else if (intel_pipe_has_type(crtc, INTEL_OUTPUT_LVDS) &&
      intel_panel_use_ssc(dev_priv) && num_connectors < 2) {
-  refclk = dev_priv->vbt.lvds_ssc_freq * 1000;
-  DRM_DEBUG_KMS("using SSC reference clock of %d MHz\n",
-         refclk / 1000);
+  refclk = dev_priv->vbt.lvds_ssc_freq;
+  DRM_DEBUG_KMS("using SSC reference clock of %d kHz\n", refclk);
  } else if (!IS_GEN2(dev)) {
   refclk = 96000;
  } else {
@@ -4634,24 +4863,24 @@ static void vlv_pllb_recal_opamp(struct drm_i915_private *dev_priv, enum pipe
   * PLLB opamp always calibrates to max value of 0x3f, force enable it
   * and set it to a reasonable value instead.
   */
- reg_val = vlv_dpio_read(dev_priv, pipe, DPIO_IREF(1));
+ reg_val = vlv_dpio_read(dev_priv, pipe, VLV_PLL_DW9(1));
  reg_val &= 0xffffff00;
  reg_val |= 0x00000030;
- vlv_dpio_write(dev_priv, pipe, DPIO_IREF(1), reg_val);
+ vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW9(1), reg_val);
 
- reg_val = vlv_dpio_read(dev_priv, pipe, DPIO_CALIBRATION);
+ reg_val = vlv_dpio_read(dev_priv, pipe, VLV_REF_DW13);
  reg_val &= 0x8cffffff;
  reg_val = 0x8c000000;
- vlv_dpio_write(dev_priv, pipe, DPIO_CALIBRATION, reg_val);
+ vlv_dpio_write(dev_priv, pipe, VLV_REF_DW13, reg_val);
 
- reg_val = vlv_dpio_read(dev_priv, pipe, DPIO_IREF(1));
+ reg_val = vlv_dpio_read(dev_priv, pipe, VLV_PLL_DW9(1));
  reg_val &= 0xffffff00;
- vlv_dpio_write(dev_priv, pipe, DPIO_IREF(1), reg_val);
+ vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW9(1), reg_val);
 
- reg_val = vlv_dpio_read(dev_priv, pipe, DPIO_CALIBRATION);
+ reg_val = vlv_dpio_read(dev_priv, pipe, VLV_REF_DW13);
  reg_val &= 0x00ffffff;
  reg_val |= 0xb0000000;
- vlv_dpio_write(dev_priv, pipe, DPIO_CALIBRATION, reg_val);
+ vlv_dpio_write(dev_priv, pipe, VLV_REF_DW13, reg_val);
 }
 
 static void intel_pch_transcoder_set_m_n(struct intel_crtc *crtc,
@@ -4720,15 +4949,15 @@ static void vlv_update_pll(struct intel_crtc *crtc)
   vlv_pllb_recal_opamp(dev_priv, pipe);
 
  /* Set up Tx target for periodic Rcomp update */
- vlv_dpio_write(dev_priv, pipe, DPIO_IREF_BCAST, 0x0100000f);
+ vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW9_BCAST, 0x0100000f);
 
  /* Disable target IRef on PLL */
- reg_val = vlv_dpio_read(dev_priv, pipe, DPIO_IREF_CTL(pipe));
+ reg_val = vlv_dpio_read(dev_priv, pipe, VLV_PLL_DW8(pipe));
  reg_val &= 0x00ffffff;
- vlv_dpio_write(dev_priv, pipe, DPIO_IREF_CTL(pipe), reg_val);
+ vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW8(pipe), reg_val);
 
  /* Disable fast lock */
- vlv_dpio_write(dev_priv, pipe, DPIO_FASTCLK_DISABLE, 0x610);
+ vlv_dpio_write(dev_priv, pipe, VLV_CMN_DW0, 0x610);
 
  /* Set idtafcrecal before PLL is enabled */
  mdiv = ((bestm1 << DPIO_M1DIV_SHIFT) | (bestm2 & DPIO_M2DIV_MASK));
@@ -4742,50 +4971,54 @@ static void vlv_update_pll(struct intel_crtc *crtc)
   * Note: don't use the DAC post divider as it seems unstable.
   */
  mdiv |= (DPIO_POST_DIV_HDMIDP << DPIO_POST_DIV_SHIFT);
- vlv_dpio_write(dev_priv, pipe, DPIO_DIV(pipe), mdiv);
+ vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW3(pipe), mdiv);
 
  mdiv |= DPIO_ENABLE_CALIBRATION;
- vlv_dpio_write(dev_priv, pipe, DPIO_DIV(pipe), mdiv);
+ vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW3(pipe), mdiv);
 
  /* Set HBR and RBR LPF coefficients */
  if (crtc->config.port_clock == 162000 ||
      intel_pipe_has_type(&crtc->base, INTEL_OUTPUT_ANALOG) ||
      intel_pipe_has_type(&crtc->base, INTEL_OUTPUT_HDMI))
-  vlv_dpio_write(dev_priv, pipe, DPIO_LPF_COEFF(pipe),
+  vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW10(pipe),
      0x009f0003);
  else
-  vlv_dpio_write(dev_priv, pipe, DPIO_LPF_COEFF(pipe),
+  vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW10(pipe),
      0x00d0000f);
 
  if (intel_pipe_has_type(&crtc->base, INTEL_OUTPUT_EDP) ||
      intel_pipe_has_type(&crtc->base, INTEL_OUTPUT_DISPLAYPORT)) {
   /* Use SSC source */
   if (!pipe)
-   vlv_dpio_write(dev_priv, pipe, DPIO_REFSFR(pipe),
+   vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW5(pipe),
       0x0df40000);
   else
-   vlv_dpio_write(dev_priv, pipe, DPIO_REFSFR(pipe),
+   vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW5(pipe),
       0x0df70000);
  } else { /* HDMI or VGA */
   /* Use bend source */
   if (!pipe)
-   vlv_dpio_write(dev_priv, pipe, DPIO_REFSFR(pipe),
+   vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW5(pipe),
       0x0df70000);
   else
-   vlv_dpio_write(dev_priv, pipe, DPIO_REFSFR(pipe),
+   vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW5(pipe),
       0x0df40000);
  }
 
- coreclk = vlv_dpio_read(dev_priv, pipe, DPIO_CORE_CLK(pipe));
+ coreclk = vlv_dpio_read(dev_priv, pipe, VLV_PLL_DW7(pipe));
  coreclk = (coreclk & 0x0000ff00) | 0x01c00000;
  if (intel_pipe_has_type(&crtc->base, INTEL_OUTPUT_DISPLAYPORT) ||
      intel_pipe_has_type(&crtc->base, INTEL_OUTPUT_EDP))
   coreclk |= 0x01000000;
- vlv_dpio_write(dev_priv, pipe, DPIO_CORE_CLK(pipe), coreclk);
+ vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW7(pipe), coreclk);
 
- vlv_dpio_write(dev_priv, pipe, DPIO_PLL_CML(pipe), 0x87871000);
+ vlv_dpio_write(dev_priv, pipe, VLV_PLL_DW11(pipe), 0x87871000);
 
- /* Enable DPIO clock input */
+ /*
+  * Enable DPIO clock input. We should never disable the reference
+  * clock for pipe B, since VGA hotplug / manual detection depends
+  * on it.
+  */
  dpll = DPLL_EXT_BUFFER_ENABLE_VLV | DPLL_REFA_CLK_ENABLE_VLV |
   DPLL_VGA_MODE_DIS | DPLL_INTEGRATED_CLOCK_VLV;
  /* We should never disable this, set it here for state tracking */
@@ -5230,6 +5463,9 @@ static void i9xx_get_pfit_config(struct intel_crtc *crtc,
  struct drm_i915_private *dev_priv = dev->dev_private;
  uint32_t tmp;
 
+ if (INTEL_INFO(dev)->gen <= 3 && (IS_I830(dev) || !IS_MOBILE(dev)))
+  return;
+
  tmp = I915_READ(PFIT_CONTROL);
  if (!(tmp & PFIT_ENABLE))
   return;
@@ -5261,7 +5497,7 @@ static void vlv_crtc_clock_get(struct intel_crtc *crtc,
  int refclk = 100000;
 
  mutex_lock(&dev_priv->dpio_lock);
- mdiv = vlv_dpio_read(dev_priv, pipe, DPIO_DIV(pipe));
+ mdiv = vlv_dpio_read(dev_priv, pipe, VLV_PLL_DW3(pipe));
  mutex_unlock(&dev_priv->dpio_lock);
 
  clock.m1 = (mdiv >> DPIO_M1DIV_SHIFT) & 7;
@@ -5718,9 +5954,9 @@ static int ironlake_get_refclk(struct drm_crtc *crtc)
  }
 
  if (is_lvds && intel_panel_use_ssc(dev_priv) && num_connectors < 2) {
-  DRM_DEBUG_KMS("using SSC reference clock of %d MHz\n",
+  DRM_DEBUG_KMS("using SSC reference clock of %d kHz\n",
          dev_priv->vbt.lvds_ssc_freq);
-  return dev_priv->vbt.lvds_ssc_freq * 1000;
+  return dev_priv->vbt.lvds_ssc_freq;
  }
 
  return 120000;
@@ -5982,7 +6218,7 @@ static uint32_t ironlake_compute_dpll(struct intel_crtc *intel_crtc,
  factor = 21;
  if (is_lvds) {
   if ((intel_panel_use_ssc(dev_priv) &&
-       dev_priv->vbt.lvds_ssc_freq == 100) ||
+       dev_priv->vbt.lvds_ssc_freq == 100000) ||
       (HAS_PCH_IBX(dev) && intel_is_dual_link_lvds(dev)))
    factor = 25;
  } else if (intel_crtc->config.sdvo_tv_clock)
@@ -6323,7 +6559,7 @@ static void assert_can_disable_lcpll(struct drm_i915_private *dev_priv)
 
  spin_lock_irqsave(&dev_priv->irq_lock, irqflags);
  val = I915_READ(DEIMR);
- WARN((val & ~DE_PCH_EVENT_IVB) != val,
+ WARN((val | DE_PCH_EVENT_IVB) != 0xffffffff,
       "Unexpected DEIMR bits enabled: 0x%x\n", val);
  val = I915_READ(SDEIMR);
  WARN((val | SDE_HOTPLUG_MASK_CPT) != 0xffffffff,
@@ -6402,7 +6638,7 @@ static void hsw_restore_lcpll(struct drm_i915_private *dev_priv)
 
  /* Make sure we're not on PC8 state before disabling PC8, otherwise
   * we'll hang the machine! */
- gen6_gt_force_wake_get(dev_priv);
+ gen6_gt_force_wake_get(dev_priv, FORCEWAKE_ALL);
 
  if (val & LCPLL_POWER_DOWN_ALLOW) {
   val &= ~LCPLL_POWER_DOWN_ALLOW;
@@ -6436,7 +6672,7 @@ static void hsw_restore_lcpll(struct drm_i915_private *dev_priv)
    DRM_ERROR("Switching back to LCPLL failed\n");
  }
 
- gen6_gt_force_wake_put(dev_priv);
+ gen6_gt_force_wake_put(dev_priv, FORCEWAKE_ALL);
 }
 
 void hsw_enable_pc8_work(struct work_struct *__work)
@@ -6447,6 +6683,8 @@ void hsw_enable_pc8_work(struct work_struct *__work)
  struct drm_device *dev = dev_priv->dev;
  uint32_t val;
 
+ WARN_ON(!HAS_PC8(dev));
+
  if (dev_priv->pc8.enabled)
   return;
 
@@ -6463,6 +6701,8 @@ void hsw_enable_pc8_work(struct work_struct *__work)
  lpt_disable_clkout_dp(dev);
  hsw_pc8_disable_interrupts(dev);
  hsw_disable_lcpll(dev_priv, true, true);
+
+ intel_runtime_pm_put(dev_priv);
 }
 
 static void __hsw_enable_package_c8(struct drm_i915_private *dev_priv)
@@ -6492,12 +6732,16 @@ static void __hsw_disable_package_c8(struct drm_i915_private *dev_priv)
  if (dev_priv->pc8.disable_count != 1)
   return;
 
+ WARN_ON(!HAS_PC8(dev));
+
  cancel_delayed_work_sync(&dev_priv->pc8.enable_work);
  if (!dev_priv->pc8.enabled)
   return;
 
  DRM_DEBUG_KMS("Disabling package C8+\n");
 
+ intel_runtime_pm_get(dev_priv);
+
  hsw_restore_lcpll(dev_priv);
  hsw_pc8_restore_interrupts(dev);
  lpt_init_pch_refclk(dev);
@@ -6704,8 +6948,9 @@ static int haswell_crtc_mode_set(struct drm_crtc *crtc,
  int plane = intel_crtc->plane;
  int ret;
 
- if (!intel_ddi_pll_mode_set(crtc))
+ if (!intel_ddi_pll_select(intel_crtc))
   return -EINVAL;
+ intel_ddi_pll_enable(intel_crtc);
 
  if (intel_crtc->config.has_dp_encoder)
   intel_dp_set_m_n(intel_crtc);
@@ -6796,8 +7041,9 @@ static bool haswell_get_pipe_config(struct intel_crtc *crtc,
  if (intel_display_power_enabled(dev, pfit_domain))
   ironlake_get_pfit_config(crtc, pipe_config);
 
- pipe_config->ips_enabled = hsw_crtc_supports_ips(crtc) &&
-       (I915_READ(IPS_CTL) & IPS_ENABLE);
+ if (IS_HASWELL(dev))
+  pipe_config->ips_enabled = hsw_crtc_supports_ips(crtc) &&
+   (I915_READ(IPS_CTL) & IPS_ENABLE);
 
  pipe_config->pixel_multiplier = 1;
 
@@ -7689,7 +7935,7 @@ static int i9xx_pll_refclk(struct drm_device *dev,
  u32 dpll = pipe_config->dpll_hw_state.dpll;
 
  if ((dpll & PLL_REF_INPUT_MASK) == PLLB_REF_INPUT_SPREADSPECTRUMIN)
-  return dev_priv->vbt.lvds_ssc_freq * 1000;
+  return dev_priv->vbt.lvds_ssc_freq;
  else if (HAS_PCH_SPLIT(dev))
   return 120000;
  else if (!IS_GEN2(dev))
@@ -7752,12 +7998,17 @@ static void i9xx_crtc_clock_get(struct intel_crtc *crtc,
   else
    i9xx_clock(refclk, &clock);
  } else {
-  bool is_lvds = (pipe == 1) && (I915_READ(LVDS) & LVDS_PORT_EN);
+  u32 lvds = IS_I830(dev) ? 0 : I915_READ(LVDS);
+  bool is_lvds = (pipe == 1) && (lvds & LVDS_PORT_EN);
 
   if (is_lvds) {
    clock.p1 = ffs((dpll & DPLL_FPA01_P1_POST_DIV_MASK_I830_LVDS) >>
            DPLL_FPA01_P1_POST_DIV_SHIFT);
-   clock.p2 = 14;
+
+   if (lvds & LVDS_CLKB_POWER_UP)
+    clock.p2 = 7;
+   else
+    clock.p2 = 14;
   } else {
    if (dpll & PLL_P1_DIVIDE_BY_TWO)
     clock.p1 = 2;
@@ -8507,28 +8758,6 @@ static struct drm_crtc_helper_funcs intel_helper_funcs = {
  .load_lut = intel_crtc_load_lut,
 };
 
-static bool intel_encoder_crtc_ok(struct drm_encoder *encoder,
-      struct drm_crtc *crtc)
-{
- struct drm_device *dev;
- struct drm_crtc *tmp;
- int crtc_mask = 1;
-
- WARN(!crtc, "checking null crtc?\n");
-
- dev = crtc->dev;
-
- list_for_each_entry(tmp, &dev->mode_config.crtc_list, head) {
-  if (tmp == crtc)
-   break;
-  crtc_mask <<= 1;
- }
-
- if (encoder->possible_crtcs & crtc_mask)
-  return true;
- return false;
-}
-
 /**
  * intel_modeset_update_staged_output_state
  *
@@ -9136,7 +9365,9 @@ intel_pipe_config_compare(struct drm_device *dev,
   PIPE_CONF_CHECK_I(pch_pfit.size);
  }
 
- PIPE_CONF_CHECK_I(ips_enabled);
+ /* BDW+ don't expose a synchronous way to read the state */
+ if (IS_HASWELL(dev))
+  PIPE_CONF_CHECK_I(ips_enabled);
 
  PIPE_CONF_CHECK_I(double_wide);
 
@@ -9382,21 +9613,19 @@ static int __intel_set_mode(struct drm_crtc *crtc,
 {
  struct drm_device *dev = crtc->dev;
  drm_i915_private_t *dev_priv = dev->dev_private;
- struct drm_display_mode *saved_mode, *saved_hwmode;
+ struct drm_display_mode *saved_mode;
  struct intel_crtc_config *pipe_config = NULL;
  struct intel_crtc *intel_crtc;
  unsigned disable_pipes, prepare_pipes, modeset_pipes;
  int ret = 0;
 
- saved_mode = kcalloc(2, sizeof(*saved_mode), GFP_KERNEL);
+ saved_mode = kmalloc(sizeof(*saved_mode), GFP_KERNEL);
  if (!saved_mode)
   return -ENOMEM;
- saved_hwmode = saved_mode + 1;
 
  intel_modeset_affected_pipes(crtc, &modeset_pipes,
          &prepare_pipes, &disable_pipes);
 
- *saved_hwmode = crtc->hwmode;
  *saved_mode = crtc->mode;
 
  /* Hack: Because we don't (yet) support global modeset on multiple
@@ -9416,6 +9645,21 @@ static int __intel_set_mode(struct drm_crtc *crtc,
            "[modeset]");
  }
 
+ /*
+  * See if the config requires any additional preparation, e.g.
+  * to adjust global state with pipes off.  We need to do this
+  * here so we can get the modeset_pipe updated config for the new
+  * mode set on this crtc.  For other crtcs we need to use the
+  * adjusted_mode bits in the crtc directly.
+  */
+ if (IS_VALLEYVIEW(dev)) {
+  valleyview_modeset_global_pipes(dev, &prepare_pipes,
+      modeset_pipes, pipe_config);
+
+  /* may have added more to prepare_pipes than we should */
+  prepare_pipes &= ~disable_pipes;
+ }
+
  for_each_intel_crtc_masked(dev, disable_pipes, intel_crtc)
   intel_crtc_disable(&intel_crtc->base);
 
@@ -9432,6 +9676,14 @@ static int __intel_set_mode(struct drm_crtc *crtc,
   /* mode_set/enable/disable functions rely on a correct pipe
    * config. */
   to_intel_crtc(crtc)->config = *pipe_config;
+
+  /*
+   * Calculate and store various constants which
+   * are later needed by vblank and swap-completion
+   * timestamping. They are derived from true hwmode.
+   */
+  drm_calc_timestamping_constants(crtc,
+      &pipe_config->adjusted_mode);
  }
 
  /* Only after disabling all output pipelines that will be changed can we
@@ -9455,23 +9707,10 @@ static int __intel_set_mode(struct drm_crtc *crtc,
  for_each_intel_crtc_masked(dev, prepare_pipes, intel_crtc)
   dev_priv->display.crtc_enable(&intel_crtc->base);
 
- if (modeset_pipes) {
-  /* Store real post-adjustment hardware mode. */
-  crtc->hwmode = pipe_config->adjusted_mode;
-
-  /* Calculate and store various constants which
-   * are later needed by vblank and swap-completion
-   * timestamping. They are derived from true hwmode.
-   */
-  drm_calc_timestamping_constants(crtc);
- }
-
  /* FIXME: add subpixel order */
 done:
- if (ret && crtc->enabled) {
-  crtc->hwmode = *saved_hwmode;
+ if (ret && crtc->enabled)
   crtc->mode = *saved_mode;
- }
 
 out:
  kfree(pipe_config);
@@ -9693,8 +9932,8 @@ intel_modeset_stage_output_state(struct drm_device *dev,
   }
 
   /* Make sure the new CRTC will work with the encoder */
-  if (!intel_encoder_crtc_ok(&connector->new_encoder->base,
-        new_crtc)) {
+  if (!drm_encoder_crtc_ok(&connector->new_encoder->base,
+      new_crtc)) {
    return -EINVAL;
   }
   connector->encoder->new_crtc = to_intel_crtc(new_crtc);
@@ -9708,17 +9947,21 @@ intel_modeset_stage_output_state(struct drm_device *dev,
  /* Check for any encoders that needs to be disabled. */
  list_for_each_entry(encoder, &dev->mode_config.encoder_list,
        base.head) {
+  int num_connectors = 0;
   list_for_each_entry(connector,
         &dev->mode_config.connector_list,
         base.head) {
    if (connector->new_encoder == encoder) {
     WARN_ON(!connector->new_encoder->new_crtc);
-
-    goto next_encoder;
+    num_connectors++;
    }
   }
-  encoder->new_crtc = NULL;
-next_encoder:
+
+  if (num_connectors == 0)
+   encoder->new_crtc = NULL;
+  else if (num_connectors > 1)
+   return -EINVAL;
+
   /* Only now check for crtc changes so we don't miss encoders
    * that will be disabled. */
   if (&encoder->new_crtc->base != encoder->base.crtc) {
@@ -9789,6 +10032,16 @@ static int intel_crtc_set_config(struct drm_mode_set *set)
 
   ret = intel_pipe_set_base(set->crtc,
        set->x, set->y, set->fb);
+  /*
+   * In the fastboot case this may be our only check of the
+   * state after boot.  It would be better to only do it on
+   * the first update, but we don't have a nice way of doing that
+   * (and really, set_config isn't used much for high freq page
+   * flipping, so increasing its cost here shouldn't be a big
+   * deal).
+   */
+  if (i915_fastboot && ret == 0)
+   intel_modeset_check_state(set->crtc->dev);
  }
 
  if (ret) {
@@ -9849,7 +10102,7 @@ static void ibx_pch_dpll_enable(struct drm_i915_private *dev_priv,
     struct intel_shared_dpll *pll)
 {
  /* PCH refclock must be enabled first */
- assert_pch_refclk_enabled(dev_priv);
+ ibx_assert_pch_refclk_enabled(dev_priv);
 
  I915_WRITE(PCH_DPLL(pll->id), pll->hw_state.dpll);
 
@@ -9917,8 +10170,6 @@ static void intel_shared_dpll_init(struct drm_device *dev)
   dev_priv->num_shared_dpll = 0;
 
  BUG_ON(dev_priv->num_shared_dpll > I915_NUM_PLLS);
- DRM_DEBUG_KMS("%i shared PLLs initialized\n",
-        dev_priv->num_shared_dpll);
 }
 
 static void intel_crtc_init(struct drm_device *dev, int pipe)
@@ -9940,10 +10191,13 @@ static void intel_crtc_init(struct drm_device *dev, int pipe)
   intel_crtc->lut_b[i] = i;
  }
 
- /* Swap pipes & planes for FBC on pre-965 */
+ /*
+  * On gen2/3 only plane A can do fbc, but the panel fitter and lvds port
+  * is hooked to plane B. Hence we want plane A feeding pipe B.
+  */
  intel_crtc->pipe = pipe;
  intel_crtc->plane = pipe;
- if (IS_MOBILE(dev) && IS_GEN3(dev)) {
+ if (HAS_FBC(dev) && INTEL_INFO(dev)->gen < 4) {
   DRM_DEBUG_KMS("swapping pipes & planes for FBC\n");
   intel_crtc->plane = !pipe;
  }
@@ -10032,6 +10286,28 @@ static bool has_edp_a(struct drm_device *dev)
  return true;
 }
 
+const char *intel_output_name(int output)
+{
+ static const char *names[] = {
+  [INTEL_OUTPUT_UNUSED] = "Unused",
+  [INTEL_OUTPUT_ANALOG] = "Analog",
+  [INTEL_OUTPUT_DVO] = "DVO",
+  [INTEL_OUTPUT_SDVO] = "SDVO",
+  [INTEL_OUTPUT_LVDS] = "LVDS",
+  [INTEL_OUTPUT_TVOUT] = "TV",
+  [INTEL_OUTPUT_HDMI] = "HDMI",
+  [INTEL_OUTPUT_DISPLAYPORT] = "DisplayPort",
+  [INTEL_OUTPUT_EDP] = "eDP",
+  [INTEL_OUTPUT_DSI] = "DSI",
+  [INTEL_OUTPUT_UNKNOWN] = "Unknown",
+ };
+
+ if (output < 0 || output >= ARRAY_SIZE(names) || !names[output])
+  return "Invalid";
+
+ return names[output];
+}
+
 static void intel_setup_outputs(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
@@ -10426,8 +10702,11 @@ static void intel_init_display(struct drm_device *dev)
   }
  } else if (IS_G4X(dev)) {
   dev_priv->display.write_eld = g4x_write_eld;
- } else if (IS_VALLEYVIEW(dev))
+ } else if (IS_VALLEYVIEW(dev)) {
+  dev_priv->display.modeset_global_resources =
+   valleyview_modeset_global_resources;
   dev_priv->display.write_eld = ironlake_write_eld;
+ }
 
  /* Default just returns -ENODEV to indicate unsupported */
  dev_priv->display.queue_flip = intel_default_queue_flip;
@@ -10454,6 +10733,8 @@ static void intel_init_display(struct drm_device *dev)
   dev_priv->display.queue_flip = intel_gen7_queue_flip;
   break;
  }
+
+ intel_panel_init_backlight_funcs(dev);
 }
 
 /*
@@ -10490,17 +10771,6 @@ static void quirk_invert_brightness(struct drm_device *dev)
  DRM_INFO("applying inverted panel brightness quirk\n");
 }
 
-/*
- * Some machines (Dell XPS13) suffer broken backlight controls if
- * BLM_PCH_PWM_ENABLE is set.
- */
-static void quirk_no_pcm_pwm_enable(struct drm_device *dev)
-{
- struct drm_i915_private *dev_priv = dev->dev_private;
- dev_priv->quirks |= QUIRK_NO_PCH_PWM_ENABLE;
- DRM_INFO("applying no-PCH_PWM_ENABLE quirk\n");
-}
-
 struct intel_quirk {
  int device;
  int subsystem_vendor;
@@ -10569,11 +10839,6 @@ static struct intel_quirk intel_quirks[] = {
 
  /* Acer Aspire 4736Z */
  { 0x2a42, 0x1025, 0x0260, quirk_invert_brightness },
-
- /* Dell XPS13 HD Sandy Bridge */
- { 0x0116, 0x1028, 0x052e, quirk_no_pcm_pwm_enable },
- /* Dell XPS13 HD and XPS13 FHD Ivy Bridge */
- { 0x0166, 0x1028, 0x058b, quirk_no_pcm_pwm_enable },
 };
 
 static void intel_init_quirks(struct drm_device *dev)
@@ -10617,18 +10882,11 @@ static void i915_disable_vga(struct drm_device *dev)
 
 void intel_modeset_init_hw(struct drm_device *dev)
 {
- struct drm_i915_private *dev_priv = dev->dev_private;
-
  intel_prepare_ddi(dev);
 
  intel_init_clock_gating(dev);
 
- /* Enable the CRI clock source so we can get at the display */
- if (IS_VALLEYVIEW(dev))
-  I915_WRITE(DPLL(PIPE_B), I915_READ(DPLL(PIPE_B)) |
-      DPLL_INTEGRATED_CRI_CLK_VLV);
-
- intel_init_dpio(dev);
+ intel_reset_dpio(dev);
 
  mutex_lock(&dev->struct_mutex);
  intel_enable_gt_powersave(dev);
@@ -10690,6 +10948,9 @@ void intel_modeset_init(struct drm_device *dev)
   }
  }
 
+ intel_init_dpio(dev);
+ intel_reset_dpio(dev);
+
  intel_cpu_pll_init(dev);
  intel_shared_dpll_init(dev);
 
@@ -10893,7 +11154,7 @@ void i915_redisable_vga(struct drm_device *dev)
   * level, just check if the power well is enabled instead of trying to
   * follow the "don't touch the power well if we don't need it" policy
   * the rest of the driver uses. */
- if (HAS_POWER_WELL(dev) &&
+ if ((IS_HASWELL(dev) || IS_BROADWELL(dev)) &&
      (I915_READ(HSW_PWR_WELL_DRIVER) & HSW_PWR_WELL_STATE_ENABLED) == 0)
   return;
 
@@ -11037,7 +11298,7 @@ void intel_modeset_setup_hw_state(struct drm_device *dev,
   pll->on = false;
  }
 
- if (IS_HASWELL(dev))
+ if (HAS_PCH_SPLIT(dev))
   ilk_wm_get_hw_state(dev);
 
  if (force_restore) {
@@ -11115,12 +11376,11 @@ void intel_modeset_cleanup(struct drm_device *dev)
  /* flush any delayed tasks or pending work */
  flush_scheduled_work();
 
- /* destroy backlight, if any, before the connectors */
- intel_panel_destroy_backlight(dev);
-
- /* destroy the sysfs files before encoders/connectors */
- list_for_each_entry(connector, &dev->mode_config.connector_list, head)
+ /* destroy the backlight and sysfs files before encoders/connectors */
+ list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
+  intel_panel_destroy_backlight(connector);
   drm_sysfs_connector_remove(connector);
+ }
 
  drm_mode_config_cleanup(dev);
 
@@ -11175,6 +11435,7 @@ struct intel_display_error_state {
  } cursor[I915_MAX_PIPES];
 
  struct intel_pipe_error_state {
+  bool power_domain_on;
   u32 source;
  } pipe[I915_MAX_PIPES];
 
@@ -11189,6 +11450,7 @@ struct intel_display_error_state {
  } plane[I915_MAX_PIPES];
 
  struct intel_transcoder_error_state {
+  bool power_domain_on;
   enum transcoder cpu_transcoder;
 
   u32 conf;
@@ -11222,11 +11484,13 @@ intel_display_capture_error_state(struct drm_device *dev)
  if (error == NULL)
   return NULL;
 
- if (HAS_POWER_WELL(dev))
+ if (IS_HASWELL(dev) || IS_BROADWELL(dev))
   error->power_well_driver = I915_READ(HSW_PWR_WELL_DRIVER);
 
  for_each_pipe(i) {
-  if (!intel_display_power_enabled(dev, POWER_DOMAIN_PIPE(i)))
+  error->pipe[i].power_domain_on =
+   intel_display_power_enabled_sw(dev, POWER_DOMAIN_PIPE(i));
+  if (!error->pipe[i].power_domain_on)
    continue;
 
   if (INTEL_INFO(dev)->gen <= 6 || IS_VALLEYVIEW(dev)) {
@@ -11262,8 +11526,10 @@ intel_display_capture_error_state(struct drm_device *dev)
  for (i = 0; i < error->num_transcoders; i++) {
   enum transcoder cpu_transcoder = transcoders[i];
 
-  if (!intel_display_power_enabled(dev,
-    POWER_DOMAIN_TRANSCODER(cpu_transcoder)))
+  error->transcoder[i].power_domain_on =
+   intel_display_power_enabled_sw(dev,
+    POWER_DOMAIN_TRANSCODER(cpu_transcoder));
+  if (!error->transcoder[i].power_domain_on)
    continue;
 
   error->transcoder[i].cpu_transcoder = cpu_transcoder;
@@ -11293,11 +11559,13 @@ intel_display_print_error_state(struct drm_i915_error_state_buf *m,
   return;
 
  err_printf(m, "Num Pipes: %d\n", INTEL_INFO(dev)->num_pipes);
- if (HAS_POWER_WELL(dev))
+ if (IS_HASWELL(dev) || IS_BROADWELL(dev))
   err_printf(m, "PWR_WELL_CTL2: %08x\n",
       error->power_well_driver);
  for_each_pipe(i) {
   err_printf(m, "Pipe [%d]:\n", i);
+  err_printf(m, "  Power: %s\n",
+      error->pipe[i].power_domain_on ? "on" : "off");
   err_printf(m, "  SRC: %08x\n", error->pipe[i].source);
 
   err_printf(m, "Plane [%d]:\n", i);
@@ -11323,6 +11591,8 @@ intel_display_print_error_state(struct drm_i915_error_state_buf *m,
  for (i = 0; i < error->num_transcoders; i++) {
   err_printf(m, "CPU transcoder: %c\n",
       transcoder_name(error->transcoder[i].cpu_transcoder));
+  err_printf(m, "  Power: %s\n",
+      error->transcoder[i].power_domain_on ? "on" : "off");
   err_printf(m, "  CONF: %08x\n", error->transcoder[i].conf);
   err_printf(m, "  HTOTAL: %08x\n", error->transcoder[i].htotal);
   err_printf(m, "  HBLANK: %08x\n", error->transcoder[i].hblank);
diff --git a/drivers/gpu/drm/i915/intel_dp.c b/drivers/gpu/drm/i915/intel_dp.c
index 6b50a14..2688f6d 100644
--- a/drivers/gpu/drm/i915/intel_dp.c
+++ b/drivers/gpu/drm/i915/intel_dp.c
@@ -142,7 +142,7 @@ intel_dp_max_data_rate(int max_link_clock, int max_lanes)
  return (max_link_clock * max_lanes * 8) / 10;
 }
 
-static int
+static enum drm_mode_status
 intel_dp_mode_valid(struct drm_connector *connector,
       struct drm_display_mode *mode)
 {
@@ -404,7 +404,7 @@ intel_dp_aux_ch(struct intel_dp *intel_dp,
  int i, ret, recv_bytes;
  uint32_t status;
  int try, precharge, clock = 0;
- bool has_aux_irq = INTEL_INFO(dev)->gen >= 5 && !IS_VALLEYVIEW(dev);
+ bool has_aux_irq = HAS_AUX_IRQ(dev);
  uint32_t timeout;
 
  /* dp aux is extremely sensitive to irq latency, hence request the
@@ -543,7 +543,7 @@ intel_dp_aux_native_write(struct intel_dp *intel_dp,
   return -E2BIG;
 
  intel_dp_check_edp(intel_dp);
- msg[0] = AUX_NATIVE_WRITE << 4;
+ msg[0] = DP_AUX_NATIVE_WRITE << 4;
  msg[1] = address >> 8;
  msg[2] = address & 0xff;
  msg[3] = send_bytes - 1;
@@ -553,9 +553,10 @@ intel_dp_aux_native_write(struct intel_dp *intel_dp,
   ret = intel_dp_aux_ch(intel_dp, msg, msg_bytes, &ack, 1);
   if (ret < 0)
    return ret;
-  if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_ACK)
+  ack >>= 4;
+  if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_ACK)
    return send_bytes;
-  else if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_DEFER)
+  else if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_DEFER)
    usleep_range(400, 500);
   else
    return -EIO;
@@ -590,7 +591,7 @@ intel_dp_aux_native_read(struct intel_dp *intel_dp,
   return -E2BIG;
 
  intel_dp_check_edp(intel_dp);
- msg[0] = AUX_NATIVE_READ << 4;
+ msg[0] = DP_AUX_NATIVE_READ << 4;
  msg[1] = address >> 8;
  msg[2] = address & 0xff;
  msg[3] = recv_bytes - 1;
@@ -605,12 +606,12 @@ intel_dp_aux_native_read(struct intel_dp *intel_dp,
    return -EPROTO;
   if (ret < 0)
    return ret;
-  ack = reply[0];
-  if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_ACK) {
+  ack = reply[0] >> 4;
+  if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_ACK) {
    memcpy(recv, reply + 1, ret - 1);
    return ret - 1;
   }
-  else if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_DEFER)
+  else if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_DEFER)
    usleep_range(400, 500);
   else
    return -EIO;
@@ -640,12 +641,12 @@ intel_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
  intel_dp_check_edp(intel_dp);
  /* Set up the command byte */
  if (mode & MODE_I2C_READ)
-  msg[0] = AUX_I2C_READ << 4;
+  msg[0] = DP_AUX_I2C_READ << 4;
  else
-  msg[0] = AUX_I2C_WRITE << 4;
+  msg[0] = DP_AUX_I2C_WRITE << 4;
 
  if (!(mode & MODE_I2C_STOP))
-  msg[0] |= AUX_I2C_MOT << 4;
+  msg[0] |= DP_AUX_I2C_MOT << 4;
 
  msg[1] = address >> 8;
  msg[2] = address;
@@ -682,17 +683,17 @@ intel_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
    goto out;
   }
 
-  switch (reply[0] & AUX_NATIVE_REPLY_MASK) {
-  case AUX_NATIVE_REPLY_ACK:
+  switch ((reply[0] >> 4) & DP_AUX_NATIVE_REPLY_MASK) {
+  case DP_AUX_NATIVE_REPLY_ACK:
    /* I2C-over-AUX Reply field is only valid
     * when paired with AUX ACK.
     */
    break;
-  case AUX_NATIVE_REPLY_NACK:
+  case DP_AUX_NATIVE_REPLY_NACK:
    DRM_DEBUG_KMS("aux_ch native nack\n");
    ret = -EREMOTEIO;
    goto out;
-  case AUX_NATIVE_REPLY_DEFER:
+  case DP_AUX_NATIVE_REPLY_DEFER:
    /*
     * For now, just give more slack to branch devices. We
     * could check the DPCD for I2C bit rate capabilities,
@@ -713,18 +714,18 @@ intel_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
    goto out;
   }
 
-  switch (reply[0] & AUX_I2C_REPLY_MASK) {
-  case AUX_I2C_REPLY_ACK:
+  switch ((reply[0] >> 4) & DP_AUX_I2C_REPLY_MASK) {
+  case DP_AUX_I2C_REPLY_ACK:
    if (mode == MODE_I2C_READ) {
     *read_byte = reply[1];
    }
    ret = reply_bytes - 1;
    goto out;
-  case AUX_I2C_REPLY_NACK:
+  case DP_AUX_I2C_REPLY_NACK:
    DRM_DEBUG_KMS("aux_i2c nack\n");
    ret = -EREMOTEIO;
    goto out;
-  case AUX_I2C_REPLY_DEFER:
+  case DP_AUX_I2C_REPLY_DEFER:
    DRM_DEBUG_KMS("aux_i2c defer\n");
    udelay(100);
    break;
@@ -1044,6 +1045,8 @@ static void ironlake_wait_panel_status(struct intel_dp *intel_dp,
     I915_READ(pp_stat_reg),
     I915_READ(pp_ctrl_reg));
  }
+
+ DRM_DEBUG_KMS("Wait complete\n");
 }
 
 static void ironlake_wait_panel_on(struct intel_dp *intel_dp)
@@ -1099,6 +1102,8 @@ void ironlake_edp_panel_vdd_on(struct intel_dp *intel_dp)
  if (ironlake_edp_have_panel_vdd(intel_dp))
   return;
 
+ intel_runtime_pm_get(dev_priv);
+
  DRM_DEBUG_KMS("Turning eDP VDD on\n");
 
  if (!ironlake_edp_have_panel_power(intel_dp))
@@ -1147,7 +1152,11 @@ static void ironlake_panel_vdd_off_sync(struct intel_dp *intel_dp)
   /* Make sure sequencer is idle before allowing subsequent activity */
   DRM_DEBUG_KMS("PP_STATUS: 0x%08x PP_CONTROL: 0x%08x\n",
   I915_READ(pp_stat_reg), I915_READ(pp_ctrl_reg));
-  msleep(intel_dp->panel_power_down_delay);
+
+  if ((pp & POWER_TARGET_ON) == 0)
+   msleep(intel_dp->panel_power_cycle_delay);
+
+  intel_runtime_pm_put(dev_priv);
  }
 }
 
@@ -1255,6 +1264,9 @@ void ironlake_edp_panel_off(struct intel_dp *intel_dp)
  intel_dp->want_panel_vdd = false;
 
  ironlake_wait_panel_off(intel_dp);
+
+ /* We got a reference when we enabled the VDD. */
+ intel_runtime_pm_put(dev_priv);
 }
 
 void ironlake_edp_backlight_on(struct intel_dp *intel_dp)
@@ -1852,23 +1864,23 @@ static void vlv_pre_enable_dp(struct intel_encoder *encoder)
  struct drm_device *dev = encoder->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc = to_intel_crtc(encoder->base.crtc);
- int port = vlv_dport_to_channel(dport);
+ enum dpio_channel port = vlv_dport_to_channel(dport);
  int pipe = intel_crtc->pipe;
  struct edp_power_seq power_seq;
  u32 val;
 
  mutex_lock(&dev_priv->dpio_lock);
 
- val = vlv_dpio_read(dev_priv, pipe, DPIO_DATA_LANE_A(port));
+ val = vlv_dpio_read(dev_priv, pipe, VLV_PCS01_DW8(port));
  val = 0;
  if (pipe)
   val |= (1<<21);
  else
   val &= ~(1<<21);
  val |= 0x001000c4;
- vlv_dpio_write(dev_priv, pipe, DPIO_DATA_CHANNEL(port), val);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CLOCKBUF0(port), 0x00760018);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CLOCKBUF8(port), 0x00400888);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW8(port), val);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW14(port), 0x00760018);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW23(port), 0x00400888);
 
  mutex_unlock(&dev_priv->dpio_lock);
 
@@ -1881,7 +1893,7 @@ static void vlv_pre_enable_dp(struct intel_encoder *encoder)
 
  intel_enable_dp(encoder);
 
- vlv_wait_port_ready(dev_priv, port);
+ vlv_wait_port_ready(dev_priv, dport);
 }
 
 static void vlv_dp_pre_pll_enable(struct intel_encoder *encoder)
@@ -1891,24 +1903,24 @@ static void vlv_dp_pre_pll_enable(struct intel_encoder *encoder)
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc =
   to_intel_crtc(encoder->base.crtc);
- int port = vlv_dport_to_channel(dport);
+ enum dpio_channel port = vlv_dport_to_channel(dport);
  int pipe = intel_crtc->pipe;
 
  /* Program Tx lane resets to default */
  mutex_lock(&dev_priv->dpio_lock);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_TX(port),
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW0(port),
     DPIO_PCS_TX_LANE2_RESET |
     DPIO_PCS_TX_LANE1_RESET);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CLK(port),
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW1(port),
     DPIO_PCS_CLK_CRI_RXEB_EIOS_EN |
     DPIO_PCS_CLK_CRI_RXDIGFILTSG_EN |
     (1<<DPIO_PCS_CLK_DATAWIDTH_SHIFT) |
      DPIO_PCS_CLK_SOFT_RESET);
 
  /* Fix up inter-pair skew failure */
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_STAGGER1(port), 0x00750f00);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_CTL(port), 0x00001500);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_LANE(port), 0x40400000);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW12(port), 0x00750f00);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW11(port), 0x00001500);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW14(port), 0x40400000);
  mutex_unlock(&dev_priv->dpio_lock);
 }
 
@@ -1950,18 +1962,6 @@ intel_dp_get_link_status(struct intel_dp *intel_dp, uint8_t link_status[DP_LINK_
            DP_LINK_STATUS_SIZE);
 }
 
-#if 0
-static char *voltage_names[] = {
- "0.4V", "0.6V", "0.8V", "1.2V"
-};
-static char *pre_emph_names[] = {
- "0dB", "3.5dB", "6dB", "9.5dB"
-};
-static char *link_train_names[] = {
- "pattern 1", "pattern 2", "idle", "off"
-};
-#endif
-
 /*
  * These are source-specific values; current Intel hardware supports
  * a maximum voltage of 800mV and a maximum pre-emphasis of 6dB
@@ -2059,7 +2059,7 @@ static uint32_t intel_vlv_signal_levels(struct intel_dp *intel_dp)
  unsigned long demph_reg_value, preemph_reg_value,
   uniqtranscale_reg_value;
  uint8_t train_set = intel_dp->train_set[0];
- int port = vlv_dport_to_channel(dport);
+ enum dpio_channel port = vlv_dport_to_channel(dport);
  int pipe = intel_crtc->pipe;
 
  switch (train_set & DP_TRAIN_PRE_EMPHASIS_MASK) {
@@ -2136,14 +2136,14 @@ static uint32_t intel_vlv_signal_levels(struct intel_dp *intel_dp)
  }
 
  mutex_lock(&dev_priv->dpio_lock);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_OCALINIT(port), 0x00000000);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_SWING_CTL4(port), demph_reg_value);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_SWING_CTL2(port),
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW5(port), 0x00000000);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW4(port), demph_reg_value);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW2(port),
     uniqtranscale_reg_value);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_SWING_CTL3(port), 0x0C782040);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_STAGGER0(port), 0x00030000);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CTL_OVER1(port), preemph_reg_value);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_OCALINIT(port), 0x80000000);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW3(port), 0x0C782040);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW11(port), 0x00030000);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW9(port), preemph_reg_value);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW5(port), 0x80000000);
  mutex_unlock(&dev_priv->dpio_lock);
 
  return 0;
@@ -2655,7 +2655,6 @@ intel_dp_complete_link_train(struct intel_dp *intel_dp)
 
   if (cr_tries > 5) {
    DRM_ERROR("failed to train DP, aborting\n");
-   intel_dp_link_down(intel_dp);
    break;
   }
 
@@ -2908,13 +2907,11 @@ intel_dp_check_link_status(struct intel_dp *intel_dp)
 
  /* Try to read receiver status if the link appears to be up */
  if (!intel_dp_get_link_status(intel_dp, link_status)) {
-  intel_dp_link_down(intel_dp);
   return;
  }
 
  /* Now read the DPCD to see if it's actually running */
  if (!intel_dp_get_dpcd(intel_dp)) {
-  intel_dp_link_down(intel_dp);
   return;
  }
 
@@ -3107,9 +3104,12 @@ intel_dp_detect(struct drm_connector *connector, bool force)
  struct intel_digital_port *intel_dig_port = dp_to_dig_port(intel_dp);
  struct intel_encoder *intel_encoder = &intel_dig_port->base;
  struct drm_device *dev = connector->dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
  enum drm_connector_status status;
  struct edid *edid = NULL;
 
+ intel_runtime_pm_get(dev_priv);
+
  DRM_DEBUG_KMS("[CONNECTOR:%d:%s]\n",
         connector->base.id, drm_get_connector_name(connector));
 
@@ -3121,7 +3121,7 @@ intel_dp_detect(struct drm_connector *connector, bool force)
   status = g4x_dp_detect(intel_dp);
 
  if (status != connector_status_connected)
-  return status;
+  goto out;
 
  intel_dp_probe_oui(intel_dp);
 
@@ -3137,7 +3137,11 @@ intel_dp_detect(struct drm_connector *connector, bool force)
 
  if (intel_encoder->type != INTEL_OUTPUT_EDP)
   intel_encoder->type = INTEL_OUTPUT_DISPLAYPORT;
- return connector_status_connected;
+ status = connector_status_connected;
+
+out:
+ intel_runtime_pm_put(dev_priv);
+ return status;
 }
 
 static int intel_dp_get_modes(struct drm_connector *connector)
diff --git a/drivers/gpu/drm/i915/intel_drv.h b/drivers/gpu/drm/i915/intel_drv.h
index 79f91f2..fbfaaba 100644
--- a/drivers/gpu/drm/i915/intel_drv.h
+++ b/drivers/gpu/drm/i915/intel_drv.h
@@ -65,8 +65,8 @@
 #define wait_for_atomic_us(COND, US) _wait_for((COND), \
             DIV_ROUND_UP((US), 1000), 0)
 
-#define KHz(x) (1000*x)
-#define MHz(x) KHz(1000*x)
+#define KHz(x) (1000 * (x))
+#define MHz(x) KHz(1000 * (x))
 
 /*
  * Display related stuff
@@ -155,7 +155,19 @@ struct intel_encoder {
 
 struct intel_panel {
  struct drm_display_mode *fixed_mode;
+ struct drm_display_mode *downclock_mode;
  int fitting_mode;
+
+ /* backlight */
+ struct {
+  bool present;
+  u32 level;
+  u32 max;
+  bool enabled;
+  bool combination_mode; /* gen 2/4 only */
+  bool active_low_pwm;
+  struct backlight_device *device;
+ } backlight;
 };
 
 struct intel_connector {
@@ -443,7 +455,7 @@ struct intel_hdmi {
  bool rgb_quant_range_selectable;
  void (*write_infoframe)(struct drm_encoder *encoder,
     enum hdmi_infoframe_type type,
-    const uint8_t *frame, ssize_t len);
+    const void *frame, ssize_t len);
  void (*set_infoframes)(struct drm_encoder *encoder,
           struct drm_display_mode *adjusted_mode);
 };
@@ -490,9 +502,9 @@ vlv_dport_to_channel(struct intel_digital_port *dport)
 {
  switch (dport->port) {
  case PORT_B:
-  return 0;
+  return DPIO_CH0;
  case PORT_C:
-  return 1;
+  return DPIO_CH1;
  default:
   BUG();
  }
@@ -601,7 +613,8 @@ void intel_ddi_disable_transcoder_func(struct drm_i915_private *dev_priv,
 void intel_ddi_enable_pipe_clock(struct intel_crtc *intel_crtc);
 void intel_ddi_disable_pipe_clock(struct intel_crtc *intel_crtc);
 void intel_ddi_setup_hw_pll_state(struct drm_device *dev);
-bool intel_ddi_pll_mode_set(struct drm_crtc *crtc);
+bool intel_ddi_pll_select(struct intel_crtc *crtc);
+void intel_ddi_pll_enable(struct intel_crtc *crtc);
 void intel_ddi_put_crtc_pll(struct drm_crtc *crtc);
 void intel_ddi_set_pipe_settings(struct drm_crtc *crtc);
 void intel_ddi_prepare_link_retrain(struct drm_encoder *encoder);
@@ -612,6 +625,8 @@ void intel_ddi_get_config(struct intel_encoder *encoder,
 
 
 /* intel_display.c */
+const char *intel_output_name(int output);
+bool intel_has_pending_fb_unpin(struct drm_device *dev);
 int intel_pch_rawclk(struct drm_device *dev);
 void intel_mark_busy(struct drm_device *dev);
 void intel_mark_fb_busy(struct drm_i915_gem_object *obj,
@@ -638,7 +653,8 @@ enum transcoder intel_pipe_to_cpu_transcoder(struct drm_i915_private *dev_priv,
 void intel_wait_for_vblank(struct drm_device *dev, int pipe);
 void intel_wait_for_pipe_off(struct drm_device *dev, int pipe);
 int ironlake_get_lanes_required(int target_clock, int link_bw, int bpp);
-void vlv_wait_port_ready(struct drm_i915_private *dev_priv, int port);
+void vlv_wait_port_ready(struct drm_i915_private *dev_priv,
+    struct intel_digital_port *dport);
 bool intel_get_load_detect_pipe(struct drm_connector *connector,
     struct drm_display_mode *mode,
     struct intel_load_detect_pipe *old);
@@ -690,11 +706,10 @@ void
 ironlake_check_encoder_dotclock(const struct intel_crtc_config *pipe_config,
     int dotclock);
 bool intel_crtc_active(struct drm_crtc *crtc);
-void i915_disable_vga_mem(struct drm_device *dev);
 void hsw_enable_ips(struct intel_crtc *crtc);
 void hsw_disable_ips(struct intel_crtc *crtc);
 void intel_display_set_init_power(struct drm_device *dev, bool enable);
-
+int valleyview_get_vco(struct drm_i915_private *dev_priv);
 
 /* intel_dp.c */
 void intel_dp_init(struct drm_device *dev, int output_reg, enum port port);
@@ -808,9 +823,13 @@ void intel_panel_set_backlight(struct intel_connector *connector, u32 level,
 int intel_panel_setup_backlight(struct drm_connector *connector);
 void intel_panel_enable_backlight(struct intel_connector *connector);
 void intel_panel_disable_backlight(struct intel_connector *connector);
-void intel_panel_destroy_backlight(struct drm_device *dev);
+void intel_panel_destroy_backlight(struct drm_connector *connector);
+void intel_panel_init_backlight_funcs(struct drm_device *dev);
 enum drm_connector_status intel_panel_detect(struct drm_device *dev);
-
+extern struct drm_display_mode *intel_find_panel_downclock(
+    struct drm_device *dev,
+    struct drm_display_mode *fixed_mode,
+    struct drm_connector *connector);
 
 /* intel_pm.c */
 void intel_init_clock_gating(struct drm_device *dev);
@@ -830,6 +849,8 @@ int intel_power_domains_init(struct drm_device *dev);
 void intel_power_domains_remove(struct drm_device *dev);
 bool intel_display_power_enabled(struct drm_device *dev,
      enum intel_display_power_domain domain);
+bool intel_display_power_enabled_sw(struct drm_device *dev,
+        enum intel_display_power_domain domain);
 void intel_display_power_get(struct drm_device *dev,
         enum intel_display_power_domain domain);
 void intel_display_power_put(struct drm_device *dev,
@@ -844,6 +865,10 @@ void gen6_rps_idle(struct drm_i915_private *dev_priv);
 void gen6_rps_boost(struct drm_i915_private *dev_priv);
 void intel_aux_display_runtime_get(struct drm_i915_private *dev_priv);
 void intel_aux_display_runtime_put(struct drm_i915_private *dev_priv);
+void intel_runtime_pm_get(struct drm_i915_private *dev_priv);
+void intel_runtime_pm_put(struct drm_i915_private *dev_priv);
+void intel_init_runtime_pm(struct drm_i915_private *dev_priv);
+void intel_fini_runtime_pm(struct drm_i915_private *dev_priv);
 void ilk_wm_get_hw_state(struct drm_device *dev);
 
 
diff --git a/drivers/gpu/drm/i915/intel_dsi.c b/drivers/gpu/drm/i915/intel_dsi.c
index d257b09..fabbf0d 100644
--- a/drivers/gpu/drm/i915/intel_dsi.c
+++ b/drivers/gpu/drm/i915/intel_dsi.c
@@ -37,49 +37,18 @@
 static const struct intel_dsi_device intel_dsi_devices[] = {
 };
 
-
-static void vlv_cck_modify(struct drm_i915_private *dev_priv, u32 reg, u32 val,
-      u32 mask)
-{
- u32 tmp = vlv_cck_read(dev_priv, reg);
- tmp &= ~mask;
- tmp |= val;
- vlv_cck_write(dev_priv, reg, tmp);
-}
-
-static void band_gap_wa(struct drm_i915_private *dev_priv)
+static void band_gap_reset(struct drm_i915_private *dev_priv)
 {
  mutex_lock(&dev_priv->dpio_lock);
 
- /* Enable bandgap fix in GOP driver */
- vlv_cck_modify(dev_priv, 0x6D, 0x00010000, 0x00030000);
- msleep(20);
- vlv_cck_modify(dev_priv, 0x6E, 0x00010000, 0x00030000);
- msleep(20);
- vlv_cck_modify(dev_priv, 0x6F, 0x00010000, 0x00030000);
- msleep(20);
- vlv_cck_modify(dev_priv, 0x00, 0x00008000, 0x00008000);
- msleep(20);
- vlv_cck_modify(dev_priv, 0x00, 0x00000000, 0x00008000);
- msleep(20);
-
- /* Turn Display Trunk on */
- vlv_cck_modify(dev_priv, 0x6B, 0x00020000, 0x00030000);
- msleep(20);
-
- vlv_cck_modify(dev_priv, 0x6C, 0x00020000, 0x00030000);
- msleep(20);
-
- vlv_cck_modify(dev_priv, 0x6D, 0x00020000, 0x00030000);
- msleep(20);
- vlv_cck_modify(dev_priv, 0x6E, 0x00020000, 0x00030000);
- msleep(20);
- vlv_cck_modify(dev_priv, 0x6F, 0x00020000, 0x00030000);
+ vlv_flisdsi_write(dev_priv, 0x08, 0x0001);
+ vlv_flisdsi_write(dev_priv, 0x0F, 0x0005);
+ vlv_flisdsi_write(dev_priv, 0x0F, 0x0025);
+ udelay(150);
+ vlv_flisdsi_write(dev_priv, 0x0F, 0x0000);
+ vlv_flisdsi_write(dev_priv, 0x08, 0x0000);
 
  mutex_unlock(&dev_priv->dpio_lock);
-
- /* Need huge delay, otherwise clock is not stable */
- msleep(100);
 }
 
 static struct intel_dsi *intel_attached_dsi(struct drm_connector *connector)
@@ -132,14 +101,47 @@ static void intel_dsi_pre_pll_enable(struct intel_encoder *encoder)
  vlv_enable_dsi_pll(encoder);
 }
 
+static void intel_dsi_device_ready(struct intel_encoder *encoder)
+{
+ struct drm_i915_private *dev_priv = encoder->base.dev->dev_private;
+ struct intel_crtc *intel_crtc = to_intel_crtc(encoder->base.crtc);
+ int pipe = intel_crtc->pipe;
+ u32 val;
+
+ DRM_DEBUG_KMS("\n");
+
+ val = I915_READ(MIPI_PORT_CTRL(pipe));
+ I915_WRITE(MIPI_PORT_CTRL(pipe), val | LP_OUTPUT_HOLD);
+ usleep_range(1000, 1500);
+ I915_WRITE(MIPI_DEVICE_READY(pipe), DEVICE_READY | ULPS_STATE_EXIT);
+ usleep_range(2000, 2500);
+ I915_WRITE(MIPI_DEVICE_READY(pipe), DEVICE_READY);
+ usleep_range(2000, 2500);
+ I915_WRITE(MIPI_DEVICE_READY(pipe), 0x00);
+ usleep_range(2000, 2500);
+ I915_WRITE(MIPI_DEVICE_READY(pipe), DEVICE_READY);
+ usleep_range(2000, 2500);
+}
 static void intel_dsi_pre_enable(struct intel_encoder *encoder)
 {
+ struct intel_dsi *intel_dsi = enc_to_intel_dsi(&encoder->base);
+
  DRM_DEBUG_KMS("\n");
+
+ if (intel_dsi->dev.dev_ops->panel_reset)
+  intel_dsi->dev.dev_ops->panel_reset(&intel_dsi->dev);
+
+ /* put device in ready state */
+ intel_dsi_device_ready(encoder);
+
+ if (intel_dsi->dev.dev_ops->send_otp_cmds)
+  intel_dsi->dev.dev_ops->send_otp_cmds(&intel_dsi->dev);
 }
 
 static void intel_dsi_enable(struct intel_encoder *encoder)
 {
- struct drm_i915_private *dev_priv = encoder->base.dev->dev_private;
+ struct drm_device *dev = encoder->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc = to_intel_crtc(encoder->base.crtc);
  struct intel_dsi *intel_dsi = enc_to_intel_dsi(&encoder->base);
  int pipe = intel_crtc->pipe;
@@ -147,41 +149,28 @@ static void intel_dsi_enable(struct intel_encoder *encoder)
 
  DRM_DEBUG_KMS("\n");
 
- temp = I915_READ(MIPI_DEVICE_READY(pipe));
- if ((temp & DEVICE_READY) == 0) {
-  temp &= ~ULPS_STATE_MASK;
-  I915_WRITE(MIPI_DEVICE_READY(pipe), temp | DEVICE_READY);
- } else if (temp & ULPS_STATE_MASK) {
-  temp &= ~ULPS_STATE_MASK;
-  I915_WRITE(MIPI_DEVICE_READY(pipe), temp | ULPS_STATE_EXIT);
-  /*
-   * We need to ensure that there is a minimum of 1 ms time
-   * available before clearing the UPLS exit state.
-   */
-  msleep(2);
-  I915_WRITE(MIPI_DEVICE_READY(pipe), temp);
- }
-
  if (is_cmd_mode(intel_dsi))
   I915_WRITE(MIPI_MAX_RETURN_PKT_SIZE(pipe), 8 * 4);
-
- if (is_vid_mode(intel_dsi)) {
+ else {
   msleep(20); /* XXX */
   dpi_send_cmd(intel_dsi, TURN_ON);
   msleep(100);
 
   /* assert ip_tg_enable signal */
-  temp = I915_READ(MIPI_PORT_CTRL(pipe));
+  temp = I915_READ(MIPI_PORT_CTRL(pipe)) & ~LANE_CONFIGURATION_MASK;
+  temp = temp | intel_dsi->port_bits;
   I915_WRITE(MIPI_PORT_CTRL(pipe), temp | DPI_ENABLE);
   POSTING_READ(MIPI_PORT_CTRL(pipe));
  }
 
- intel_dsi->dev.dev_ops->enable(&intel_dsi->dev);
+ if (intel_dsi->dev.dev_ops->enable)
+  intel_dsi->dev.dev_ops->enable(&intel_dsi->dev);
 }
 
 static void intel_dsi_disable(struct intel_encoder *encoder)
 {
- struct drm_i915_private *dev_priv = encoder->base.dev->dev_private;
+ struct drm_device *dev = encoder->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc = to_intel_crtc(encoder->base.crtc);
  struct intel_dsi *intel_dsi = enc_to_intel_dsi(&encoder->base);
  int pipe = intel_crtc->pipe;
@@ -189,8 +178,6 @@ static void intel_dsi_disable(struct intel_encoder *encoder)
 
  DRM_DEBUG_KMS("\n");
 
- intel_dsi->dev.dev_ops->disable(&intel_dsi->dev);
-
  if (is_vid_mode(intel_dsi)) {
   dpi_send_cmd(intel_dsi, SHUTDOWN);
   msleep(10);
@@ -203,20 +190,54 @@ static void intel_dsi_disable(struct intel_encoder *encoder)
   msleep(2);
  }
 
- temp = I915_READ(MIPI_DEVICE_READY(pipe));
- if (temp & DEVICE_READY) {
-  temp &= ~DEVICE_READY;
-  temp &= ~ULPS_STATE_MASK;
-  I915_WRITE(MIPI_DEVICE_READY(pipe), temp);
- }
+ /* if disable packets are sent before sending shutdown packet then in
+  * some next enable sequence send turn on packet error is observed */
+ if (intel_dsi->dev.dev_ops->disable)
+  intel_dsi->dev.dev_ops->disable(&intel_dsi->dev);
 }
 
-static void intel_dsi_post_disable(struct intel_encoder *encoder)
+static void intel_dsi_clear_device_ready(struct intel_encoder *encoder)
 {
+ struct drm_i915_private *dev_priv = encoder->base.dev->dev_private;
+ struct intel_crtc *intel_crtc = to_intel_crtc(encoder->base.crtc);
+ int pipe = intel_crtc->pipe;
+ u32 val;
+
  DRM_DEBUG_KMS("\n");
 
+ I915_WRITE(MIPI_DEVICE_READY(pipe), ULPS_STATE_ENTER);
+ usleep_range(2000, 2500);
+
+ I915_WRITE(MIPI_DEVICE_READY(pipe), ULPS_STATE_EXIT);
+ usleep_range(2000, 2500);
+
+ I915_WRITE(MIPI_DEVICE_READY(pipe), ULPS_STATE_ENTER);
+ usleep_range(2000, 2500);
+
+ val = I915_READ(MIPI_PORT_CTRL(pipe));
+ I915_WRITE(MIPI_PORT_CTRL(pipe), val & ~LP_OUTPUT_HOLD);
+ usleep_range(1000, 1500);
+
+ if (wait_for(((I915_READ(MIPI_PORT_CTRL(pipe)) & AFE_LATCHOUT)
+     == 0x00000), 30))
+  DRM_ERROR("DSI LP not going Low\n");
+
+ I915_WRITE(MIPI_DEVICE_READY(pipe), 0x00);
+ usleep_range(2000, 2500);
+
  vlv_disable_dsi_pll(encoder);
 }
+static void intel_dsi_post_disable(struct intel_encoder *encoder)
+{
+ struct intel_dsi *intel_dsi = enc_to_intel_dsi(&encoder->base);
+
+ DRM_DEBUG_KMS("\n");
+
+ intel_dsi_clear_device_ready(encoder);
+
+ if (intel_dsi->dev.dev_ops->disable_panel_power)
+  intel_dsi->dev.dev_ops->disable_panel_power(&intel_dsi->dev);
+}
 
 static bool intel_dsi_get_hw_state(struct intel_encoder *encoder,
        enum pipe *pipe)
@@ -251,8 +272,9 @@ static void intel_dsi_get_config(struct intel_encoder *encoder,
  /* XXX: read flags, set to adjusted_mode */
 }
 
-static int intel_dsi_mode_valid(struct drm_connector *connector,
-    struct drm_display_mode *mode)
+static enum drm_mode_status
+intel_dsi_mode_valid(struct drm_connector *connector,
+       struct drm_display_mode *mode)
 {
  struct intel_connector *intel_connector = to_intel_connector(connector);
  struct drm_display_mode *fixed_mode = intel_connector->panel.fixed_mode;
@@ -352,11 +374,8 @@ static void intel_dsi_mode_set(struct intel_encoder *intel_encoder)
 
  DRM_DEBUG_KMS("pipe %c\n", pipe_name(pipe));
 
- /* Update the DSI PLL */
- vlv_enable_dsi_pll(intel_encoder);
-
  /* XXX: Location of the call */
- band_gap_wa(dev_priv);
+ band_gap_reset(dev_priv);
 
  /* escape clock divider, 20MHz, shared for A and C. device ready must be
   * off when doing this! txclkesc? */
@@ -373,11 +392,7 @@ static void intel_dsi_mode_set(struct intel_encoder *intel_encoder)
  I915_WRITE(MIPI_INTR_STAT(pipe), 0xffffffff);
  I915_WRITE(MIPI_INTR_EN(pipe), 0xffffffff);
 
- I915_WRITE(MIPI_DPHY_PARAM(pipe),
-     0x3c << EXIT_ZERO_COUNT_SHIFT |
-     0x1f << TRAIL_COUNT_SHIFT |
-     0xc5 << CLK_ZERO_COUNT_SHIFT |
-     0x1f << PREPARE_COUNT_SHIFT);
+ I915_WRITE(MIPI_DPHY_PARAM(pipe), intel_dsi->dphy_reg);
 
  I915_WRITE(MIPI_DPI_RESOLUTION(pipe),
      adjusted_mode->vdisplay << VERTICAL_ADDRESS_SHIFT |
@@ -425,9 +440,9 @@ static void intel_dsi_mode_set(struct intel_encoder *intel_encoder)
            adjusted_mode->htotal,
            bpp, intel_dsi->lane_count) + 1);
  }
- I915_WRITE(MIPI_LP_RX_TIMEOUT(pipe), 8309); /* max */
- I915_WRITE(MIPI_TURN_AROUND_TIMEOUT(pipe), 0x14); /* max */
- I915_WRITE(MIPI_DEVICE_RESET_TIMER(pipe), 0xffff); /* max */
+ I915_WRITE(MIPI_LP_RX_TIMEOUT(pipe), intel_dsi->lp_rx_timeout);
+ I915_WRITE(MIPI_TURN_AROUND_TIMEOUT(pipe), intel_dsi->turn_arnd_val);
+ I915_WRITE(MIPI_DEVICE_RESET_TIMER(pipe), intel_dsi->rst_timer_val);
 
  /* dphy stuff */
 
@@ -442,29 +457,31 @@ static void intel_dsi_mode_set(struct intel_encoder *intel_encoder)
   *
   * XXX: write MIPI_STOP_STATE_STALL?
   */
- I915_WRITE(MIPI_HIGH_LOW_SWITCH_COUNT(pipe), 0x46);
+ I915_WRITE(MIPI_HIGH_LOW_SWITCH_COUNT(pipe),
+      intel_dsi->hs_to_lp_count);
 
  /* XXX: low power clock equivalence in terms of byte clock. the number
   * of byte clocks occupied in one low power clock. based on txbyteclkhs
   * and txclkesc. txclkesc time / txbyteclk time * (105 +
   * MIPI_STOP_STATE_STALL) / 105.???
   */
- I915_WRITE(MIPI_LP_BYTECLK(pipe), 4);
+ I915_WRITE(MIPI_LP_BYTECLK(pipe), intel_dsi->lp_byte_clk);
 
  /* the bw essential for transmitting 16 long packets containing 252
   * bytes meant for dcs write memory command is programmed in this
   * register in terms of byte clocks. based on dsi transfer rate and the
   * number of lanes configured the time taken to transmit 16 long packets
   * in a dsi stream varies. */
- I915_WRITE(MIPI_DBI_BW_CTRL(pipe), 0x820);
+ I915_WRITE(MIPI_DBI_BW_CTRL(pipe), intel_dsi->bw_timer);
 
  I915_WRITE(MIPI_CLK_LANE_SWITCH_TIME_CNT(pipe),
-     0xa << LP_HS_SSW_CNT_SHIFT |
-     0x14 << HS_LP_PWR_SW_CNT_SHIFT);
+     intel_dsi->clk_lp_to_hs_count << LP_HS_SSW_CNT_SHIFT |
+     intel_dsi->clk_hs_to_lp_count << HS_LP_PWR_SW_CNT_SHIFT);
 
  if (is_vid_mode(intel_dsi))
   I915_WRITE(MIPI_VIDEO_MODE_FORMAT(pipe),
-      intel_dsi->video_mode_format);
+    intel_dsi->video_frmt_cfg_bits |
+    intel_dsi->video_mode_format);
 }
 
 static enum drm_connector_status
diff --git a/drivers/gpu/drm/i915/intel_dsi.h b/drivers/gpu/drm/i915/intel_dsi.h
index c7765f3..b4a27ce 100644
--- a/drivers/gpu/drm/i915/intel_dsi.h
+++ b/drivers/gpu/drm/i915/intel_dsi.h
@@ -39,6 +39,13 @@ struct intel_dsi_device {
 struct intel_dsi_dev_ops {
  bool (*init)(struct intel_dsi_device *dsi);
 
+ void (*panel_reset)(struct intel_dsi_device *dsi);
+
+ void (*disable_panel_power)(struct intel_dsi_device *dsi);
+
+ /* one time programmable commands if needed */
+ void (*send_otp_cmds)(struct intel_dsi_device *dsi);
+
  /* This callback must be able to assume DSI commands can be sent */
  void (*enable)(struct intel_dsi_device *dsi);
 
@@ -89,6 +96,20 @@ struct intel_dsi {
 
  /* eot for MIPI_EOT_DISABLE register */
  u32 eot_disable;
+
+ u32 port_bits;
+ u32 bw_timer;
+ u32 dphy_reg;
+ u32 video_frmt_cfg_bits;
+ u16 lp_byte_clk;
+
+ /* timeouts in byte clocks */
+ u16 lp_rx_timeout;
+ u16 turn_arnd_val;
+ u16 rst_timer_val;
+ u16 hs_to_lp_count;
+ u16 clk_lp_to_hs_count;
+ u16 clk_hs_to_lp_count;
 };
 
 static inline struct intel_dsi *enc_to_intel_dsi(struct drm_encoder *encoder)
diff --git a/drivers/gpu/drm/i915/intel_dsi_pll.c b/drivers/gpu/drm/i915/intel_dsi_pll.c
index 44279b2..ba79ec1 100644
--- a/drivers/gpu/drm/i915/intel_dsi_pll.c
+++ b/drivers/gpu/drm/i915/intel_dsi_pll.c
@@ -50,6 +50,8 @@ static const u32 lfsr_converts[] = {
  71, 35       /* 91 - 92 */
 };
 
+#ifdef DSI_CLK_FROM_RR
+
 static u32 dsi_rr_formula(const struct drm_display_mode *mode,
      int pixel_format, int video_mode_format,
      int lane_count, bool eotp)
@@ -121,7 +123,7 @@ static u32 dsi_rr_formula(const struct drm_display_mode *mode,
 
  /* the dsi clock is divided by 2 in the hardware to get dsi ddr clock */
  dsi_bit_clock_hz = bytes_per_x_frames_x_lanes * 8;
- dsi_clk = dsi_bit_clock_hz / (1000 * 1000);
+ dsi_clk = dsi_bit_clock_hz / 1000;
 
  if (eotp && video_mode_format == VIDEO_MODE_BURST)
   dsi_clk *= 2;
@@ -129,64 +131,37 @@ static u32 dsi_rr_formula(const struct drm_display_mode *mode,
  return dsi_clk;
 }
 
-#ifdef MNP_FROM_TABLE
-
-struct dsi_clock_table {
- u32 freq;
- u8 m;
- u8 p;
-};
-
-static const struct dsi_clock_table dsi_clk_tbl[] = {
- {300, 72, 6}, {313, 75, 6}, {323, 78, 6}, {333, 80, 6},
- {343, 82, 6}, {353, 85, 6}, {363, 87, 6}, {373, 90, 6},
- {383, 92, 6}, {390, 78, 5}, {393, 79, 5}, {400, 80, 5},
- {401, 80, 5}, {402, 80, 5}, {403, 81, 5}, {404, 81, 5},
- {405, 81, 5}, {406, 81, 5}, {407, 81, 5}, {408, 82, 5},
- {409, 82, 5}, {410, 82, 5}, {411, 82, 5}, {412, 82, 5},
- {413, 83, 5}, {414, 83, 5}, {415, 83, 5}, {416, 83, 5},
- {417, 83, 5}, {418, 84, 5}, {419, 84, 5}, {420, 84, 5},
- {430, 86, 5}, {440, 88, 5}, {450, 90, 5}, {460, 92, 5},
- {470, 75, 4}, {480, 77, 4}, {490, 78, 4}, {500, 80, 4},
- {510, 82, 4}, {520, 83, 4}, {530, 85, 4}, {540, 86, 4},
- {550, 88, 4}, {560, 90, 4}, {570, 91, 4}, {580, 70, 3},
- {590, 71, 3}, {600, 72, 3}, {610, 73, 3}, {620, 74, 3},
- {630, 76, 3}, {640, 77, 3}, {650, 78, 3}, {660, 79, 3},
- {670, 80, 3}, {680, 82, 3}, {690, 83, 3}, {700, 84, 3},
- {710, 85, 3}, {720, 86, 3}, {730, 88, 3}, {740, 89, 3},
- {750, 90, 3}, {760, 91, 3}, {770, 92, 3}, {780, 62, 2},
- {790, 63, 2}, {800, 64, 2}, {880, 70, 2}, {900, 72, 2},
- {1000, 80, 2},  /* dsi clock frequency in Mhz*/
-};
+#else
 
-static int dsi_calc_mnp(u32 dsi_clk, struct dsi_mnp *dsi_mnp)
+/* Get DSI clock from pixel clock */
+static u32 dsi_clk_from_pclk(const struct drm_display_mode *mode,
+     int pixel_format, int lane_count)
 {
- unsigned int i;
- u8 m;
- u8 n;
- u8 p;
- u32 m_seed;
-
- if (dsi_clk < 300 || dsi_clk > 1000)
-  return -ECHRNG;
+ u32 dsi_clk_khz;
+ u32 bpp;
 
- for (i = 0; i <= ARRAY_SIZE(dsi_clk_tbl); i++) {
-  if (dsi_clk_tbl[i].freq > dsi_clk)
-   break;
+ switch (pixel_format) {
+ default:
+ case VID_MODE_FORMAT_RGB888:
+ case VID_MODE_FORMAT_RGB666_LOOSE:
+  bpp = 24;
+  break;
+ case VID_MODE_FORMAT_RGB666:
+  bpp = 18;
+  break;
+ case VID_MODE_FORMAT_RGB565:
+  bpp = 16;
+  break;
  }
 
- m = dsi_clk_tbl[i].m;
- p = dsi_clk_tbl[i].p;
- m_seed = lfsr_converts[m - 62];
- n = 1;
- dsi_mnp->dsi_pll_ctrl = 1 << (DSI_PLL_P1_POST_DIV_SHIFT + p - 2);
- dsi_mnp->dsi_pll_div = (n - 1) << DSI_PLL_N1_DIV_SHIFT |
-  m_seed << DSI_PLL_M1_DIV_SHIFT;
+ /* DSI data rate = pixel clock * bits per pixel / lane count
+    pixel clock is converted from KHz to Hz */
+ dsi_clk_khz = DIV_ROUND_CLOSEST(mode->clock * bpp, lane_count);
 
- return 0;
+ return dsi_clk_khz;
 }
 
-#else
+#endif
 
 static int dsi_calc_mnp(u32 dsi_clk, struct dsi_mnp *dsi_mnp)
 {
@@ -194,36 +169,47 @@ static int dsi_calc_mnp(u32 dsi_clk, struct dsi_mnp *dsi_mnp)
  u32 ref_clk;
  u32 error;
  u32 tmp_error;
- u32 target_dsi_clk;
- u32 calc_dsi_clk;
+ int target_dsi_clk;
+ int calc_dsi_clk;
  u32 calc_m;
  u32 calc_p;
  u32 m_seed;
 
- if (dsi_clk < 300 || dsi_clk > 1150) {
+ /* dsi_clk is expected in KHZ */
+ if (dsi_clk < 300000 || dsi_clk > 1150000) {
   DRM_ERROR("DSI CLK Out of Range\n");
   return -ECHRNG;
  }
 
  ref_clk = 25000;
- target_dsi_clk = dsi_clk * 1000;
+ target_dsi_clk = dsi_clk;
  error = 0xFFFFFFFF;
+ tmp_error = 0xFFFFFFFF;
  calc_m = 0;
  calc_p = 0;
 
  for (m = 62; m <= 92; m++) {
   for (p = 2; p <= 6; p++) {
-
+   /* Find the optimal m and p divisors
+   with minimal error +/- the required clock */
    calc_dsi_clk = (m * ref_clk) / p;
-   if (calc_dsi_clk >= target_dsi_clk) {
-    tmp_error = calc_dsi_clk - target_dsi_clk;
-    if (tmp_error < error) {
-     error = tmp_error;
-     calc_m = m;
-     calc_p = p;
-    }
+   if (calc_dsi_clk == target_dsi_clk) {
+    calc_m = m;
+    calc_p = p;
+    error = 0;
+    break;
+   } else
+    tmp_error = abs(target_dsi_clk - calc_dsi_clk);
+
+   if (tmp_error < error) {
+    error = tmp_error;
+    calc_m = m;
+    calc_p = p;
    }
   }
+
+  if (error == 0)
+   break;
  }
 
  m_seed = lfsr_converts[calc_m - 62];
@@ -235,8 +221,6 @@ static int dsi_calc_mnp(u32 dsi_clk, struct dsi_mnp *dsi_mnp)
  return 0;
 }
 
-#endif
-
 /*
  * XXX: The muxing and gating is hard coded for now. Need to add support for
  * sharing PLLs with two DSI outputs.
@@ -251,9 +235,8 @@ static void vlv_configure_dsi_pll(struct intel_encoder *encoder)
  struct dsi_mnp dsi_mnp;
  u32 dsi_clk;
 
- dsi_clk = dsi_rr_formula(mode, intel_dsi->pixel_format,
-     intel_dsi->video_mode_format,
-     intel_dsi->lane_count, !intel_dsi->eot_disable);
+ dsi_clk = dsi_clk_from_pclk(mode, intel_dsi->pixel_format,
+      intel_dsi->lane_count);
 
  ret = dsi_calc_mnp(dsi_clk, &dsi_mnp);
  if (ret) {
diff --git a/drivers/gpu/drm/i915/intel_dvo.c b/drivers/gpu/drm/i915/intel_dvo.c
index 3c77365..eeff998 100644
--- a/drivers/gpu/drm/i915/intel_dvo.c
+++ b/drivers/gpu/drm/i915/intel_dvo.c
@@ -234,8 +234,9 @@ static void intel_dvo_dpms(struct drm_connector *connector, int mode)
  intel_modeset_check_state(connector->dev);
 }
 
-static int intel_dvo_mode_valid(struct drm_connector *connector,
-    struct drm_display_mode *mode)
+static enum drm_mode_status
+intel_dvo_mode_valid(struct drm_connector *connector,
+       struct drm_display_mode *mode)
 {
  struct intel_dvo *intel_dvo = intel_attached_dvo(connector);
 
diff --git a/drivers/gpu/drm/i915/intel_fbdev.c b/drivers/gpu/drm/i915/intel_fbdev.c
index 895fcb4..39eac99 100644
--- a/drivers/gpu/drm/i915/intel_fbdev.c
+++ b/drivers/gpu/drm/i915/intel_fbdev.c
@@ -57,18 +57,14 @@ static struct fb_ops intelfb_ops = {
  .fb_debug_leave = drm_fb_helper_debug_leave,
 };
 
-static int intelfb_create(struct drm_fb_helper *helper,
-     struct drm_fb_helper_surface_size *sizes)
+static int intelfb_alloc(struct drm_fb_helper *helper,
+    struct drm_fb_helper_surface_size *sizes)
 {
  struct intel_fbdev *ifbdev =
   container_of(helper, struct intel_fbdev, helper);
  struct drm_device *dev = helper->dev;
- struct drm_i915_private *dev_priv = dev->dev_private;
- struct fb_info *info;
- struct drm_framebuffer *fb;
  struct drm_mode_fb_cmd2 mode_cmd = {};
  struct drm_i915_gem_object *obj;
- struct device *device = &dev->pdev->dev;
  int size, ret;
 
  /* we don't do packed 24bpp */
@@ -94,8 +90,6 @@ static int intelfb_create(struct drm_fb_helper *helper,
   goto out;
  }
 
- mutex_lock(&dev->struct_mutex);
-
  /* Flush everything out, we'll be doing GTT only from now on */
  ret = intel_pin_and_fence_fb_obj(dev, obj, NULL);
  if (ret) {
@@ -103,7 +97,50 @@ static int intelfb_create(struct drm_fb_helper *helper,
   goto out_unref;
  }
 
- info = framebuffer_alloc(0, device);
+ ret = intel_framebuffer_init(dev, &ifbdev->ifb, &mode_cmd, obj);
+ if (ret)
+  goto out_unpin;
+
+ return 0;
+
+out_unpin:
+ i915_gem_object_unpin(obj);
+out_unref:
+ drm_gem_object_unreference(&obj->base);
+out:
+ return ret;
+}
+
+static int intelfb_create(struct drm_fb_helper *helper,
+     struct drm_fb_helper_surface_size *sizes)
+{
+ struct intel_fbdev *ifbdev =
+  container_of(helper, struct intel_fbdev, helper);
+ struct intel_framebuffer *intel_fb = &ifbdev->ifb;
+ struct drm_device *dev = helper->dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct fb_info *info;
+ struct drm_framebuffer *fb;
+ struct drm_i915_gem_object *obj;
+ int size, ret;
+
+ mutex_lock(&dev->struct_mutex);
+
+ if (!intel_fb->obj) {
+  DRM_DEBUG_KMS("no BIOS fb, allocating a new one\n");
+  ret = intelfb_alloc(helper, sizes);
+  if (ret)
+   goto out_unlock;
+ } else {
+  DRM_DEBUG_KMS("re-using BIOS fb\n");
+  sizes->fb_width = intel_fb->base.width;
+  sizes->fb_height = intel_fb->base.height;
+ }
+
+ obj = intel_fb->obj;
+ size = obj->base.size;
+
+ info = framebuffer_alloc(0, &dev->pdev->dev);
  if (!info) {
   ret = -ENOMEM;
   goto out_unpin;
@@ -111,10 +148,6 @@ static int intelfb_create(struct drm_fb_helper *helper,
 
  info->par = helper;
 
- ret = intel_framebuffer_init(dev, &ifbdev->ifb, &mode_cmd, obj);
- if (ret)
-  goto out_unpin;
-
  fb = &ifbdev->ifb.base;
 
  ifbdev->helper.fb = fb;
@@ -170,17 +203,15 @@ static int intelfb_create(struct drm_fb_helper *helper,
         fb->width, fb->height,
         i915_gem_obj_ggtt_offset(obj), obj);
 
-
  mutex_unlock(&dev->struct_mutex);
  vga_switcheroo_client_fb_set(dev->pdev, info);
  return 0;
 
 out_unpin:
  i915_gem_object_unpin(obj);
-out_unref:
  drm_gem_object_unreference(&obj->base);
+out_unlock:
  mutex_unlock(&dev->struct_mutex);
-out:
  return ret;
 }
 
@@ -297,8 +328,6 @@ void intel_fbdev_set_suspend(struct drm_device *dev, int state)
  fb_set_suspend(info, state);
 }
 
-MODULE_LICENSE("GPL and additional rights");
-
 void intel_fbdev_output_poll_changed(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
diff --git a/drivers/gpu/drm/i915/intel_hdmi.c b/drivers/gpu/drm/i915/intel_hdmi.c
index bb850b3..ee3181e 100644
--- a/drivers/gpu/drm/i915/intel_hdmi.c
+++ b/drivers/gpu/drm/i915/intel_hdmi.c
@@ -130,9 +130,9 @@ static u32 hsw_infoframe_data_reg(enum hdmi_infoframe_type type,
 
 static void g4x_write_infoframe(struct drm_encoder *encoder,
     enum hdmi_infoframe_type type,
-    const uint8_t *frame, ssize_t len)
+    const void *frame, ssize_t len)
 {
- uint32_t *data = (uint32_t *)frame;
+ const uint32_t *data = frame;
  struct drm_device *dev = encoder->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
  u32 val = I915_READ(VIDEO_DIP_CTL);
@@ -167,9 +167,9 @@ static void g4x_write_infoframe(struct drm_encoder *encoder,
 
 static void ibx_write_infoframe(struct drm_encoder *encoder,
     enum hdmi_infoframe_type type,
-    const uint8_t *frame, ssize_t len)
+    const void *frame, ssize_t len)
 {
- uint32_t *data = (uint32_t *)frame;
+ const uint32_t *data = frame;
  struct drm_device *dev = encoder->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc = to_intel_crtc(encoder->crtc);
@@ -205,9 +205,9 @@ static void ibx_write_infoframe(struct drm_encoder *encoder,
 
 static void cpt_write_infoframe(struct drm_encoder *encoder,
     enum hdmi_infoframe_type type,
-    const uint8_t *frame, ssize_t len)
+    const void *frame, ssize_t len)
 {
- uint32_t *data = (uint32_t *)frame;
+ const uint32_t *data = frame;
  struct drm_device *dev = encoder->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc = to_intel_crtc(encoder->crtc);
@@ -246,9 +246,9 @@ static void cpt_write_infoframe(struct drm_encoder *encoder,
 
 static void vlv_write_infoframe(struct drm_encoder *encoder,
     enum hdmi_infoframe_type type,
-    const uint8_t *frame, ssize_t len)
+    const void *frame, ssize_t len)
 {
- uint32_t *data = (uint32_t *)frame;
+ const uint32_t *data = frame;
  struct drm_device *dev = encoder->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc = to_intel_crtc(encoder->crtc);
@@ -284,9 +284,9 @@ static void vlv_write_infoframe(struct drm_encoder *encoder,
 
 static void hsw_write_infoframe(struct drm_encoder *encoder,
     enum hdmi_infoframe_type type,
-    const uint8_t *frame, ssize_t len)
+    const void *frame, ssize_t len)
 {
- uint32_t *data = (uint32_t *)frame;
+ const uint32_t *data = frame;
  struct drm_device *dev = encoder->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc = to_intel_crtc(encoder->crtc);
@@ -853,8 +853,9 @@ static int hdmi_portclock_limit(struct intel_hdmi *hdmi)
   return 225000;
 }
 
-static int intel_hdmi_mode_valid(struct drm_connector *connector,
-     struct drm_display_mode *mode)
+static enum drm_mode_status
+intel_hdmi_mode_valid(struct drm_connector *connector,
+        struct drm_display_mode *mode)
 {
  if (mode->clock > hdmi_portclock_limit(intel_attached_hdmi(connector)))
   return MODE_CLOCK_HIGH;
@@ -1081,7 +1082,7 @@ static void vlv_hdmi_pre_enable(struct intel_encoder *encoder)
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc =
   to_intel_crtc(encoder->base.crtc);
- int port = vlv_dport_to_channel(dport);
+ enum dpio_channel port = vlv_dport_to_channel(dport);
  int pipe = intel_crtc->pipe;
  u32 val;
 
@@ -1090,41 +1091,33 @@ static void vlv_hdmi_pre_enable(struct intel_encoder *encoder)
 
  /* Enable clock channels for this port */
  mutex_lock(&dev_priv->dpio_lock);
- val = vlv_dpio_read(dev_priv, pipe, DPIO_DATA_LANE_A(port));
+ val = vlv_dpio_read(dev_priv, pipe, VLV_PCS01_DW8(port));
  val = 0;
  if (pipe)
   val |= (1<<21);
  else
   val &= ~(1<<21);
  val |= 0x001000c4;
- vlv_dpio_write(dev_priv, pipe, DPIO_DATA_CHANNEL(port), val);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW8(port), val);
 
  /* HDMI 1.0V-2dB */
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_OCALINIT(port), 0);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_SWING_CTL4(port),
-    0x2b245f5f);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_SWING_CTL2(port),
-    0x5578b83a);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_SWING_CTL3(port),
-    0x0c782040);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX3_SWING_CTL4(port),
-    0x2b247878);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_STAGGER0(port), 0x00030000);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CTL_OVER1(port),
-    0x00002000);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_OCALINIT(port),
-    DPIO_TX_OCALINIT_EN);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW5(port), 0);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW4(port), 0x2b245f5f);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW2(port), 0x5578b83a);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW3(port), 0x0c782040);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX3_DW4(port), 0x2b247878);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW11(port), 0x00030000);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW9(port), 0x00002000);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW5(port), DPIO_TX_OCALINIT_EN);
 
  /* Program lane clock */
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CLOCKBUF0(port),
-    0x00760018);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CLOCKBUF8(port),
-    0x00400888);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW14(port), 0x00760018);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW23(port), 0x00400888);
  mutex_unlock(&dev_priv->dpio_lock);
 
  intel_enable_hdmi(encoder);
 
- vlv_wait_port_ready(dev_priv, port);
+ vlv_wait_port_ready(dev_priv, dport);
 }
 
 static void vlv_hdmi_pre_pll_enable(struct intel_encoder *encoder)
@@ -1134,7 +1127,7 @@ static void vlv_hdmi_pre_pll_enable(struct intel_encoder *encoder)
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_crtc *intel_crtc =
   to_intel_crtc(encoder->base.crtc);
- int port = vlv_dport_to_channel(dport);
+ enum dpio_channel port = vlv_dport_to_channel(dport);
  int pipe = intel_crtc->pipe;
 
  if (!IS_VALLEYVIEW(dev))
@@ -1142,24 +1135,22 @@ static void vlv_hdmi_pre_pll_enable(struct intel_encoder *encoder)
 
  /* Program Tx lane resets to default */
  mutex_lock(&dev_priv->dpio_lock);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_TX(port),
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW0(port),
     DPIO_PCS_TX_LANE2_RESET |
     DPIO_PCS_TX_LANE1_RESET);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CLK(port),
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW1(port),
     DPIO_PCS_CLK_CRI_RXEB_EIOS_EN |
     DPIO_PCS_CLK_CRI_RXDIGFILTSG_EN |
     (1<<DPIO_PCS_CLK_DATAWIDTH_SHIFT) |
     DPIO_PCS_CLK_SOFT_RESET);
 
  /* Fix up inter-pair skew failure */
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_STAGGER1(port), 0x00750f00);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_CTL(port), 0x00001500);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_LANE(port), 0x40400000);
-
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CTL_OVER1(port),
-    0x00002000);
- vlv_dpio_write(dev_priv, pipe, DPIO_TX_OCALINIT(port),
-    DPIO_TX_OCALINIT_EN);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW12(port), 0x00750f00);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW11(port), 0x00001500);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW14(port), 0x40400000);
+
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW9(port), 0x00002000);
+ vlv_dpio_write(dev_priv, pipe, VLV_TX_DW5(port), DPIO_TX_OCALINIT_EN);
  mutex_unlock(&dev_priv->dpio_lock);
 }
 
@@ -1169,13 +1160,13 @@ static void vlv_hdmi_post_disable(struct intel_encoder *encoder)
  struct drm_i915_private *dev_priv = encoder->base.dev->dev_private;
  struct intel_crtc *intel_crtc =
   to_intel_crtc(encoder->base.crtc);
- int port = vlv_dport_to_channel(dport);
+ enum dpio_channel port = vlv_dport_to_channel(dport);
  int pipe = intel_crtc->pipe;
 
  /* Reset lanes to avoid HDMI flicker (VLV w/a) */
  mutex_lock(&dev_priv->dpio_lock);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_TX(port), 0x00000000);
- vlv_dpio_write(dev_priv, pipe, DPIO_PCS_CLK(port), 0x00e00060);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW0(port), 0x00000000);
+ vlv_dpio_write(dev_priv, pipe, VLV_PCS_DW1(port), 0x00e00060);
  mutex_unlock(&dev_priv->dpio_lock);
 }
 
diff --git a/drivers/gpu/drm/i915/intel_i2c.c b/drivers/gpu/drm/i915/intel_i2c.c
index 2ca17b1..d33b61d 100644
--- a/drivers/gpu/drm/i915/intel_i2c.c
+++ b/drivers/gpu/drm/i915/intel_i2c.c
@@ -82,20 +82,11 @@ static int get_disp_clk_div(struct drm_i915_private *dev_priv,
 
 static void gmbus_set_freq(struct drm_i915_private *dev_priv)
 {
- int vco_freq[] = { 800, 1600, 2000, 2400 };
- int gmbus_freq = 0, cdclk_div, hpll_freq;
+ int vco, gmbus_freq = 0, cdclk_div;
 
  BUG_ON(!IS_VALLEYVIEW(dev_priv->dev));
 
- /* Skip setting the gmbus freq if BIOS has already programmed it */
- if (I915_READ(GMBUSFREQ_VLV) != 0xA0)
-  return;
-
- /* Obtain SKU information */
- mutex_lock(&dev_priv->dpio_lock);
- hpll_freq =
-  vlv_cck_read(dev_priv, CCK_FUSE_REG) & CCK_FUSE_HPLL_FREQ_MASK;
- mutex_unlock(&dev_priv->dpio_lock);
+ vco = valleyview_get_vco(dev_priv);
 
  /* Get the CDCLK divide ratio */
  cdclk_div = get_disp_clk_div(dev_priv, CDCLK);
@@ -106,7 +97,7 @@ static void gmbus_set_freq(struct drm_i915_private *dev_priv)
   * in fact 1MHz is the correct frequency.
   */
  if (cdclk_div)
-  gmbus_freq = (vco_freq[hpll_freq] << 1) / cdclk_div;
+  gmbus_freq = (vco << 1) / cdclk_div;
 
  if (WARN_ON(gmbus_freq == 0))
   return;
@@ -267,13 +258,6 @@ intel_gpio_setup(struct intel_gmbus *bus, u32 pin)
  algo->data = bus;
 }
 
-/*
- * gmbus on gen4 seems to be able to generate legacy interrupts even when in MSI
- * mode. This results in spurious interrupt warnings if the legacy irq no. is
- * shared with another device. The kernel then disables that interrupt source
- * and so prevents the other device from working properly.
- */
-#define HAS_GMBUS_IRQ(dev) (INTEL_INFO(dev)->gen >= 5)
 static int
 gmbus_wait_hw_status(struct drm_i915_private *dev_priv,
        u32 gmbus2_status,
diff --git a/drivers/gpu/drm/i915/intel_lvds.c b/drivers/gpu/drm/i915/intel_lvds.c
index c3b4da7..8bcb93a 100644
--- a/drivers/gpu/drm/i915/intel_lvds.c
+++ b/drivers/gpu/drm/i915/intel_lvds.c
@@ -256,8 +256,9 @@ static void intel_disable_lvds(struct intel_encoder *encoder)
  POSTING_READ(lvds_encoder->reg);
 }
 
-static int intel_lvds_mode_valid(struct drm_connector *connector,
-     struct drm_display_mode *mode)
+static enum drm_mode_status
+intel_lvds_mode_valid(struct drm_connector *connector,
+        struct drm_display_mode *mode)
 {
  struct intel_connector *intel_connector = to_intel_connector(connector);
  struct drm_display_mode *fixed_mode = intel_connector->panel.fixed_mode;
@@ -446,9 +447,19 @@ static int intel_lid_notify(struct notifier_block *nb, unsigned long val,
  if (dev_priv->modeset_restore == MODESET_DONE)
   goto exit;
 
- drm_modeset_lock_all(dev);
- intel_modeset_setup_hw_state(dev, true);
- drm_modeset_unlock_all(dev);
+ /*
+  * Some old platform's BIOS love to wreak havoc while the lid is closed.
+  * We try to detect this here and undo any damage. The split for PCH
+  * platforms is rather conservative and a bit arbitrary expect that on
+  * those platforms VGA disabling requires actual legacy VGA I/O access,
+  * and as part of the cleanup in the hw state restore we also redisable
+  * the vga plane.
+  */
+ if (!HAS_PCH_SPLIT(dev)) {
+  drm_modeset_lock_all(dev);
+  intel_modeset_setup_hw_state(dev, true);
+  drm_modeset_unlock_all(dev);
+ }
 
  dev_priv->modeset_restore = MODESET_DONE;
 
@@ -744,57 +755,6 @@ static const struct dmi_system_id intel_no_lvds[] = {
  { } /* terminating entry */
 };
 
-/**
- * intel_find_lvds_downclock - find the reduced downclock for LVDS in EDID
- * @dev: drm device
- * @connector: LVDS connector
- *
- * Find the reduced downclock for LVDS in EDID.
- */
-static void intel_find_lvds_downclock(struct drm_device *dev,
-          struct drm_display_mode *fixed_mode,
-          struct drm_connector *connector)
-{
- struct drm_i915_private *dev_priv = dev->dev_private;
- struct drm_display_mode *scan;
- int temp_downclock;
-
- temp_downclock = fixed_mode->clock;
- list_for_each_entry(scan, &connector->probed_modes, head) {
-  /*
-   * If one mode has the same resolution with the fixed_panel
-   * mode while they have the different refresh rate, it means
-   * that the reduced downclock is found for the LVDS. In such
-   * case we can set the different FPx0/1 to dynamically select
-   * between low and high frequency.
-   */
-  if (scan->hdisplay == fixed_mode->hdisplay &&
-      scan->hsync_start == fixed_mode->hsync_start &&
-      scan->hsync_end == fixed_mode->hsync_end &&
-      scan->htotal == fixed_mode->htotal &&
-      scan->vdisplay == fixed_mode->vdisplay &&
-      scan->vsync_start == fixed_mode->vsync_start &&
-      scan->vsync_end == fixed_mode->vsync_end &&
-      scan->vtotal == fixed_mode->vtotal) {
-   if (scan->clock < temp_downclock) {
-    /*
-     * The downclock is already found. But we
-     * expect to find the lower downclock.
-     */
-    temp_downclock = scan->clock;
-   }
-  }
- }
- if (temp_downclock < fixed_mode->clock && i915_lvds_downclock) {
-  /* We found the downclock for LVDS. */
-  dev_priv->lvds_downclock_avail = 1;
-  dev_priv->lvds_downclock = temp_downclock;
-  DRM_DEBUG_KMS("LVDS downclock is found in EDID. "
-         "Normal clock %dKhz, downclock %dKhz\n",
-         fixed_mode->clock, temp_downclock);
- }
-}
-
 /*
  * Enumerate the child dev array parsed from VBT to check whether
  * the LVDS is present.
@@ -1072,8 +1032,22 @@ void intel_lvds_init(struct drm_device *dev)
 
    fixed_mode = drm_mode_duplicate(dev, scan);
    if (fixed_mode) {
-    intel_find_lvds_downclock(dev, fixed_mode,
-         connector);
+    intel_connector->panel.downclock_mode =
+     intel_find_panel_downclock(dev,
+     fixed_mode, connector);
+    if (intel_connector->panel.downclock_mode !=
+     NULL && i915_lvds_downclock) {
+     /* We found the downclock for LVDS. */
+     dev_priv->lvds_downclock_avail = true;
+     dev_priv->lvds_downclock =
+      intel_connector->panel.
+      downclock_mode->clock;
+     DRM_DEBUG_KMS("LVDS downclock is found"
+     " in EDID. Normal clock %dKhz, "
+     "downclock %dKhz\n",
+     fixed_mode->clock,
+     dev_priv->lvds_downclock);
+    }
     goto out;
    }
   }
diff --git a/drivers/gpu/drm/i915/intel_opregion.c b/drivers/gpu/drm/i915/intel_opregion.c
index 6d69a9b..5e907ad 100644
--- a/drivers/gpu/drm/i915/intel_opregion.c
+++ b/drivers/gpu/drm/i915/intel_opregion.c
@@ -64,7 +64,7 @@ struct opregion_header {
  u8 driver_ver[16];
  u32 mboxes;
  u8 reserved[164];
-} __attribute__((packed));
+} __packed;
 
 /* OpRegion mailbox #1: public ACPI methods */
 struct opregion_acpi {
@@ -86,7 +86,7 @@ struct opregion_acpi {
  u32 cnot;       /* current OS notification */
  u32 nrdy;       /* driver status */
  u8 rsvd2[60];
-} __attribute__((packed));
+} __packed;
 
 /* OpRegion mailbox #2: SWSCI */
 struct opregion_swsci {
@@ -94,7 +94,7 @@ struct opregion_swsci {
  u32 parm;       /* command parameters */
  u32 dslp;       /* driver sleep time-out */
  u8 rsvd[244];
-} __attribute__((packed));
+} __packed;
 
 /* OpRegion mailbox #3: ASLE */
 struct opregion_asle {
@@ -115,7 +115,7 @@ struct opregion_asle {
  u32 srot;       /* supported rotation angles */
  u32 iuer;       /* IUER events */
  u8 rsvd[86];
-} __attribute__((packed));
+} __packed;
 
 /* Driver readiness indicator */
 #define ASLE_ARDY_READY  (1 << 0)
diff --git a/drivers/gpu/drm/i915/intel_overlay.c b/drivers/gpu/drm/i915/intel_overlay.c
index a98a990..a759ecd 100644
--- a/drivers/gpu/drm/i915/intel_overlay.c
+++ b/drivers/gpu/drm/i915/intel_overlay.c
@@ -1005,7 +1005,7 @@ static int intel_panel_fitter_pipe(struct drm_device *dev)
  u32  pfit_control;
 
  /* i830 doesn't have a panel fitter */
- if (IS_I830(dev))
+ if (INTEL_INFO(dev)->gen <= 3 && (IS_I830(dev) || !IS_MOBILE(dev)))
   return -1;
 
  pfit_control = I915_READ(PFIT_CONTROL);
diff --git a/drivers/gpu/drm/i915/intel_panel.c b/drivers/gpu/drm/i915/intel_panel.c
index e6f782d..079ea38 100644
--- a/drivers/gpu/drm/i915/intel_panel.c
+++ b/drivers/gpu/drm/i915/intel_panel.c
@@ -325,214 +325,170 @@ out:
  pipe_config->gmch_pfit.lvds_border_bits = border;
 }
 
-static int is_backlight_combination_mode(struct drm_device *dev)
+static int i915_panel_invert_brightness;
+MODULE_PARM_DESC(invert_brightness, "Invert backlight brightness "
+ "(-1 force normal, 0 machine defaults, 1 force inversion), please "
+ "report PCI device ID, subsystem vendor and subsystem device ID "
+ "to dri-devel@lists.freedesktop.org, if your machine needs it. "
+ "It will then be included in an upcoming module version.");
+module_param_named(invert_brightness, i915_panel_invert_brightness, int, 0600);
+static u32 intel_panel_compute_brightness(struct intel_connector *connector,
+       u32 val)
 {
+ struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
 
- if (IS_GEN4(dev))
-  return I915_READ(BLC_PWM_CTL2) & BLM_COMBINATION_MODE;
+ WARN_ON(panel->backlight.max == 0);
+
+ if (i915_panel_invert_brightness < 0)
+  return val;
 
- if (IS_GEN2(dev))
-  return I915_READ(BLC_PWM_CTL) & BLM_LEGACY_MODE;
+ if (i915_panel_invert_brightness > 0 ||
+     dev_priv->quirks & QUIRK_INVERT_BRIGHTNESS) {
+  return panel->backlight.max - val;
+ }
 
- return 0;
+ return val;
 }
 
-/* XXX: query mode clock or hardware clock and program max PWM appropriately
- * when it's 0.
- */
-static u32 i915_read_blc_pwm_ctl(struct drm_device *dev, enum pipe pipe)
+static u32 bdw_get_backlight(struct intel_connector *connector)
 {
+ struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
- u32 val;
-
- WARN_ON_SMP(!spin_is_locked(&dev_priv->backlight.lock));
 
- /* Restore the CTL value if it lost, e.g. GPU reset */
-
- if (HAS_PCH_SPLIT(dev_priv->dev)) {
-  val = I915_READ(BLC_PWM_PCH_CTL2);
-  if (dev_priv->regfile.saveBLC_PWM_CTL2 == 0) {
-   dev_priv->regfile.saveBLC_PWM_CTL2 = val;
-  } else if (val == 0) {
-   val = dev_priv->regfile.saveBLC_PWM_CTL2;
-   I915_WRITE(BLC_PWM_PCH_CTL2, val);
-  }
- } else if (IS_VALLEYVIEW(dev)) {
-  val = I915_READ(VLV_BLC_PWM_CTL(pipe));
-  if (dev_priv->regfile.saveBLC_PWM_CTL == 0) {
-   dev_priv->regfile.saveBLC_PWM_CTL = val;
-   dev_priv->regfile.saveBLC_PWM_CTL2 =
-    I915_READ(VLV_BLC_PWM_CTL2(pipe));
-  } else if (val == 0) {
-   val = dev_priv->regfile.saveBLC_PWM_CTL;
-   I915_WRITE(VLV_BLC_PWM_CTL(pipe), val);
-   I915_WRITE(VLV_BLC_PWM_CTL2(pipe),
-       dev_priv->regfile.saveBLC_PWM_CTL2);
-  }
+ return I915_READ(BLC_PWM_PCH_CTL2) & BACKLIGHT_DUTY_CYCLE_MASK;
+}
 
-  if (!val)
-   val = 0x0f42ffff;
- } else {
-  val = I915_READ(BLC_PWM_CTL);
-  if (dev_priv->regfile.saveBLC_PWM_CTL == 0) {
-   dev_priv->regfile.saveBLC_PWM_CTL = val;
-   if (INTEL_INFO(dev)->gen >= 4)
-    dev_priv->regfile.saveBLC_PWM_CTL2 =
-     I915_READ(BLC_PWM_CTL2);
-  } else if (val == 0) {
-   val = dev_priv->regfile.saveBLC_PWM_CTL;
-   I915_WRITE(BLC_PWM_CTL, val);
-   if (INTEL_INFO(dev)->gen >= 4)
-    I915_WRITE(BLC_PWM_CTL2,
-        dev_priv->regfile.saveBLC_PWM_CTL2);
-  }
- }
+static u32 pch_get_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
 
- return val;
+ return I915_READ(BLC_PWM_CPU_CTL) & BACKLIGHT_DUTY_CYCLE_MASK;
 }
 
-static u32 intel_panel_get_max_backlight(struct drm_device *dev,
-      enum pipe pipe)
+static u32 i9xx_get_backlight(struct intel_connector *connector)
 {
- u32 max;
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ u32 val;
 
- max = i915_read_blc_pwm_ctl(dev, pipe);
+ val = I915_READ(BLC_PWM_CTL) & BACKLIGHT_DUTY_CYCLE_MASK;
+ if (INTEL_INFO(dev)->gen < 4)
+  val >>= 1;
 
- if (HAS_PCH_SPLIT(dev)) {
-  max >>= 16;
- } else {
-  if (INTEL_INFO(dev)->gen < 4)
-   max >>= 17;
-  else
-   max >>= 16;
+ if (panel->backlight.combination_mode) {
+  u8 lbpc;
 
-  if (is_backlight_combination_mode(dev))
-   max *= 0xff;
+  pci_read_config_byte(dev->pdev, PCI_LBPC, &lbpc);
+  val *= lbpc;
  }
 
- DRM_DEBUG_DRIVER("max backlight PWM = %d\n", max);
-
- return max;
+ return val;
 }
 
-static int i915_panel_invert_brightness;
-MODULE_PARM_DESC(invert_brightness, "Invert backlight brightness "
- "(-1 force normal, 0 machine defaults, 1 force inversion), please "
- "report PCI device ID, subsystem vendor and subsystem device ID "
- "to dri-devel@lists.freedesktop.org, if your machine needs it. "
- "It will then be included in an upcoming module version.");
-module_param_named(invert_brightness, i915_panel_invert_brightness, int, 0600);
-static u32 intel_panel_compute_brightness(struct drm_device *dev,
-       enum pipe pipe, u32 val)
+static u32 _vlv_get_backlight(struct drm_device *dev, enum pipe pipe)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
 
- if (i915_panel_invert_brightness < 0)
-  return val;
+ return I915_READ(VLV_BLC_PWM_CTL(pipe)) & BACKLIGHT_DUTY_CYCLE_MASK;
+}
 
- if (i915_panel_invert_brightness > 0 ||
-     dev_priv->quirks & QUIRK_INVERT_BRIGHTNESS) {
-  u32 max = intel_panel_get_max_backlight(dev, pipe);
-  if (max)
-   return max - val;
- }
+static u32 vlv_get_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ enum pipe pipe = intel_get_pipe_from_connector(connector);
 
- return val;
+ return _vlv_get_backlight(dev, pipe);
 }
 
-static u32 intel_panel_get_backlight(struct drm_device *dev,
-         enum pipe pipe)
+static u32 intel_panel_get_backlight(struct intel_connector *connector)
 {
+ struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
  u32 val;
  unsigned long flags;
- int reg;
-
- spin_lock_irqsave(&dev_priv->backlight.lock, flags);
-
- if (IS_BROADWELL(dev)) {
-  val = I915_READ(BLC_PWM_PCH_CTL2) & BACKLIGHT_DUTY_CYCLE_MASK;
- } else if (HAS_PCH_SPLIT(dev)) {
-  val = I915_READ(BLC_PWM_CPU_CTL) & BACKLIGHT_DUTY_CYCLE_MASK;
- } else {
-  if (IS_VALLEYVIEW(dev))
-   reg = VLV_BLC_PWM_CTL(pipe);
-  else
-   reg = BLC_PWM_CTL;
-
-  val = I915_READ(reg) & BACKLIGHT_DUTY_CYCLE_MASK;
-  if (INTEL_INFO(dev)->gen < 4)
-   val >>= 1;
 
-  if (is_backlight_combination_mode(dev)) {
-   u8 lbpc;
-
-   pci_read_config_byte(dev->pdev, PCI_LBPC, &lbpc);
-   val *= lbpc;
-  }
- }
+ spin_lock_irqsave(&dev_priv->backlight_lock, flags);
 
- val = intel_panel_compute_brightness(dev, pipe, val);
+ val = dev_priv->display.get_backlight(connector);
+ val = intel_panel_compute_brightness(connector, val);
 
- spin_unlock_irqrestore(&dev_priv->backlight.lock, flags);
+ spin_unlock_irqrestore(&dev_priv->backlight_lock, flags);
 
  DRM_DEBUG_DRIVER("get backlight PWM = %d\n", val);
  return val;
 }
 
-static void intel_bdw_panel_set_backlight(struct drm_device *dev, u32 level)
+static void bdw_set_backlight(struct intel_connector *connector, u32 level)
 {
+ struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
  u32 val = I915_READ(BLC_PWM_PCH_CTL2) & ~BACKLIGHT_DUTY_CYCLE_MASK;
  I915_WRITE(BLC_PWM_PCH_CTL2, val | level);
 }
 
-static void intel_pch_panel_set_backlight(struct drm_device *dev, u32 level)
+static void pch_set_backlight(struct intel_connector *connector, u32 level)
 {
+ struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
- u32 val = I915_READ(BLC_PWM_CPU_CTL) & ~BACKLIGHT_DUTY_CYCLE_MASK;
- I915_WRITE(BLC_PWM_CPU_CTL, val | level);
+ u32 tmp;
+
+ tmp = I915_READ(BLC_PWM_CPU_CTL) & ~BACKLIGHT_DUTY_CYCLE_MASK;
+ I915_WRITE(BLC_PWM_CPU_CTL, tmp | level);
 }
 
-static void intel_panel_actually_set_backlight(struct drm_device *dev,
-            enum pipe pipe, u32 level)
+static void i9xx_set_backlight(struct intel_connector *connector, u32 level)
 {
+ struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
- u32 tmp;
- int reg;
+ struct intel_panel *panel = &connector->panel;
+ u32 tmp, mask;
 
- DRM_DEBUG_DRIVER("set backlight PWM = %d\n", level);
- level = intel_panel_compute_brightness(dev, pipe, level);
+ WARN_ON(panel->backlight.max == 0);
 
- if (IS_BROADWELL(dev))
-  return intel_bdw_panel_set_backlight(dev, level);
- else if (HAS_PCH_SPLIT(dev))
-  return intel_pch_panel_set_backlight(dev, level);
-
- if (is_backlight_combination_mode(dev)) {
-  u32 max = intel_panel_get_max_backlight(dev, pipe);
+ if (panel->backlight.combination_mode) {
   u8 lbpc;
 
-  /* we're screwed, but keep behaviour backwards compatible */
-  if (!max)
-   max = 1;
-
-  lbpc = level * 0xfe / max + 1;
+  lbpc = level * 0xfe / panel->backlight.max + 1;
   level /= lbpc;
   pci_write_config_byte(dev->pdev, PCI_LBPC, lbpc);
  }
 
- if (IS_VALLEYVIEW(dev))
-  reg = VLV_BLC_PWM_CTL(pipe);
- else
-  reg = BLC_PWM_CTL;
-
- tmp = I915_READ(reg);
- if (INTEL_INFO(dev)->gen < 4)
+ if (IS_GEN4(dev)) {
+  mask = BACKLIGHT_DUTY_CYCLE_MASK;
+ } else {
   level <<= 1;
- tmp &= ~BACKLIGHT_DUTY_CYCLE_MASK;
- I915_WRITE(reg, tmp | level);
+  mask = BACKLIGHT_DUTY_CYCLE_MASK_PNV;
+ }
+
+ tmp = I915_READ(BLC_PWM_CTL) & ~mask;
+ I915_WRITE(BLC_PWM_CTL, tmp | level);
+}
+
+static void vlv_set_backlight(struct intel_connector *connector, u32 level)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ enum pipe pipe = intel_get_pipe_from_connector(connector);
+ u32 tmp;
+
+ tmp = I915_READ(VLV_BLC_PWM_CTL(pipe)) & ~BACKLIGHT_DUTY_CYCLE_MASK;
+ I915_WRITE(VLV_BLC_PWM_CTL(pipe), tmp | level);
+}
+
+static void
+intel_panel_actually_set_backlight(struct intel_connector *connector, u32 level)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+
+ DRM_DEBUG_DRIVER("set backlight PWM = %d\n", level);
+
+ level = intel_panel_compute_brightness(connector, level);
+ dev_priv->display.set_backlight(connector, level);
 }
 
 /* set backlight brightness to level in range [0..max] */
@@ -541,45 +497,89 @@ void intel_panel_set_backlight(struct intel_connector *connector, u32 level,
 {
  struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
  enum pipe pipe = intel_get_pipe_from_connector(connector);
  u32 freq;
  unsigned long flags;
 
- if (pipe == INVALID_PIPE)
+ if (!panel->backlight.present || pipe == INVALID_PIPE)
   return;
 
- spin_lock_irqsave(&dev_priv->backlight.lock, flags);
+ spin_lock_irqsave(&dev_priv->backlight_lock, flags);
 
- freq = intel_panel_get_max_backlight(dev, pipe);
- if (!freq) {
-  /* we are screwed, bail out */
-  goto out;
- }
+ WARN_ON(panel->backlight.max == 0);
 
- /* scale to hardware, but be careful to not overflow */
+ /* scale to hardware max, but be careful to not overflow */
+ freq = panel->backlight.max;
  if (freq < max)
   level = level * freq / max;
  else
   level = freq / max * level;
 
- dev_priv->backlight.level = level;
- if (dev_priv->backlight.device)
-  dev_priv->backlight.device->props.brightness = level;
+ panel->backlight.level = level;
+ if (panel->backlight.device)
+  panel->backlight.device->props.brightness = level;
 
- if (dev_priv->backlight.enabled)
-  intel_panel_actually_set_backlight(dev, pipe, level);
-out:
- spin_unlock_irqrestore(&dev_priv->backlight.lock, flags);
+ if (panel->backlight.enabled)
+  intel_panel_actually_set_backlight(connector, level);
+
+ spin_unlock_irqrestore(&dev_priv->backlight_lock, flags);
+}
+
+static void pch_disable_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ u32 tmp;
+
+ intel_panel_actually_set_backlight(connector, 0);
+
+ tmp = I915_READ(BLC_PWM_CPU_CTL2);
+ I915_WRITE(BLC_PWM_CPU_CTL2, tmp & ~BLM_PWM_ENABLE);
+
+ tmp = I915_READ(BLC_PWM_PCH_CTL1);
+ I915_WRITE(BLC_PWM_PCH_CTL1, tmp & ~BLM_PCH_PWM_ENABLE);
+}
+
+static void i9xx_disable_backlight(struct intel_connector *connector)
+{
+ intel_panel_actually_set_backlight(connector, 0);
+}
+
+static void i965_disable_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ u32 tmp;
+
+ intel_panel_actually_set_backlight(connector, 0);
+
+ tmp = I915_READ(BLC_PWM_CTL2);
+ I915_WRITE(BLC_PWM_CTL2, tmp & ~BLM_PWM_ENABLE);
+}
+
+static void vlv_disable_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ enum pipe pipe = intel_get_pipe_from_connector(connector);
+ u32 tmp;
+
+ intel_panel_actually_set_backlight(connector, 0);
+
+ tmp = I915_READ(VLV_BLC_PWM_CTL2(pipe));
+ I915_WRITE(VLV_BLC_PWM_CTL2(pipe), tmp & ~BLM_PWM_ENABLE);
 }
 
 void intel_panel_disable_backlight(struct intel_connector *connector)
 {
  struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
  enum pipe pipe = intel_get_pipe_from_connector(connector);
  unsigned long flags;
 
- if (pipe == INVALID_PIPE)
+ if (!panel->backlight.present || pipe == INVALID_PIPE)
   return;
 
  /*
@@ -593,150 +593,215 @@ void intel_panel_disable_backlight(struct intel_connector *connector)
   return;
  }
 
- spin_lock_irqsave(&dev_priv->backlight.lock, flags);
+ spin_lock_irqsave(&dev_priv->backlight_lock, flags);
 
- dev_priv->backlight.enabled = false;
- intel_panel_actually_set_backlight(dev, pipe, 0);
+ panel->backlight.enabled = false;
+ dev_priv->display.disable_backlight(connector);
 
- if (INTEL_INFO(dev)->gen >= 4) {
-  uint32_t reg, tmp;
+ spin_unlock_irqrestore(&dev_priv->backlight_lock, flags);
+}
 
-  if (HAS_PCH_SPLIT(dev))
-   reg = BLC_PWM_CPU_CTL2;
-  else if (IS_VALLEYVIEW(dev))
-   reg = VLV_BLC_PWM_CTL2(pipe);
-  else
-   reg = BLC_PWM_CTL2;
+static void bdw_enable_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ u32 pch_ctl1, pch_ctl2;
+
+ pch_ctl1 = I915_READ(BLC_PWM_PCH_CTL1);
+ if (pch_ctl1 & BLM_PCH_PWM_ENABLE) {
+  DRM_DEBUG_KMS("pch backlight already enabled\n");
+  pch_ctl1 &= ~BLM_PCH_PWM_ENABLE;
+  I915_WRITE(BLC_PWM_PCH_CTL1, pch_ctl1);
+ }
 
-  I915_WRITE(reg, I915_READ(reg) & ~BLM_PWM_ENABLE);
+ pch_ctl2 = panel->backlight.max << 16;
+ I915_WRITE(BLC_PWM_PCH_CTL2, pch_ctl2);
 
-  if (HAS_PCH_SPLIT(dev)) {
-   tmp = I915_READ(BLC_PWM_PCH_CTL1);
-   tmp &= ~BLM_PCH_PWM_ENABLE;
-   I915_WRITE(BLC_PWM_PCH_CTL1, tmp);
-  }
- }
+ pch_ctl1 = 0;
+ if (panel->backlight.active_low_pwm)
+  pch_ctl1 |= BLM_PCH_POLARITY;
+
+ /* BDW always uses the pch pwm controls. */
+ pch_ctl1 |= BLM_PCH_OVERRIDE_ENABLE;
 
- spin_unlock_irqrestore(&dev_priv->backlight.lock, flags);
+ I915_WRITE(BLC_PWM_PCH_CTL1, pch_ctl1);
+ POSTING_READ(BLC_PWM_PCH_CTL1);
+ I915_WRITE(BLC_PWM_PCH_CTL1, pch_ctl1 | BLM_PCH_PWM_ENABLE);
+
+ /* This won't stick until the above enable. */
+ intel_panel_actually_set_backlight(connector, panel->backlight.level);
 }
 
-void intel_panel_enable_backlight(struct intel_connector *connector)
+static void pch_enable_backlight(struct intel_connector *connector)
 {
  struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
  enum pipe pipe = intel_get_pipe_from_connector(connector);
  enum transcoder cpu_transcoder =
   intel_pipe_to_cpu_transcoder(dev_priv, pipe);
- unsigned long flags;
+ u32 cpu_ctl2, pch_ctl1, pch_ctl2;
 
- if (pipe == INVALID_PIPE)
-  return;
+ cpu_ctl2 = I915_READ(BLC_PWM_CPU_CTL2);
+ if (cpu_ctl2 & BLM_PWM_ENABLE) {
+  WARN(1, "cpu backlight already enabled\n");
+  cpu_ctl2 &= ~BLM_PWM_ENABLE;
+  I915_WRITE(BLC_PWM_CPU_CTL2, cpu_ctl2);
+ }
 
- DRM_DEBUG_KMS("pipe %c\n", pipe_name(pipe));
+ pch_ctl1 = I915_READ(BLC_PWM_PCH_CTL1);
+ if (pch_ctl1 & BLM_PCH_PWM_ENABLE) {
+  DRM_DEBUG_KMS("pch backlight already enabled\n");
+  pch_ctl1 &= ~BLM_PCH_PWM_ENABLE;
+  I915_WRITE(BLC_PWM_PCH_CTL1, pch_ctl1);
+ }
+
+ if (cpu_transcoder == TRANSCODER_EDP)
+  cpu_ctl2 = BLM_TRANSCODER_EDP;
+ else
+  cpu_ctl2 = BLM_PIPE(cpu_transcoder);
+ I915_WRITE(BLC_PWM_CPU_CTL2, cpu_ctl2);
+ POSTING_READ(BLC_PWM_CPU_CTL2);
+ I915_WRITE(BLC_PWM_CPU_CTL2, cpu_ctl2 | BLM_PWM_ENABLE);
+
+ /* This won't stick until the above enable. */
+ intel_panel_actually_set_backlight(connector, panel->backlight.level);
+
+ pch_ctl2 = panel->backlight.max << 16;
+ I915_WRITE(BLC_PWM_PCH_CTL2, pch_ctl2);
+
+ pch_ctl1 = 0;
+ if (panel->backlight.active_low_pwm)
+  pch_ctl1 |= BLM_PCH_POLARITY;
+
+ I915_WRITE(BLC_PWM_PCH_CTL1, pch_ctl1);
+ POSTING_READ(BLC_PWM_PCH_CTL1);
+ I915_WRITE(BLC_PWM_PCH_CTL1, pch_ctl1 | BLM_PCH_PWM_ENABLE);
+}
 
- spin_lock_irqsave(&dev_priv->backlight.lock, flags);
+static void i9xx_enable_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ u32 ctl, freq;
 
- if (dev_priv->backlight.level == 0) {
-  dev_priv->backlight.level = intel_panel_get_max_backlight(dev,
-           pipe);
-  if (dev_priv->backlight.device)
-   dev_priv->backlight.device->props.brightness =
-    dev_priv->backlight.level;
+ ctl = I915_READ(BLC_PWM_CTL);
+ if (ctl & BACKLIGHT_DUTY_CYCLE_MASK_PNV) {
+  WARN(1, "backlight already enabled\n");
+  I915_WRITE(BLC_PWM_CTL, 0);
  }
 
- if (INTEL_INFO(dev)->gen >= 4) {
-  uint32_t reg, tmp;
+ freq = panel->backlight.max;
+ if (panel->backlight.combination_mode)
+  freq /= 0xff;
 
-  if (HAS_PCH_SPLIT(dev))
-   reg = BLC_PWM_CPU_CTL2;
-  else if (IS_VALLEYVIEW(dev))
-   reg = VLV_BLC_PWM_CTL2(pipe);
-  else
-   reg = BLC_PWM_CTL2;
+ ctl = freq << 17;
+ if (panel->backlight.combination_mode)
+  ctl |= BLM_LEGACY_MODE;
+ if (IS_PINEVIEW(dev) && panel->backlight.active_low_pwm)
+  ctl |= BLM_POLARITY_PNV;
 
-  tmp = I915_READ(reg);
+ I915_WRITE(BLC_PWM_CTL, ctl);
+ POSTING_READ(BLC_PWM_CTL);
 
-  /* Note that this can also get called through dpms changes. And
-   * we don't track the backlight dpms state, hence check whether
-   * we have to do anything first. */
-  if (tmp & BLM_PWM_ENABLE)
-   goto set_level;
+ /* XXX: combine this into above write? */
+ intel_panel_actually_set_backlight(connector, panel->backlight.level);
+}
 
-  if (INTEL_INFO(dev)->num_pipes == 3)
-   tmp &= ~BLM_PIPE_SELECT_IVB;
-  else
-   tmp &= ~BLM_PIPE_SELECT;
+static void i965_enable_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ enum pipe pipe = intel_get_pipe_from_connector(connector);
+ u32 ctl, ctl2, freq;
 
-  if (cpu_transcoder == TRANSCODER_EDP)
-   tmp |= BLM_TRANSCODER_EDP;
-  else
-   tmp |= BLM_PIPE(cpu_transcoder);
-  tmp &= ~BLM_PWM_ENABLE;
-
-  I915_WRITE(reg, tmp);
-  POSTING_READ(reg);
-  I915_WRITE(reg, tmp | BLM_PWM_ENABLE);
-
-  if (IS_BROADWELL(dev)) {
-   /*
-    * Broadwell requires PCH override to drive the PCH
-    * backlight pin. The above will configure the CPU
-    * backlight pin, which we don't plan to use.
-    */
-   tmp = I915_READ(BLC_PWM_PCH_CTL1);
-   tmp |= BLM_PCH_OVERRIDE_ENABLE | BLM_PCH_PWM_ENABLE;
-   I915_WRITE(BLC_PWM_PCH_CTL1, tmp);
-  } else if (HAS_PCH_SPLIT(dev) &&
-      !(dev_priv->quirks & QUIRK_NO_PCH_PWM_ENABLE)) {
-   tmp = I915_READ(BLC_PWM_PCH_CTL1);
-   tmp |= BLM_PCH_PWM_ENABLE;
-   tmp &= ~BLM_PCH_OVERRIDE_ENABLE;
-   I915_WRITE(BLC_PWM_PCH_CTL1, tmp);
-  }
+ ctl2 = I915_READ(BLC_PWM_CTL2);
+ if (ctl2 & BLM_PWM_ENABLE) {
+  WARN(1, "backlight already enabled\n");
+  ctl2 &= ~BLM_PWM_ENABLE;
+  I915_WRITE(BLC_PWM_CTL2, ctl2);
  }
 
-set_level:
- /* Call below after setting BLC_PWM_CPU_CTL2 and BLC_PWM_PCH_CTL1.
-  * BLC_PWM_CPU_CTL may be cleared to zero automatically when these
-  * registers are set.
-  */
- dev_priv->backlight.enabled = true;
- intel_panel_actually_set_backlight(dev, pipe,
-        dev_priv->backlight.level);
+ freq = panel->backlight.max;
+ if (panel->backlight.combination_mode)
+  freq /= 0xff;
+
+ ctl = freq << 16;
+ I915_WRITE(BLC_PWM_CTL, ctl);
+
+ /* XXX: combine this into above write? */
+ intel_panel_actually_set_backlight(connector, panel->backlight.level);
 
- spin_unlock_irqrestore(&dev_priv->backlight.lock, flags);
+ ctl2 = BLM_PIPE(pipe);
+ if (panel->backlight.combination_mode)
+  ctl2 |= BLM_COMBINATION_MODE;
+ if (panel->backlight.active_low_pwm)
+  ctl2 |= BLM_POLARITY_I965;
+ I915_WRITE(BLC_PWM_CTL2, ctl2);
+ POSTING_READ(BLC_PWM_CTL2);
+ I915_WRITE(BLC_PWM_CTL2, ctl2 | BLM_PWM_ENABLE);
 }
 
-/* FIXME: use VBT vals to init PWM_CTL and PWM_CTL2 correctly */
-static void intel_panel_init_backlight_regs(struct drm_device *dev)
+static void vlv_enable_backlight(struct intel_connector *connector)
 {
+ struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ enum pipe pipe = intel_get_pipe_from_connector(connector);
+ u32 ctl, ctl2;
 
- if (IS_VALLEYVIEW(dev)) {
-  enum pipe pipe;
+ ctl2 = I915_READ(VLV_BLC_PWM_CTL2(pipe));
+ if (ctl2 & BLM_PWM_ENABLE) {
+  WARN(1, "backlight already enabled\n");
+  ctl2 &= ~BLM_PWM_ENABLE;
+  I915_WRITE(VLV_BLC_PWM_CTL2(pipe), ctl2);
+ }
 
-  for_each_pipe(pipe) {
-   u32 cur_val = I915_READ(VLV_BLC_PWM_CTL(pipe));
+ ctl = panel->backlight.max << 16;
+ I915_WRITE(VLV_BLC_PWM_CTL(pipe), ctl);
 
-   /* Skip if the modulation freq is already set */
-   if (cur_val & ~BACKLIGHT_DUTY_CYCLE_MASK)
-    continue;
+ /* XXX: combine this into above write? */
+ intel_panel_actually_set_backlight(connector, panel->backlight.level);
 
-   cur_val &= BACKLIGHT_DUTY_CYCLE_MASK;
-   I915_WRITE(VLV_BLC_PWM_CTL(pipe), (0xf42 << 16) |
-       cur_val);
-  }
- }
+ ctl2 = 0;
+ if (panel->backlight.active_low_pwm)
+  ctl2 |= BLM_POLARITY_I965;
+ I915_WRITE(VLV_BLC_PWM_CTL2(pipe), ctl2);
+ POSTING_READ(VLV_BLC_PWM_CTL2(pipe));
+ I915_WRITE(VLV_BLC_PWM_CTL2(pipe), ctl2 | BLM_PWM_ENABLE);
 }
 
-static void intel_panel_init_backlight(struct drm_device *dev)
+void intel_panel_enable_backlight(struct intel_connector *connector)
 {
+ struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ enum pipe pipe = intel_get_pipe_from_connector(connector);
+ unsigned long flags;
+
+ if (!panel->backlight.present || pipe == INVALID_PIPE)
+  return;
+
+ DRM_DEBUG_KMS("pipe %c\n", pipe_name(pipe));
+
+ spin_lock_irqsave(&dev_priv->backlight_lock, flags);
+
+ WARN_ON(panel->backlight.max == 0);
 
- intel_panel_init_backlight_regs(dev);
+ if (panel->backlight.level == 0) {
+  panel->backlight.level = panel->backlight.max;
+  if (panel->backlight.device)
+   panel->backlight.device->props.brightness =
+    panel->backlight.level;
+ }
+
+ dev_priv->display.enable_backlight(connector);
+ panel->backlight.enabled = true;
 
- dev_priv->backlight.level = intel_panel_get_backlight(dev, 0);
- dev_priv->backlight.enabled = dev_priv->backlight.level != 0;
+ spin_unlock_irqrestore(&dev_priv->backlight_lock, flags);
 }
 
 enum drm_connector_status
@@ -762,7 +827,7 @@ intel_panel_detect(struct drm_device *dev)
 }
 
 #if IS_ENABLED(CONFIG_BACKLIGHT_CLASS_DEVICE)
-static int intel_panel_update_status(struct backlight_device *bd)
+static int intel_backlight_device_update_status(struct backlight_device *bd)
 {
  struct intel_connector *connector = bl_get_data(bd);
  struct drm_device *dev = connector->base.dev;
@@ -776,85 +841,362 @@ static int intel_panel_update_status(struct backlight_device *bd)
  return 0;
 }
 
-static int intel_panel_get_brightness(struct backlight_device *bd)
+static int intel_backlight_device_get_brightness(struct backlight_device *bd)
 {
  struct intel_connector *connector = bl_get_data(bd);
  struct drm_device *dev = connector->base.dev;
- enum pipe pipe;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ int ret;
 
+ intel_runtime_pm_get(dev_priv);
  mutex_lock(&dev->mode_config.mutex);
- pipe = intel_get_pipe_from_connector(connector);
+ ret = intel_panel_get_backlight(connector);
  mutex_unlock(&dev->mode_config.mutex);
- if (pipe == INVALID_PIPE)
-  return 0;
+ intel_runtime_pm_put(dev_priv);
 
- return intel_panel_get_backlight(connector->base.dev, pipe);
+ return ret;
 }
 
-static const struct backlight_ops intel_panel_bl_ops = {
- .update_status = intel_panel_update_status,
- .get_brightness = intel_panel_get_brightness,
+static const struct backlight_ops intel_backlight_device_ops = {
+ .update_status = intel_backlight_device_update_status,
+ .get_brightness = intel_backlight_device_get_brightness,
 };
 
-int intel_panel_setup_backlight(struct drm_connector *connector)
+static int intel_backlight_device_register(struct intel_connector *connector)
 {
- struct drm_device *dev = connector->dev;
- struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
  struct backlight_properties props;
- unsigned long flags;
 
- intel_panel_init_backlight(dev);
-
- if (WARN_ON(dev_priv->backlight.device))
+ if (WARN_ON(panel->backlight.device))
   return -ENODEV;
 
+ BUG_ON(panel->backlight.max == 0);
+
  memset(&props, 0, sizeof(props));
  props.type = BACKLIGHT_RAW;
- props.brightness = dev_priv->backlight.level;
+ props.brightness = panel->backlight.level;
+ props.max_brightness = panel->backlight.max;
 
- spin_lock_irqsave(&dev_priv->backlight.lock, flags);
- props.max_brightness = intel_panel_get_max_backlight(dev, 0);
- spin_unlock_irqrestore(&dev_priv->backlight.lock, flags);
-
- if (props.max_brightness == 0) {
-  DRM_DEBUG_DRIVER("Failed to get maximum backlight value\n");
-  return -ENODEV;
- }
- dev_priv->backlight.device =
+ /*
+  * Note: using the same name independent of the connector prevents
+  * registration of multiple backlight devices in the driver.
+  */
+ panel->backlight.device =
   backlight_device_register("intel_backlight",
-       connector->kdev,
-       to_intel_connector(connector),
-       &intel_panel_bl_ops, &props);
+       connector->base.kdev,
+       connector,
+       &intel_backlight_device_ops, &props);
 
- if (IS_ERR(dev_priv->backlight.device)) {
+ if (IS_ERR(panel->backlight.device)) {
   DRM_ERROR("Failed to register backlight: %ld\n",
-     PTR_ERR(dev_priv->backlight.device));
-  dev_priv->backlight.device = NULL;
+     PTR_ERR(panel->backlight.device));
+  panel->backlight.device = NULL;
   return -ENODEV;
  }
  return 0;
 }
 
-void intel_panel_destroy_backlight(struct drm_device *dev)
+static void intel_backlight_device_unregister(struct intel_connector *connector)
+{
+ struct intel_panel *panel = &connector->panel;
+
+ if (panel->backlight.device) {
+  backlight_device_unregister(panel->backlight.device);
+  panel->backlight.device = NULL;
+ }
+}
+#else /* CONFIG_BACKLIGHT_CLASS_DEVICE */
+static int intel_backlight_device_register(struct intel_connector *connector)
+{
+ return 0;
+}
+static void intel_backlight_device_unregister(struct intel_connector *connector)
+{
+}
+#endif /* CONFIG_BACKLIGHT_CLASS_DEVICE */
+
+/*
+ * Note: The setup hooks can't assume pipe is set!
+ *
+ * XXX: Query mode clock or hardware clock and program PWM modulation frequency
+ * appropriately when it's 0. Use VBT and/or sane defaults.
+ */
+static int bdw_setup_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ u32 pch_ctl1, pch_ctl2, val;
+
+ pch_ctl1 = I915_READ(BLC_PWM_PCH_CTL1);
+ panel->backlight.active_low_pwm = pch_ctl1 & BLM_PCH_POLARITY;
+
+ pch_ctl2 = I915_READ(BLC_PWM_PCH_CTL2);
+ panel->backlight.max = pch_ctl2 >> 16;
+ if (!panel->backlight.max)
+  return -ENODEV;
+
+ val = bdw_get_backlight(connector);
+ panel->backlight.level = intel_panel_compute_brightness(connector, val);
+
+ panel->backlight.enabled = (pch_ctl1 & BLM_PCH_PWM_ENABLE) &&
+  panel->backlight.level != 0;
+
+ return 0;
+}
+
+static int pch_setup_backlight(struct intel_connector *connector)
 {
+ struct drm_device *dev = connector->base.dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
- if (dev_priv->backlight.device) {
-  backlight_device_unregister(dev_priv->backlight.device);
-  dev_priv->backlight.device = NULL;
+ struct intel_panel *panel = &connector->panel;
+ u32 cpu_ctl2, pch_ctl1, pch_ctl2, val;
+
+ pch_ctl1 = I915_READ(BLC_PWM_PCH_CTL1);
+ panel->backlight.active_low_pwm = pch_ctl1 & BLM_PCH_POLARITY;
+
+ pch_ctl2 = I915_READ(BLC_PWM_PCH_CTL2);
+ panel->backlight.max = pch_ctl2 >> 16;
+ if (!panel->backlight.max)
+  return -ENODEV;
+
+ val = pch_get_backlight(connector);
+ panel->backlight.level = intel_panel_compute_brightness(connector, val);
+
+ cpu_ctl2 = I915_READ(BLC_PWM_CPU_CTL2);
+ panel->backlight.enabled = (cpu_ctl2 & BLM_PWM_ENABLE) &&
+  (pch_ctl1 & BLM_PCH_PWM_ENABLE) && panel->backlight.level != 0;
+
+ return 0;
+}
+
+static int i9xx_setup_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ u32 ctl, val;
+
+ ctl = I915_READ(BLC_PWM_CTL);
+
+ if (IS_GEN2(dev) || IS_I915GM(dev) || IS_I945GM(dev))
+  panel->backlight.combination_mode = ctl & BLM_LEGACY_MODE;
+
+ if (IS_PINEVIEW(dev))
+  panel->backlight.active_low_pwm = ctl & BLM_POLARITY_PNV;
+
+ panel->backlight.max = ctl >> 17;
+ if (panel->backlight.combination_mode)
+  panel->backlight.max *= 0xff;
+
+ if (!panel->backlight.max)
+  return -ENODEV;
+
+ val = i9xx_get_backlight(connector);
+ panel->backlight.level = intel_panel_compute_brightness(connector, val);
+
+ panel->backlight.enabled = panel->backlight.level != 0;
+
+ return 0;
+}
+
+static int i965_setup_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ u32 ctl, ctl2, val;
+
+ ctl2 = I915_READ(BLC_PWM_CTL2);
+ panel->backlight.combination_mode = ctl2 & BLM_COMBINATION_MODE;
+ panel->backlight.active_low_pwm = ctl2 & BLM_POLARITY_I965;
+
+ ctl = I915_READ(BLC_PWM_CTL);
+ panel->backlight.max = ctl >> 16;
+ if (panel->backlight.combination_mode)
+  panel->backlight.max *= 0xff;
+
+ if (!panel->backlight.max)
+  return -ENODEV;
+
+ val = i9xx_get_backlight(connector);
+ panel->backlight.level = intel_panel_compute_brightness(connector, val);
+
+ panel->backlight.enabled = (ctl2 & BLM_PWM_ENABLE) &&
+  panel->backlight.level != 0;
+
+ return 0;
+}
+
+static int vlv_setup_backlight(struct intel_connector *connector)
+{
+ struct drm_device *dev = connector->base.dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_panel *panel = &connector->panel;
+ enum pipe pipe;
+ u32 ctl, ctl2, val;
+
+ for_each_pipe(pipe) {
+  u32 cur_val = I915_READ(VLV_BLC_PWM_CTL(pipe));
+
+  /* Skip if the modulation freq is already set */
+  if (cur_val & ~BACKLIGHT_DUTY_CYCLE_MASK)
+   continue;
+
+  cur_val &= BACKLIGHT_DUTY_CYCLE_MASK;
+  I915_WRITE(VLV_BLC_PWM_CTL(pipe), (0xf42 << 16) |
+      cur_val);
  }
+
+ ctl2 = I915_READ(VLV_BLC_PWM_CTL2(PIPE_A));
+ panel->backlight.active_low_pwm = ctl2 & BLM_POLARITY_I965;
+
+ ctl = I915_READ(VLV_BLC_PWM_CTL(PIPE_A));
+ panel->backlight.max = ctl >> 16;
+ if (!panel->backlight.max)
+  return -ENODEV;
+
+ val = _vlv_get_backlight(dev, PIPE_A);
+ panel->backlight.level = intel_panel_compute_brightness(connector, val);
+
+ panel->backlight.enabled = (ctl2 & BLM_PWM_ENABLE) &&
+  panel->backlight.level != 0;
+
+ return 0;
 }
-#else
+
 int intel_panel_setup_backlight(struct drm_connector *connector)
 {
- intel_panel_init_backlight(connector->dev);
+ struct drm_device *dev = connector->dev;
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct intel_connector *intel_connector = to_intel_connector(connector);
+ struct intel_panel *panel = &intel_connector->panel;
+ unsigned long flags;
+ int ret;
+
+ /* set level and max in panel struct */
+ spin_lock_irqsave(&dev_priv->backlight_lock, flags);
+ ret = dev_priv->display.setup_backlight(intel_connector);
+ spin_unlock_irqrestore(&dev_priv->backlight_lock, flags);
+
+ if (ret) {
+  DRM_DEBUG_KMS("failed to setup backlight for connector %s\n",
+         drm_get_connector_name(connector));
+  return ret;
+ }
+
+ intel_backlight_device_register(intel_connector);
+
+ panel->backlight.present = true;
+
+ DRM_DEBUG_KMS("backlight initialized, %s, brightness %u/%u, "
+        "sysfs interface %sregistered\n",
+        panel->backlight.enabled ? "enabled" : "disabled",
+        panel->backlight.level, panel->backlight.max,
+        panel->backlight.device ? "" : "not ");
+
  return 0;
 }
 
-void intel_panel_destroy_backlight(struct drm_device *dev)
+void intel_panel_destroy_backlight(struct drm_connector *connector)
 {
- return;
+ struct intel_connector *intel_connector = to_intel_connector(connector);
+ struct intel_panel *panel = &intel_connector->panel;
+
+ panel->backlight.present = false;
+ intel_backlight_device_unregister(intel_connector);
+}
+
+/**
+ * intel_find_panel_downclock - find the reduced downclock for LVDS in EDID
+ * @dev: drm device
+ * @fixed_mode : panel native mode
+ * @connector: LVDS/eDP connector
+ *
+ * Return downclock_avail
+ * Find the reduced downclock for LVDS/eDP in EDID.
+ */
+struct drm_display_mode *
+intel_find_panel_downclock(struct drm_device *dev,
+   struct drm_display_mode *fixed_mode,
+   struct drm_connector *connector)
+{
+ struct drm_display_mode *scan, *tmp_mode;
+ int temp_downclock;
+
+ temp_downclock = fixed_mode->clock;
+ tmp_mode = NULL;
+
+ list_for_each_entry(scan, &connector->probed_modes, head) {
+  /*
+   * If one mode has the same resolution with the fixed_panel
+   * mode while they have the different refresh rate, it means
+   * that the reduced downclock is found. In such
+   * case we can set the different FPx0/1 to dynamically select
+   * between low and high frequency.
+   */
+  if (scan->hdisplay == fixed_mode->hdisplay &&
+      scan->hsync_start == fixed_mode->hsync_start &&
+      scan->hsync_end == fixed_mode->hsync_end &&
+      scan->htotal == fixed_mode->htotal &&
+      scan->vdisplay == fixed_mode->vdisplay &&
+      scan->vsync_start == fixed_mode->vsync_start &&
+      scan->vsync_end == fixed_mode->vsync_end &&
+      scan->vtotal == fixed_mode->vtotal) {
+   if (scan->clock < temp_downclock) {
+    /*
+     * The downclock is already found. But we
+     * expect to find the lower downclock.
+     */
+    temp_downclock = scan->clock;
+    tmp_mode = scan;
+   }
+  }
+ }
+
+ if (temp_downclock < fixed_mode->clock)
+  return drm_mode_duplicate(dev, tmp_mode);
+ else
+  return NULL;
+}
+
+/* Set up chip specific backlight functions */
+void intel_panel_init_backlight_funcs(struct drm_device *dev)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+
+ if (IS_BROADWELL(dev)) {
+  dev_priv->display.setup_backlight = bdw_setup_backlight;
+  dev_priv->display.enable_backlight = bdw_enable_backlight;
+  dev_priv->display.disable_backlight = pch_disable_backlight;
+  dev_priv->display.set_backlight = bdw_set_backlight;
+  dev_priv->display.get_backlight = bdw_get_backlight;
+ } else if (HAS_PCH_SPLIT(dev)) {
+  dev_priv->display.setup_backlight = pch_setup_backlight;
+  dev_priv->display.enable_backlight = pch_enable_backlight;
+  dev_priv->display.disable_backlight = pch_disable_backlight;
+  dev_priv->display.set_backlight = pch_set_backlight;
+  dev_priv->display.get_backlight = pch_get_backlight;
+ } else if (IS_VALLEYVIEW(dev)) {
+  dev_priv->display.setup_backlight = vlv_setup_backlight;
+  dev_priv->display.enable_backlight = vlv_enable_backlight;
+  dev_priv->display.disable_backlight = vlv_disable_backlight;
+  dev_priv->display.set_backlight = vlv_set_backlight;
+  dev_priv->display.get_backlight = vlv_get_backlight;
+ } else if (IS_GEN4(dev)) {
+  dev_priv->display.setup_backlight = i965_setup_backlight;
+  dev_priv->display.enable_backlight = i965_enable_backlight;
+  dev_priv->display.disable_backlight = i965_disable_backlight;
+  dev_priv->display.set_backlight = i9xx_set_backlight;
+  dev_priv->display.get_backlight = i9xx_get_backlight;
+ } else {
+  dev_priv->display.setup_backlight = i9xx_setup_backlight;
+  dev_priv->display.enable_backlight = i9xx_enable_backlight;
+  dev_priv->display.disable_backlight = i9xx_disable_backlight;
+  dev_priv->display.set_backlight = i9xx_set_backlight;
+  dev_priv->display.get_backlight = i9xx_get_backlight;
+ }
 }
-#endif
 
 int intel_panel_init(struct intel_panel *panel,
        struct drm_display_mode *fixed_mode)
@@ -871,4 +1213,8 @@ void intel_panel_fini(struct intel_panel *panel)
 
  if (panel->fixed_mode)
   drm_mode_destroy(intel_connector->base.dev, panel->fixed_mode);
+
+ if (panel->downclock_mode)
+  drm_mode_destroy(intel_connector->base.dev,
+    panel->downclock_mode);
 }
diff --git a/drivers/gpu/drm/i915/intel_pm.c b/drivers/gpu/drm/i915/intel_pm.c
index 26c29c1..e1fc35a 100644
--- a/drivers/gpu/drm/i915/intel_pm.c
+++ b/drivers/gpu/drm/i915/intel_pm.c
@@ -30,7 +30,9 @@
 #include "intel_drv.h"
 #include "../../../platform/x86/intel_ips.h"
 #include <linux/module.h>
+#include <linux/vgaarb.h>
 #include <drm/i915_powerwell.h>
+#include <linux/pm_runtime.h>
 
 /**
  * RC6 is a special power stage which allows the GPU to enter an very
@@ -86,7 +88,7 @@ static void i8xx_disable_fbc(struct drm_device *dev)
  DRM_DEBUG_KMS("disabled FBC\n");
 }
 
-static void i8xx_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
+static void i8xx_enable_fbc(struct drm_crtc *crtc)
 {
  struct drm_device *dev = crtc->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
@@ -96,32 +98,40 @@ static void i8xx_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
  struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
  int cfb_pitch;
  int plane, i;
- u32 fbc_ctl, fbc_ctl2;
+ u32 fbc_ctl;
 
  cfb_pitch = dev_priv->fbc.size / FBC_LL_SIZE;
  if (fb->pitches[0] < cfb_pitch)
   cfb_pitch = fb->pitches[0];
 
- /* FBC_CTL wants 64B units */
- cfb_pitch = (cfb_pitch / 64) - 1;
+ /* FBC_CTL wants 32B or 64B units */
+ if (IS_GEN2(dev))
+  cfb_pitch = (cfb_pitch / 32) - 1;
+ else
+  cfb_pitch = (cfb_pitch / 64) - 1;
  plane = intel_crtc->plane == 0 ? FBC_CTL_PLANEA : FBC_CTL_PLANEB;
 
  /* Clear old tags */
  for (i = 0; i < (FBC_LL_SIZE / 32) + 1; i++)
   I915_WRITE(FBC_TAG + (i * 4), 0);
 
- /* Set it up... */
- fbc_ctl2 = FBC_CTL_FENCE_DBL | FBC_CTL_IDLE_IMM | FBC_CTL_CPU_FENCE;
- fbc_ctl2 |= plane;
- I915_WRITE(FBC_CONTROL2, fbc_ctl2);
- I915_WRITE(FBC_FENCE_OFF, crtc->y);
+ if (IS_GEN4(dev)) {
+  u32 fbc_ctl2;
+
+  /* Set it up... */
+  fbc_ctl2 = FBC_CTL_FENCE_DBL | FBC_CTL_IDLE_IMM | FBC_CTL_CPU_FENCE;
+  fbc_ctl2 |= plane;
+  I915_WRITE(FBC_CONTROL2, fbc_ctl2);
+  I915_WRITE(FBC_FENCE_OFF, crtc->y);
+ }
 
  /* enable it... */
- fbc_ctl = FBC_CTL_EN | FBC_CTL_PERIODIC;
+ fbc_ctl = I915_READ(FBC_CONTROL);
+ fbc_ctl &= 0x3fff << FBC_CTL_INTERVAL_SHIFT;
+ fbc_ctl |= FBC_CTL_EN | FBC_CTL_PERIODIC;
  if (IS_I945GM(dev))
   fbc_ctl |= FBC_CTL_C3_IDLE; /* 945 needs special SR handling */
  fbc_ctl |= (cfb_pitch & 0xff) << FBC_CTL_STRIDE_SHIFT;
- fbc_ctl |= (interval & 0x2fff) << FBC_CTL_INTERVAL_SHIFT;
  fbc_ctl |= obj->fence_reg;
  I915_WRITE(FBC_CONTROL, fbc_ctl);
 
@@ -136,7 +146,7 @@ static bool i8xx_fbc_enabled(struct drm_device *dev)
  return I915_READ(FBC_CONTROL) & FBC_CTL_EN;
 }
 
-static void g4x_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
+static void g4x_enable_fbc(struct drm_crtc *crtc)
 {
  struct drm_device *dev = crtc->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
@@ -145,16 +155,12 @@ static void g4x_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
  struct drm_i915_gem_object *obj = intel_fb->obj;
  struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
  int plane = intel_crtc->plane == 0 ? DPFC_CTL_PLANEA : DPFC_CTL_PLANEB;
- unsigned long stall_watermark = 200;
  u32 dpfc_ctl;
 
  dpfc_ctl = plane | DPFC_SR_EN | DPFC_CTL_LIMIT_1X;
  dpfc_ctl |= DPFC_CTL_FENCE_EN | obj->fence_reg;
  I915_WRITE(DPFC_CHICKEN, DPFC_HT_MODIFY);
 
- I915_WRITE(DPFC_RECOMP_CTL, DPFC_RECOMP_STALL_EN |
-     (stall_watermark << DPFC_RECOMP_STALL_WM_SHIFT) |
-     (interval << DPFC_RECOMP_TIMER_COUNT_SHIFT));
  I915_WRITE(DPFC_FENCE_YOFF, crtc->y);
 
  /* enable it... */
@@ -191,7 +197,11 @@ static void sandybridge_blit_fbc_update(struct drm_device *dev)
  u32 blt_ecoskpd;
 
  /* Make sure blitter notifies FBC of writes */
- gen6_gt_force_wake_get(dev_priv);
+
+ /* Blitter is part of Media powerwell on VLV. No impact of
+  * his param in other platforms for now */
+ gen6_gt_force_wake_get(dev_priv, FORCEWAKE_MEDIA);
+
  blt_ecoskpd = I915_READ(GEN6_BLITTER_ECOSKPD);
  blt_ecoskpd |= GEN6_BLITTER_FBC_NOTIFY <<
   GEN6_BLITTER_LOCK_SHIFT;
@@ -202,10 +212,11 @@ static void sandybridge_blit_fbc_update(struct drm_device *dev)
     GEN6_BLITTER_LOCK_SHIFT);
  I915_WRITE(GEN6_BLITTER_ECOSKPD, blt_ecoskpd);
  POSTING_READ(GEN6_BLITTER_ECOSKPD);
- gen6_gt_force_wake_put(dev_priv);
+
+ gen6_gt_force_wake_put(dev_priv, FORCEWAKE_MEDIA);
 }
 
-static void ironlake_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
+static void ironlake_enable_fbc(struct drm_crtc *crtc)
 {
  struct drm_device *dev = crtc->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
@@ -214,7 +225,6 @@ static void ironlake_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
  struct drm_i915_gem_object *obj = intel_fb->obj;
  struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
  int plane = intel_crtc->plane == 0 ? DPFC_CTL_PLANEA : DPFC_CTL_PLANEB;
- unsigned long stall_watermark = 200;
  u32 dpfc_ctl;
 
  dpfc_ctl = I915_READ(ILK_DPFC_CONTROL);
@@ -222,12 +232,11 @@ static void ironlake_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
  dpfc_ctl |= (plane | DPFC_CTL_LIMIT_1X);
  /* Set persistent mode for front-buffer rendering, ala X. */
  dpfc_ctl |= DPFC_CTL_PERSISTENT_MODE;
- dpfc_ctl |= (DPFC_CTL_FENCE_EN | obj->fence_reg);
+ dpfc_ctl |= DPFC_CTL_FENCE_EN;
+ if (IS_GEN5(dev))
+  dpfc_ctl |= obj->fence_reg;
  I915_WRITE(ILK_DPFC_CHICKEN, DPFC_HT_MODIFY);
 
- I915_WRITE(ILK_DPFC_RECOMP_CTL, DPFC_RECOMP_STALL_EN |
-     (stall_watermark << DPFC_RECOMP_STALL_WM_SHIFT) |
-     (interval << DPFC_RECOMP_TIMER_COUNT_SHIFT));
  I915_WRITE(ILK_DPFC_FENCE_YOFF, crtc->y);
  I915_WRITE(ILK_FBC_RT_BASE, i915_gem_obj_ggtt_offset(obj) | ILK_FBC_RT_VALID);
  /* enable it... */
@@ -265,7 +274,7 @@ static bool ironlake_fbc_enabled(struct drm_device *dev)
  return I915_READ(ILK_DPFC_CONTROL) & DPFC_CTL_EN;
 }
 
-static void gen7_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
+static void gen7_enable_fbc(struct drm_crtc *crtc)
 {
  struct drm_device *dev = crtc->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
@@ -295,7 +304,7 @@ static void gen7_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
 
  sandybridge_blit_fbc_update(dev);
 
- DRM_DEBUG_KMS("enabled fbc on plane %d\n", intel_crtc->plane);
+ DRM_DEBUG_KMS("enabled fbc on plane %c\n", plane_name(intel_crtc->plane));
 }
 
 bool intel_fbc_enabled(struct drm_device *dev)
@@ -322,8 +331,7 @@ static void intel_fbc_work_fn(struct work_struct *__work)
    * the prior work.
    */
   if (work->crtc->fb == work->fb) {
-   dev_priv->display.enable_fbc(work->crtc,
-           work->interval);
+   dev_priv->display.enable_fbc(work->crtc);
 
    dev_priv->fbc.plane = to_intel_crtc(work->crtc)->plane;
    dev_priv->fbc.fb_id = work->crtc->fb->base.id;
@@ -360,7 +368,7 @@ static void intel_cancel_fbc_work(struct drm_i915_private *dev_priv)
  dev_priv->fbc.fbc_work = NULL;
 }
 
-static void intel_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
+static void intel_enable_fbc(struct drm_crtc *crtc)
 {
  struct intel_fbc_work *work;
  struct drm_device *dev = crtc->dev;
@@ -374,13 +382,12 @@ static void intel_enable_fbc(struct drm_crtc *crtc, unsigned long interval)
  work = kzalloc(sizeof(*work), GFP_KERNEL);
  if (work == NULL) {
   DRM_ERROR("Failed to allocate FBC work structure\n");
-  dev_priv->display.enable_fbc(crtc, interval);
+  dev_priv->display.enable_fbc(crtc);
   return;
  }
 
  work->crtc = crtc;
  work->fb = crtc->fb;
- work->interval = interval;
  INIT_DELAYED_WORK(&work->work, intel_fbc_work_fn);
 
  dev_priv->fbc.fbc_work = work;
@@ -454,7 +461,7 @@ void intel_update_fbc(struct drm_device *dev)
  const struct drm_display_mode *adjusted_mode;
  unsigned int max_width, max_height;
 
- if (!I915_HAS_FBC(dev)) {
+ if (!HAS_FBC(dev)) {
   set_no_fbc_reason(dev_priv, FBC_UNSUPPORTED);
   return;
  }
@@ -530,10 +537,10 @@ void intel_update_fbc(struct drm_device *dev)
    DRM_DEBUG_KMS("mode too large for compression, disabling\n");
   goto out_disable;
  }
- if ((IS_I915GM(dev) || IS_I945GM(dev) || IS_HASWELL(dev)) &&
-     intel_crtc->plane != 0) {
+ if ((INTEL_INFO(dev)->gen < 4 || IS_HASWELL(dev)) &&
+     intel_crtc->plane != PLANE_A) {
   if (set_no_fbc_reason(dev_priv, FBC_BAD_PLANE))
-   DRM_DEBUG_KMS("plane not 0, disabling compression\n");
+   DRM_DEBUG_KMS("plane not A, disabling compression\n");
   goto out_disable;
  }
 
@@ -595,7 +602,7 @@ void intel_update_fbc(struct drm_device *dev)
   intel_disable_fbc(dev);
  }
 
- intel_enable_fbc(crtc, 500);
+ intel_enable_fbc(crtc);
  dev_priv->fbc.no_fbc_reason = FBC_OK;
  return;
 
@@ -817,7 +824,7 @@ static int i9xx_get_fifo_size(struct drm_device *dev, int plane)
  return size;
 }
 
-static int i85x_get_fifo_size(struct drm_device *dev, int plane)
+static int i830_get_fifo_size(struct drm_device *dev, int plane)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  uint32_t dsparb = I915_READ(DSPARB);
@@ -850,21 +857,6 @@ static int i845_get_fifo_size(struct drm_device *dev, int plane)
  return size;
 }
 
-static int i830_get_fifo_size(struct drm_device *dev, int plane)
-{
- struct drm_i915_private *dev_priv = dev->dev_private;
- uint32_t dsparb = I915_READ(DSPARB);
- int size;
-
- size = dsparb & 0x7f;
- size >>= 1; /* Convert to cachelines */
-
- DRM_DEBUG_KMS("FIFO size - (0x%08x) %s: %d\n", dsparb,
-        plane ? "B" : "A", size);
-
- return size;
-}
-
 /* Pineview has different values for various configs */
 static const struct intel_watermark_params pineview_display_wm = {
  PINEVIEW_DISPLAY_FIFO,
@@ -943,14 +935,14 @@ static const struct intel_watermark_params i915_wm_info = {
  2,
  I915_FIFO_LINE_SIZE
 };
-static const struct intel_watermark_params i855_wm_info = {
+static const struct intel_watermark_params i830_wm_info = {
  I855GM_FIFO_SIZE,
  I915_MAX_WM,
  1,
  2,
  I830_FIFO_LINE_SIZE
 };
-static const struct intel_watermark_params i830_wm_info = {
+static const struct intel_watermark_params i845_wm_info = {
  I830_FIFO_SIZE,
  I915_MAX_WM,
  1,
@@ -958,65 +950,6 @@ static const struct intel_watermark_params i830_wm_info = {
  I830_FIFO_LINE_SIZE
 };
 
-static const struct intel_watermark_params ironlake_display_wm_info = {
- ILK_DISPLAY_FIFO,
- ILK_DISPLAY_MAXWM,
- ILK_DISPLAY_DFTWM,
- 2,
- ILK_FIFO_LINE_SIZE
-};
-static const struct intel_watermark_params ironlake_cursor_wm_info = {
- ILK_CURSOR_FIFO,
- ILK_CURSOR_MAXWM,
- ILK_CURSOR_DFTWM,
- 2,
- ILK_FIFO_LINE_SIZE
-};
-static const struct intel_watermark_params ironlake_display_srwm_info = {
- ILK_DISPLAY_SR_FIFO,
- ILK_DISPLAY_MAX_SRWM,
- ILK_DISPLAY_DFT_SRWM,
- 2,
- ILK_FIFO_LINE_SIZE
-};
-static const struct intel_watermark_params ironlake_cursor_srwm_info = {
- ILK_CURSOR_SR_FIFO,
- ILK_CURSOR_MAX_SRWM,
- ILK_CURSOR_DFT_SRWM,
- 2,
- ILK_FIFO_LINE_SIZE
-};
-
-static const struct intel_watermark_params sandybridge_display_wm_info = {
- SNB_DISPLAY_FIFO,
- SNB_DISPLAY_MAXWM,
- SNB_DISPLAY_DFTWM,
- 2,
- SNB_FIFO_LINE_SIZE
-};
-static const struct intel_watermark_params sandybridge_cursor_wm_info = {
- SNB_CURSOR_FIFO,
- SNB_CURSOR_MAXWM,
- SNB_CURSOR_DFTWM,
- 2,
- SNB_FIFO_LINE_SIZE
-};
-static const struct intel_watermark_params sandybridge_display_srwm_info = {
- SNB_DISPLAY_SR_FIFO,
- SNB_DISPLAY_MAX_SRWM,
- SNB_DISPLAY_DFT_SRWM,
- 2,
- SNB_FIFO_LINE_SIZE
-};
-static const struct intel_watermark_params sandybridge_cursor_srwm_info = {
- SNB_CURSOR_SR_FIFO,
- SNB_CURSOR_MAX_SRWM,
- SNB_CURSOR_DFT_SRWM,
- 2,
- SNB_FIFO_LINE_SIZE
-};
-
-
 /**
  * intel_calculate_wm - calculate watermark level
  * @clock_in_khz: pixel clock
@@ -1567,7 +1500,7 @@ static void i9xx_update_wm(struct drm_crtc *unused_crtc)
  else if (!IS_GEN2(dev))
   wm_info = &i915_wm_info;
  else
-  wm_info = &i855_wm_info;
+  wm_info = &i830_wm_info;
 
  fifo_size = dev_priv->display.get_fifo_size(dev, 0);
  crtc = intel_get_crtc_for_plane(dev, 0);
@@ -1615,7 +1548,7 @@ static void i9xx_update_wm(struct drm_crtc *unused_crtc)
  if (IS_I945G(dev) || IS_I945GM(dev))
   I915_WRITE(FW_BLC_SELF, FW_BLC_SELF_EN_MASK | 0);
  else if (IS_I915GM(dev))
-  I915_WRITE(INSTPM, I915_READ(INSTPM) & ~INSTPM_SELF_EN);
+  I915_WRITE(INSTPM, _MASKED_BIT_DISABLE(INSTPM_SELF_EN));
 
  /* Calc sr entries for one plane configs */
  if (HAS_FW_BLC(dev) && enabled) {
@@ -1667,14 +1600,14 @@ static void i9xx_update_wm(struct drm_crtc *unused_crtc)
     I915_WRITE(FW_BLC_SELF,
         FW_BLC_SELF_EN_MASK | FW_BLC_SELF_EN);
    else if (IS_I915GM(dev))
-    I915_WRITE(INSTPM, I915_READ(INSTPM) | INSTPM_SELF_EN);
+    I915_WRITE(INSTPM, _MASKED_BIT_ENABLE(INSTPM_SELF_EN));
    DRM_DEBUG_KMS("memory self refresh enabled\n");
   } else
    DRM_DEBUG_KMS("memory self refresh disabled\n");
  }
 }
 
-static void i830_update_wm(struct drm_crtc *unused_crtc)
+static void i845_update_wm(struct drm_crtc *unused_crtc)
 {
  struct drm_device *dev = unused_crtc->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
@@ -1689,7 +1622,7 @@ static void i830_update_wm(struct drm_crtc *unused_crtc)
 
  adjusted_mode = &to_intel_crtc(crtc)->config.adjusted_mode;
  planea_wm = intel_calculate_wm(adjusted_mode->crtc_clock,
-           &i830_wm_info,
+           &i845_wm_info,
            dev_priv->display.get_fifo_size(dev, 0),
            4, latency_ns);
  fwater_lo = I915_READ(FW_BLC) & ~0xfff;
@@ -1700,423 +1633,6 @@ static void i830_update_wm(struct drm_crtc *unused_crtc)
  I915_WRITE(FW_BLC, fwater_lo);
 }
 
-/*
- * Check the wm result.
- *
- * If any calculated watermark values is larger than the maximum value that
- * can be programmed into the associated watermark register, that watermark
- * must be disabled.
- */
-static bool ironlake_check_srwm(struct drm_device *dev, int level,
-    int fbc_wm, int display_wm, int cursor_wm,
-    const struct intel_watermark_params *display,
-    const struct intel_watermark_params *cursor)
-{
- struct drm_i915_private *dev_priv = dev->dev_private;
-
- DRM_DEBUG_KMS("watermark %d: display plane %d, fbc lines %d,"
-        " cursor %d\n", level, display_wm, fbc_wm, cursor_wm);
-
- if (fbc_wm > SNB_FBC_MAX_SRWM) {
-  DRM_DEBUG_KMS("fbc watermark(%d) is too large(%d), disabling wm%d+\n",
-         fbc_wm, SNB_FBC_MAX_SRWM, level);
-
-  /* fbc has it's own way to disable FBC WM */
-  I915_WRITE(DISP_ARB_CTL,
-      I915_READ(DISP_ARB_CTL) | DISP_FBC_WM_DIS);
-  return false;
- } else if (INTEL_INFO(dev)->gen >= 6) {
-  /* enable FBC WM (except on ILK, where it must remain off) */
-  I915_WRITE(DISP_ARB_CTL,
-      I915_READ(DISP_ARB_CTL) & ~DISP_FBC_WM_DIS);
- }
-
- if (display_wm > display->max_wm) {
-  DRM_DEBUG_KMS("display watermark(%d) is too large(%d), disabling wm%d+\n",
-         display_wm, SNB_DISPLAY_MAX_SRWM, level);
-  return false;
- }
-
- if (cursor_wm > cursor->max_wm) {
-  DRM_DEBUG_KMS("cursor watermark(%d) is too large(%d), disabling wm%d+\n",
-         cursor_wm, SNB_CURSOR_MAX_SRWM, level);
-  return false;
- }
-
- if (!(fbc_wm || display_wm || cursor_wm)) {
-  DRM_DEBUG_KMS("latency %d is 0, disabling wm%d+\n", level, level);
-  return false;
- }
-
- return true;
-}
-
-/*
- * Compute watermark values of WM[1-3],
- */
-static bool ironlake_compute_srwm(struct drm_device *dev, int level, int plane,
-      int latency_ns,
-      const struct intel_watermark_params *display,
-      const struct intel_watermark_params *cursor,
-      int *fbc_wm, int *display_wm, int *cursor_wm)
-{
- struct drm_crtc *crtc;
- const struct drm_display_mode *adjusted_mode;
- unsigned long line_time_us;
- int hdisplay, htotal, pixel_size, clock;
- int line_count, line_size;
- int small, large;
- int entries;
-
- if (!latency_ns) {
-  *fbc_wm = *display_wm = *cursor_wm = 0;
-  return false;
- }
-
- crtc = intel_get_crtc_for_plane(dev, plane);
- adjusted_mode = &to_intel_crtc(crtc)->config.adjusted_mode;
- clock = adjusted_mode->crtc_clock;
- htotal = adjusted_mode->crtc_htotal;
- hdisplay = to_intel_crtc(crtc)->config.pipe_src_w;
- pixel_size = crtc->fb->bits_per_pixel / 8;
-
- line_time_us = (htotal * 1000) / clock;
- line_count = (latency_ns / line_time_us + 1000) / 1000;
- line_size = hdisplay * pixel_size;
-
- /* Use the minimum of the small and large buffer method for primary */
- small = ((clock * pixel_size / 1000) * latency_ns) / 1000;
- large = line_count * line_size;
-
- entries = DIV_ROUND_UP(min(small, large), display->cacheline_size);
- *display_wm = entries + display->guard_size;
-
- /*
-  * Spec says:
-  * FBC WM = ((Final Primary WM * 64) / number of bytes per line) + 2
-  */
- *fbc_wm = DIV_ROUND_UP(*display_wm * 64, line_size) + 2;
-
- /* calculate the self-refresh watermark for display cursor */
- entries = line_count * pixel_size * 64;
- entries = DIV_ROUND_UP(entries, cursor->cacheline_size);
- *cursor_wm = entries + cursor->guard_size;
-
- return ironlake_check_srwm(dev, level,
-       *fbc_wm, *display_wm, *cursor_wm,
-       display, cursor);
-}
-
-static void ironlake_update_wm(struct drm_crtc *crtc)
-{
- struct drm_device *dev = crtc->dev;
- struct drm_i915_private *dev_priv = dev->dev_private;
- int fbc_wm, plane_wm, cursor_wm;
- unsigned int enabled;
-
- enabled = 0;
- if (g4x_compute_wm0(dev, PIPE_A,
-       &ironlake_display_wm_info,
-       dev_priv->wm.pri_latency[0] * 100,
-       &ironlake_cursor_wm_info,
-       dev_priv->wm.cur_latency[0] * 100,
-       &plane_wm, &cursor_wm)) {
-  I915_WRITE(WM0_PIPEA_ILK,
-      (plane_wm << WM0_PIPE_PLANE_SHIFT) | cursor_wm);
-  DRM_DEBUG_KMS("FIFO watermarks For pipe A -"
-         " plane %d, " "cursor: %d\n",
-         plane_wm, cursor_wm);
-  enabled |= 1 << PIPE_A;
- }
-
- if (g4x_compute_wm0(dev, PIPE_B,
-       &ironlake_display_wm_info,
-       dev_priv->wm.pri_latency[0] * 100,
-       &ironlake_cursor_wm_info,
-       dev_priv->wm.cur_latency[0] * 100,
-       &plane_wm, &cursor_wm)) {
-  I915_WRITE(WM0_PIPEB_ILK,
-      (plane_wm << WM0_PIPE_PLANE_SHIFT) | cursor_wm);
-  DRM_DEBUG_KMS("FIFO watermarks For pipe B -"
-         " plane %d, cursor: %d\n",
-         plane_wm, cursor_wm);
-  enabled |= 1 << PIPE_B;
- }
-
- /*
-  * Calculate and update the self-refresh watermark only when one
-  * display plane is used.
-  */
- I915_WRITE(WM3_LP_ILK, 0);
- I915_WRITE(WM2_LP_ILK, 0);
- I915_WRITE(WM1_LP_ILK, 0);
-
- if (!single_plane_enabled(enabled))
-  return;
- enabled = ffs(enabled) - 1;
-
- /* WM1 */
- if (!ironlake_compute_srwm(dev, 1, enabled,
-       dev_priv->wm.pri_latency[1] * 500,
-       &ironlake_display_srwm_info,
-       &ironlake_cursor_srwm_info,
-       &fbc_wm, &plane_wm, &cursor_wm))
-  return;
-
- I915_WRITE(WM1_LP_ILK,
-     WM1_LP_SR_EN |
-     (dev_priv->wm.pri_latency[1] << WM1_LP_LATENCY_SHIFT) |
-     (fbc_wm << WM1_LP_FBC_SHIFT) |
-     (plane_wm << WM1_LP_SR_SHIFT) |
-     cursor_wm);
-
- /* WM2 */
- if (!ironlake_compute_srwm(dev, 2, enabled,
-       dev_priv->wm.pri_latency[2] * 500,
-       &ironlake_display_srwm_info,
-       &ironlake_cursor_srwm_info,
-       &fbc_wm, &plane_wm, &cursor_wm))
-  return;
-
- I915_WRITE(WM2_LP_ILK,
-     WM2_LP_EN |
-     (dev_priv->wm.pri_latency[2] << WM1_LP_LATENCY_SHIFT) |
-     (fbc_wm << WM1_LP_FBC_SHIFT) |
-     (plane_wm << WM1_LP_SR_SHIFT) |
-     cursor_wm);
-
- /*
-  * WM3 is unsupported on ILK, probably because we don't have latency
-  * data for that power state
-  */
-}
-
-static void sandybridge_update_wm(struct drm_crtc *crtc)
-{
- struct drm_device *dev = crtc->dev;
- struct drm_i915_private *dev_priv = dev->dev_private;
- int latency = dev_priv->wm.pri_latency[0] * 100; /* In unit 0.1us */
- u32 val;
- int fbc_wm, plane_wm, cursor_wm;
- unsigned int enabled;
-
- enabled = 0;
- if (g4x_compute_wm0(dev, PIPE_A,
-       &sandybridge_display_wm_info, latency,
-       &sandybridge_cursor_wm_info, latency,
-       &plane_wm, &cursor_wm)) {
-  val = I915_READ(WM0_PIPEA_ILK);
-  val &= ~(WM0_PIPE_PLANE_MASK | WM0_PIPE_CURSOR_MASK);
-  I915_WRITE(WM0_PIPEA_ILK, val |
-      ((plane_wm << WM0_PIPE_PLANE_SHIFT) | cursor_wm));
-  DRM_DEBUG_KMS("FIFO watermarks For pipe A -"
-         " plane %d, " "cursor: %d\n",
-         plane_wm, cursor_wm);
-  enabled |= 1 << PIPE_A;
- }
-
- if (g4x_compute_wm0(dev, PIPE_B,
-       &sandybridge_display_wm_info, latency,
-       &sandybridge_cursor_wm_info, latency,
-       &plane_wm, &cursor_wm)) {
-  val = I915_READ(WM0_PIPEB_ILK);
-  val &= ~(WM0_PIPE_PLANE_MASK | WM0_PIPE_CURSOR_MASK);
-  I915_WRITE(WM0_PIPEB_ILK, val |
-      ((plane_wm << WM0_PIPE_PLANE_SHIFT) | cursor_wm));
-  DRM_DEBUG_KMS("FIFO watermarks For pipe B -"
-         " plane %d, cursor: %d\n",
-         plane_wm, cursor_wm);
-  enabled |= 1 << PIPE_B;
- }
-
- /*
-  * Calculate and update the self-refresh watermark only when one
-  * display plane is used.
-  *
-  * SNB support 3 levels of watermark.
-  *
-  * WM1/WM2/WM2 watermarks have to be enabled in the ascending order,
-  * and disabled in the descending order
-  *
-  */
- I915_WRITE(WM3_LP_ILK, 0);
- I915_WRITE(WM2_LP_ILK, 0);
- I915_WRITE(WM1_LP_ILK, 0);
-
- if (!single_plane_enabled(enabled) ||
-     dev_priv->sprite_scaling_enabled)
-  return;
- enabled = ffs(enabled) - 1;
-
- /* WM1 */
- if (!ironlake_compute_srwm(dev, 1, enabled,
-       dev_priv->wm.pri_latency[1] * 500,
-       &sandybridge_display_srwm_info,
-       &sandybridge_cursor_srwm_info,
-       &fbc_wm, &plane_wm, &cursor_wm))
-  return;
-
- I915_WRITE(WM1_LP_ILK,
-     WM1_LP_SR_EN |
-     (dev_priv->wm.pri_latency[1] << WM1_LP_LATENCY_SHIFT) |
-     (fbc_wm << WM1_LP_FBC_SHIFT) |
-     (plane_wm << WM1_LP_SR_SHIFT) |
-     cursor_wm);
-
- /* WM2 */
- if (!ironlake_compute_srwm(dev, 2, enabled,
-       dev_priv->wm.pri_latency[2] * 500,
-       &sandybridge_display_srwm_info,
-       &sandybridge_cursor_srwm_info,
-       &fbc_wm, &plane_wm, &cursor_wm))
-  return;
-
- I915_WRITE(WM2_LP_ILK,
-     WM2_LP_EN |
-     (dev_priv->wm.pri_latency[2] << WM1_LP_LATENCY_SHIFT) |
-     (fbc_wm << WM1_LP_FBC_SHIFT) |
-     (plane_wm << WM1_LP_SR_SHIFT) |
-     cursor_wm);
-
- /* WM3 */
- if (!ironlake_compute_srwm(dev, 3, enabled,
-       dev_priv->wm.pri_latency[3] * 500,
-       &sandybridge_display_srwm_info,
-       &sandybridge_cursor_srwm_info,
-       &fbc_wm, &plane_wm, &cursor_wm))
-  return;
-
- I915_WRITE(WM3_LP_ILK,
-     WM3_LP_EN |
-     (dev_priv->wm.pri_latency[3] << WM1_LP_LATENCY_SHIFT) |
-     (fbc_wm << WM1_LP_FBC_SHIFT) |
-     (plane_wm << WM1_LP_SR_SHIFT) |
-     cursor_wm);
-}
-
-static void ivybridge_update_wm(struct drm_crtc *crtc)
-{
- struct drm_device *dev = crtc->dev;
- struct drm_i915_private *dev_priv = dev->dev_private;
- int latency = dev_priv->wm.pri_latency[0] * 100; /* In unit 0.1us */
- u32 val;
- int fbc_wm, plane_wm, cursor_wm;
- int ignore_fbc_wm, ignore_plane_wm, ignore_cursor_wm;
- unsigned int enabled;
-
- enabled = 0;
- if (g4x_compute_wm0(dev, PIPE_A,
-       &sandybridge_display_wm_info, latency,
-       &sandybridge_cursor_wm_info, latency,
-       &plane_wm, &cursor_wm)) {
-  val = I915_READ(WM0_PIPEA_ILK);
-  val &= ~(WM0_PIPE_PLANE_MASK | WM0_PIPE_CURSOR_MASK);
-  I915_WRITE(WM0_PIPEA_ILK, val |
-      ((plane_wm << WM0_PIPE_PLANE_SHIFT) | cursor_wm));
-  DRM_DEBUG_KMS("FIFO watermarks For pipe A -"
-         " plane %d, " "cursor: %d\n",
-         plane_wm, cursor_wm);
-  enabled |= 1 << PIPE_A;
- }
-
- if (g4x_compute_wm0(dev, PIPE_B,
-       &sandybridge_display_wm_info, latency,
-       &sandybridge_cursor_wm_info, latency,
-       &plane_wm, &cursor_wm)) {
-  val = I915_READ(WM0_PIPEB_ILK);
-  val &= ~(WM0_PIPE_PLANE_MASK | WM0_PIPE_CURSOR_MASK);
-  I915_WRITE(WM0_PIPEB_ILK, val |
-      ((plane_wm << WM0_PIPE_PLANE_SHIFT) | cursor_wm));
-  DRM_DEBUG_KMS("FIFO watermarks For pipe B -"
-         " plane %d, cursor: %d\n",
-         plane_wm, cursor_wm);
-  enabled |= 1 << PIPE_B;
- }
-
- if (g4x_compute_wm0(dev, PIPE_C,
-       &sandybridge_display_wm_info, latency,
-       &sandybridge_cursor_wm_info, latency,
-       &plane_wm, &cursor_wm)) {
-  val = I915_READ(WM0_PIPEC_IVB);
-  val &= ~(WM0_PIPE_PLANE_MASK | WM0_PIPE_CURSOR_MASK);
-  I915_WRITE(WM0_PIPEC_IVB, val |
-      ((plane_wm << WM0_PIPE_PLANE_SHIFT) | cursor_wm));
-  DRM_DEBUG_KMS("FIFO watermarks For pipe C -"
-         " plane %d, cursor: %d\n",
-         plane_wm, cursor_wm);
-  enabled |= 1 << PIPE_C;
- }
-
- /*
-  * Calculate and update the self-refresh watermark only when one
-  * display plane is used.
-  *
-  * SNB support 3 levels of watermark.
-  *
-  * WM1/WM2/WM2 watermarks have to be enabled in the ascending order,
-  * and disabled in the descending order
-  *
-  */
- I915_WRITE(WM3_LP_ILK, 0);
- I915_WRITE(WM2_LP_ILK, 0);
- I915_WRITE(WM1_LP_ILK, 0);
-
- if (!single_plane_enabled(enabled) ||
-     dev_priv->sprite_scaling_enabled)
-  return;
- enabled = ffs(enabled) - 1;
-
- /* WM1 */
- if (!ironlake_compute_srwm(dev, 1, enabled,
-       dev_priv->wm.pri_latency[1] * 500,
-       &sandybridge_display_srwm_info,
-       &sandybridge_cursor_srwm_info,
-       &fbc_wm, &plane_wm, &cursor_wm))
-  return;
-
- I915_WRITE(WM1_LP_ILK,
-     WM1_LP_SR_EN |
-     (dev_priv->wm.pri_latency[1] << WM1_LP_LATENCY_SHIFT) |
-     (fbc_wm << WM1_LP_FBC_SHIFT) |
-     (plane_wm << WM1_LP_SR_SHIFT) |
-     cursor_wm);
-
- /* WM2 */
- if (!ironlake_compute_srwm(dev, 2, enabled,
-       dev_priv->wm.pri_latency[2] * 500,
-       &sandybridge_display_srwm_info,
-       &sandybridge_cursor_srwm_info,
-       &fbc_wm, &plane_wm, &cursor_wm))
-  return;
-
- I915_WRITE(WM2_LP_ILK,
-     WM2_LP_EN |
-     (dev_priv->wm.pri_latency[2] << WM1_LP_LATENCY_SHIFT) |
-     (fbc_wm << WM1_LP_FBC_SHIFT) |
-     (plane_wm << WM1_LP_SR_SHIFT) |
-     cursor_wm);
-
- /* WM3, note we have to correct the cursor latency */
- if (!ironlake_compute_srwm(dev, 3, enabled,
-       dev_priv->wm.pri_latency[3] * 500,
-       &sandybridge_display_srwm_info,
-       &sandybridge_cursor_srwm_info,
-       &fbc_wm, &plane_wm, &ignore_cursor_wm) ||
-     !ironlake_compute_srwm(dev, 3, enabled,
-       dev_priv->wm.cur_latency[3] * 500,
-       &sandybridge_display_srwm_info,
-       &sandybridge_cursor_srwm_info,
-       &ignore_fbc_wm, &ignore_plane_wm, &cursor_wm))
-  return;
-
- I915_WRITE(WM3_LP_ILK,
-     WM3_LP_EN |
-     (dev_priv->wm.pri_latency[3] << WM1_LP_LATENCY_SHIFT) |
-     (fbc_wm << WM1_LP_FBC_SHIFT) |
-     (plane_wm << WM1_LP_SR_SHIFT) |
-     cursor_wm);
-}
-
 static uint32_t ilk_pipe_pixel_rate(struct drm_device *dev,
         struct drm_crtc *crtc)
 {
@@ -2185,7 +1701,7 @@ static uint32_t ilk_wm_fbc(uint32_t pri_val, uint32_t horiz_pixels,
  return DIV_ROUND_UP(pri_val * 64, horiz_pixels * bytes_per_pixel) + 2;
 }
 
-struct hsw_pipe_wm_parameters {
+struct ilk_pipe_wm_parameters {
  bool active;
  uint32_t pipe_htotal;
  uint32_t pixel_rate;
@@ -2194,7 +1710,7 @@ struct hsw_pipe_wm_parameters {
  struct intel_plane_wm_parameters cur;
 };
 
-struct hsw_wm_maximums {
+struct ilk_wm_maximums {
  uint16_t pri;
  uint16_t spr;
  uint16_t cur;
@@ -2212,7 +1728,7 @@ struct intel_wm_config {
  * For both WM_PIPE and WM_LP.
  * mem_value must be in 0.1us units.
  */
-static uint32_t ilk_compute_pri_wm(const struct hsw_pipe_wm_parameters *params,
+static uint32_t ilk_compute_pri_wm(const struct ilk_pipe_wm_parameters *params,
        uint32_t mem_value,
        bool is_lp)
 {
@@ -2241,7 +1757,7 @@ static uint32_t ilk_compute_pri_wm(const struct hsw_pipe_wm_parameters *params,
  * For both WM_PIPE and WM_LP.
  * mem_value must be in 0.1us units.
  */
-static uint32_t ilk_compute_spr_wm(const struct hsw_pipe_wm_parameters *params,
+static uint32_t ilk_compute_spr_wm(const struct ilk_pipe_wm_parameters *params,
        uint32_t mem_value)
 {
  uint32_t method1, method2;
@@ -2264,7 +1780,7 @@ static uint32_t ilk_compute_spr_wm(const struct hsw_pipe_wm_parameters *params,
  * For both WM_PIPE and WM_LP.
  * mem_value must be in 0.1us units.
  */
-static uint32_t ilk_compute_cur_wm(const struct hsw_pipe_wm_parameters *params,
+static uint32_t ilk_compute_cur_wm(const struct ilk_pipe_wm_parameters *params,
        uint32_t mem_value)
 {
  if (!params->active || !params->cur.enabled)
@@ -2278,7 +1794,7 @@ static uint32_t ilk_compute_cur_wm(const struct hsw_pipe_wm_parameters *params,
 }
 
 /* Only for WM_LP. */
-static uint32_t ilk_compute_fbc_wm(const struct hsw_pipe_wm_parameters *params,
+static uint32_t ilk_compute_fbc_wm(const struct ilk_pipe_wm_parameters *params,
        uint32_t pri_val)
 {
  if (!params->active || !params->pri.enabled)
@@ -2383,7 +1899,7 @@ static void ilk_compute_wm_maximums(struct drm_device *dev,
         int level,
         const struct intel_wm_config *config,
         enum intel_ddb_partitioning ddb_partitioning,
-        struct hsw_wm_maximums *max)
+        struct ilk_wm_maximums *max)
 {
  max->pri = ilk_plane_wm_max(dev, level, config, ddb_partitioning, false);
  max->spr = ilk_plane_wm_max(dev, level, config, ddb_partitioning, true);
@@ -2392,7 +1908,7 @@ static void ilk_compute_wm_maximums(struct drm_device *dev,
 }
 
 static bool ilk_validate_wm_level(int level,
-      const struct hsw_wm_maximums *max,
+      const struct ilk_wm_maximums *max,
       struct intel_wm_level *result)
 {
  bool ret;
@@ -2434,7 +1950,7 @@ static bool ilk_validate_wm_level(int level,
 
 static void ilk_compute_wm_level(struct drm_i915_private *dev_priv,
      int level,
-     const struct hsw_pipe_wm_parameters *p,
+     const struct ilk_pipe_wm_parameters *p,
      struct intel_wm_level *result)
 {
  uint16_t pri_latency = dev_priv->wm.pri_latency[level];
@@ -2482,7 +1998,7 @@ static void intel_read_wm_latency(struct drm_device *dev, uint16_t wm[5])
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
 
- if (IS_HASWELL(dev)) {
+ if (IS_HASWELL(dev) || IS_BROADWELL(dev)) {
   uint64_t sskpd = I915_READ64(MCH_SSKPD);
 
   wm[0] = (sskpd >> 56) & 0xFF;
@@ -2530,7 +2046,7 @@ static void intel_fixup_cur_wm_latency(struct drm_device *dev, uint16_t wm[5])
 static int ilk_wm_max_level(const struct drm_device *dev)
 {
  /* how many WM levels are we expecting */
- if (IS_HASWELL(dev))
+ if (IS_HASWELL(dev) || IS_BROADWELL(dev))
   return 4;
  else if (INTEL_INFO(dev)->gen >= 6)
   return 3;
@@ -2582,8 +2098,8 @@ static void intel_setup_wm_latency(struct drm_device *dev)
  intel_print_wm_latency(dev, "Cursor", dev_priv->wm.cur_latency);
 }
 
-static void hsw_compute_wm_parameters(struct drm_crtc *crtc,
-          struct hsw_pipe_wm_parameters *p,
+static void ilk_compute_wm_parameters(struct drm_crtc *crtc,
+          struct ilk_pipe_wm_parameters *p,
           struct intel_wm_config *config)
 {
  struct drm_device *dev = crtc->dev;
@@ -2593,7 +2109,7 @@ static void hsw_compute_wm_parameters(struct drm_crtc *crtc,
 
  p->active = intel_crtc_active(crtc);
  if (p->active) {
-  p->pipe_htotal = intel_crtc->config.adjusted_mode.htotal;
+  p->pipe_htotal = intel_crtc->config.adjusted_mode.crtc_htotal;
   p->pixel_rate = ilk_pipe_pixel_rate(dev, crtc);
   p->pri.bytes_per_pixel = crtc->fb->bits_per_pixel / 8;
   p->cur.bytes_per_pixel = 4;
@@ -2620,7 +2136,7 @@ static void hsw_compute_wm_parameters(struct drm_crtc *crtc,
 
 /* Compute new watermarks for the pipe */
 static bool intel_compute_pipe_wm(struct drm_crtc *crtc,
-      const struct hsw_pipe_wm_parameters *params,
+      const struct ilk_pipe_wm_parameters *params,
       struct intel_pipe_wm *pipe_wm)
 {
  struct drm_device *dev = crtc->dev;
@@ -2632,16 +2148,25 @@ static bool intel_compute_pipe_wm(struct drm_crtc *crtc,
   .sprites_enabled = params->spr.enabled,
   .sprites_scaled = params->spr.scaled,
  };
- struct hsw_wm_maximums max;
+ struct ilk_wm_maximums max;
 
  /* LP0 watermarks always use 1/2 DDB partitioning */
  ilk_compute_wm_maximums(dev, 0, &config, INTEL_DDB_PART_1_2, &max);
 
+ /* ILK/SNB: LP2+ watermarks only w/o sprites */
+ if (INTEL_INFO(dev)->gen <= 6 && params->spr.enabled)
+  max_level = 1;
+
+ /* ILK/SNB/IVB: LP1+ watermarks only w/o scaling */
+ if (params->spr.scaled)
+  max_level = 0;
+
  for (level = 0; level <= max_level; level++)
   ilk_compute_wm_level(dev_priv, level, params,
          &pipe_wm->wm[level]);
 
- pipe_wm->linetime = hsw_compute_linetime_wm(dev, crtc);
+ if (IS_HASWELL(dev) || IS_BROADWELL(dev))
+  pipe_wm->linetime = hsw_compute_linetime_wm(dev, crtc);
 
  /* At least LP0 must be valid */
  return ilk_validate_wm_level(0, &max, &pipe_wm->wm[0]);
@@ -2676,12 +2201,19 @@ static void ilk_merge_wm_level(struct drm_device *dev,
  * Merge all low power watermarks for all active pipes.
  */
 static void ilk_wm_merge(struct drm_device *dev,
-    const struct hsw_wm_maximums *max,
+    const struct intel_wm_config *config,
+    const struct ilk_wm_maximums *max,
     struct intel_pipe_wm *merged)
 {
  int level, max_level = ilk_wm_max_level(dev);
 
- merged->fbc_wm_enabled = true;
+ /* ILK/SNB/IVB: LP1+ watermarks only w/ single pipe */
+ if ((INTEL_INFO(dev)->gen <= 6 || IS_IVYBRIDGE(dev)) &&
+     config->num_pipes_active > 1)
+  return;
+
+ /* ILK: FBC WM must be disabled always */
+ merged->fbc_wm_enabled = INTEL_INFO(dev)->gen >= 6;
 
  /* merge each WM1+ level */
  for (level = 1; level <= max_level; level++) {
@@ -2701,6 +2233,20 @@ static void ilk_wm_merge(struct drm_device *dev,
    wm->fbc_val = 0;
   }
  }
+
+ /* ILK: LP2+ must be disabled when FBC WM is disabled but FBC enabled */
+ /*
+  * FIXME this is racy. FBC might get enabled later.
+  * What we should check here is whether FBC can be
+  * enabled sometime later.
+  */
+ if (IS_GEN5(dev) && !merged->fbc_wm_enabled && intel_fbc_enabled(dev)) {
+  for (level = 2; level <= max_level; level++) {
+   struct intel_wm_level *wm = &merged->wm[level];
+
+   wm->enable = false;
+  }
+ }
 }
 
 static int ilk_wm_lp_to_level(int wm_lp, const struct intel_pipe_wm *pipe_wm)
@@ -2709,10 +2255,21 @@ static int ilk_wm_lp_to_level(int wm_lp, const struct intel_pipe_wm *pipe_wm)
  return wm_lp + (wm_lp >= 2 && pipe_wm->wm[4].enable);
 }
 
-static void hsw_compute_wm_results(struct drm_device *dev,
+/* The value we need to program into the WM_LPx latency field */
+static unsigned int ilk_wm_lp_latency(struct drm_device *dev, int level)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+
+ if (IS_HASWELL(dev) || IS_BROADWELL(dev))
+  return 2 * level;
+ else
+  return dev_priv->wm.pri_latency[level];
+}
+
+static void ilk_compute_wm_results(struct drm_device *dev,
        const struct intel_pipe_wm *merged,
        enum intel_ddb_partitioning partitioning,
-       struct hsw_wm_values *results)
+       struct ilk_wm_values *results)
 {
  struct intel_crtc *intel_crtc;
  int level, wm_lp;
@@ -2731,7 +2288,7 @@ static void hsw_compute_wm_results(struct drm_device *dev,
    break;
 
   results->wm_lp[wm_lp - 1] = WM3_LP_EN |
-   ((level * 2) << WM1_LP_LATENCY_SHIFT) |
+   (ilk_wm_lp_latency(dev, level) << WM1_LP_LATENCY_SHIFT) |
    (r->pri_val << WM1_LP_SR_SHIFT) |
    r->cur_val;
 
@@ -2742,7 +2299,11 @@ static void hsw_compute_wm_results(struct drm_device *dev,
    results->wm_lp[wm_lp - 1] |=
     r->fbc_val << WM1_LP_FBC_SHIFT;
 
-  results->wm_lp_spr[wm_lp - 1] = r->spr_val;
+  if (INTEL_INFO(dev)->gen <= 6 && r->spr_val) {
+   WARN_ON(wm_lp != 1);
+   results->wm_lp_spr[wm_lp - 1] = WM1S_LP_EN | r->spr_val;
+  } else
+   results->wm_lp_spr[wm_lp - 1] = r->spr_val;
  }
 
  /* LP0 register values */
@@ -2765,7 +2326,7 @@ static void hsw_compute_wm_results(struct drm_device *dev,
 
 /* Find the result with the highest level enabled. Check for enable_fbc_wm in
  * case both are at the same level. Prefer r1 in case they're the same. */
-static struct intel_pipe_wm *hsw_find_best_result(struct drm_device *dev,
+static struct intel_pipe_wm *ilk_find_best_result(struct drm_device *dev,
         struct intel_pipe_wm *r1,
         struct intel_pipe_wm *r2)
 {
@@ -2800,8 +2361,8 @@ static struct intel_pipe_wm *hsw_find_best_result(struct drm_device *dev,
 #define WM_DIRTY_DDB (1 << 25)
 
 static unsigned int ilk_compute_wm_dirty(struct drm_device *dev,
-      const struct hsw_wm_values *old,
-      const struct hsw_wm_values *new)
+      const struct ilk_wm_values *old,
+      const struct ilk_wm_values *new)
 {
  unsigned int dirty = 0;
  enum pipe pipe;
@@ -2851,27 +2412,53 @@ static unsigned int ilk_compute_wm_dirty(struct drm_device *dev,
  return dirty;
 }
 
+static bool _ilk_disable_lp_wm(struct drm_i915_private *dev_priv,
+          unsigned int dirty)
+{
+ struct ilk_wm_values *previous = &dev_priv->wm.hw;
+ bool changed = false;
+
+ if (dirty & WM_DIRTY_LP(3) && previous->wm_lp[2] & WM1_LP_SR_EN) {
+  previous->wm_lp[2] &= ~WM1_LP_SR_EN;
+  I915_WRITE(WM3_LP_ILK, previous->wm_lp[2]);
+  changed = true;
+ }
+ if (dirty & WM_DIRTY_LP(2) && previous->wm_lp[1] & WM1_LP_SR_EN) {
+  previous->wm_lp[1] &= ~WM1_LP_SR_EN;
+  I915_WRITE(WM2_LP_ILK, previous->wm_lp[1]);
+  changed = true;
+ }
+ if (dirty & WM_DIRTY_LP(1) && previous->wm_lp[0] & WM1_LP_SR_EN) {
+  previous->wm_lp[0] &= ~WM1_LP_SR_EN;
+  I915_WRITE(WM1_LP_ILK, previous->wm_lp[0]);
+  changed = true;
+ }
+
+ /*
+  * Don't touch WM1S_LP_EN here.
+  * Doing so could cause underruns.
+  */
+
+ return changed;
+}
+
 /*
  * The spec says we shouldn't write when we don't need, because every write
  * causes WMs to be re-evaluated, expending some power.
  */
-static void hsw_write_wm_values(struct drm_i915_private *dev_priv,
-    struct hsw_wm_values *results)
+static void ilk_write_wm_values(struct drm_i915_private *dev_priv,
+    struct ilk_wm_values *results)
 {
- struct hsw_wm_values *previous = &dev_priv->wm.hw;
+ struct drm_device *dev = dev_priv->dev;
+ struct ilk_wm_values *previous = &dev_priv->wm.hw;
  unsigned int dirty;
  uint32_t val;
 
- dirty = ilk_compute_wm_dirty(dev_priv->dev, previous, results);
+ dirty = ilk_compute_wm_dirty(dev, previous, results);
  if (!dirty)
   return;
 
- if (dirty & WM_DIRTY_LP(3) && previous->wm_lp[2] != 0)
-  I915_WRITE(WM3_LP_ILK, 0);
- if (dirty & WM_DIRTY_LP(2) && previous->wm_lp[1] != 0)
-  I915_WRITE(WM2_LP_ILK, 0);
- if (dirty & WM_DIRTY_LP(1) && previous->wm_lp[0] != 0)
-  I915_WRITE(WM1_LP_ILK, 0);
+ _ilk_disable_lp_wm(dev_priv, dirty);
 
  if (dirty & WM_DIRTY_PIPE(PIPE_A))
   I915_WRITE(WM0_PIPEA_ILK, results->wm_pipe[0]);
@@ -2888,12 +2475,21 @@ static void hsw_write_wm_values(struct drm_i915_private *dev_priv,
   I915_WRITE(PIPE_WM_LINETIME(PIPE_C), results->wm_linetime[2]);
 
  if (dirty & WM_DIRTY_DDB) {
-  val = I915_READ(WM_MISC);
-  if (results->partitioning == INTEL_DDB_PART_1_2)
-   val &= ~WM_MISC_DATA_PARTITION_5_6;
-  else
-   val |= WM_MISC_DATA_PARTITION_5_6;
-  I915_WRITE(WM_MISC, val);
+  if (IS_HASWELL(dev) || IS_BROADWELL(dev)) {
+   val = I915_READ(WM_MISC);
+   if (results->partitioning == INTEL_DDB_PART_1_2)
+    val &= ~WM_MISC_DATA_PARTITION_5_6;
+   else
+    val |= WM_MISC_DATA_PARTITION_5_6;
+   I915_WRITE(WM_MISC, val);
+  } else {
+   val = I915_READ(DISP_ARB_CTL2);
+   if (results->partitioning == INTEL_DDB_PART_1_2)
+    val &= ~DISP_DATA_PARTITION_5_6;
+   else
+    val |= DISP_DATA_PARTITION_5_6;
+   I915_WRITE(DISP_ARB_CTL2, val);
+  }
  }
 
  if (dirty & WM_DIRTY_FBC) {
@@ -2905,37 +2501,48 @@ static void hsw_write_wm_values(struct drm_i915_private *dev_priv,
   I915_WRITE(DISP_ARB_CTL, val);
  }
 
- if (dirty & WM_DIRTY_LP(1) && previous->wm_lp_spr[0] != results->wm_lp_spr[0])
+ if (dirty & WM_DIRTY_LP(1) &&
+     previous->wm_lp_spr[0] != results->wm_lp_spr[0])
   I915_WRITE(WM1S_LP_ILK, results->wm_lp_spr[0]);
- if (dirty & WM_DIRTY_LP(2) && previous->wm_lp_spr[1] != results->wm_lp_spr[1])
-  I915_WRITE(WM2S_LP_IVB, results->wm_lp_spr[1]);
- if (dirty & WM_DIRTY_LP(3) && previous->wm_lp_spr[2] != results->wm_lp_spr[2])
-  I915_WRITE(WM3S_LP_IVB, results->wm_lp_spr[2]);
 
- if (dirty & WM_DIRTY_LP(1) && results->wm_lp[0] != 0)
+ if (INTEL_INFO(dev)->gen >= 7) {
+  if (dirty & WM_DIRTY_LP(2) && previous->wm_lp_spr[1] != results->wm_lp_spr[1])
+   I915_WRITE(WM2S_LP_IVB, results->wm_lp_spr[1]);
+  if (dirty & WM_DIRTY_LP(3) && previous->wm_lp_spr[2] != results->wm_lp_spr[2])
+   I915_WRITE(WM3S_LP_IVB, results->wm_lp_spr[2]);
+ }
+
+ if (dirty & WM_DIRTY_LP(1) && previous->wm_lp[0] != results->wm_lp[0])
   I915_WRITE(WM1_LP_ILK, results->wm_lp[0]);
- if (dirty & WM_DIRTY_LP(2) && results->wm_lp[1] != 0)
+ if (dirty & WM_DIRTY_LP(2) && previous->wm_lp[1] != results->wm_lp[1])
   I915_WRITE(WM2_LP_ILK, results->wm_lp[1]);
- if (dirty & WM_DIRTY_LP(3) && results->wm_lp[2] != 0)
+ if (dirty & WM_DIRTY_LP(3) && previous->wm_lp[2] != results->wm_lp[2])
   I915_WRITE(WM3_LP_ILK, results->wm_lp[2]);
 
  dev_priv->wm.hw = *results;
 }
 
-static void haswell_update_wm(struct drm_crtc *crtc)
+static bool ilk_disable_lp_wm(struct drm_device *dev)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+
+ return _ilk_disable_lp_wm(dev_priv, WM_DIRTY_LP_ALL);
+}
+
+static void ilk_update_wm(struct drm_crtc *crtc)
 {
  struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
  struct drm_device *dev = crtc->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
- struct hsw_wm_maximums max;
- struct hsw_pipe_wm_parameters params = {};
- struct hsw_wm_values results = {};
+ struct ilk_wm_maximums max;
+ struct ilk_pipe_wm_parameters params = {};
+ struct ilk_wm_values results = {};
  enum intel_ddb_partitioning partitioning;
  struct intel_pipe_wm pipe_wm = {};
  struct intel_pipe_wm lp_wm_1_2 = {}, lp_wm_5_6 = {}, *best_lp_wm;
  struct intel_wm_config config = {};
 
- hsw_compute_wm_parameters(crtc, &params, &config);
+ ilk_compute_wm_parameters(crtc, &params, &config);
 
  intel_compute_pipe_wm(crtc, &params, &pipe_wm);
 
@@ -2945,15 +2552,15 @@ static void haswell_update_wm(struct drm_crtc *crtc)
  intel_crtc->wm.active = pipe_wm;
 
  ilk_compute_wm_maximums(dev, 1, &config, INTEL_DDB_PART_1_2, &max);
- ilk_wm_merge(dev, &max, &lp_wm_1_2);
+ ilk_wm_merge(dev, &config, &max, &lp_wm_1_2);
 
  /* 5/6 split only in single pipe config on IVB+ */
  if (INTEL_INFO(dev)->gen >= 7 &&
      config.num_pipes_active == 1 && config.sprites_enabled) {
   ilk_compute_wm_maximums(dev, 1, &config, INTEL_DDB_PART_5_6, &max);
-  ilk_wm_merge(dev, &max, &lp_wm_5_6);
+  ilk_wm_merge(dev, &config, &max, &lp_wm_5_6);
 
-  best_lp_wm = hsw_find_best_result(dev, &lp_wm_1_2, &lp_wm_5_6);
+  best_lp_wm = ilk_find_best_result(dev, &lp_wm_1_2, &lp_wm_5_6);
  } else {
   best_lp_wm = &lp_wm_1_2;
  }
@@ -2961,16 +2568,17 @@ static void haswell_update_wm(struct drm_crtc *crtc)
  partitioning = (best_lp_wm == &lp_wm_1_2) ?
          INTEL_DDB_PART_1_2 : INTEL_DDB_PART_5_6;
 
- hsw_compute_wm_results(dev, best_lp_wm, partitioning, &results);
+ ilk_compute_wm_results(dev, best_lp_wm, partitioning, &results);
 
- hsw_write_wm_values(dev_priv, &results);
+ ilk_write_wm_values(dev_priv, &results);
 }
 
-static void haswell_update_sprite_wm(struct drm_plane *plane,
+static void ilk_update_sprite_wm(struct drm_plane *plane,
          struct drm_crtc *crtc,
          uint32_t sprite_width, int pixel_size,
          bool enabled, bool scaled)
 {
+ struct drm_device *dev = plane->dev;
  struct intel_plane *intel_plane = to_intel_plane(plane);
 
  intel_plane->wm.enabled = enabled;
@@ -2978,176 +2586,24 @@ static void haswell_update_sprite_wm(struct drm_plane *plane,
  intel_plane->wm.horiz_pixels = sprite_width;
  intel_plane->wm.bytes_per_pixel = pixel_size;
 
- haswell_update_wm(crtc);
-}
-
-static bool
-sandybridge_compute_sprite_wm(struct drm_device *dev, int plane,
-         uint32_t sprite_width, int pixel_size,
-         const struct intel_watermark_params *display,
-         int display_latency_ns, int *sprite_wm)
-{
- struct drm_crtc *crtc;
- int clock;
- int entries, tlb_miss;
-
- crtc = intel_get_crtc_for_plane(dev, plane);
- if (!intel_crtc_active(crtc)) {
-  *sprite_wm = display->guard_size;
-  return false;
- }
-
- clock = to_intel_crtc(crtc)->config.adjusted_mode.crtc_clock;
-
- /* Use the small buffer method to calculate the sprite watermark */
- entries = ((clock * pixel_size / 1000) * display_latency_ns) / 1000;
- tlb_miss = display->fifo_size*display->cacheline_size -
-  sprite_width * 8;
- if (tlb_miss > 0)
-  entries += tlb_miss;
- entries = DIV_ROUND_UP(entries, display->cacheline_size);
- *sprite_wm = entries + display->guard_size;
- if (*sprite_wm > (int)display->max_wm)
-  *sprite_wm = display->max_wm;
-
- return true;
-}
-
-static bool
-sandybridge_compute_sprite_srwm(struct drm_device *dev, int plane,
-    uint32_t sprite_width, int pixel_size,
-    const struct intel_watermark_params *display,
-    int latency_ns, int *sprite_wm)
-{
- struct drm_crtc *crtc;
- unsigned long line_time_us;
- int clock;
- int line_count, line_size;
- int small, large;
- int entries;
-
- if (!latency_ns) {
-  *sprite_wm = 0;
-  return false;
- }
-
- crtc = intel_get_crtc_for_plane(dev, plane);
- clock = to_intel_crtc(crtc)->config.adjusted_mode.crtc_clock;
- if (!clock) {
-  *sprite_wm = 0;
-  return false;
- }
-
- line_time_us = (sprite_width * 1000) / clock;
- if (!line_time_us) {
-  *sprite_wm = 0;
-  return false;
- }
-
- line_count = (latency_ns / line_time_us + 1000) / 1000;
- line_size = sprite_width * pixel_size;
-
- /* Use the minimum of the small and large buffer method for primary */
- small = ((clock * pixel_size / 1000) * latency_ns) / 1000;
- large = line_count * line_size;
-
- entries = DIV_ROUND_UP(min(small, large), display->cacheline_size);
- *sprite_wm = entries + display->guard_size;
-
- return *sprite_wm > 0x3ff ? false : true;
-}
-
-static void sandybridge_update_sprite_wm(struct drm_plane *plane,
-      struct drm_crtc *crtc,
-      uint32_t sprite_width, int pixel_size,
-      bool enabled, bool scaled)
-{
- struct drm_device *dev = plane->dev;
- struct drm_i915_private *dev_priv = dev->dev_private;
- int pipe = to_intel_plane(plane)->pipe;
- int latency = dev_priv->wm.spr_latency[0] * 100; /* In unit 0.1us */
- u32 val;
- int sprite_wm, reg;
- int ret;
-
- if (!enabled)
-  return;
-
- switch (pipe) {
- case 0:
-  reg = WM0_PIPEA_ILK;
-  break;
- case 1:
-  reg = WM0_PIPEB_ILK;
-  break;
- case 2:
-  reg = WM0_PIPEC_IVB;
-  break;
- default:
-  return; /* bad pipe */
- }
-
- ret = sandybridge_compute_sprite_wm(dev, pipe, sprite_width, pixel_size,
-         &sandybridge_display_wm_info,
-         latency, &sprite_wm);
- if (!ret) {
-  DRM_DEBUG_KMS("failed to compute sprite wm for pipe %c\n",
-         pipe_name(pipe));
-  return;
- }
-
- val = I915_READ(reg);
- val &= ~WM0_PIPE_SPRITE_MASK;
- I915_WRITE(reg, val | (sprite_wm << WM0_PIPE_SPRITE_SHIFT));
- DRM_DEBUG_KMS("sprite watermarks For pipe %c - %d\n", pipe_name(pipe), sprite_wm);
-
-
- ret = sandybridge_compute_sprite_srwm(dev, pipe, sprite_width,
-           pixel_size,
-           &sandybridge_display_srwm_info,
-           dev_priv->wm.spr_latency[1] * 500,
-           &sprite_wm);
- if (!ret) {
-  DRM_DEBUG_KMS("failed to compute sprite lp1 wm on pipe %c\n",
-         pipe_name(pipe));
-  return;
- }
- I915_WRITE(WM1S_LP_ILK, sprite_wm);
-
- /* Only IVB has two more LP watermarks for sprite */
- if (!IS_IVYBRIDGE(dev))
-  return;
-
- ret = sandybridge_compute_sprite_srwm(dev, pipe, sprite_width,
-           pixel_size,
-           &sandybridge_display_srwm_info,
-           dev_priv->wm.spr_latency[2] * 500,
-           &sprite_wm);
- if (!ret) {
-  DRM_DEBUG_KMS("failed to compute sprite lp2 wm on pipe %c\n",
-         pipe_name(pipe));
-  return;
- }
- I915_WRITE(WM2S_LP_IVB, sprite_wm);
+ /*
+  * IVB workaround: must disable low power watermarks for at least
+  * one frame before enabling scaling.  LP watermarks can be re-enabled
+  * when scaling is disabled.
+  *
+  * WaCxSRDisabledForSpriteScaling:ivb
+  */
+ if (IS_IVYBRIDGE(dev) && scaled && ilk_disable_lp_wm(dev))
+  intel_wait_for_vblank(dev, intel_plane->pipe);
 
- ret = sandybridge_compute_sprite_srwm(dev, pipe, sprite_width,
-           pixel_size,
-           &sandybridge_display_srwm_info,
-           dev_priv->wm.spr_latency[3] * 500,
-           &sprite_wm);
- if (!ret) {
-  DRM_DEBUG_KMS("failed to compute sprite lp3 wm on pipe %c\n",
-         pipe_name(pipe));
-  return;
- }
- I915_WRITE(WM3S_LP_IVB, sprite_wm);
+ ilk_update_wm(crtc);
 }
 
 static void ilk_pipe_wm_get_hw_state(struct drm_crtc *crtc)
 {
  struct drm_device *dev = crtc->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
- struct hsw_wm_values *hw = &dev_priv->wm.hw;
+ struct ilk_wm_values *hw = &dev_priv->wm.hw;
  struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
  struct intel_pipe_wm *active = &intel_crtc->wm.active;
  enum pipe pipe = intel_crtc->pipe;
@@ -3158,7 +2614,8 @@ static void ilk_pipe_wm_get_hw_state(struct drm_crtc *crtc)
  };
 
  hw->wm_pipe[pipe] = I915_READ(wm0_pipe_reg[pipe]);
- hw->wm_linetime[pipe] = I915_READ(PIPE_WM_LINETIME(pipe));
+ if (IS_HASWELL(dev) || IS_BROADWELL(dev))
+  hw->wm_linetime[pipe] = I915_READ(PIPE_WM_LINETIME(pipe));
 
  if (intel_crtc_active(crtc)) {
   u32 tmp = hw->wm_pipe[pipe];
@@ -3190,7 +2647,7 @@ static void ilk_pipe_wm_get_hw_state(struct drm_crtc *crtc)
 void ilk_wm_get_hw_state(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
- struct hsw_wm_values *hw = &dev_priv->wm.hw;
+ struct ilk_wm_values *hw = &dev_priv->wm.hw;
  struct drm_crtc *crtc;
 
  list_for_each_entry(crtc, &dev->mode_config.crtc_list, head)
@@ -3204,8 +2661,12 @@ void ilk_wm_get_hw_state(struct drm_device *dev)
  hw->wm_lp_spr[1] = I915_READ(WM2S_LP_IVB);
  hw->wm_lp_spr[2] = I915_READ(WM3S_LP_IVB);
 
- hw->partitioning = (I915_READ(WM_MISC) & WM_MISC_DATA_PARTITION_5_6) ?
-  INTEL_DDB_PART_5_6 : INTEL_DDB_PART_1_2;
+ if (IS_HASWELL(dev) || IS_BROADWELL(dev))
+  hw->partitioning = (I915_READ(WM_MISC) & WM_MISC_DATA_PARTITION_5_6) ?
+   INTEL_DDB_PART_5_6 : INTEL_DDB_PART_1_2;
+ else if (IS_IVYBRIDGE(dev))
+  hw->partitioning = (I915_READ(DISP_ARB_CTL2) & DISP_DATA_PARTITION_5_6) ?
+   INTEL_DDB_PART_5_6 : INTEL_DDB_PART_1_2;
 
  hw->enable_fbc_wm =
   !(I915_READ(DISP_ARB_CTL) & DISP_FBC_WM_DIS);
@@ -3430,26 +2891,19 @@ static void ironlake_disable_drps(struct drm_device *dev)
  * ourselves, instead of doing a rmw cycle (which might result in us clearing
  * all limits and the gpu stuck at whatever frequency it is at atm).
  */
-static u32 gen6_rps_limits(struct drm_i915_private *dev_priv, u8 *val)
+static u32 gen6_rps_limits(struct drm_i915_private *dev_priv, u8 val)
 {
  u32 limits;
 
- limits = 0;
-
- if (*val >= dev_priv->rps.max_delay)
-  *val = dev_priv->rps.max_delay;
- limits |= dev_priv->rps.max_delay << 24;
-
  /* Only set the down limit when we've reached the lowest level to avoid
   * getting more interrupts, otherwise leave this clear. This prevents a
   * race in the hw when coming out of rc6: There's a tiny window where
   * the hw runs at the minimal clock before selecting the desired
   * frequency, if the down threshold expires in that window we will not
   * receive a down interrupt. */
- if (*val <= dev_priv->rps.min_delay) {
-  *val = dev_priv->rps.min_delay;
+ limits = dev_priv->rps.max_delay << 24;
+ if (val <= dev_priv->rps.min_delay)
   limits |= dev_priv->rps.min_delay << 16;
- }
 
  return limits;
 }
@@ -3549,7 +3003,6 @@ static void gen6_set_rps_thresholds(struct drm_i915_private *dev_priv, u8 val)
 void gen6_set_rps(struct drm_device *dev, u8 val)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
- u32 limits = gen6_rps_limits(dev_priv, &val);
 
  WARN_ON(!mutex_is_locked(&dev_priv->rps.hw_lock));
  WARN_ON(val > dev_priv->rps.max_delay);
@@ -3572,7 +3025,8 @@ void gen6_set_rps(struct drm_device *dev, u8 val)
  /* Make sure we continue to get interrupts
   * until we hit the minimum or maximum frequencies.
   */
- I915_WRITE(GEN6_RP_INTERRUPT_LIMITS, limits);
+ I915_WRITE(GEN6_RP_INTERRUPT_LIMITS,
+     gen6_rps_limits(dev_priv, val));
 
  POSTING_READ(GEN6_RPNSWREQ);
 
@@ -3583,9 +3037,11 @@ void gen6_set_rps(struct drm_device *dev, u8 val)
 
 void gen6_rps_idle(struct drm_i915_private *dev_priv)
 {
+ struct drm_device *dev = dev_priv->dev;
+
  mutex_lock(&dev_priv->rps.hw_lock);
  if (dev_priv->rps.enabled) {
-  if (dev_priv->info->is_valleyview)
+  if (IS_VALLEYVIEW(dev))
    valleyview_set_rps(dev_priv->dev, dev_priv->rps.min_delay);
   else
    gen6_set_rps(dev_priv->dev, dev_priv->rps.min_delay);
@@ -3596,9 +3052,11 @@ void gen6_rps_idle(struct drm_i915_private *dev_priv)
 
 void gen6_rps_boost(struct drm_i915_private *dev_priv)
 {
+ struct drm_device *dev = dev_priv->dev;
+
  mutex_lock(&dev_priv->rps.hw_lock);
  if (dev_priv->rps.enabled) {
-  if (dev_priv->info->is_valleyview)
+  if (IS_VALLEYVIEW(dev))
    valleyview_set_rps(dev_priv->dev, dev_priv->rps.max_delay);
   else
    gen6_set_rps(dev_priv->dev, dev_priv->rps.max_delay);
@@ -3607,48 +3065,18 @@ void gen6_rps_boost(struct drm_i915_private *dev_priv)
  mutex_unlock(&dev_priv->rps.hw_lock);
 }
 
-/*
- * Wait until the previous freq change has completed,
- * or the timeout elapsed, and then update our notion
- * of the current GPU frequency.
- */
-static void vlv_update_rps_cur_delay(struct drm_i915_private *dev_priv)
-{
- u32 pval;
-
- WARN_ON(!mutex_is_locked(&dev_priv->rps.hw_lock));
-
- if (wait_for(((pval = vlv_punit_read(dev_priv, PUNIT_REG_GPU_FREQ_STS)) & GENFREQSTATUS) == 0, 10))
-  DRM_DEBUG_DRIVER("timed out waiting for Punit\n");
-
- pval >>= 8;
-
- if (pval != dev_priv->rps.cur_delay)
-  DRM_DEBUG_DRIVER("Punit overrode GPU freq: %d MHz (%u) requested, but got %d Mhz (%u)\n",
-     vlv_gpu_freq(dev_priv->mem_freq, dev_priv->rps.cur_delay),
-     dev_priv->rps.cur_delay,
-     vlv_gpu_freq(dev_priv->mem_freq, pval), pval);
-
- dev_priv->rps.cur_delay = pval;
-}
-
 void valleyview_set_rps(struct drm_device *dev, u8 val)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
 
- gen6_rps_limits(dev_priv, &val);
-
  WARN_ON(!mutex_is_locked(&dev_priv->rps.hw_lock));
  WARN_ON(val > dev_priv->rps.max_delay);
  WARN_ON(val < dev_priv->rps.min_delay);
 
- vlv_update_rps_cur_delay(dev_priv);
-
  DRM_DEBUG_DRIVER("GPU freq request from %d MHz (%u) to %d MHz (%u)\n",
-    vlv_gpu_freq(dev_priv->mem_freq,
-          dev_priv->rps.cur_delay),
+    vlv_gpu_freq(dev_priv, dev_priv->rps.cur_delay),
     dev_priv->rps.cur_delay,
-    vlv_gpu_freq(dev_priv->mem_freq, val), val);
+    vlv_gpu_freq(dev_priv, val), val);
 
  if (val == dev_priv->rps.cur_delay)
   return;
@@ -3657,7 +3085,7 @@ void valleyview_set_rps(struct drm_device *dev, u8 val)
 
  dev_priv->rps.cur_delay = val;
 
- trace_intel_gpu_freq_change(vlv_gpu_freq(dev_priv->mem_freq, val));
+ trace_intel_gpu_freq_change(vlv_gpu_freq(dev_priv, val));
 }
 
 static void gen6_disable_rps_interrupts(struct drm_device *dev)
@@ -3775,7 +3203,7 @@ static void gen8_enable_rps(struct drm_device *dev)
 
  /* 1c & 1d: Get forcewake during program sequence. Although the driver
   * hasn't enabled a state yet where we need forcewake, BIOS may have.*/
- gen6_gt_force_wake_get(dev_priv);
+ gen6_gt_force_wake_get(dev_priv, FORCEWAKE_ALL);
 
  /* 2a: Disable RC states. */
  I915_WRITE(GEN6_RC_CONTROL, 0);
@@ -3832,7 +3260,7 @@ static void gen8_enable_rps(struct drm_device *dev)
 
  gen6_enable_rps_interrupts(dev);
 
- gen6_gt_force_wake_put(dev_priv);
+ gen6_gt_force_wake_put(dev_priv, FORCEWAKE_ALL);
 }
 
 static void gen6_enable_rps(struct drm_device *dev)
@@ -3862,7 +3290,7 @@ static void gen6_enable_rps(struct drm_device *dev)
   I915_WRITE(GTFIFODBG, gtfifodbg);
  }
 
- gen6_gt_force_wake_get(dev_priv);
+ gen6_gt_force_wake_get(dev_priv, FORCEWAKE_ALL);
 
  rp_state_cap = I915_READ(GEN6_RP_STATE_CAP);
  gt_perf_status = I915_READ(GEN6_GT_PERF_STATUS);
@@ -3954,7 +3382,7 @@ static void gen6_enable_rps(struct drm_device *dev)
    DRM_ERROR("Couldn't fix incorrect rc6 voltage\n");
  }
 
- gen6_gt_force_wake_put(dev_priv);
+ gen6_gt_force_wake_put(dev_priv, FORCEWAKE_ALL);
 }
 
 void gen6_update_ring_freq(struct drm_device *dev)
@@ -4065,6 +3493,8 @@ static void valleyview_setup_pctx(struct drm_device *dev)
  u32 pcbr;
  int pctx_size = 24*1024;
 
+ WARN_ON(!mutex_is_locked(&dev->struct_mutex));
+
  pcbr = I915_READ(VLV_PCBR);
  if (pcbr) {
   /* BIOS set it up already, grab the pre-alloc'd space */
@@ -4114,9 +3544,8 @@ static void valleyview_enable_rps(struct drm_device *dev)
   I915_WRITE(GTFIFODBG, gtfifodbg);
  }
 
- valleyview_setup_pctx(dev);
-
- gen6_gt_force_wake_get(dev_priv);
+ /* If VLV, Forcewake all wells, else re-direct to regular path */
+ gen6_gt_force_wake_get(dev_priv, FORCEWAKE_ALL);
 
  I915_WRITE(GEN6_RP_UP_THRESHOLD, 59400);
  I915_WRITE(GEN6_RP_DOWN_THRESHOLD, 245000);
@@ -4140,7 +3569,7 @@ static void valleyview_enable_rps(struct drm_device *dev)
  for_each_ring(ring, dev_priv, i)
   I915_WRITE(RING_MAX_IDLE(ring->mmio_base), 10);
 
- I915_WRITE(GEN6_RC6_THRESHOLD, 0xc350);
+ I915_WRITE(GEN6_RC6_THRESHOLD, 0x557);
 
  /* allows RC6 residency counter to work */
  I915_WRITE(VLV_COUNTER_CONTROL,
@@ -4148,65 +3577,47 @@ static void valleyview_enable_rps(struct drm_device *dev)
           VLV_MEDIA_RC6_COUNT_EN |
           VLV_RENDER_RC6_COUNT_EN));
  if (intel_enable_rc6(dev) & INTEL_RC6_ENABLE)
-  rc6_mode = GEN7_RC_CTL_TO_MODE;
+  rc6_mode = GEN7_RC_CTL_TO_MODE | VLV_RC_CTL_CTX_RST_PARALLEL;
 
  intel_print_rc6_info(dev, rc6_mode);
 
  I915_WRITE(GEN6_RC_CONTROL, rc6_mode);
 
  val = vlv_punit_read(dev_priv, PUNIT_REG_GPU_FREQ_STS);
- switch ((val >> 6) & 3) {
- case 0:
- case 1:
-  dev_priv->mem_freq = 800;
-  break;
- case 2:
-  dev_priv->mem_freq = 1066;
-  break;
- case 3:
-  dev_priv->mem_freq = 1333;
-  break;
- }
- DRM_DEBUG_DRIVER("DDR speed: %d MHz", dev_priv->mem_freq);
 
  DRM_DEBUG_DRIVER("GPLL enabled? %s\n", val & 0x10 ? "yes" : "no");
  DRM_DEBUG_DRIVER("GPU status: 0x%08x\n", val);
 
  dev_priv->rps.cur_delay = (val >> 8) & 0xff;
  DRM_DEBUG_DRIVER("current GPU freq: %d MHz (%u)\n",
-    vlv_gpu_freq(dev_priv->mem_freq,
-          dev_priv->rps.cur_delay),
+    vlv_gpu_freq(dev_priv, dev_priv->rps.cur_delay),
     dev_priv->rps.cur_delay);
 
  dev_priv->rps.max_delay = valleyview_rps_max_freq(dev_priv);
  dev_priv->rps.hw_max = dev_priv->rps.max_delay;
  DRM_DEBUG_DRIVER("max GPU freq: %d MHz (%u)\n",
-    vlv_gpu_freq(dev_priv->mem_freq,
-          dev_priv->rps.max_delay),
+    vlv_gpu_freq(dev_priv, dev_priv->rps.max_delay),
     dev_priv->rps.max_delay);
 
  dev_priv->rps.rpe_delay = valleyview_rps_rpe_freq(dev_priv);
  DRM_DEBUG_DRIVER("RPe GPU freq: %d MHz (%u)\n",
-    vlv_gpu_freq(dev_priv->mem_freq,
-          dev_priv->rps.rpe_delay),
+    vlv_gpu_freq(dev_priv, dev_priv->rps.rpe_delay),
     dev_priv->rps.rpe_delay);
 
  dev_priv->rps.min_delay = valleyview_rps_min_freq(dev_priv);
  DRM_DEBUG_DRIVER("min GPU freq: %d MHz (%u)\n",
-    vlv_gpu_freq(dev_priv->mem_freq,
-          dev_priv->rps.min_delay),
+    vlv_gpu_freq(dev_priv, dev_priv->rps.min_delay),
     dev_priv->rps.min_delay);
 
  DRM_DEBUG_DRIVER("setting GPU freq to %d MHz (%u)\n",
-    vlv_gpu_freq(dev_priv->mem_freq,
-          dev_priv->rps.rpe_delay),
+    vlv_gpu_freq(dev_priv, dev_priv->rps.rpe_delay),
     dev_priv->rps.rpe_delay);
 
  valleyview_set_rps(dev_priv->dev, dev_priv->rps.rpe_delay);
 
  gen6_enable_rps_interrupts(dev);
 
- gen6_gt_force_wake_put(dev_priv);
+ gen6_gt_force_wake_put(dev_priv, FORCEWAKE_ALL);
 }
 
 void ironlake_teardown_rc6(struct drm_device *dev)
@@ -4984,6 +4395,8 @@ void intel_enable_gt_powersave(struct drm_device *dev)
   ironlake_enable_rc6(dev);
   intel_init_emon(dev);
  } else if (IS_GEN6(dev) || IS_GEN7(dev)) {
+  if (IS_VALLEYVIEW(dev))
+   valleyview_setup_pctx(dev);
   /*
    * PCU communication is slow and this doesn't need to be
    * done at any specific time, so do this out of our fast path
@@ -5019,6 +4432,20 @@ static void g4x_disable_trickle_feed(struct drm_device *dev)
  }
 }
 
+static void ilk_init_lp_watermarks(struct drm_device *dev)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+
+ I915_WRITE(WM3_LP_ILK, I915_READ(WM3_LP_ILK) & ~WM1_LP_SR_EN);
+ I915_WRITE(WM2_LP_ILK, I915_READ(WM2_LP_ILK) & ~WM1_LP_SR_EN);
+ I915_WRITE(WM1_LP_ILK, I915_READ(WM1_LP_ILK) & ~WM1_LP_SR_EN);
+
+ /*
+  * Don't touch WM1S_LP_EN here.
+  * Doing so could cause underruns.
+  */
+}
+
 static void ironlake_init_clock_gating(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
@@ -5052,9 +4479,8 @@ static void ironlake_init_clock_gating(struct drm_device *dev)
  I915_WRITE(DISP_ARB_CTL,
      (I915_READ(DISP_ARB_CTL) |
       DISP_FBC_WM_DIS));
- I915_WRITE(WM3_LP_ILK, 0);
- I915_WRITE(WM2_LP_ILK, 0);
- I915_WRITE(WM1_LP_ILK, 0);
+
+ ilk_init_lp_watermarks(dev);
 
  /*
   * Based on the document from hardware guys the following bits
@@ -5161,9 +4587,7 @@ static void gen6_init_clock_gating(struct drm_device *dev)
   I915_WRITE(GEN6_GT_MODE,
       _MASKED_BIT_ENABLE(GEN6_TD_FOUR_ROW_DISPATCH_DISABLE));
 
- I915_WRITE(WM3_LP_ILK, 0);
- I915_WRITE(WM2_LP_ILK, 0);
- I915_WRITE(WM1_LP_ILK, 0);
+ ilk_init_lp_watermarks(dev);
 
  I915_WRITE(CACHE_MODE_0,
      _MASKED_BIT_DISABLE(CM0_STC_EVICT_DISABLE_LRA_SNB));
@@ -5304,28 +4728,40 @@ static void gen8_init_clock_gating(struct drm_device *dev)
  I915_WRITE(GEN7_HALF_SLICE_CHICKEN1,
      _MASKED_BIT_ENABLE(GEN7_SINGLE_SUBSCAN_DISPATCH_ENABLE));
 
- /* WaSwitchSolVfFArbitrationPriority */
+ /* WaSwitchSolVfFArbitrationPriority:bdw */
  I915_WRITE(GAM_ECOCHK, I915_READ(GAM_ECOCHK) | HSW_ECOCHK_ARB_PRIO_SOL);
 
- /* WaPsrDPAMaskVBlankInSRD */
+ /* WaPsrDPAMaskVBlankInSRD:bdw */
  I915_WRITE(CHICKEN_PAR1_1,
      I915_READ(CHICKEN_PAR1_1) | DPA_MASK_VBLANK_SRD);
 
- /* WaPsrDPRSUnmaskVBlankInSRD */
+ /* WaPsrDPRSUnmaskVBlankInSRD:bdw */
  for_each_pipe(i) {
   I915_WRITE(CHICKEN_PIPESL_1(i),
       I915_READ(CHICKEN_PIPESL_1(i) |
          DPRS_MASK_VBLANK_SRD));
  }
+
+ /* Use Force Non-Coherent whenever executing a 3D context. This is a
+  * workaround for for a possible hang in the unlikely event a TLB
+  * invalidation occurs during a PSD flush.
+  */
+ I915_WRITE(HDC_CHICKEN0,
+     I915_READ(HDC_CHICKEN0) |
+     _MASKED_BIT_ENABLE(HDC_FORCE_NON_COHERENT));
+
+ /* WaVSRefCountFullforceMissDisable:bdw */
+ /* WaDSRefCountFullforceMissDisable:bdw */
+ I915_WRITE(GEN7_FF_THREAD_MODE,
+     I915_READ(GEN7_FF_THREAD_MODE) &
+     ~(GEN8_FF_DS_REF_CNT_FFME | GEN7_FF_VS_REF_CNT_FFME));
 }
 
 static void haswell_init_clock_gating(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
 
- I915_WRITE(WM3_LP_ILK, 0);
- I915_WRITE(WM2_LP_ILK, 0);
- I915_WRITE(WM1_LP_ILK, 0);
+ ilk_init_lp_watermarks(dev);
 
  /* According to the spec, bit 13 (RCZUNIT) must be set on IVB.
   * This implements the WaDisableRCZUnitClockGating:hsw workaround.
@@ -5374,9 +4810,7 @@ static void ivybridge_init_clock_gating(struct drm_device *dev)
  struct drm_i915_private *dev_priv = dev->dev_private;
  uint32_t snpcr;
 
- I915_WRITE(WM3_LP_ILK, 0);
- I915_WRITE(WM2_LP_ILK, 0);
- I915_WRITE(WM1_LP_ILK, 0);
+ ilk_init_lp_watermarks(dev);
 
  I915_WRITE(ILK_DSPCLK_GATE_D, ILK_VRHUNIT_CLOCK_GATE_DISABLE);
 
@@ -5463,6 +4897,26 @@ static void ivybridge_init_clock_gating(struct drm_device *dev)
 static void valleyview_init_clock_gating(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
+ u32 val;
+
+ mutex_lock(&dev_priv->rps.hw_lock);
+ val = vlv_punit_read(dev_priv, PUNIT_REG_GPU_FREQ_STS);
+ mutex_unlock(&dev_priv->rps.hw_lock);
+ switch ((val >> 6) & 3) {
+ case 0:
+  dev_priv->mem_freq = 800;
+  break;
+ case 1:
+  dev_priv->mem_freq = 1066;
+  break;
+ case 2:
+  dev_priv->mem_freq = 1333;
+  break;
+ case 3:
+  dev_priv->mem_freq = 1333;
+  break;
+ }
+ DRM_DEBUG_DRIVER("DDR speed: %d MHz", dev_priv->mem_freq);
 
  I915_WRITE(DSPCLK_GATE_D, VRHUNIT_CLOCK_GATE_DISABLE);
 
@@ -5642,50 +5096,133 @@ void intel_suspend_hw(struct drm_device *dev)
   lpt_suspend_hw(dev);
 }
 
-static bool is_always_on_power_domain(struct drm_device *dev,
-          enum intel_display_power_domain domain)
-{
- unsigned long always_on_domains;
+#define for_each_power_well(i, power_well, domain_mask, power_domains) \
+ for (i = 0;       \
+      i < (power_domains)->power_well_count &&   \
+   ((power_well) = &(power_domains)->power_wells[i]); \
+      i++)       \
+  if ((power_well)->domains & (domain_mask))
 
- BUG_ON(BIT(domain) & ~POWER_DOMAIN_MASK);
-
- if (IS_BROADWELL(dev)) {
-  always_on_domains = BDW_ALWAYS_ON_POWER_DOMAINS;
- } else if (IS_HASWELL(dev)) {
-  always_on_domains = HSW_ALWAYS_ON_POWER_DOMAINS;
- } else {
-  WARN_ON(1);
-  return true;
- }
-
- return BIT(domain) & always_on_domains;
-}
+#define for_each_power_well_rev(i, power_well, domain_mask, power_domains) \
+ for (i = (power_domains)->power_well_count - 1;    \
+      i >= 0 && ((power_well) = &(power_domains)->power_wells[i]);\
+      i--)        \
+  if ((power_well)->domains & (domain_mask))
 
 /**
  * We should only use the power well if we explicitly asked the hardware to
  * enable it, so check if it's enabled and also check if we've requested it to
  * be enabled.
  */
+static bool hsw_power_well_enabled(struct drm_device *dev,
+       struct i915_power_well *power_well)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+
+ return I915_READ(HSW_PWR_WELL_DRIVER) ==
+       (HSW_PWR_WELL_ENABLE_REQUEST | HSW_PWR_WELL_STATE_ENABLED);
+}
+
+bool intel_display_power_enabled_sw(struct drm_device *dev,
+        enum intel_display_power_domain domain)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct i915_power_domains *power_domains;
+
+ power_domains = &dev_priv->power_domains;
+
+ return power_domains->domain_use_count[domain];
+}
+
 bool intel_display_power_enabled(struct drm_device *dev,
      enum intel_display_power_domain domain)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
+ struct i915_power_domains *power_domains;
+ struct i915_power_well *power_well;
+ bool is_enabled;
+ int i;
 
- if (!HAS_POWER_WELL(dev))
-  return true;
+ power_domains = &dev_priv->power_domains;
 
- if (is_always_on_power_domain(dev, domain))
-  return true;
+ is_enabled = true;
 
- return I915_READ(HSW_PWR_WELL_DRIVER) ==
-       (HSW_PWR_WELL_ENABLE_REQUEST | HSW_PWR_WELL_STATE_ENABLED);
+ mutex_lock(&power_domains->lock);
+ for_each_power_well_rev(i, power_well, BIT(domain), power_domains) {
+  if (power_well->always_on)
+   continue;
+
+  if (!power_well->is_enabled(dev, power_well)) {
+   is_enabled = false;
+   break;
+  }
+ }
+ mutex_unlock(&power_domains->lock);
+
+ return is_enabled;
+}
+
+static void hsw_power_well_post_enable(struct drm_i915_private *dev_priv)
+{
+ struct drm_device *dev = dev_priv->dev;
+ unsigned long irqflags;
+
+ /*
+  * After we re-enable the power well, if we touch VGA register 0x3d5
+  * we'll get unclaimed register interrupts. This stops after we write
+  * anything to the VGA MSR register. The vgacon module uses this
+  * register all the time, so if we unbind our driver and, as a
+  * consequence, bind vgacon, we'll get stuck in an infinite loop at
+  * console_unlock(). So make here we touch the VGA MSR register, making
+  * sure vgacon can keep working normally without triggering interrupts
+  * and error messages.
+  */
+ vga_get_uninterruptible(dev->pdev, VGA_RSRC_LEGACY_IO);
+ outb(inb(VGA_MSR_READ), VGA_MSR_WRITE);
+ vga_put(dev->pdev, VGA_RSRC_LEGACY_IO);
+
+ if (IS_BROADWELL(dev)) {
+  spin_lock_irqsave(&dev_priv->irq_lock, irqflags);
+  I915_WRITE(GEN8_DE_PIPE_IMR(PIPE_B),
+      dev_priv->de_irq_mask[PIPE_B]);
+  I915_WRITE(GEN8_DE_PIPE_IER(PIPE_B),
+      ~dev_priv->de_irq_mask[PIPE_B] |
+      GEN8_PIPE_VBLANK);
+  I915_WRITE(GEN8_DE_PIPE_IMR(PIPE_C),
+      dev_priv->de_irq_mask[PIPE_C]);
+  I915_WRITE(GEN8_DE_PIPE_IER(PIPE_C),
+      ~dev_priv->de_irq_mask[PIPE_C] |
+      GEN8_PIPE_VBLANK);
+  POSTING_READ(GEN8_DE_PIPE_IER(PIPE_C));
+  spin_unlock_irqrestore(&dev_priv->irq_lock, irqflags);
+ }
+}
+
+static void hsw_power_well_post_disable(struct drm_i915_private *dev_priv)
+{
+ struct drm_device *dev = dev_priv->dev;
+ enum pipe p;
+ unsigned long irqflags;
+
+ /*
+  * After this, the registers on the pipes that are part of the power
+  * well will become zero, so we have to adjust our counters according to
+  * that.
+  *
+  * FIXME: Should we do this in general in drm_vblank_post_modeset?
+  */
+ spin_lock_irqsave(&dev->vbl_lock, irqflags);
+ for_each_pipe(p)
+  if (p != PIPE_A)
+   dev->vblank[p].last = 0;
+ spin_unlock_irqrestore(&dev->vbl_lock, irqflags);
 }
 
-static void __intel_set_power_well(struct drm_device *dev, bool enable)
+static void hsw_set_power_well(struct drm_device *dev,
+          struct i915_power_well *power_well, bool enable)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  bool is_enabled, enable_requested;
- unsigned long irqflags;
  uint32_t tmp;
 
  WARN_ON(dev_priv->pc8.enabled);
@@ -5706,42 +5243,14 @@ static void __intel_set_power_well(struct drm_device *dev, bool enable)
     DRM_ERROR("Timeout enabling power well\n");
   }
 
-  if (IS_BROADWELL(dev)) {
-   spin_lock_irqsave(&dev_priv->irq_lock, irqflags);
-   I915_WRITE(GEN8_DE_PIPE_IMR(PIPE_B),
-       dev_priv->de_irq_mask[PIPE_B]);
-   I915_WRITE(GEN8_DE_PIPE_IER(PIPE_B),
-       ~dev_priv->de_irq_mask[PIPE_B] |
-       GEN8_PIPE_VBLANK);
-   I915_WRITE(GEN8_DE_PIPE_IMR(PIPE_C),
-       dev_priv->de_irq_mask[PIPE_C]);
-   I915_WRITE(GEN8_DE_PIPE_IER(PIPE_C),
-       ~dev_priv->de_irq_mask[PIPE_C] |
-       GEN8_PIPE_VBLANK);
-   POSTING_READ(GEN8_DE_PIPE_IER(PIPE_C));
-   spin_unlock_irqrestore(&dev_priv->irq_lock, irqflags);
-  }
+  hsw_power_well_post_enable(dev_priv);
  } else {
   if (enable_requested) {
-   enum pipe p;
-
    I915_WRITE(HSW_PWR_WELL_DRIVER, 0);
    POSTING_READ(HSW_PWR_WELL_DRIVER);
    DRM_DEBUG_KMS("Requesting to disable the power well\n");
 
-   /*
-    * After this, the registers on the pipes that are part
-    * of the power well will become zero, so we have to
-    * adjust our counters according to that.
-    *
-    * FIXME: Should we do this in general in
-    * drm_vblank_post_modeset?
-    */
-   spin_lock_irqsave(&dev->vbl_lock, irqflags);
-   for_each_pipe(p)
-    if (p != PIPE_A)
-     dev->vblank[p].last = 0;
-   spin_unlock_irqrestore(&dev->vbl_lock, irqflags);
+   hsw_power_well_post_disable(dev_priv);
   }
  }
 }
@@ -5751,9 +5260,9 @@ static void __intel_power_well_get(struct drm_device *dev,
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
 
- if (!power_well->count++) {
+ if (!power_well->count++ && power_well->set) {
   hsw_disable_package_c8(dev_priv);
-  __intel_set_power_well(dev, true);
+  power_well->set(dev, power_well, true);
  }
 }
 
@@ -5763,8 +5272,10 @@ static void __intel_power_well_put(struct drm_device *dev,
  struct drm_i915_private *dev_priv = dev->dev_private;
 
  WARN_ON(!power_well->count);
- if (!--power_well->count && i915_disable_power_well) {
-  __intel_set_power_well(dev, false);
+
+ if (!--power_well->count && power_well->set &&
+     i915_disable_power_well) {
+  power_well->set(dev, power_well, false);
   hsw_enable_package_c8(dev_priv);
  }
 }
@@ -5774,17 +5285,18 @@ void intel_display_power_get(struct drm_device *dev,
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct i915_power_domains *power_domains;
-
- if (!HAS_POWER_WELL(dev))
-  return;
-
- if (is_always_on_power_domain(dev, domain))
-  return;
+ struct i915_power_well *power_well;
+ int i;
 
  power_domains = &dev_priv->power_domains;
 
  mutex_lock(&power_domains->lock);
- __intel_power_well_get(dev, &power_domains->power_wells[0]);
+
+ for_each_power_well(i, power_well, BIT(domain), power_domains)
+  __intel_power_well_get(dev, power_well);
+
+ power_domains->domain_use_count[domain]++;
+
  mutex_unlock(&power_domains->lock);
 }
 
@@ -5793,17 +5305,19 @@ void intel_display_power_put(struct drm_device *dev,
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct i915_power_domains *power_domains;
-
- if (!HAS_POWER_WELL(dev))
-  return;
-
- if (is_always_on_power_domain(dev, domain))
-  return;
+ struct i915_power_well *power_well;
+ int i;
 
  power_domains = &dev_priv->power_domains;
 
  mutex_lock(&power_domains->lock);
- __intel_power_well_put(dev, &power_domains->power_wells[0]);
+
+ WARN_ON(!power_domains->domain_use_count[domain]);
+ power_domains->domain_use_count[domain]--;
+
+ for_each_power_well_rev(i, power_well, BIT(domain), power_domains)
+  __intel_power_well_put(dev, power_well);
+
  mutex_unlock(&power_domains->lock);
 }
 
@@ -5819,10 +5333,7 @@ void i915_request_power_well(void)
 
  dev_priv = container_of(hsw_pwr, struct drm_i915_private,
     power_domains);
-
- mutex_lock(&hsw_pwr->lock);
- __intel_power_well_get(dev_priv->dev, &hsw_pwr->power_wells[0]);
- mutex_unlock(&hsw_pwr->lock);
+ intel_display_power_get(dev_priv->dev, POWER_DOMAIN_AUDIO);
 }
 EXPORT_SYMBOL_GPL(i915_request_power_well);
 
@@ -5836,24 +5347,71 @@ void i915_release_power_well(void)
 
  dev_priv = container_of(hsw_pwr, struct drm_i915_private,
     power_domains);
-
- mutex_lock(&hsw_pwr->lock);
- __intel_power_well_put(dev_priv->dev, &hsw_pwr->power_wells[0]);
- mutex_unlock(&hsw_pwr->lock);
+ intel_display_power_put(dev_priv->dev, POWER_DOMAIN_AUDIO);
 }
 EXPORT_SYMBOL_GPL(i915_release_power_well);
 
+static struct i915_power_well i9xx_always_on_power_well[] = {
+ {
+  .name = "always-on",
+  .always_on = 1,
+  .domains = POWER_DOMAIN_MASK,
+ },
+};
+
+static struct i915_power_well hsw_power_wells[] = {
+ {
+  .name = "always-on",
+  .always_on = 1,
+  .domains = HSW_ALWAYS_ON_POWER_DOMAINS,
+ },
+ {
+  .name = "display",
+  .domains = POWER_DOMAIN_MASK & ~HSW_ALWAYS_ON_POWER_DOMAINS,
+  .is_enabled = hsw_power_well_enabled,
+  .set = hsw_set_power_well,
+ },
+};
+
+static struct i915_power_well bdw_power_wells[] = {
+ {
+  .name = "always-on",
+  .always_on = 1,
+  .domains = BDW_ALWAYS_ON_POWER_DOMAINS,
+ },
+ {
+  .name = "display",
+  .domains = POWER_DOMAIN_MASK & ~BDW_ALWAYS_ON_POWER_DOMAINS,
+  .is_enabled = hsw_power_well_enabled,
+  .set = hsw_set_power_well,
+ },
+};
+
+#define set_power_wells(power_domains, __power_wells) ({  \
+ (power_domains)->power_wells = (__power_wells);   \
+ (power_domains)->power_well_count = ARRAY_SIZE(__power_wells); \
+})
+
 int intel_power_domains_init(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct i915_power_domains *power_domains = &dev_priv->power_domains;
- struct i915_power_well *power_well;
 
  mutex_init(&power_domains->lock);
- hsw_pwr = power_domains;
 
- power_well = &power_domains->power_wells[0];
- power_well->count = 0;
+ /*
+  * The enabling order will be from lower to higher indexed wells,
+  * the disabling order is reversed.
+  */
+ if (IS_HASWELL(dev)) {
+  set_power_wells(power_domains, hsw_power_wells);
+  hsw_pwr = power_domains;
+ } else if (IS_BROADWELL(dev)) {
+  set_power_wells(power_domains, bdw_power_wells);
+  hsw_pwr = power_domains;
+ } else {
+  set_power_wells(power_domains, i9xx_always_on_power_well);
+ }
 
  return 0;
 }
@@ -5868,15 +5426,13 @@ static void intel_power_domains_resume(struct drm_device *dev)
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct i915_power_domains *power_domains = &dev_priv->power_domains;
  struct i915_power_well *power_well;
-
- if (!HAS_POWER_WELL(dev))
-  return;
+ int i;
 
  mutex_lock(&power_domains->lock);
-
- power_well = &power_domains->power_wells[0];
- __intel_set_power_well(dev, power_well->count > 0);
-
+ for_each_power_well(i, power_well, POWER_DOMAIN_MASK, power_domains) {
+  if (power_well->set)
+   power_well->set(dev, power_well, power_well->count > 0);
+ }
  mutex_unlock(&power_domains->lock);
 }
 
@@ -5890,13 +5446,13 @@ void intel_power_domains_init_hw(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
 
- if (!HAS_POWER_WELL(dev))
-  return;
-
  /* For now, we need the power well to be always enabled. */
  intel_display_set_init_power(dev, true);
  intel_power_domains_resume(dev);
 
+ if (!(IS_HASWELL(dev) || IS_BROADWELL(dev)))
+  return;
+
  /* We're taking over the BIOS, so clear any requests made by it since
   * the driver is in charge now. */
  if (I915_READ(HSW_PWR_WELL_BIOS) & HSW_PWR_WELL_ENABLE_REQUEST)
@@ -5914,31 +5470,86 @@ void intel_aux_display_runtime_put(struct drm_i915_private *dev_priv)
  hsw_enable_package_c8(dev_priv);
 }
 
+void intel_runtime_pm_get(struct drm_i915_private *dev_priv)
+{
+ struct drm_device *dev = dev_priv->dev;
+ struct device *device = &dev->pdev->dev;
+
+ if (!HAS_RUNTIME_PM(dev))
+  return;
+
+ pm_runtime_get_sync(device);
+ WARN(dev_priv->pm.suspended, "Device still suspended.\n");
+}
+
+void intel_runtime_pm_put(struct drm_i915_private *dev_priv)
+{
+ struct drm_device *dev = dev_priv->dev;
+ struct device *device = &dev->pdev->dev;
+
+ if (!HAS_RUNTIME_PM(dev))
+  return;
+
+ pm_runtime_mark_last_busy(device);
+ pm_runtime_put_autosuspend(device);
+}
+
+void intel_init_runtime_pm(struct drm_i915_private *dev_priv)
+{
+ struct drm_device *dev = dev_priv->dev;
+ struct device *device = &dev->pdev->dev;
+
+ dev_priv->pm.suspended = false;
+
+ if (!HAS_RUNTIME_PM(dev))
+  return;
+
+ pm_runtime_set_active(device);
+
+ pm_runtime_set_autosuspend_delay(device, 10000); /* 10s */
+ pm_runtime_mark_last_busy(device);
+ pm_runtime_use_autosuspend(device);
+}
+
+void intel_fini_runtime_pm(struct drm_i915_private *dev_priv)
+{
+ struct drm_device *dev = dev_priv->dev;
+ struct device *device = &dev->pdev->dev;
+
+ if (!HAS_RUNTIME_PM(dev))
+  return;
+
+ /* Make sure we're not suspended first. */
+ pm_runtime_get_sync(device);
+ pm_runtime_disable(device);
+}
+
 /* Set up chip specific power management-related functions */
 void intel_init_pm(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
 
- if (I915_HAS_FBC(dev)) {
-  if (HAS_PCH_SPLIT(dev)) {
+ if (HAS_FBC(dev)) {
+  if (INTEL_INFO(dev)->gen >= 7) {
    dev_priv->display.fbc_enabled = ironlake_fbc_enabled;
-   if (IS_IVYBRIDGE(dev) || IS_HASWELL(dev))
-    dev_priv->display.enable_fbc =
-     gen7_enable_fbc;
-   else
-    dev_priv->display.enable_fbc =
-     ironlake_enable_fbc;
+   dev_priv->display.enable_fbc = gen7_enable_fbc;
+   dev_priv->display.disable_fbc = ironlake_disable_fbc;
+  } else if (INTEL_INFO(dev)->gen >= 5) {
+   dev_priv->display.fbc_enabled = ironlake_fbc_enabled;
+   dev_priv->display.enable_fbc = ironlake_enable_fbc;
    dev_priv->display.disable_fbc = ironlake_disable_fbc;
   } else if (IS_GM45(dev)) {
    dev_priv->display.fbc_enabled = g4x_fbc_enabled;
    dev_priv->display.enable_fbc = g4x_enable_fbc;
    dev_priv->display.disable_fbc = g4x_disable_fbc;
-  } else if (IS_CRESTLINE(dev)) {
+  } else {
    dev_priv->display.fbc_enabled = i8xx_fbc_enabled;
    dev_priv->display.enable_fbc = i8xx_enable_fbc;
    dev_priv->display.disable_fbc = i8xx_disable_fbc;
+
+   /* This value was pulled out of someone's hat */
+   I915_WRITE(FBC_CONTROL, 500 << FBC_CTL_INTERVAL_SHIFT);
   }
-  /* 855GM needs testing */
  }
 
  /* For cxsr */
@@ -5951,58 +5562,27 @@ void intel_init_pm(struct drm_device *dev)
  if (HAS_PCH_SPLIT(dev)) {
   intel_setup_wm_latency(dev);
 
-  if (IS_GEN5(dev)) {
-   if (dev_priv->wm.pri_latency[1] &&
-       dev_priv->wm.spr_latency[1] &&
-       dev_priv->wm.cur_latency[1])
-    dev_priv->display.update_wm = ironlake_update_wm;
-   else {
-    DRM_DEBUG_KMS("Failed to get proper latency. "
-           "Disable CxSR\n");
-    dev_priv->display.update_wm = NULL;
-   }
+  if ((IS_GEN5(dev) && dev_priv->wm.pri_latency[1] &&
+       dev_priv->wm.spr_latency[1] && dev_priv->wm.cur_latency[1]) ||
+      (!IS_GEN5(dev) && dev_priv->wm.pri_latency[0] &&
+       dev_priv->wm.spr_latency[0] && dev_priv->wm.cur_latency[0])) {
+   dev_priv->display.update_wm = ilk_update_wm;
+   dev_priv->display.update_sprite_wm = ilk_update_sprite_wm;
+  } else {
+   DRM_DEBUG_KMS("Failed to read display plane latency. "
+          "Disable CxSR\n");
+  }
+
+  if (IS_GEN5(dev))
    dev_priv->display.init_clock_gating = ironlake_init_clock_gating;
-  } else if (IS_GEN6(dev)) {
-   if (dev_priv->wm.pri_latency[0] &&
-       dev_priv->wm.spr_latency[0] &&
-       dev_priv->wm.cur_latency[0]) {
-    dev_priv->display.update_wm = sandybridge_update_wm;
-    dev_priv->display.update_sprite_wm = sandybridge_update_sprite_wm;
-   } else {
-    DRM_DEBUG_KMS("Failed to read display plane latency. "
-           "Disable CxSR\n");
-    dev_priv->display.update_wm = NULL;
-   }
+  else if (IS_GEN6(dev))
    dev_priv->display.init_clock_gating = gen6_init_clock_gating;
-  } else if (IS_IVYBRIDGE(dev)) {
-   if (dev_priv->wm.pri_latency[0] &&
-       dev_priv->wm.spr_latency[0] &&
-       dev_priv->wm.cur_latency[0]) {
-    dev_priv->display.update_wm = ivybridge_update_wm;
-    dev_priv->display.update_sprite_wm = sandybridge_update_sprite_wm;
-   } else {
-    DRM_DEBUG_KMS("Failed to read display plane latency. "
-           "Disable CxSR\n");
-    dev_priv->display.update_wm = NULL;
-   }
+  else if (IS_IVYBRIDGE(dev))
    dev_priv->display.init_clock_gating = ivybridge_init_clock_gating;
-  } else if (IS_HASWELL(dev)) {
-   if (dev_priv->wm.pri_latency[0] &&
-       dev_priv->wm.spr_latency[0] &&
-       dev_priv->wm.cur_latency[0]) {
-    dev_priv->display.update_wm = haswell_update_wm;
-    dev_priv->display.update_sprite_wm =
-     haswell_update_sprite_wm;
-   } else {
-    DRM_DEBUG_KMS("Failed to read display plane latency. "
-           "Disable CxSR\n");
-    dev_priv->display.update_wm = NULL;
-   }
+  else if (IS_HASWELL(dev))
    dev_priv->display.init_clock_gating = haswell_init_clock_gating;
-  } else if (INTEL_INFO(dev)->gen == 8) {
+  else if (INTEL_INFO(dev)->gen == 8)
    dev_priv->display.init_clock_gating = gen8_init_clock_gating;
-  } else
-   dev_priv->display.update_wm = NULL;
  } else if (IS_VALLEYVIEW(dev)) {
   dev_priv->display.update_wm = valleyview_update_wm;
   dev_priv->display.init_clock_gating =
@@ -6036,21 +5616,21 @@ void intel_init_pm(struct drm_device *dev)
   dev_priv->display.update_wm = i9xx_update_wm;
   dev_priv->display.get_fifo_size = i9xx_get_fifo_size;
   dev_priv->display.init_clock_gating = gen3_init_clock_gating;
- } else if (IS_I865G(dev)) {
-  dev_priv->display.update_wm = i830_update_wm;
-  dev_priv->display.init_clock_gating = i85x_init_clock_gating;
-  dev_priv->display.get_fifo_size = i830_get_fifo_size;
- } else if (IS_I85X(dev)) {
-  dev_priv->display.update_wm = i9xx_update_wm;
-  dev_priv->display.get_fifo_size = i85x_get_fifo_size;
-  dev_priv->display.init_clock_gating = i85x_init_clock_gating;
- } else {
-  dev_priv->display.update_wm = i830_update_wm;
-  dev_priv->display.init_clock_gating = i830_init_clock_gating;
-  if (IS_845G(dev))
+ } else if (IS_GEN2(dev)) {
+  if (INTEL_INFO(dev)->num_pipes == 1) {
+   dev_priv->display.update_wm = i845_update_wm;
    dev_priv->display.get_fifo_size = i845_get_fifo_size;
-  else
+  } else {
+   dev_priv->display.update_wm = i9xx_update_wm;
    dev_priv->display.get_fifo_size = i830_get_fifo_size;
+  }
+
+  if (IS_I85X(dev) || IS_I865G(dev))
+   dev_priv->display.init_clock_gating = i85x_init_clock_gating;
+  else
+   dev_priv->display.init_clock_gating = i830_init_clock_gating;
+ } else {
+  DRM_ERROR("unexpected fall-through in intel_init_pm\n");
  }
 }
 
@@ -6101,59 +5681,48 @@ int sandybridge_pcode_write(struct drm_i915_private *dev_priv, u8 mbox, u32 val)
  return 0;
 }
 
-int vlv_gpu_freq(int ddr_freq, int val)
+int vlv_gpu_freq(struct drm_i915_private *dev_priv, int val)
 {
- int mult, base;
+ int div;
 
- switch (ddr_freq) {
+ /* 4 x czclk */
+ switch (dev_priv->mem_freq) {
  case 800:
-  mult = 20;
-  base = 120;
+  div = 10;
   break;
  case 1066:
-  mult = 22;
-  base = 133;
+  div = 12;
   break;
  case 1333:
-  mult = 21;
-  base = 125;
+  div = 16;
   break;
  default:
   return -1;
  }
 
- return ((val - 0xbd) * mult) + base;
+ return DIV_ROUND_CLOSEST(dev_priv->mem_freq * (val + 6 - 0xbd), 4 * div);
 }
 
-int vlv_freq_opcode(int ddr_freq, int val)
+int vlv_freq_opcode(struct drm_i915_private *dev_priv, int val)
 {
- int mult, base;
+ int mul;
 
- switch (ddr_freq) {
+ /* 4 x czclk */
+ switch (dev_priv->mem_freq) {
  case 800:
-  mult = 20;
-  base = 120;
+  mul = 10;
   break;
  case 1066:
-  mult = 22;
-  base = 133;
+  mul = 12;
   break;
  case 1333:
-  mult = 21;
-  base = 125;
+  mul = 16;
   break;
  default:
   return -1;
  }
 
- val /= mult;
- val -= base / mult;
- val += 0xbd;
-
- if (val > 0xea)
-  val = 0xea;
-
- return val;
+ return DIV_ROUND_CLOSEST(4 * mul * val, dev_priv->mem_freq) + 0xbd - 6;
 }
 
 void intel_pm_setup(struct drm_device *dev)
diff --git a/drivers/gpu/drm/i915/intel_ringbuffer.c b/drivers/gpu/drm/i915/intel_ringbuffer.c
index 53f5458..31b36c5 100644
--- a/drivers/gpu/drm/i915/intel_ringbuffer.c
+++ b/drivers/gpu/drm/i915/intel_ringbuffer.c
@@ -285,14 +285,16 @@ static int gen7_ring_fbc_flush(struct intel_ring_buffer *ring, u32 value)
  if (!ring->fbc_dirty)
   return 0;
 
- ret = intel_ring_begin(ring, 4);
+ ret = intel_ring_begin(ring, 6);
  if (ret)
   return ret;
- intel_ring_emit(ring, MI_NOOP);
  /* WaFbcNukeOn3DBlt:ivb/hsw */
  intel_ring_emit(ring, MI_LOAD_REGISTER_IMM(1));
  intel_ring_emit(ring, MSG_FBC_REND_STATE);
  intel_ring_emit(ring, value);
+ intel_ring_emit(ring, MI_STORE_REGISTER_MEM(1) | MI_SRM_LRM_GLOBAL_GTT);
+ intel_ring_emit(ring, MSG_FBC_REND_STATE);
+ intel_ring_emit(ring, ring->scratch.gtt_offset + 256);
  intel_ring_advance(ring);
 
  ring->fbc_dirty = false;
@@ -354,7 +356,7 @@ gen7_render_ring_flush(struct intel_ring_buffer *ring,
  intel_ring_emit(ring, 0);
  intel_ring_advance(ring);
 
- if (flush_domains)
+ if (!invalidate_domains && flush_domains)
   return gen7_ring_fbc_flush(ring, FBC_REND_NUKE);
 
  return 0;
@@ -436,7 +438,7 @@ static int init_ring_common(struct intel_ring_buffer *ring)
  int ret = 0;
  u32 head;
 
- gen6_gt_force_wake_get(dev_priv);
+ gen6_gt_force_wake_get(dev_priv, FORCEWAKE_ALL);
 
  if (I915_NEED_GFX_HWS(dev))
   intel_ring_setup_status_page(ring);
@@ -509,7 +511,7 @@ static int init_ring_common(struct intel_ring_buffer *ring)
  memset(&ring->hangcheck, 0, sizeof(ring->hangcheck));
 
 out:
- gen6_gt_force_wake_put(dev_priv);
+ gen6_gt_force_wake_put(dev_priv, FORCEWAKE_ALL);
 
  return ret;
 }
@@ -661,19 +663,22 @@ gen6_add_request(struct intel_ring_buffer *ring)
  struct drm_device *dev = ring->dev;
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_ring_buffer *useless;
- int i, ret;
+ int i, ret, num_dwords = 4;
+
+ if (i915_semaphore_is_enabled(dev))
+  num_dwords += ((I915_NUM_RINGS-1) * MBOX_UPDATE_DWORDS);
+#undef MBOX_UPDATE_DWORDS
 
- ret = intel_ring_begin(ring, ((I915_NUM_RINGS-1) *
-          MBOX_UPDATE_DWORDS) +
-          4);
+ ret = intel_ring_begin(ring, num_dwords);
  if (ret)
   return ret;
-#undef MBOX_UPDATE_DWORDS
 
- for_each_ring(useless, dev_priv, i) {
-  u32 mbox_reg = ring->signal_mbox[i];
-  if (mbox_reg != GEN6_NOSYNC)
-   update_mboxes(ring, mbox_reg);
+ if (i915_semaphore_is_enabled(dev)) {
+  for_each_ring(useless, dev_priv, i) {
+   u32 mbox_reg = ring->signal_mbox[i];
+   if (mbox_reg != GEN6_NOSYNC)
+    update_mboxes(ring, mbox_reg);
+  }
  }
 
  intel_ring_emit(ring, MI_STORE_DWORD_INDEX);
@@ -1030,11 +1035,6 @@ gen6_ring_get_irq(struct intel_ring_buffer *ring)
  if (!dev->irq_enabled)
         return false;
 
- /* It looks like we need to prevent the gt from suspending while waiting
-  * for an notifiy irq, otherwise irqs seem to get lost on at least the
-  * blt/bsd rings on ivb. */
- gen6_gt_force_wake_get(dev_priv);
-
  spin_lock_irqsave(&dev_priv->irq_lock, flags);
  if (ring->irq_refcount++ == 0) {
   if (HAS_L3_DPF(dev) && ring->id == RCS)
@@ -1066,8 +1066,6 @@ gen6_ring_put_irq(struct intel_ring_buffer *ring)
   ilk_disable_gt_irq(dev_priv, ring->irq_enable_mask);
  }
  spin_unlock_irqrestore(&dev_priv->irq_lock, flags);
-
- gen6_gt_force_wake_put(dev_priv);
 }
 
 static bool
@@ -1863,7 +1861,7 @@ static int gen6_ring_flush(struct intel_ring_buffer *ring,
  }
  intel_ring_advance(ring);
 
- if (IS_GEN7(dev) && flush)
+ if (IS_GEN7(dev) && !invalidate && flush)
   return gen7_ring_fbc_flush(ring, FBC_REND_CACHE_CLEAN);
 
  return 0;
diff --git a/drivers/gpu/drm/i915/intel_sdvo.c b/drivers/gpu/drm/i915/intel_sdvo.c
index a583e8f..95bdfb3 100644
--- a/drivers/gpu/drm/i915/intel_sdvo.c
+++ b/drivers/gpu/drm/i915/intel_sdvo.c
@@ -413,23 +413,34 @@ static const struct _sdvo_cmd_name {
 static void intel_sdvo_debug_write(struct intel_sdvo *intel_sdvo, u8 cmd,
        const void *args, int args_len)
 {
- int i;
+ int i, pos = 0;
+#define BUF_LEN 256
+ char buffer[BUF_LEN];
+
+#define BUF_PRINT(args...) \
+ pos += snprintf(buffer + pos, max_t(int, BUF_LEN - pos, 0), args)
+
 
- DRM_DEBUG_KMS("%s: W: %02X ",
-    SDVO_NAME(intel_sdvo), cmd);
- for (i = 0; i < args_len; i++)
-  DRM_LOG_KMS("%02X ", ((u8 *)args)[i]);
- for (; i < 8; i++)
-  DRM_LOG_KMS("   ");
+ for (i = 0; i < args_len; i++) {
+  BUF_PRINT("%02X ", ((u8 *)args)[i]);
+ }
+ for (; i < 8; i++) {
+  BUF_PRINT("   ");
+ }
  for (i = 0; i < ARRAY_SIZE(sdvo_cmd_names); i++) {
   if (cmd == sdvo_cmd_names[i].cmd) {
-   DRM_LOG_KMS("(%s)", sdvo_cmd_names[i].name);
+   BUF_PRINT("(%s)", sdvo_cmd_names[i].name);
    break;
   }
  }
- if (i == ARRAY_SIZE(sdvo_cmd_names))
-  DRM_LOG_KMS("(%02X)", cmd);
- DRM_LOG_KMS("\n");
+ if (i == ARRAY_SIZE(sdvo_cmd_names)) {
+  BUF_PRINT("(%02X)", cmd);
+ }
+ BUG_ON(pos >= BUF_LEN - 1);
+#undef BUF_PRINT
+#undef BUF_LEN
+
+ DRM_DEBUG_KMS("%s: W: %02X %s\n", SDVO_NAME(intel_sdvo), cmd, buffer);
 }
 
 static const char *cmd_status_names[] = {
@@ -512,9 +523,10 @@ static bool intel_sdvo_read_response(struct intel_sdvo *intel_sdvo,
 {
  u8 retry = 15; /* 5 quick checks, followed by 10 long checks */
  u8 status;
- int i;
+ int i, pos = 0;
+#define BUF_LEN 256
+ char buffer[BUF_LEN];
 
- DRM_DEBUG_KMS("%s: R: ", SDVO_NAME(intel_sdvo));
 
  /*
   * The documentation states that all commands will be
@@ -551,10 +563,13 @@ static bool intel_sdvo_read_response(struct intel_sdvo *intel_sdvo,
    goto log_fail;
  }
 
+#define BUF_PRINT(args...) \
+ pos += snprintf(buffer + pos, max_t(int, BUF_LEN - pos, 0), args)
+
  if (status <= SDVO_CMD_STATUS_SCALING_NOT_SUPP)
-  DRM_LOG_KMS("(%s)", cmd_status_names[status]);
+  BUF_PRINT("(%s)", cmd_status_names[status]);
  else
-  DRM_LOG_KMS("(??? %d)", status);
+  BUF_PRINT("(??? %d)", status);
 
  if (status != SDVO_CMD_STATUS_SUCCESS)
   goto log_fail;
@@ -565,13 +580,17 @@ static bool intel_sdvo_read_response(struct intel_sdvo *intel_sdvo,
        SDVO_I2C_RETURN_0 + i,
        &((u8 *)response)[i]))
    goto log_fail;
-  DRM_LOG_KMS(" %02X", ((u8 *)response)[i]);
+  BUF_PRINT(" %02X", ((u8 *)response)[i]);
  }
- DRM_LOG_KMS("\n");
+ BUG_ON(pos >= BUF_LEN - 1);
+#undef BUF_PRINT
+#undef BUF_LEN
+
+ DRM_DEBUG_KMS("%s: R: %s\n", SDVO_NAME(intel_sdvo), buffer);
  return true;
 
 log_fail:
- DRM_LOG_KMS("... failed\n");
+ DRM_DEBUG_KMS("%s: R: ... failed\n", SDVO_NAME(intel_sdvo));
  return false;
 }
 
@@ -933,7 +952,7 @@ static void intel_sdvo_dump_hdmi_buf(struct intel_sdvo *intel_sdvo)
 
 static bool intel_sdvo_write_infoframe(struct intel_sdvo *intel_sdvo,
            unsigned if_index, uint8_t tx_rate,
-           uint8_t *data, unsigned length)
+           const uint8_t *data, unsigned length)
 {
  uint8_t set_buf_index[2] = { if_index, 0 };
  uint8_t hbuf_size, tmp[8];
@@ -1517,8 +1536,9 @@ static void intel_sdvo_dpms(struct drm_connector *connector, int mode)
  intel_modeset_check_state(connector->dev);
 }
 
-static int intel_sdvo_mode_valid(struct drm_connector *connector,
-     struct drm_display_mode *mode)
+static enum drm_mode_status
+intel_sdvo_mode_valid(struct drm_connector *connector,
+        struct drm_display_mode *mode)
 {
  struct intel_sdvo *intel_sdvo = intel_attached_sdvo(connector);
 
diff --git a/drivers/gpu/drm/i915/intel_sdvo_regs.h b/drivers/gpu/drm/i915/intel_sdvo_regs.h
index 770bdd6..2e2d4eb 100644
--- a/drivers/gpu/drm/i915/intel_sdvo_regs.h
+++ b/drivers/gpu/drm/i915/intel_sdvo_regs.h
@@ -59,7 +59,7 @@ struct intel_sdvo_caps {
  unsigned int stall_support:1;
  unsigned int pad:1;
  u16 output_flags;
-} __attribute__((packed));
+} __packed;
 
 /* Note: SDVO detailed timing flags match EDID misc flags. */
 #define DTD_FLAG_HSYNC_POSITIVE (1 << 1)
@@ -94,12 +94,12 @@ struct intel_sdvo_dtd {
   u8 v_sync_off_high;
   u8 reserved;
  } part2;
-} __attribute__((packed));
+} __packed;
 
 struct intel_sdvo_pixel_clock_range {
  u16 min; /**< pixel clock, in 10kHz units */
  u16 max; /**< pixel clock, in 10kHz units */
-} __attribute__((packed));
+} __packed;
 
 struct intel_sdvo_preferred_input_timing_args {
  u16 clock;
@@ -108,7 +108,7 @@ struct intel_sdvo_preferred_input_timing_args {
  u8 interlace:1;
  u8 scaled:1;
  u8 pad:6;
-} __attribute__((packed));
+} __packed;
 
 /* I2C registers for SDVO */
 #define SDVO_I2C_ARG_0    0x07
@@ -162,7 +162,7 @@ struct intel_sdvo_get_trained_inputs_response {
  unsigned int input0_trained:1;
  unsigned int input1_trained:1;
  unsigned int pad:6;
-} __attribute__((packed));
+} __packed;
 
 /** Returns a struct intel_sdvo_output_flags of active outputs. */
 #define SDVO_CMD_GET_ACTIVE_OUTPUTS   0x04
@@ -219,7 +219,7 @@ struct intel_sdvo_get_interrupt_event_source_response {
  unsigned int ambient_light_interrupt:1;
  unsigned int hdmi_audio_encrypt_change:1;
  unsigned int pad:6;
-} __attribute__((packed));
+} __packed;
 
 /**
  * Selects which input is affected by future input commands.
@@ -232,7 +232,7 @@ struct intel_sdvo_get_interrupt_event_source_response {
 struct intel_sdvo_set_target_input_args {
  unsigned int target_1:1;
  unsigned int pad:7;
-} __attribute__((packed));
+} __packed;
 
 /**
  * Takes a struct intel_sdvo_output_flags of which outputs are targeted by
@@ -370,7 +370,7 @@ struct intel_sdvo_tv_format {
  unsigned int hdtv_std_eia_7702a_480i_60:1;
  unsigned int hdtv_std_eia_7702a_480p_60:1;
  unsigned int pad:3;
-} __attribute__((packed));
+} __packed;
 
 #define SDVO_CMD_GET_TV_FORMAT    0x28
 
@@ -401,7 +401,7 @@ struct intel_sdvo_sdtv_resolution_request {
  unsigned int secam_l:1;
  unsigned int secam_60:1;
  unsigned int pad:5;
-} __attribute__((packed));
+} __packed;
 
 struct intel_sdvo_sdtv_resolution_reply {
  unsigned int res_320x200:1;
@@ -426,7 +426,7 @@ struct intel_sdvo_sdtv_resolution_reply {
  unsigned int res_1024x768:1;
  unsigned int res_1280x1024:1;
  unsigned int pad:5;
-} __attribute__((packed));
+} __packed;
 
 /* Get supported resolution with squire pixel aspect ratio that can be
    scaled for the requested HDTV format */
@@ -463,7 +463,7 @@ struct intel_sdvo_hdtv_resolution_request {
  unsigned int hdtv_std_eia_7702a_480i_60:1;
  unsigned int hdtv_std_eia_7702a_480p_60:1;
  unsigned int pad:6;
-} __attribute__((packed));
+} __packed;
 
 struct intel_sdvo_hdtv_resolution_reply {
  unsigned int res_640x480:1;
@@ -517,7 +517,7 @@ struct intel_sdvo_hdtv_resolution_reply {
 
  unsigned int res_1280x768:1;
  unsigned int pad5:7;
-} __attribute__((packed));
+} __packed;
 
 /* Get supported power state returns info for encoder and monitor, rely on
    last SetTargetInput and SetTargetOutput calls */
@@ -557,13 +557,13 @@ struct sdvo_panel_power_sequencing {
 
  unsigned int t4_high:2;
  unsigned int pad:6;
-} __attribute__((packed));
+} __packed;
 
 #define SDVO_CMD_GET_MAX_BACKLIGHT_LEVEL  0x30
 struct sdvo_max_backlight_reply {
  u8 max_value;
  u8 default_value;
-} __attribute__((packed));
+} __packed;
 
 #define SDVO_CMD_GET_BACKLIGHT_LEVEL   0x31
 #define SDVO_CMD_SET_BACKLIGHT_LEVEL   0x32
@@ -573,14 +573,14 @@ struct sdvo_get_ambient_light_reply {
  u16 trip_low;
  u16 trip_high;
  u16 value;
-} __attribute__((packed));
+} __packed;
 #define SDVO_CMD_SET_AMBIENT_LIGHT   0x34
 struct sdvo_set_ambient_light_reply {
  u16 trip_low;
  u16 trip_high;
  unsigned int enable:1;
  unsigned int pad:7;
-} __attribute__((packed));
+} __packed;
 
 /* Set display power state */
 #define SDVO_CMD_SET_DISPLAY_POWER_STATE  0x7d
@@ -608,7 +608,7 @@ struct intel_sdvo_enhancements_reply {
  unsigned int dither:1;
  unsigned int tv_chroma_filter:1;
  unsigned int tv_luma_filter:1;
-} __attribute__((packed));
+} __packed;
 
 /* Picture enhancement limits below are dependent on the current TV format,
  * and thus need to be queried and set after it.
@@ -630,7 +630,7 @@ struct intel_sdvo_enhancements_reply {
 struct intel_sdvo_enhancement_limits_reply {
  u16 max_value;
  u16 default_value;
-} __attribute__((packed));
+} __packed;
 
 #define SDVO_CMD_GET_LVDS_PANEL_INFORMATION  0x7f
 #define SDVO_CMD_SET_LVDS_PANEL_INFORMATION  0x80
@@ -671,7 +671,7 @@ struct intel_sdvo_enhancement_limits_reply {
 #define SDVO_CMD_SET_TV_LUMA_FILTER   0x79
 struct intel_sdvo_enhancements_arg {
  u16 value;
-} __attribute__((packed));
+} __packed;
 
 #define SDVO_CMD_GET_DOT_CRAWL    0x70
 #define SDVO_CMD_SET_DOT_CRAWL    0x71
@@ -727,4 +727,4 @@ struct intel_sdvo_enhancements_arg {
 struct intel_sdvo_encode {
  u8 dvi_rev;
  u8 hdmi_rev;
-} __attribute__ ((packed));
+} __packed;
diff --git a/drivers/gpu/drm/i915/intel_sideband.c b/drivers/gpu/drm/i915/intel_sideband.c
index 9944d81..0954f13 100644
--- a/drivers/gpu/drm/i915/intel_sideband.c
+++ b/drivers/gpu/drm/i915/intel_sideband.c
@@ -90,6 +90,22 @@ void vlv_punit_write(struct drm_i915_private *dev_priv, u8 addr, u32 val)
  mutex_unlock(&dev_priv->dpio_lock);
 }
 
+u32 vlv_bunit_read(struct drm_i915_private *dev_priv, u32 reg)
+{
+ u32 val = 0;
+
+ vlv_sideband_rw(dev_priv, PCI_DEVFN(2, 0), IOSF_PORT_BUNIT,
+   PUNIT_OPCODE_REG_READ, reg, &val);
+
+ return val;
+}
+
+void vlv_bunit_write(struct drm_i915_private *dev_priv, u32 reg, u32 val)
+{
+ vlv_sideband_rw(dev_priv, PCI_DEVFN(2, 0), IOSF_PORT_BUNIT,
+   PUNIT_OPCODE_REG_WRITE, reg, &val);
+}
+
 u32 vlv_nc_read(struct drm_i915_private *dev_priv, u8 addr)
 {
  u32 val = 0;
@@ -160,27 +176,18 @@ void vlv_gps_core_write(struct drm_i915_private *dev_priv, u32 reg, u32 val)
    PUNIT_OPCODE_REG_WRITE, reg, &val);
 }
 
-static u32 vlv_get_phy_port(enum pipe pipe)
-{
- u32 port = IOSF_PORT_DPIO;
-
- WARN_ON ((pipe != PIPE_A) && (pipe != PIPE_B));
-
- return port;
-}
-
 u32 vlv_dpio_read(struct drm_i915_private *dev_priv, enum pipe pipe, int reg)
 {
  u32 val = 0;
 
- vlv_sideband_rw(dev_priv, DPIO_DEVFN, vlv_get_phy_port(pipe),
+ vlv_sideband_rw(dev_priv, DPIO_DEVFN, DPIO_PHY_IOSF_PORT(DPIO_PHY(pipe)),
    DPIO_OPCODE_REG_READ, reg, &val);
  return val;
 }
 
 void vlv_dpio_write(struct drm_i915_private *dev_priv, enum pipe pipe, int reg, u32 val)
 {
- vlv_sideband_rw(dev_priv, DPIO_DEVFN, vlv_get_phy_port(pipe),
+ vlv_sideband_rw(dev_priv, DPIO_DEVFN, DPIO_PHY_IOSF_PORT(DPIO_PHY(pipe)),
    DPIO_OPCODE_REG_WRITE, reg, &val);
 }
 
@@ -242,3 +249,17 @@ void intel_sbi_write(struct drm_i915_private *dev_priv, u16 reg, u32 value,
   return;
  }
 }
+
+u32 vlv_flisdsi_read(struct drm_i915_private *dev_priv, u32 reg)
+{
+ u32 val = 0;
+ vlv_sideband_rw(dev_priv, DPIO_DEVFN, IOSF_PORT_FLISDSI,
+     DPIO_OPCODE_REG_READ, reg, &val);
+ return val;
+}
+
+void vlv_flisdsi_write(struct drm_i915_private *dev_priv, u32 reg, u32 val)
+{
+ vlv_sideband_rw(dev_priv, DPIO_DEVFN, IOSF_PORT_FLISDSI,
+     DPIO_OPCODE_REG_WRITE, reg, &val);
+}
diff --git a/drivers/gpu/drm/i915/intel_sprite.c b/drivers/gpu/drm/i915/intel_sprite.c
index b9fabf8..716a3c9 100644
--- a/drivers/gpu/drm/i915/intel_sprite.c
+++ b/drivers/gpu/drm/i915/intel_sprite.c
@@ -104,6 +104,12 @@ vlv_update_plane(struct drm_plane *dplane, struct drm_crtc *crtc,
   break;
  }
 
+ /*
+  * Enable gamma to match primary/cursor plane behaviour.
+  * FIXME should be user controllable via propertiesa.
+  */
+ sprctl |= SP_GAMMA_ENABLE;
+
  if (obj->tiling_mode != I915_TILING_NONE)
   sprctl |= SP_TILED;
 
@@ -135,8 +141,8 @@ vlv_update_plane(struct drm_plane *dplane, struct drm_crtc *crtc,
 
  I915_WRITE(SPSIZE(pipe, plane), (crtc_h << 16) | crtc_w);
  I915_WRITE(SPCNTR(pipe, plane), sprctl);
- I915_MODIFY_DISPBASE(SPSURF(pipe, plane), i915_gem_obj_ggtt_offset(obj) +
-        sprsurf_offset);
+ I915_WRITE(SPSURF(pipe, plane), i915_gem_obj_ggtt_offset(obj) +
+     sprsurf_offset);
  POSTING_READ(SPSURF(pipe, plane));
 }
 
@@ -152,7 +158,7 @@ vlv_disable_plane(struct drm_plane *dplane, struct drm_crtc *crtc)
  I915_WRITE(SPCNTR(pipe, plane), I915_READ(SPCNTR(pipe, plane)) &
      ~SP_ENABLE);
  /* Activate double buffered register update */
- I915_MODIFY_DISPBASE(SPSURF(pipe, plane), 0);
+ I915_WRITE(SPSURF(pipe, plane), 0);
  POSTING_READ(SPSURF(pipe, plane));
 
  intel_update_sprite_watermarks(dplane, crtc, 0, 0, false, false);
@@ -224,7 +230,6 @@ ivb_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
  u32 sprctl, sprscale = 0;
  unsigned long sprsurf_offset, linear_offset;
  int pixel_size = drm_format_plane_cpp(fb->pixel_format, 0);
- bool scaling_was_enabled = dev_priv->sprite_scaling_enabled;
 
  sprctl = I915_READ(SPRCTL(pipe));
 
@@ -257,6 +262,12 @@ ivb_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
   BUG();
  }
 
+ /*
+  * Enable gamma to match primary/cursor plane behaviour.
+  * FIXME should be user controllable via propertiesa.
+  */
+ sprctl |= SPRITE_GAMMA_ENABLE;
+
  if (obj->tiling_mode != I915_TILING_NONE)
   sprctl |= SPRITE_TILED;
 
@@ -279,21 +290,8 @@ ivb_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
  crtc_w--;
  crtc_h--;
 
- /*
-  * IVB workaround: must disable low power watermarks for at least
-  * one frame before enabling scaling.  LP watermarks can be re-enabled
-  * when scaling is disabled.
-  */
- if (crtc_w != src_w || crtc_h != src_h) {
-  dev_priv->sprite_scaling_enabled |= 1 << pipe;
-
-  if (!scaling_was_enabled) {
-   intel_update_watermarks(crtc);
-   intel_wait_for_vblank(dev, pipe);
-  }
+ if (crtc_w != src_w || crtc_h != src_h)
   sprscale = SPRITE_SCALE_ENABLE | (src_w << 16) | src_h;
- } else
-  dev_priv->sprite_scaling_enabled &= ~(1 << pipe);
 
  I915_WRITE(SPRSTRIDE(pipe), fb->pitches[0]);
  I915_WRITE(SPRPOS(pipe), (crtc_y << 16) | crtc_x);
@@ -317,13 +315,9 @@ ivb_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
  if (intel_plane->can_scale)
   I915_WRITE(SPRSCALE(pipe), sprscale);
  I915_WRITE(SPRCTL(pipe), sprctl);
- I915_MODIFY_DISPBASE(SPRSURF(pipe),
-        i915_gem_obj_ggtt_offset(obj) + sprsurf_offset);
+ I915_WRITE(SPRSURF(pipe),
+     i915_gem_obj_ggtt_offset(obj) + sprsurf_offset);
  POSTING_READ(SPRSURF(pipe));
-
- /* potentially re-enable LP watermarks */
- if (scaling_was_enabled && !dev_priv->sprite_scaling_enabled)
-  intel_update_watermarks(crtc);
 }
 
 static void
@@ -333,23 +327,22 @@ ivb_disable_plane(struct drm_plane *plane, struct drm_crtc *crtc)
  struct drm_i915_private *dev_priv = dev->dev_private;
  struct intel_plane *intel_plane = to_intel_plane(plane);
  int pipe = intel_plane->pipe;
- bool scaling_was_enabled = dev_priv->sprite_scaling_enabled;
 
  I915_WRITE(SPRCTL(pipe), I915_READ(SPRCTL(pipe)) & ~SPRITE_ENABLE);
  /* Can't leave the scaler enabled... */
  if (intel_plane->can_scale)
   I915_WRITE(SPRSCALE(pipe), 0);
  /* Activate double buffered register update */
- I915_MODIFY_DISPBASE(SPRSURF(pipe), 0);
+ I915_WRITE(SPRSURF(pipe), 0);
  POSTING_READ(SPRSURF(pipe));
 
- dev_priv->sprite_scaling_enabled &= ~(1 << pipe);
+ /*
+  * Avoid underruns when disabling the sprite.
+  * FIXME remove once watermark updates are done properly.
+  */
+ intel_wait_for_vblank(dev, pipe);
 
  intel_update_sprite_watermarks(plane, crtc, 0, 0, false, false);
-
- /* potentially re-enable LP watermarks */
- if (scaling_was_enabled && !dev_priv->sprite_scaling_enabled)
-  intel_update_watermarks(crtc);
 }
 
 static int
@@ -453,6 +446,12 @@ ilk_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
   BUG();
  }
 
+ /*
+  * Enable gamma to match primary/cursor plane behaviour.
+  * FIXME should be user controllable via propertiesa.
+  */
+ dvscntr |= DVS_GAMMA_ENABLE;
+
  if (obj->tiling_mode != I915_TILING_NONE)
   dvscntr |= DVS_TILED;
 
@@ -470,7 +469,7 @@ ilk_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
  crtc_h--;
 
  dvsscale = 0;
- if (IS_GEN5(dev) || crtc_w != src_w || crtc_h != src_h)
+ if (crtc_w != src_w || crtc_h != src_h)
   dvsscale = DVS_SCALE_ENABLE | (src_w << 16) | src_h;
 
  I915_WRITE(DVSSTRIDE(pipe), fb->pitches[0]);
@@ -490,8 +489,8 @@ ilk_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
  I915_WRITE(DVSSIZE(pipe), (crtc_h << 16) | crtc_w);
  I915_WRITE(DVSSCALE(pipe), dvsscale);
  I915_WRITE(DVSCNTR(pipe), dvscntr);
- I915_MODIFY_DISPBASE(DVSSURF(pipe),
-        i915_gem_obj_ggtt_offset(obj) + dvssurf_offset);
+ I915_WRITE(DVSSURF(pipe),
+     i915_gem_obj_ggtt_offset(obj) + dvssurf_offset);
  POSTING_READ(DVSSURF(pipe));
 }
 
@@ -507,9 +506,15 @@ ilk_disable_plane(struct drm_plane *plane, struct drm_crtc *crtc)
  /* Disable the scaler */
  I915_WRITE(DVSSCALE(pipe), 0);
  /* Flush double buffered register updates */
- I915_MODIFY_DISPBASE(DVSSURF(pipe), 0);
+ I915_WRITE(DVSSURF(pipe), 0);
  POSTING_READ(DVSSURF(pipe));
 
+ /*
+  * Avoid underruns when disabling the sprite.
+  * FIXME remove once watermark updates are done properly.
+  */
+ intel_wait_for_vblank(dev, pipe);
+
  intel_update_sprite_watermarks(plane, crtc, 0, 0, false, false);
 }
 
@@ -643,6 +648,15 @@ format_is_yuv(uint32_t format)
  }
 }
 
+static bool colorkey_enabled(struct intel_plane *intel_plane)
+{
+ struct drm_intel_sprite_colorkey key;
+
+ intel_plane->get_colorkey(&intel_plane->base, &key);
+
+ return key.flags != I915_SET_COLORKEY_NONE;
+}
+
 static int
 intel_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
      struct drm_framebuffer *fb, int crtc_x, int crtc_y,
@@ -828,7 +842,7 @@ intel_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
   * If the sprite is completely covering the primary plane,
   * we can disable the primary and save power.
   */
- disable_primary = drm_rect_equals(&dst, &clip);
+ disable_primary = drm_rect_equals(&dst, &clip) && !colorkey_enabled(intel_plane);
  WARN_ON(disable_primary && !visible && intel_crtc->active);
 
  mutex_lock(&dev->struct_mutex);
diff --git a/drivers/gpu/drm/i915/intel_uncore.c b/drivers/gpu/drm/i915/intel_uncore.c
index 25cbe07..87df68f 100644
--- a/drivers/gpu/drm/i915/intel_uncore.c
+++ b/drivers/gpu/drm/i915/intel_uncore.c
@@ -64,7 +64,8 @@ static void __gen6_gt_force_wake_reset(struct drm_i915_private *dev_priv)
  __raw_posting_read(dev_priv, ECOBUS);
 }
 
-static void __gen6_gt_force_wake_get(struct drm_i915_private *dev_priv)
+static void __gen6_gt_force_wake_get(struct drm_i915_private *dev_priv,
+       int fw_engine)
 {
  if (wait_for_atomic((__raw_i915_read32(dev_priv, FORCEWAKE_ACK) & 1) == 0,
        FORCEWAKE_ACK_TIMEOUT_MS))
@@ -89,7 +90,8 @@ static void __gen6_gt_force_wake_mt_reset(struct drm_i915_private *dev_priv)
  __raw_posting_read(dev_priv, ECOBUS);
 }
 
-static void __gen6_gt_force_wake_mt_get(struct drm_i915_private *dev_priv)
+static void __gen6_gt_force_wake_mt_get(struct drm_i915_private *dev_priv,
+       int fw_engine)
 {
  u32 forcewake_ack;
 
@@ -121,12 +123,12 @@ static void gen6_gt_check_fifodbg(struct drm_i915_private *dev_priv)
  u32 gtfifodbg;
 
  gtfifodbg = __raw_i915_read32(dev_priv, GTFIFODBG);
- if (WARN(gtfifodbg & GT_FIFO_CPU_ERROR_MASK,
-      "MMIO read or write has been dropped %x\n", gtfifodbg))
-  __raw_i915_write32(dev_priv, GTFIFODBG, GT_FIFO_CPU_ERROR_MASK);
+ if (WARN(gtfifodbg, "GT wake FIFO error 0x%x\n", gtfifodbg))
+  __raw_i915_write32(dev_priv, GTFIFODBG, gtfifodbg);
 }
 
-static void __gen6_gt_force_wake_put(struct drm_i915_private *dev_priv)
+static void __gen6_gt_force_wake_put(struct drm_i915_private *dev_priv,
+       int fw_engine)
 {
  __raw_i915_write32(dev_priv, FORCEWAKE, 0);
  /* something from same cacheline, but !FORCEWAKE */
@@ -134,7 +136,8 @@ static void __gen6_gt_force_wake_put(struct drm_i915_private *dev_priv)
  gen6_gt_check_fifodbg(dev_priv);
 }
 
-static void __gen6_gt_force_wake_mt_put(struct drm_i915_private *dev_priv)
+static void __gen6_gt_force_wake_mt_put(struct drm_i915_private *dev_priv,
+       int fw_engine)
 {
  __raw_i915_write32(dev_priv, FORCEWAKE_MT,
       _MASKED_BIT_DISABLE(FORCEWAKE_KERNEL));
@@ -147,12 +150,19 @@ static int __gen6_gt_wait_for_fifo(struct drm_i915_private *dev_priv)
 {
  int ret = 0;
 
+ /* On VLV, FIFO will be shared by both SW and HW.
+  * So, we need to read the FREE_ENTRIES everytime */
+ if (IS_VALLEYVIEW(dev_priv->dev))
+  dev_priv->uncore.fifo_count =
+   __raw_i915_read32(dev_priv, GTFIFOCTL) &
+      GT_FIFO_FREE_ENTRIES_MASK;
+
  if (dev_priv->uncore.fifo_count < GT_FIFO_NUM_RESERVED_ENTRIES) {
   int loop = 500;
-  u32 fifo = __raw_i915_read32(dev_priv, GT_FIFO_FREE_ENTRIES);
+  u32 fifo = __raw_i915_read32(dev_priv, GTFIFOCTL) & GT_FIFO_FREE_ENTRIES_MASK;
   while (fifo <= GT_FIFO_NUM_RESERVED_ENTRIES && loop--) {
    udelay(10);
-   fifo = __raw_i915_read32(dev_priv, GT_FIFO_FREE_ENTRIES);
+   fifo = __raw_i915_read32(dev_priv, GTFIFOCTL) & GT_FIFO_FREE_ENTRIES_MASK;
   }
   if (WARN_ON(loop < 0 && fifo <= GT_FIFO_NUM_RESERVED_ENTRIES))
    ++ret;
@@ -171,38 +181,112 @@ static void vlv_force_wake_reset(struct drm_i915_private *dev_priv)
  __raw_posting_read(dev_priv, FORCEWAKE_ACK_VLV);
 }
 
-static void vlv_force_wake_get(struct drm_i915_private *dev_priv)
+static void __vlv_force_wake_get(struct drm_i915_private *dev_priv,
+      int fw_engine)
 {
- if (wait_for_atomic((__raw_i915_read32(dev_priv, FORCEWAKE_ACK_VLV) & FORCEWAKE_KERNEL) == 0,
-       FORCEWAKE_ACK_TIMEOUT_MS))
-  DRM_ERROR("Timed out waiting for forcewake old ack to clear.\n");
+ /* Check for Render Engine */
+ if (FORCEWAKE_RENDER & fw_engine) {
+  if (wait_for_atomic((__raw_i915_read32(dev_priv,
+      FORCEWAKE_ACK_VLV) &
+      FORCEWAKE_KERNEL) == 0,
+     FORCEWAKE_ACK_TIMEOUT_MS))
+   DRM_ERROR("Timed out: Render forcewake old ack to clear.\n");
 
- __raw_i915_write32(dev_priv, FORCEWAKE_VLV,
-      _MASKED_BIT_ENABLE(FORCEWAKE_KERNEL));
- __raw_i915_write32(dev_priv, FORCEWAKE_MEDIA_VLV,
-      _MASKED_BIT_ENABLE(FORCEWAKE_KERNEL));
+  __raw_i915_write32(dev_priv, FORCEWAKE_VLV,
+       _MASKED_BIT_ENABLE(FORCEWAKE_KERNEL));
 
- if (wait_for_atomic((__raw_i915_read32(dev_priv, FORCEWAKE_ACK_VLV) & FORCEWAKE_KERNEL),
-       FORCEWAKE_ACK_TIMEOUT_MS))
-  DRM_ERROR("Timed out waiting for GT to ack forcewake request.\n");
+  if (wait_for_atomic((__raw_i915_read32(dev_priv,
+      FORCEWAKE_ACK_VLV) &
+      FORCEWAKE_KERNEL),
+     FORCEWAKE_ACK_TIMEOUT_MS))
+   DRM_ERROR("Timed out: waiting for Render to ack.\n");
+ }
 
- if (wait_for_atomic((__raw_i915_read32(dev_priv, FORCEWAKE_ACK_MEDIA_VLV) &
-        FORCEWAKE_KERNEL),
-       FORCEWAKE_ACK_TIMEOUT_MS))
-  DRM_ERROR("Timed out waiting for media to ack forcewake request.\n");
+ /* Check for Media Engine */
+ if (FORCEWAKE_MEDIA & fw_engine) {
+  if (wait_for_atomic((__raw_i915_read32(dev_priv,
+      FORCEWAKE_ACK_MEDIA_VLV) &
+      FORCEWAKE_KERNEL) == 0,
+     FORCEWAKE_ACK_TIMEOUT_MS))
+   DRM_ERROR("Timed out: Media forcewake old ack to clear.\n");
+
+  __raw_i915_write32(dev_priv, FORCEWAKE_MEDIA_VLV,
+       _MASKED_BIT_ENABLE(FORCEWAKE_KERNEL));
+
+  if (wait_for_atomic((__raw_i915_read32(dev_priv,
+      FORCEWAKE_ACK_MEDIA_VLV) &
+      FORCEWAKE_KERNEL),
+     FORCEWAKE_ACK_TIMEOUT_MS))
+   DRM_ERROR("Timed out: waiting for media to ack.\n");
+ }
 
  /* WaRsForcewakeWaitTC0:vlv */
  __gen6_gt_wait_for_thread_c0(dev_priv);
+
 }
 
-static void vlv_force_wake_put(struct drm_i915_private *dev_priv)
+static void __vlv_force_wake_put(struct drm_i915_private *dev_priv,
+     int fw_engine)
 {
- __raw_i915_write32(dev_priv, FORCEWAKE_VLV,
-      _MASKED_BIT_DISABLE(FORCEWAKE_KERNEL));
- __raw_i915_write32(dev_priv, FORCEWAKE_MEDIA_VLV,
-      _MASKED_BIT_DISABLE(FORCEWAKE_KERNEL));
+
+ /* Check for Render Engine */
+ if (FORCEWAKE_RENDER & fw_engine)
+  __raw_i915_write32(dev_priv, FORCEWAKE_VLV,
+     _MASKED_BIT_DISABLE(FORCEWAKE_KERNEL));
+
+
+ /* Check for Media Engine */
+ if (FORCEWAKE_MEDIA & fw_engine)
+  __raw_i915_write32(dev_priv, FORCEWAKE_MEDIA_VLV,
+    _MASKED_BIT_DISABLE(FORCEWAKE_KERNEL));
+
  /* The below doubles as a POSTING_READ */
  gen6_gt_check_fifodbg(dev_priv);
+
+}
+
+void vlv_force_wake_get(struct drm_i915_private *dev_priv,
+      int fw_engine)
+{
+ unsigned long irqflags;
+
+ spin_lock_irqsave(&dev_priv->uncore.lock, irqflags);
+ if (FORCEWAKE_RENDER & fw_engine) {
+  if (dev_priv->uncore.fw_rendercount++ == 0)
+   dev_priv->uncore.funcs.force_wake_get(dev_priv,
+       FORCEWAKE_RENDER);
+ }
+ if (FORCEWAKE_MEDIA & fw_engine) {
+  if (dev_priv->uncore.fw_mediacount++ == 0)
+   dev_priv->uncore.funcs.force_wake_get(dev_priv,
+       FORCEWAKE_MEDIA);
+ }
+
+ spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags);
+}
+
+void vlv_force_wake_put(struct drm_i915_private *dev_priv,
+      int fw_engine)
+{
+ unsigned long irqflags;
+
+ spin_lock_irqsave(&dev_priv->uncore.lock, irqflags);
+
+ if (FORCEWAKE_RENDER & fw_engine) {
+  WARN_ON(dev_priv->uncore.fw_rendercount == 0);
+  if (--dev_priv->uncore.fw_rendercount == 0)
+   dev_priv->uncore.funcs.force_wake_put(dev_priv,
+       FORCEWAKE_RENDER);
+ }
+
+ if (FORCEWAKE_MEDIA & fw_engine) {
+  WARN_ON(dev_priv->uncore.fw_mediacount == 0);
+  if (--dev_priv->uncore.fw_mediacount == 0)
+   dev_priv->uncore.funcs.force_wake_put(dev_priv,
+       FORCEWAKE_MEDIA);
+ }
+
+ spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags);
 }
 
 static void gen6_force_wake_work(struct work_struct *work)
@@ -213,7 +297,7 @@ static void gen6_force_wake_work(struct work_struct *work)
 
  spin_lock_irqsave(&dev_priv->uncore.lock, irqflags);
  if (--dev_priv->uncore.forcewake_count == 0)
-  dev_priv->uncore.funcs.force_wake_put(dev_priv);
+  dev_priv->uncore.funcs.force_wake_put(dev_priv, FORCEWAKE_ALL);
  spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags);
 }
 
@@ -248,6 +332,11 @@ void intel_uncore_early_sanitize(struct drm_device *dev)
   DRM_INFO("Found %zuMB of eLLC\n", dev_priv->ellc_size);
  }
 
+ /* clear out old GT FIFO errors */
+ if (IS_GEN6(dev) || IS_GEN7(dev))
+  __raw_i915_write32(dev_priv, GTFIFODBG,
+       __raw_i915_read32(dev_priv, GTFIFODBG));
+
  intel_uncore_forcewake_reset(dev);
 }
 
@@ -256,8 +345,6 @@ void intel_uncore_sanitize(struct drm_device *dev)
  struct drm_i915_private *dev_priv = dev->dev_private;
  u32 reg_val;
 
- intel_uncore_forcewake_reset(dev);
-
  /* BIOS often leaves RC6 enabled, but disable it for hw init */
  intel_disable_gt_powersave(dev);
 
@@ -281,29 +368,40 @@ void intel_uncore_sanitize(struct drm_device *dev)
  * be called at the beginning of the sequence followed by a call to
  * gen6_gt_force_wake_put() at the end of the sequence.
  */
-void gen6_gt_force_wake_get(struct drm_i915_private *dev_priv)
+void gen6_gt_force_wake_get(struct drm_i915_private *dev_priv, int fw_engine)
 {
  unsigned long irqflags;
 
  if (!dev_priv->uncore.funcs.force_wake_get)
   return;
 
+ intel_runtime_pm_get(dev_priv);
+
+ /* Redirect to VLV specific routine */
+ if (IS_VALLEYVIEW(dev_priv->dev))
+  return vlv_force_wake_get(dev_priv, fw_engine);
+
  spin_lock_irqsave(&dev_priv->uncore.lock, irqflags);
  if (dev_priv->uncore.forcewake_count++ == 0)
-  dev_priv->uncore.funcs.force_wake_get(dev_priv);
+  dev_priv->uncore.funcs.force_wake_get(dev_priv, FORCEWAKE_ALL);
  spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags);
 }
 
 /*
  * see gen6_gt_force_wake_get()
  */
-void gen6_gt_force_wake_put(struct drm_i915_private *dev_priv)
+void gen6_gt_force_wake_put(struct drm_i915_private *dev_priv, int fw_engine)
 {
  unsigned long irqflags;
 
  if (!dev_priv->uncore.funcs.force_wake_put)
   return;
 
+ /* Redirect to VLV specific routine */
+ if (IS_VALLEYVIEW(dev_priv->dev))
+  return vlv_force_wake_put(dev_priv, fw_engine);
+
+
  spin_lock_irqsave(&dev_priv->uncore.lock, irqflags);
  if (--dev_priv->uncore.forcewake_count == 0) {
   dev_priv->uncore.forcewake_count++;
@@ -312,6 +410,8 @@ void gen6_gt_force_wake_put(struct drm_i915_private *dev_priv)
      1);
  }
  spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags);
+
+ intel_runtime_pm_put(dev_priv);
 }
 
 /* We give fast paths for the really cool registers */
@@ -346,6 +446,13 @@ hsw_unclaimed_reg_check(struct drm_i915_private *dev_priv, u32 reg)
  }
 }
 
+static void
+assert_device_not_suspended(struct drm_i915_private *dev_priv)
+{
+ WARN(HAS_RUNTIME_PM(dev_priv->dev) && dev_priv->pm.suspended,
+      "Device suspended\n");
+}
+
 #define REG_READ_HEADER(x) \
  unsigned long irqflags; \
  u##x val = 0; \
@@ -379,16 +486,51 @@ gen6_read##x(struct drm_i915_private *dev_priv, off_t reg, bool trace) { \
  REG_READ_HEADER(x); \
  if (NEEDS_FORCE_WAKE((dev_priv), (reg))) { \
   if (dev_priv->uncore.forcewake_count == 0) \
-   dev_priv->uncore.funcs.force_wake_get(dev_priv); \
+   dev_priv->uncore.funcs.force_wake_get(dev_priv, \
+       FORCEWAKE_ALL); \
   val = __raw_i915_read##x(dev_priv, reg); \
   if (dev_priv->uncore.forcewake_count == 0) \
-   dev_priv->uncore.funcs.force_wake_put(dev_priv); \
+   dev_priv->uncore.funcs.force_wake_put(dev_priv, \
+       FORCEWAKE_ALL); \
  } else { \
   val = __raw_i915_read##x(dev_priv, reg); \
  } \
  REG_READ_FOOTER; \
 }
 
+#define __vlv_read(x) \
+static u##x \
+vlv_read##x(struct drm_i915_private *dev_priv, off_t reg, bool trace) { \
+ unsigned fwengine = 0; \
+ unsigned *fwcount; \
+ REG_READ_HEADER(x); \
+ if (FORCEWAKE_VLV_RENDER_RANGE_OFFSET(reg)) {   \
+  fwengine = FORCEWAKE_RENDER;            \
+  fwcount = &dev_priv->uncore.fw_rendercount;    \
+ }                                               \
+ else if (FORCEWAKE_VLV_MEDIA_RANGE_OFFSET(reg)) {       \
+  fwengine = FORCEWAKE_MEDIA;             \
+  fwcount = &dev_priv->uncore.fw_mediacount;     \
+ }  \
+ if (fwengine != 0) {  \
+  if ((*fwcount)++ == 0) \
+   (dev_priv)->uncore.funcs.force_wake_get(dev_priv, \
+        fwengine); \
+  val = __raw_i915_read##x(dev_priv, reg); \
+  if (--(*fwcount) == 0) \
+   (dev_priv)->uncore.funcs.force_wake_put(dev_priv, \
+       fwengine); \
+ } else { \
+  val = __raw_i915_read##x(dev_priv, reg); \
+ } \
+ REG_READ_FOOTER; \
+}
+
+
+__vlv_read(8)
+__vlv_read(16)
+__vlv_read(32)
+__vlv_read(64)
 __gen6_read(8)
 __gen6_read(16)
 __gen6_read(32)
@@ -402,6 +544,7 @@ __gen4_read(16)
 __gen4_read(32)
 __gen4_read(64)
 
+#undef __vlv_read
 #undef __gen6_read
 #undef __gen5_read
 #undef __gen4_read
@@ -413,12 +556,15 @@ __gen4_read(64)
  trace_i915_reg_rw(true, reg, val, sizeof(val), trace); \
  spin_lock_irqsave(&dev_priv->uncore.lock, irqflags)
 
+#define REG_WRITE_FOOTER \
+ spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags)
+
 #define __gen4_write(x) \
 static void \
 gen4_write##x(struct drm_i915_private *dev_priv, off_t reg, u##x val, bool trace) { \
  REG_WRITE_HEADER; \
  __raw_i915_write##x(dev_priv, reg, val); \
- spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags); \
+ REG_WRITE_FOOTER; \
 }
 
 #define __gen5_write(x) \
@@ -427,7 +573,7 @@ gen5_write##x(struct drm_i915_private *dev_priv, off_t reg, u##x val, bool trace
  REG_WRITE_HEADER; \
  ilk_dummy_write(dev_priv); \
  __raw_i915_write##x(dev_priv, reg, val); \
- spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags); \
+ REG_WRITE_FOOTER; \
 }
 
 #define __gen6_write(x) \
@@ -438,11 +584,12 @@ gen6_write##x(struct drm_i915_private *dev_priv, off_t reg, u##x val, bool trace
  if (NEEDS_FORCE_WAKE((dev_priv), (reg))) { \
   __fifo_ret = __gen6_gt_wait_for_fifo(dev_priv); \
  } \
+ assert_device_not_suspended(dev_priv); \
  __raw_i915_write##x(dev_priv, reg, val); \
  if (unlikely(__fifo_ret)) { \
   gen6_gt_check_fifodbg(dev_priv); \
  } \
- spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags); \
+ REG_WRITE_FOOTER; \
 }
 
 #define __hsw_write(x) \
@@ -453,13 +600,14 @@ hsw_write##x(struct drm_i915_private *dev_priv, off_t reg, u##x val, bool trace)
  if (NEEDS_FORCE_WAKE((dev_priv), (reg))) { \
   __fifo_ret = __gen6_gt_wait_for_fifo(dev_priv); \
  } \
+ assert_device_not_suspended(dev_priv); \
  hsw_unclaimed_reg_clear(dev_priv, reg); \
  __raw_i915_write##x(dev_priv, reg, val); \
  if (unlikely(__fifo_ret)) { \
   gen6_gt_check_fifodbg(dev_priv); \
  } \
  hsw_unclaimed_reg_check(dev_priv, reg); \
- spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags); \
+ REG_WRITE_FOOTER; \
 }
 
 static const u32 gen8_shadowed_regs[] = {
@@ -486,16 +634,18 @@ static bool is_gen8_shadowed(struct drm_i915_private *dev_priv, u32 reg)
 #define __gen8_write(x) \
 static void \
 gen8_write##x(struct drm_i915_private *dev_priv, off_t reg, u##x val, bool trace) { \
- bool __needs_put = !is_gen8_shadowed(dev_priv, reg); \
+ bool __needs_put = reg < 0x40000 && !is_gen8_shadowed(dev_priv, reg); \
  REG_WRITE_HEADER; \
  if (__needs_put) { \
-  dev_priv->uncore.funcs.force_wake_get(dev_priv); \
+  dev_priv->uncore.funcs.force_wake_get(dev_priv, \
+       FORCEWAKE_ALL); \
  } \
  __raw_i915_write##x(dev_priv, reg, val); \
  if (__needs_put) { \
-  dev_priv->uncore.funcs.force_wake_put(dev_priv); \
+  dev_priv->uncore.funcs.force_wake_put(dev_priv, \
+       FORCEWAKE_ALL); \
  } \
- spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags); \
+ REG_WRITE_FOOTER; \
 }
 
 __gen8_write(8)
@@ -524,6 +674,7 @@ __gen4_write(64)
 #undef __gen6_write
 #undef __gen5_write
 #undef __gen4_write
+#undef REG_WRITE_FOOTER
 #undef REG_WRITE_HEADER
 
 void intel_uncore_init(struct drm_device *dev)
@@ -534,8 +685,8 @@ void intel_uncore_init(struct drm_device *dev)
      gen6_force_wake_work);
 
  if (IS_VALLEYVIEW(dev)) {
-  dev_priv->uncore.funcs.force_wake_get = vlv_force_wake_get;
-  dev_priv->uncore.funcs.force_wake_put = vlv_force_wake_put;
+  dev_priv->uncore.funcs.force_wake_get = __vlv_force_wake_get;
+  dev_priv->uncore.funcs.force_wake_put = __vlv_force_wake_put;
  } else if (IS_HASWELL(dev) || IS_GEN8(dev)) {
   dev_priv->uncore.funcs.force_wake_get = __gen6_gt_force_wake_mt_get;
   dev_priv->uncore.funcs.force_wake_put = __gen6_gt_force_wake_mt_put;
@@ -552,9 +703,9 @@ void intel_uncore_init(struct drm_device *dev)
    * forcewake being disabled.
    */
   mutex_lock(&dev->struct_mutex);
-  __gen6_gt_force_wake_mt_get(dev_priv);
+  __gen6_gt_force_wake_mt_get(dev_priv, FORCEWAKE_ALL);
   ecobus = __raw_i915_read32(dev_priv, ECOBUS);
-  __gen6_gt_force_wake_mt_put(dev_priv);
+  __gen6_gt_force_wake_mt_put(dev_priv, FORCEWAKE_ALL);
   mutex_unlock(&dev->struct_mutex);
 
   if (ecobus & FORCEWAKE_MT_ENABLE) {
@@ -601,10 +752,18 @@ void intel_uncore_init(struct drm_device *dev)
    dev_priv->uncore.funcs.mmio_writel  = gen6_write32;
    dev_priv->uncore.funcs.mmio_writeq  = gen6_write64;
   }
-  dev_priv->uncore.funcs.mmio_readb  = gen6_read8;
-  dev_priv->uncore.funcs.mmio_readw  = gen6_read16;
-  dev_priv->uncore.funcs.mmio_readl  = gen6_read32;
-  dev_priv->uncore.funcs.mmio_readq  = gen6_read64;
+
+  if (IS_VALLEYVIEW(dev)) {
+   dev_priv->uncore.funcs.mmio_readb  = vlv_read8;
+   dev_priv->uncore.funcs.mmio_readw  = vlv_read16;
+   dev_priv->uncore.funcs.mmio_readl  = vlv_read32;
+   dev_priv->uncore.funcs.mmio_readq  = vlv_read64;
+  } else {
+   dev_priv->uncore.funcs.mmio_readb  = gen6_read8;
+   dev_priv->uncore.funcs.mmio_readw  = gen6_read16;
+   dev_priv->uncore.funcs.mmio_readl  = gen6_read32;
+   dev_priv->uncore.funcs.mmio_readq  = gen6_read64;
+  }
   break;
  case 5:
   dev_priv->uncore.funcs.mmio_writeb  = gen5_write8;
@@ -646,7 +805,7 @@ static const struct register_whitelist {
  uint32_t size;
  uint32_t gen_bitmask; /* support gens, 0x10 for 4, 0x30 for 4 and 5, etc. */
 } whitelist[] = {
- { RING_TIMESTAMP(RENDER_RING_BASE), 8, 0xF0 },
+ { RING_TIMESTAMP(RENDER_RING_BASE), 8, 0x1F0 },
 };
 
 int i915_reg_read_ioctl(struct drm_device *dev,
@@ -687,6 +846,43 @@ int i915_reg_read_ioctl(struct drm_device *dev,
  return 0;
 }
 
+int i915_get_reset_stats_ioctl(struct drm_device *dev,
+          void *data, struct drm_file *file)
+{
+ struct drm_i915_private *dev_priv = dev->dev_private;
+ struct drm_i915_reset_stats *args = data;
+ struct i915_ctx_hang_stats *hs;
+ int ret;
+
+ if (args->flags || args->pad)
+  return -EINVAL;
+
+ if (args->ctx_id == DEFAULT_CONTEXT_ID && !capable(CAP_SYS_ADMIN))
+  return -EPERM;
+
+ ret = mutex_lock_interruptible(&dev->struct_mutex);
+ if (ret)
+  return ret;
+
+ hs = i915_gem_context_get_hang_stats(dev, file, args->ctx_id);
+ if (IS_ERR(hs)) {
+  mutex_unlock(&dev->struct_mutex);
+  return PTR_ERR(hs);
+ }
+
+ if (capable(CAP_SYS_ADMIN))
+  args->reset_count = i915_reset_count(&dev_priv->gpu_error);
+ else
+  args->reset_count = 0;
+
+ args->batch_active = hs->batch_active;
+ args->batch_pending = hs->batch_pending;
+
+ mutex_unlock(&dev->struct_mutex);
+
+ return 0;
+}
+
 static int i965_reset_complete(struct drm_device *dev)
 {
  u8 gdrst;
@@ -770,12 +966,12 @@ static int gen6_do_reset(struct drm_device *dev)
 
  /* If reset with a user forcewake, try to restore, otherwise turn it off */
  if (dev_priv->uncore.forcewake_count)
-  dev_priv->uncore.funcs.force_wake_get(dev_priv);
+  dev_priv->uncore.funcs.force_wake_get(dev_priv, FORCEWAKE_ALL);
  else
-  dev_priv->uncore.funcs.force_wake_put(dev_priv);
+  dev_priv->uncore.funcs.force_wake_put(dev_priv, FORCEWAKE_ALL);
 
  /* Restore fifo count */
- dev_priv->uncore.fifo_count = __raw_i915_read32(dev_priv, GT_FIFO_FREE_ENTRIES);
+ dev_priv->uncore.fifo_count = __raw_i915_read32(dev_priv, GTFIFOCTL) & GT_FIFO_FREE_ENTRIES_MASK;
 
  spin_unlock_irqrestore(&dev_priv->uncore.lock, irqflags);
  return ret;
@@ -793,15 +989,6 @@ int intel_gpu_reset(struct drm_device *dev)
  }
 }
 
-void intel_uncore_clear_errors(struct drm_device *dev)
-{
- struct drm_i915_private *dev_priv = dev->dev_private;
-
- /* XXX needs spinlock around caller's grouping */
- if (HAS_FPGA_DBG_UNCLAIMED(dev))
-  __raw_i915_write32(dev_priv, FPGA_DBG, FPGA_DBG_RM_NOCLAIM);
-}
-
 void intel_uncore_check_errors(struct drm_device *dev)
 {
  struct drm_i915_private *dev_priv = dev->dev_private;
diff --git a/drivers/gpu/drm/mga/mga_dma.c b/drivers/gpu/drm/mga/mga_dma.c
index 087db33..c3bf059 100644
--- a/drivers/gpu/drm/mga/mga_dma.c
+++ b/drivers/gpu/drm/mga/mga_dma.c
@@ -1075,10 +1075,10 @@ static int mga_dma_get_buffers(struct drm_device *dev,
 
   buf->file_priv = file_priv;
 
-  if (DRM_COPY_TO_USER(&d->request_indices[i],
+  if (copy_to_user(&d->request_indices[i],
          &buf->idx, sizeof(buf->idx)))
    return -EFAULT;
-  if (DRM_COPY_TO_USER(&d->request_sizes[i],
+  if (copy_to_user(&d->request_sizes[i],
          &buf->total, sizeof(buf->total)))
    return -EFAULT;
 
diff --git a/drivers/gpu/drm/mga/mga_drv.h b/drivers/gpu/drm/mga/mga_drv.h
index ca4bc54..fe45321 100644
--- a/drivers/gpu/drm/mga/mga_drv.h
+++ b/drivers/gpu/drm/mga/mga_drv.h
@@ -186,14 +186,14 @@ extern void mga_disable_vblank(struct drm_device *dev, int crtc);
 extern u32 mga_get_vblank_counter(struct drm_device *dev, int crtc);
 extern int mga_driver_fence_wait(struct drm_device *dev, unsigned int *sequence);
 extern int mga_driver_vblank_wait(struct drm_device *dev, unsigned int *sequence);
-extern irqreturn_t mga_driver_irq_handler(DRM_IRQ_ARGS);
+extern irqreturn_t mga_driver_irq_handler(int irq, void *arg);
 extern void mga_driver_irq_preinstall(struct drm_device *dev);
 extern int mga_driver_irq_postinstall(struct drm_device *dev);
 extern void mga_driver_irq_uninstall(struct drm_device *dev);
 extern long mga_compat_ioctl(struct file *filp, unsigned int cmd,
         unsigned long arg);
 
-#define mga_flush_write_combine() DRM_WRITEMEMORYBARRIER()
+#define mga_flush_write_combine() wmb()
 
 #define MGA_READ8(reg)  DRM_READ8(dev_priv->mmio, (reg))
 #define MGA_READ(reg)  DRM_READ32(dev_priv->mmio, (reg))
diff --git a/drivers/gpu/drm/mga/mga_ioc32.c b/drivers/gpu/drm/mga/mga_ioc32.c
index 709e90d..86b4bb8 100644
--- a/drivers/gpu/drm/mga/mga_ioc32.c
+++ b/drivers/gpu/drm/mga/mga_ioc32.c
@@ -34,6 +34,7 @@
 
 #include <drm/drmP.h>
 #include <drm/mga_drm.h>
+#include "mga_drv.h"
 
 typedef struct drm32_mga_init {
  int func;
diff --git a/drivers/gpu/drm/mga/mga_irq.c b/drivers/gpu/drm/mga/mga_irq.c
index 2b0ceb8..1b071b8 100644
--- a/drivers/gpu/drm/mga/mga_irq.c
+++ b/drivers/gpu/drm/mga/mga_irq.c
@@ -47,7 +47,7 @@ u32 mga_get_vblank_counter(struct drm_device *dev, int crtc)
 }
 
 
-irqreturn_t mga_driver_irq_handler(DRM_IRQ_ARGS)
+irqreturn_t mga_driver_irq_handler(int irq, void *arg)
 {
  struct drm_device *dev = (struct drm_device *) arg;
  drm_mga_private_t *dev_priv = (drm_mga_private_t *) dev->dev_private;
@@ -79,7 +79,7 @@ irqreturn_t mga_driver_irq_handler(DRM_IRQ_ARGS)
    MGA_WRITE(MGA_PRIMEND, prim_end);
 
   atomic_inc(&dev_priv->last_fence_retired);
-  DRM_WAKEUP(&dev_priv->fence_queue);
+  wake_up(&dev_priv->fence_queue);
   handled = 1;
  }
 
@@ -128,7 +128,7 @@ int mga_driver_fence_wait(struct drm_device *dev, unsigned int *sequence)
   * by about a day rather than she wants to wait for years
   * using fences.
   */
- DRM_WAIT_ON(ret, dev_priv->fence_queue, 3 * DRM_HZ,
+ DRM_WAIT_ON(ret, dev_priv->fence_queue, 3 * HZ,
       (((cur_fence = atomic_read(&dev_priv->last_fence_retired))
         - *sequence) <= (1 << 23)));
 
@@ -151,7 +151,7 @@ int mga_driver_irq_postinstall(struct drm_device *dev)
 {
  drm_mga_private_t *dev_priv = (drm_mga_private_t *) dev->dev_private;
 
- DRM_INIT_WAITQUEUE(&dev_priv->fence_queue);
+ init_waitqueue_head(&dev_priv->fence_queue);
 
  /* Turn on soft trap interrupt.  Vertical blank interrupts are enabled
   * in mga_enable_vblank.
diff --git a/drivers/gpu/drm/mga/mga_state.c b/drivers/gpu/drm/mga/mga_state.c
index 37cc2fb..314685b 100644
--- a/drivers/gpu/drm/mga/mga_state.c
+++ b/drivers/gpu/drm/mga/mga_state.c
@@ -1029,7 +1029,7 @@ static int mga_getparam(struct drm_device *dev, void *data, struct drm_file *fil
   return -EINVAL;
  }
 
- if (DRM_COPY_TO_USER(param->value, &value, sizeof(int))) {
+ if (copy_to_user(param->value, &value, sizeof(int))) {
   DRM_ERROR("copy_to_user\n");
   return -EFAULT;
  }
diff --git a/drivers/gpu/drm/mgag200/mgag200_fb.c b/drivers/gpu/drm/mgag200/mgag200_fb.c
index d29bb33..13b7dd8 100644
--- a/drivers/gpu/drm/mgag200/mgag200_fb.c
+++ b/drivers/gpu/drm/mgag200/mgag200_fb.c
@@ -282,6 +282,11 @@ int mgag200_fbdev_init(struct mga_device *mdev)
 {
  struct mga_fbdev *mfbdev;
  int ret;
+ int bpp_sel = 32;
+
+ /* prefer 16bpp on low end gpus with limited VRAM */
+ if (IS_G200_SE(mdev) && mdev->mc.vram_size < (2048*1024))
+  bpp_sel = 16;
 
  mfbdev = devm_kzalloc(mdev->dev->dev, sizeof(struct mga_fbdev), GFP_KERNEL);
  if (!mfbdev)
@@ -301,7 +306,7 @@ int mgag200_fbdev_init(struct mga_device *mdev)
  /* disable all the possible outputs/crtcs before entering KMS mode */
  drm_helper_disable_unused_functions(mdev->dev);
 
- drm_fb_helper_initial_config(&mfbdev->helper, 32);
+ drm_fb_helper_initial_config(&mfbdev->helper, bpp_sel);
 
  return 0;
 }
diff --git a/drivers/gpu/drm/mgag200/mgag200_main.c b/drivers/gpu/drm/mgag200/mgag200_main.c
index b1120cb..26868e5 100644
--- a/drivers/gpu/drm/mgag200/mgag200_main.c
+++ b/drivers/gpu/drm/mgag200/mgag200_main.c
@@ -217,7 +217,10 @@ int mgag200_driver_load(struct drm_device *dev, unsigned long flags)
 
  drm_mode_config_init(dev);
  dev->mode_config.funcs = (void *)&mga_mode_funcs;
- dev->mode_config.preferred_depth = 24;
+ if (IS_G200_SE(mdev) && mdev->mc.vram_size < (2048*1024))
+  dev->mode_config.preferred_depth = 16;
+ else
+  dev->mode_config.preferred_depth = 24;
  dev->mode_config.prefer_shadow = 1;
 
  r = mgag200_modeset_init(mdev);
@@ -310,7 +313,7 @@ int mgag200_dumb_create(struct drm_file *file,
  return 0;
 }
 
-void mgag200_bo_unref(struct mgag200_bo **bo)
+static void mgag200_bo_unref(struct mgag200_bo **bo)
 {
  struct ttm_buffer_object *tbo;
 
diff --git a/drivers/gpu/drm/mgag200/mgag200_mode.c b/drivers/gpu/drm/mgag200/mgag200_mode.c
index ee3465f..9683747 100644
--- a/drivers/gpu/drm/mgag200/mgag200_mode.c
+++ b/drivers/gpu/drm/mgag200/mgag200_mode.c
@@ -691,7 +691,7 @@ static void mga_g200wb_commit(struct drm_crtc *crtc)
    CRTCEXT0 has to be programmed last to trigger an update and make the
    new addr variable take effect.
  */
-void mga_set_start_address(struct drm_crtc *crtc, unsigned offset)
+static void mga_set_start_address(struct drm_crtc *crtc, unsigned offset)
 {
  struct mga_device *mdev = crtc->dev->dev_private;
  u32 addr;
@@ -1398,7 +1398,7 @@ static void mga_encoder_commit(struct drm_encoder *encoder)
 {
 }
 
-void mga_encoder_destroy(struct drm_encoder *encoder)
+static void mga_encoder_destroy(struct drm_encoder *encoder)
 {
  struct mga_encoder *mga_encoder = to_mga_encoder(encoder);
  drm_encoder_cleanup(encoder);
@@ -1558,7 +1558,7 @@ static int mga_vga_mode_valid(struct drm_connector *connector,
  return MODE_OK;
 }
 
-struct drm_encoder *mga_connector_best_encoder(struct drm_connector
+static struct drm_encoder *mga_connector_best_encoder(struct drm_connector
         *connector)
 {
  int enc_id = connector->encoder_ids[0];
diff --git a/drivers/gpu/drm/mgag200/mgag200_ttm.c b/drivers/gpu/drm/mgag200/mgag200_ttm.c
index 07b192f..adb5166 100644
--- a/drivers/gpu/drm/mgag200/mgag200_ttm.c
+++ b/drivers/gpu/drm/mgag200/mgag200_ttm.c
@@ -80,7 +80,7 @@ static int mgag200_ttm_global_init(struct mga_device *ast)
  return 0;
 }
 
-void
+static void
 mgag200_ttm_global_release(struct mga_device *ast)
 {
  if (ast->ttm.mem_global_ref.release == NULL)
@@ -102,7 +102,7 @@ static void mgag200_bo_ttm_destroy(struct ttm_buffer_object *tbo)
  kfree(bo);
 }
 
-bool mgag200_ttm_bo_is_mgag200_bo(struct ttm_buffer_object *bo)
+static bool mgag200_ttm_bo_is_mgag200_bo(struct ttm_buffer_object *bo)
 {
  if (bo->destroy == &mgag200_bo_ttm_destroy)
   return true;
@@ -208,7 +208,7 @@ static struct ttm_backend_func mgag200_tt_backend_func = {
 };
 
 
-struct ttm_tt *mgag200_ttm_tt_create(struct ttm_bo_device *bdev,
+static struct ttm_tt *mgag200_ttm_tt_create(struct ttm_bo_device *bdev,
      unsigned long size, uint32_t page_flags,
      struct page *dummy_read_page)
 {
diff --git a/drivers/gpu/drm/nouveau/Makefile b/drivers/gpu/drm/nouveau/Makefile
index b3fa1ba..d310c19 100644
--- a/drivers/gpu/drm/nouveau/Makefile
+++ b/drivers/gpu/drm/nouveau/Makefile
@@ -41,6 +41,7 @@ nouveau-y += core/subdev/bios/init.o
 nouveau-y += core/subdev/bios/mxm.o
 nouveau-y += core/subdev/bios/perf.o
 nouveau-y += core/subdev/bios/pll.o
+nouveau-y += core/subdev/bios/ramcfg.o
 nouveau-y += core/subdev/bios/rammap.o
 nouveau-y += core/subdev/bios/timing.o
 nouveau-y += core/subdev/bios/therm.o
@@ -71,7 +72,10 @@ nouveau-y += core/subdev/devinit/nv10.o
 nouveau-y += core/subdev/devinit/nv1a.o
 nouveau-y += core/subdev/devinit/nv20.o
 nouveau-y += core/subdev/devinit/nv50.o
+nouveau-y += core/subdev/devinit/nv84.o
+nouveau-y += core/subdev/devinit/nv98.o
 nouveau-y += core/subdev/devinit/nva3.o
+nouveau-y += core/subdev/devinit/nvaf.o
 nouveau-y += core/subdev/devinit/nvc0.o
 nouveau-y += core/subdev/fb/base.o
 nouveau-y += core/subdev/fb/nv04.o
@@ -137,6 +141,7 @@ nouveau-y += core/subdev/mc/base.o
 nouveau-y += core/subdev/mc/nv04.o
 nouveau-y += core/subdev/mc/nv40.o
 nouveau-y += core/subdev/mc/nv44.o
+nouveau-y += core/subdev/mc/nv4c.o
 nouveau-y += core/subdev/mc/nv50.o
 nouveau-y += core/subdev/mc/nv94.o
 nouveau-y += core/subdev/mc/nv98.o
@@ -232,6 +237,7 @@ nouveau-y += core/engine/fifo/nv50.o
 nouveau-y += core/engine/fifo/nv84.o
 nouveau-y += core/engine/fifo/nvc0.o
 nouveau-y += core/engine/fifo/nve0.o
+nouveau-y += core/engine/fifo/nv108.o
 nouveau-y += core/engine/graph/ctxnv40.o
 nouveau-y += core/engine/graph/ctxnv50.o
 nouveau-y += core/engine/graph/ctxnvc0.o
@@ -242,6 +248,7 @@ nouveau-y += core/engine/graph/ctxnvd7.o
 nouveau-y += core/engine/graph/ctxnvd9.o
 nouveau-y += core/engine/graph/ctxnve4.o
 nouveau-y += core/engine/graph/ctxnvf0.o
+nouveau-y += core/engine/graph/ctxnv108.o
 nouveau-y += core/engine/graph/nv04.o
 nouveau-y += core/engine/graph/nv10.o
 nouveau-y += core/engine/graph/nv20.o
@@ -260,6 +267,7 @@ nouveau-y += core/engine/graph/nvd7.o
 nouveau-y += core/engine/graph/nvd9.o
 nouveau-y += core/engine/graph/nve4.o
 nouveau-y += core/engine/graph/nvf0.o
+nouveau-y += core/engine/graph/nv108.o
 nouveau-y += core/engine/mpeg/nv31.o
 nouveau-y += core/engine/mpeg/nv40.o
 nouveau-y += core/engine/mpeg/nv44.o
diff --git a/drivers/gpu/drm/nouveau/core/core/engine.c b/drivers/gpu/drm/nouveau/core/core/engine.c
index c8bed4a..1f6954a 100644
--- a/drivers/gpu/drm/nouveau/core/core/engine.c
+++ b/drivers/gpu/drm/nouveau/core/core/engine.c
@@ -42,11 +42,24 @@ nouveau_engine_create_(struct nouveau_object *parent,
  if (ret)
   return ret;
 
- if ( parent &&
-     !nouveau_boolopt(nv_device(parent)->cfgopt, iname, enable)) {
-  if (!enable)
-   nv_warn(engine, "disabled, %s=1 to enable\n", iname);
-  return -ENODEV;
+ if (parent) {
+  struct nouveau_device *device = nv_device(parent);
+  int engidx = nv_engidx(nv_object(engine));
+
+  if (device->disable_mask & (1ULL << engidx)) {
+   if (!nouveau_boolopt(device->cfgopt, iname, false)) {
+    nv_debug(engine, "engine disabled by hw/fw\n");
+    return -ENODEV;
+   }
+
+   nv_warn(engine, "ignoring hw/fw engine disable\n");
+  }
+
+  if (!nouveau_boolopt(device->cfgopt, iname, enable)) {
+   if (!enable)
+    nv_warn(engine, "disabled, %s=1 to enable\n", iname);
+   return -ENODEV;
+  }
  }
 
  INIT_LIST_HEAD(&engine->contexts);
diff --git a/drivers/gpu/drm/nouveau/core/engine/copy/nvc0.c b/drivers/gpu/drm/nouveau/core/engine/copy/nvc0.c
index 993df09..ac3291f 100644
--- a/drivers/gpu/drm/nouveau/core/engine/copy/nvc0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/copy/nvc0.c
@@ -105,9 +105,6 @@ nvc0_copy0_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  struct nvc0_copy_priv *priv;
  int ret;
 
- if (nv_rd32(parent, 0x022500) & 0x00000100)
-  return -ENODEV;
-
  ret = nouveau_falcon_create(parent, engine, oclass, 0x104000, true,
         "PCE0", "copy0", &priv);
  *pobject = nv_object(priv);
@@ -133,9 +130,6 @@ nvc0_copy1_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  struct nvc0_copy_priv *priv;
  int ret;
 
- if (nv_rd32(parent, 0x022500) & 0x00000200)
-  return -ENODEV;
-
  ret = nouveau_falcon_create(parent, engine, oclass, 0x105000, true,
         "PCE1", "copy1", &priv);
  *pobject = nv_object(priv);
diff --git a/drivers/gpu/drm/nouveau/core/engine/copy/nve0.c b/drivers/gpu/drm/nouveau/core/engine/copy/nve0.c
index 30f1ef1..748a61e 100644
--- a/drivers/gpu/drm/nouveau/core/engine/copy/nve0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/copy/nve0.c
@@ -88,9 +88,6 @@ nve0_copy0_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  struct nve0_copy_priv *priv;
  int ret;
 
- if (nv_rd32(parent, 0x022500) & 0x00000100)
-  return -ENODEV;
-
  ret = nouveau_engine_create(parent, engine, oclass, true,
         "PCE0", "copy0", &priv);
  *pobject = nv_object(priv);
@@ -112,9 +109,6 @@ nve0_copy1_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  struct nve0_copy_priv *priv;
  int ret;
 
- if (nv_rd32(parent, 0x022500) & 0x00000200)
-  return -ENODEV;
-
  ret = nouveau_engine_create(parent, engine, oclass, true,
         "PCE1", "copy1", &priv);
  *pobject = nv_object(priv);
diff --git a/drivers/gpu/drm/nouveau/core/engine/device/nv04.c b/drivers/gpu/drm/nouveau/core/engine/device/nv04.c
index dbd2dde..32113b0 100644
--- a/drivers/gpu/drm/nouveau/core/engine/device/nv04.c
+++ b/drivers/gpu/drm/nouveau/core/engine/device/nv04.c
@@ -49,12 +49,12 @@ nv04_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_VBIOS  ] = &nouveau_bios_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv04_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv04_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv04_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv04_fifo_oclass;
@@ -67,12 +67,12 @@ nv04_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_VBIOS  ] = &nouveau_bios_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv05_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv05_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv04_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv04_fifo_oclass;
diff --git a/drivers/gpu/drm/nouveau/core/engine/device/nv10.c b/drivers/gpu/drm/nouveau/core/engine/device/nv10.c
index 6e03dd6..744f15d 100644
--- a/drivers/gpu/drm/nouveau/core/engine/device/nv10.c
+++ b/drivers/gpu/drm/nouveau/core/engine/device/nv10.c
@@ -51,12 +51,12 @@ nv10_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv10_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv10_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv10_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_GR     ] = &nv10_graph_oclass;
@@ -68,12 +68,12 @@ nv10_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv10_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv10_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv10_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv10_fifo_oclass;
@@ -87,12 +87,12 @@ nv10_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv10_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv10_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv10_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv10_fifo_oclass;
@@ -106,12 +106,12 @@ nv10_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv1a_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv10_fifo_oclass;
@@ -125,12 +125,12 @@ nv10_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv10_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv10_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv10_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv10_fifo_oclass;
@@ -144,12 +144,12 @@ nv10_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv10_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv10_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv10_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
@@ -163,12 +163,12 @@ nv10_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv1a_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
@@ -182,12 +182,12 @@ nv10_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv10_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv10_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv10_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
diff --git a/drivers/gpu/drm/nouveau/core/engine/device/nv20.c b/drivers/gpu/drm/nouveau/core/engine/device/nv20.c
index dcde53b..27ba61f 100644
--- a/drivers/gpu/drm/nouveau/core/engine/device/nv20.c
+++ b/drivers/gpu/drm/nouveau/core/engine/device/nv20.c
@@ -52,12 +52,12 @@ nv20_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv20_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv20_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv20_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
@@ -71,12 +71,12 @@ nv20_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv20_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv20_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv25_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
@@ -90,12 +90,12 @@ nv20_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv20_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv20_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv25_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
@@ -109,12 +109,12 @@ nv20_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv20_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv20_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv25_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
diff --git a/drivers/gpu/drm/nouveau/core/engine/device/nv30.c b/drivers/gpu/drm/nouveau/core/engine/device/nv30.c
index 7b8662e..fd47ace 100644
--- a/drivers/gpu/drm/nouveau/core/engine/device/nv30.c
+++ b/drivers/gpu/drm/nouveau/core/engine/device/nv30.c
@@ -52,12 +52,12 @@ nv30_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv20_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv20_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv30_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
@@ -71,12 +71,12 @@ nv30_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv20_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv20_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv04_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv35_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
@@ -90,12 +90,12 @@ nv30_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv20_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv20_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv30_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
@@ -110,12 +110,12 @@ nv30_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv20_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv20_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv36_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
@@ -130,12 +130,12 @@ nv30_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_GPIO   ] = &nv10_gpio_oclass;
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv04_clock_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv10_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv10_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv04_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv10_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv04_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv04_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
   device->oclass[NVDEV_ENGINE_FIFO   ] =  nv17_fifo_oclass;
diff --git a/drivers/gpu/drm/nouveau/core/engine/device/nv40.c b/drivers/gpu/drm/nouveau/core/engine/device/nv40.c
index c8c41e9..08b8859 100644
--- a/drivers/gpu/drm/nouveau/core/engine/device/nv40.c
+++ b/drivers/gpu/drm/nouveau/core/engine/device/nv40.c
@@ -57,12 +57,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv40_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv40_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -80,12 +80,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv40_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv41_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv41_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -103,12 +103,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv40_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv41_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv41_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -126,12 +126,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv40_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv41_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv41_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -149,12 +149,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv40_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv40_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv04_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -172,12 +172,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv40_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv47_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv41_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -195,12 +195,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv40_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv49_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv41_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -218,12 +218,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv40_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv49_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv41_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -241,12 +241,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv44_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv44_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv44_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -264,12 +264,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv44_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv46_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv44_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -287,12 +287,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv44_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv44_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv44_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -310,12 +310,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
-  device->oclass[NVDEV_SUBDEV_MC     ] =  nv44_mc_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_MC     ] =  nv4c_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv46_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv44_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -333,12 +333,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv4e_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
-  device->oclass[NVDEV_SUBDEV_MC     ] =  nv44_mc_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_MC     ] =  nv4c_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv4e_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv44_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -356,12 +356,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
-  device->oclass[NVDEV_SUBDEV_MC     ] =  nv44_mc_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_MC     ] =  nv4c_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv46_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv44_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -379,12 +379,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
-  device->oclass[NVDEV_SUBDEV_MC     ] =  nv44_mc_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_MC     ] =  nv4c_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv46_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv44_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
@@ -402,12 +402,12 @@ nv40_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_I2C    ] = &nv04_i2c_oclass;
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nv40_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv40_therm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv1a_devinit_oclass;
-  device->oclass[NVDEV_SUBDEV_MC     ] =  nv44_mc_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv1a_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_MC     ] =  nv4c_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv31_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv46_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv40_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv40_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv44_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nv04_dmaeng_oclass;
diff --git a/drivers/gpu/drm/nouveau/core/engine/device/nv50.c b/drivers/gpu/drm/nouveau/core/engine/device/nv50.c
index db3fc7b..81d5c26 100644
--- a/drivers/gpu/drm/nouveau/core/engine/device/nv50.c
+++ b/drivers/gpu/drm/nouveau/core/engine/device/nv50.c
@@ -65,12 +65,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nv50_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv50_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv50_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv50_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv50_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv50_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -90,12 +90,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nv84_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv84_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv84_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv50_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv50_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv84_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -118,12 +118,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nv84_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv84_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv84_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv50_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv50_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv84_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -146,12 +146,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nv84_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv84_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv84_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv50_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv50_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv84_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -174,12 +174,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nv84_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv84_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv84_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv94_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv84_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -202,12 +202,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nv84_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv84_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv84_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv94_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv84_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -230,12 +230,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nv84_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv84_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv98_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv98_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv84_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -258,12 +258,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nv84_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv84_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv84_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv98_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nv84_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -286,12 +286,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nvaa_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv84_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv98_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv98_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvaa_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -314,12 +314,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] =  nvaa_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nv84_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nv50_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nv98_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv98_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvaa_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
@@ -342,12 +342,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nva3_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nva3_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nva3_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv98_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nva3_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nva3_pwr_oclass;
@@ -372,12 +372,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nva3_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nva3_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nva3_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv98_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nva3_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nva3_pwr_oclass;
@@ -401,12 +401,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nva3_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nva3_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nva3_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv98_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nva3_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nva3_pwr_oclass;
@@ -430,12 +430,12 @@ nv50_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nva3_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nva3_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvaf_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nv98_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nv94_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvaf_fb_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nv50_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nv50_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nva3_pwr_oclass;
diff --git a/drivers/gpu/drm/nouveau/core/engine/device/nvc0.c b/drivers/gpu/drm/nouveau/core/engine/device/nvc0.c
index dbc5e33..b7d66b5 100644
--- a/drivers/gpu/drm/nouveau/core/engine/device/nvc0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/device/nvc0.c
@@ -65,14 +65,14 @@ nvc0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nvc0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc0_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvc0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nvc0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvc0_pwr_oclass;
@@ -97,14 +97,14 @@ nvc0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nvc0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc0_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvc0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nvc0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvc0_pwr_oclass;
@@ -129,14 +129,14 @@ nvc0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nvc0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvc0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nvc0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvc0_pwr_oclass;
@@ -160,14 +160,14 @@ nvc0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nvc0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc0_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvc0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nvc0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvc0_pwr_oclass;
@@ -192,14 +192,14 @@ nvc0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nvc0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvc0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nvc0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvc0_pwr_oclass;
@@ -224,14 +224,14 @@ nvc0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nvc0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvc0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nvc0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvc0_pwr_oclass;
@@ -255,14 +255,14 @@ nvc0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nvc0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nva3_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc0_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvc0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nvc0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvc0_pwr_oclass;
@@ -287,14 +287,14 @@ nvc0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nvc0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nvd0_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvc0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nvc0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvd0_pwr_oclass;
@@ -318,14 +318,14 @@ nvc0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nvc0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nvd0_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nvc0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nvc0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nvd0_dmaeng_oclass;
diff --git a/drivers/gpu/drm/nouveau/core/engine/device/nve0.c b/drivers/gpu/drm/nouveau/core/engine/device/nve0.c
index 3900104..987edbc 100644
--- a/drivers/gpu/drm/nouveau/core/engine/device/nve0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/device/nve0.c
@@ -65,14 +65,14 @@ nve0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nve0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nvd0_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nve0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nve0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvd0_pwr_oclass;
@@ -98,14 +98,14 @@ nve0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nve0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nvd0_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nve0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nve0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvd0_pwr_oclass;
@@ -131,14 +131,14 @@ nve0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nve0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nvd0_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nve0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nve0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvd0_pwr_oclass;
@@ -164,14 +164,14 @@ nve0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nve0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nvd0_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nve0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nve0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nvd0_pwr_oclass;
@@ -199,29 +199,27 @@ nve0_identify(struct nouveau_device *device)
   device->oclass[NVDEV_SUBDEV_CLOCK  ] = &nve0_clock_oclass;
   device->oclass[NVDEV_SUBDEV_THERM  ] = &nvd0_therm_oclass;
   device->oclass[NVDEV_SUBDEV_MXM    ] = &nv50_mxm_oclass;
-  device->oclass[NVDEV_SUBDEV_DEVINIT] = &nvc0_devinit_oclass;
+  device->oclass[NVDEV_SUBDEV_DEVINIT] =  nvc0_devinit_oclass;
   device->oclass[NVDEV_SUBDEV_MC     ] =  nvc3_mc_oclass;
   device->oclass[NVDEV_SUBDEV_BUS    ] =  nvc0_bus_oclass;
   device->oclass[NVDEV_SUBDEV_TIMER  ] = &nv04_timer_oclass;
   device->oclass[NVDEV_SUBDEV_FB     ] =  nve0_fb_oclass;
   device->oclass[NVDEV_SUBDEV_LTCG   ] = &nvc0_ltcg_oclass;
   device->oclass[NVDEV_SUBDEV_IBUS   ] = &nve0_ibus_oclass;
-  device->oclass[NVDEV_SUBDEV_INSTMEM] = &nv50_instmem_oclass;
+  device->oclass[NVDEV_SUBDEV_INSTMEM] =  nv50_instmem_oclass;
   device->oclass[NVDEV_SUBDEV_VM     ] = &nvc0_vmmgr_oclass;
   device->oclass[NVDEV_SUBDEV_BAR    ] = &nvc0_bar_oclass;
   device->oclass[NVDEV_SUBDEV_PWR    ] = &nv108_pwr_oclass;
   device->oclass[NVDEV_SUBDEV_VOLT   ] = &nv40_volt_oclass;
   device->oclass[NVDEV_ENGINE_DMAOBJ ] = &nvd0_dmaeng_oclass;
-#if 0
-  device->oclass[NVDEV_ENGINE_FIFO   ] =  nve0_fifo_oclass;
+  device->oclass[NVDEV_ENGINE_FIFO   ] =  nv108_fifo_oclass;
   device->oclass[NVDEV_ENGINE_SW     ] =  nvc0_software_oclass;
-  device->oclass[NVDEV_ENGINE_GR     ] =  nvf0_graph_oclass;
-#endif
+  device->oclass[NVDEV_ENGINE_GR     ] =  nv108_graph_oclass;
   device->oclass[NVDEV_ENGINE_DISP   ] = &nvf0_disp_oclass;
-#if 0
   device->oclass[NVDEV_ENGINE_COPY0  ] = &nve0_copy0_oclass;
   device->oclass[NVDEV_ENGINE_COPY1  ] = &nve0_copy1_oclass;
   device->oclass[NVDEV_ENGINE_COPY2  ] = &nve0_copy2_oclass;
+#if 0
   device->oclass[NVDEV_ENGINE_BSP    ] = &nve0_bsp_oclass;
   device->oclass[NVDEV_ENGINE_VP     ] = &nve0_vp_oclass;
   device->oclass[NVDEV_ENGINE_PPP    ] = &nvc0_ppp_oclass;
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/nv04.c b/drivers/gpu/drm/nouveau/core/engine/disp/nv04.c
index a0bc8a8..7cf8b13 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/nv04.c
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/nv04.c
@@ -31,9 +31,45 @@ struct nv04_disp_priv {
  struct nouveau_disp base;
 };
 
+static int
+nv04_disp_scanoutpos(struct nouveau_object *object, u32 mthd,
+       void *data, u32 size)
+{
+ struct nv04_disp_priv *priv = (void *)object->engine;
+ struct nv04_display_scanoutpos *args = data;
+ const int head = (mthd & NV04_DISP_MTHD_HEAD);
+ u32 line;
+
+ if (size < sizeof(*args))
+  return -EINVAL;
+
+ args->vblanks = nv_rd32(priv, 0x680800 + (head * 0x2000)) & 0xffff;
+ args->vtotal  = nv_rd32(priv, 0x680804 + (head * 0x2000)) & 0xffff;
+ args->vblanke = args->vtotal - 1;
+
+ args->hblanks = nv_rd32(priv, 0x680820 + (head * 0x2000)) & 0xffff;
+ args->htotal  = nv_rd32(priv, 0x680824 + (head * 0x2000)) & 0xffff;
+ args->hblanke = args->htotal - 1;
+
+ args->time[0] = ktime_to_ns(ktime_get());
+ line = nv_rd32(priv, 0x600868 + (head * 0x2000));
+ args->time[1] = ktime_to_ns(ktime_get());
+ args->hline = (line & 0xffff0000) >> 16;
+ args->vline = (line & 0x0000ffff);
+ return 0;
+}
+
+#define HEAD_MTHD(n) (n), (n) + 0x01
+
+static struct nouveau_omthds
+nv04_disp_omthds[] = {
+ { HEAD_MTHD(NV04_DISP_SCANOUTPOS), nv04_disp_scanoutpos },
+ {}
+};
+
 static struct nouveau_oclass
 nv04_disp_sclass[] = {
- { NV04_DISP_CLASS, &nouveau_object_ofuncs },
+ { NV04_DISP_CLASS, &nouveau_object_ofuncs, nv04_disp_omthds },
  {},
 };
 
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/nv50.c b/drivers/gpu/drm/nouveau/core/engine/disp/nv50.c
index 355e9fd..9ad722e 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/nv50.c
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/nv50.c
@@ -541,6 +541,35 @@ nv50_disp_curs_ofuncs = {
  * Base display object
  ******************************************************************************/
 
+int
+nv50_disp_base_scanoutpos(struct nouveau_object *object, u32 mthd,
+     void *data, u32 size)
+{
+ struct nv50_disp_priv *priv = (void *)object->engine;
+ struct nv04_display_scanoutpos *args = data;
+ const int head = (mthd & NV50_DISP_MTHD_HEAD);
+ u32 blanke, blanks, total;
+
+ if (size < sizeof(*args) || head >= priv->head.nr)
+  return -EINVAL;
+ blanke = nv_rd32(priv, 0x610aec + (head * 0x540));
+ blanks = nv_rd32(priv, 0x610af4 + (head * 0x540));
+ total  = nv_rd32(priv, 0x610afc + (head * 0x540));
+
+ args->vblanke = (blanke & 0xffff0000) >> 16;
+ args->hblanke = (blanke & 0x0000ffff);
+ args->vblanks = (blanks & 0xffff0000) >> 16;
+ args->hblanks = (blanks & 0x0000ffff);
+ args->vtotal  = ( total & 0xffff0000) >> 16;
+ args->htotal  = ( total & 0x0000ffff);
+
+ args->time[0] = ktime_to_ns(ktime_get());
+ args->vline   = nv_rd32(priv, 0x616340 + (head * 0x800)) & 0xffff;
+ args->time[1] = ktime_to_ns(ktime_get()); /* vline read locks hline */
+ args->hline   = nv_rd32(priv, 0x616344 + (head * 0x800)) & 0xffff;
+ return 0;
+}
+
 static void
 nv50_disp_base_vblank_enable(struct nouveau_event *event, int head)
 {
@@ -675,6 +704,7 @@ nv50_disp_base_ofuncs = {
 
 static struct nouveau_omthds
 nv50_disp_base_omthds[] = {
+ { HEAD_MTHD(NV50_DISP_SCANOUTPOS)     , nv50_disp_base_scanoutpos },
  { SOR_MTHD(NV50_DISP_SOR_PWR)         , nv50_sor_mthd },
  { SOR_MTHD(NV50_DISP_SOR_LVDS_SCRIPT) , nv50_sor_mthd },
  { DAC_MTHD(NV50_DISP_DAC_PWR)         , nv50_dac_mthd },
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/nv50.h b/drivers/gpu/drm/nouveau/core/engine/disp/nv50.h
index 1ae6ceb..d31d426 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/nv50.h
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/nv50.h
@@ -43,6 +43,10 @@ struct nv50_disp_priv {
  } pior;
 };
 
+#define HEAD_MTHD(n) (n), (n) + 0x03
+
+int nv50_disp_base_scanoutpos(struct nouveau_object *, u32, void *, u32);
+
 #define DAC_MTHD(n) (n), (n) + 0x03
 
 int nv50_dac_mthd(struct nouveau_object *, u32, void *, u32);
@@ -132,13 +136,12 @@ void nv50_disp_intr(struct nouveau_subdev *);
 
 extern struct nouveau_omthds nv84_disp_base_omthds[];
 
-extern struct nouveau_omthds nva3_disp_base_omthds[];
-
 extern struct nouveau_ofuncs nvd0_disp_mast_ofuncs;
 extern struct nouveau_ofuncs nvd0_disp_sync_ofuncs;
 extern struct nouveau_ofuncs nvd0_disp_ovly_ofuncs;
 extern struct nouveau_ofuncs nvd0_disp_oimm_ofuncs;
 extern struct nouveau_ofuncs nvd0_disp_curs_ofuncs;
+extern struct nouveau_omthds nvd0_disp_base_omthds[];
 extern struct nouveau_ofuncs nvd0_disp_base_ofuncs;
 extern struct nouveau_oclass nvd0_disp_cclass;
 void nvd0_disp_intr_supervisor(struct work_struct *);
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/nv84.c b/drivers/gpu/drm/nouveau/core/engine/disp/nv84.c
index d8c74c0..ef9ce30 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/nv84.c
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/nv84.c
@@ -41,6 +41,7 @@ nv84_disp_sclass[] = {
 
 struct nouveau_omthds
 nv84_disp_base_omthds[] = {
+ { HEAD_MTHD(NV50_DISP_SCANOUTPOS)     , nv50_disp_base_scanoutpos },
  { SOR_MTHD(NV50_DISP_SOR_PWR)         , nv50_sor_mthd },
  { SOR_MTHD(NV84_DISP_SOR_HDMI_PWR)    , nv50_sor_mthd },
  { SOR_MTHD(NV50_DISP_SOR_LVDS_SCRIPT) , nv50_sor_mthd },
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/nv94.c b/drivers/gpu/drm/nouveau/core/engine/disp/nv94.c
index a66f949..a518543 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/nv94.c
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/nv94.c
@@ -41,6 +41,7 @@ nv94_disp_sclass[] = {
 
 static struct nouveau_omthds
 nv94_disp_base_omthds[] = {
+ { HEAD_MTHD(NV50_DISP_SCANOUTPOS)     , nv50_disp_base_scanoutpos },
  { SOR_MTHD(NV50_DISP_SOR_PWR)         , nv50_sor_mthd },
  { SOR_MTHD(NV84_DISP_SOR_HDMI_PWR)    , nv50_sor_mthd },
  { SOR_MTHD(NV50_DISP_SOR_LVDS_SCRIPT) , nv50_sor_mthd },
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/nva3.c b/drivers/gpu/drm/nouveau/core/engine/disp/nva3.c
index b754131..6ad6dce 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/nva3.c
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/nva3.c
@@ -39,8 +39,9 @@ nva3_disp_sclass[] = {
  {}
 };
 
-struct nouveau_omthds
+static struct nouveau_omthds
 nva3_disp_base_omthds[] = {
+ { HEAD_MTHD(NV50_DISP_SCANOUTPOS)     , nv50_disp_base_scanoutpos },
  { SOR_MTHD(NV50_DISP_SOR_PWR)         , nv50_sor_mthd },
  { SOR_MTHD(NVA3_DISP_SOR_HDA_ELD)     , nv50_sor_mthd },
  { SOR_MTHD(NV84_DISP_SOR_HDMI_PWR)    , nv50_sor_mthd },
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/nvd0.c b/drivers/gpu/drm/nouveau/core/engine/disp/nvd0.c
index 378a015..1c5e4e8 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/nvd0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/nvd0.c
@@ -440,6 +440,36 @@ nvd0_disp_curs_ofuncs = {
  * Base display object
  ******************************************************************************/
 
+static int
+nvd0_disp_base_scanoutpos(struct nouveau_object *object, u32 mthd,
+     void *data, u32 size)
+{
+ struct nv50_disp_priv *priv = (void *)object->engine;
+ struct nv04_display_scanoutpos *args = data;
+ const int head = (mthd & NV50_DISP_MTHD_HEAD);
+ u32 blanke, blanks, total;
+
+ if (size < sizeof(*args) || head >= priv->head.nr)
+  return -EINVAL;
+
+ total  = nv_rd32(priv, 0x640414 + (head * 0x300));
+ blanke = nv_rd32(priv, 0x64041c + (head * 0x300));
+ blanks = nv_rd32(priv, 0x640420 + (head * 0x300));
+
+ args->vblanke = (blanke & 0xffff0000) >> 16;
+ args->hblanke = (blanke & 0x0000ffff);
+ args->vblanks = (blanks & 0xffff0000) >> 16;
+ args->hblanks = (blanks & 0x0000ffff);
+ args->vtotal  = ( total & 0xffff0000) >> 16;
+ args->htotal  = ( total & 0x0000ffff);
+
+ args->time[0] = ktime_to_ns(ktime_get());
+ args->vline   = nv_rd32(priv, 0x616340 + (head * 0x800)) & 0xffff;
+ args->time[1] = ktime_to_ns(ktime_get()); /* vline read locks hline */
+ args->hline   = nv_rd32(priv, 0x616344 + (head * 0x800)) & 0xffff;
+ return 0;
+}
+
 static void
 nvd0_disp_base_vblank_enable(struct nouveau_event *event, int head)
 {
@@ -573,9 +603,24 @@ nvd0_disp_base_ofuncs = {
  .fini = nvd0_disp_base_fini,
 };
 
+struct nouveau_omthds
+nvd0_disp_base_omthds[] = {
+ { HEAD_MTHD(NV50_DISP_SCANOUTPOS)     , nvd0_disp_base_scanoutpos },
+ { SOR_MTHD(NV50_DISP_SOR_PWR)         , nv50_sor_mthd },
+ { SOR_MTHD(NVA3_DISP_SOR_HDA_ELD)     , nv50_sor_mthd },
+ { SOR_MTHD(NV84_DISP_SOR_HDMI_PWR)    , nv50_sor_mthd },
+ { SOR_MTHD(NV50_DISP_SOR_LVDS_SCRIPT) , nv50_sor_mthd },
+ { DAC_MTHD(NV50_DISP_DAC_PWR)         , nv50_dac_mthd },
+ { DAC_MTHD(NV50_DISP_DAC_LOAD)        , nv50_dac_mthd },
+ { PIOR_MTHD(NV50_DISP_PIOR_PWR)       , nv50_pior_mthd },
+ { PIOR_MTHD(NV50_DISP_PIOR_TMDS_PWR)  , nv50_pior_mthd },
+ { PIOR_MTHD(NV50_DISP_PIOR_DP_PWR)    , nv50_pior_mthd },
+ {},
+};
+
 static struct nouveau_oclass
 nvd0_disp_base_oclass[] = {
- { NVD0_DISP_CLASS, &nvd0_disp_base_ofuncs, nva3_disp_base_omthds },
+ { NVD0_DISP_CLASS, &nvd0_disp_base_ofuncs, nvd0_disp_base_omthds },
  {}
 };
 
@@ -967,9 +1012,6 @@ nvd0_disp_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  int heads = nv_rd32(parent, 0x022448);
  int ret;
 
- if (nv_rd32(parent, 0x022500) & 0x00000001)
-  return -ENODEV;
-
  ret = nouveau_disp_create(parent, engine, oclass, heads,
       "PDISP", "display", &priv);
  *pobject = nv_object(priv);
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/nve0.c b/drivers/gpu/drm/nouveau/core/engine/disp/nve0.c
index fb1fe6a..ab63f32 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/nve0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/nve0.c
@@ -41,7 +41,7 @@ nve0_disp_sclass[] = {
 
 static struct nouveau_oclass
 nve0_disp_base_oclass[] = {
- { NVE0_DISP_CLASS, &nvd0_disp_base_ofuncs, nva3_disp_base_omthds },
+ { NVE0_DISP_CLASS, &nvd0_disp_base_ofuncs, nvd0_disp_base_omthds },
  {}
 };
 
@@ -54,9 +54,6 @@ nve0_disp_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  int heads = nv_rd32(parent, 0x022448);
  int ret;
 
- if (nv_rd32(parent, 0x022500) & 0x00000001)
-  return -ENODEV;
-
  ret = nouveau_disp_create(parent, engine, oclass, heads,
       "PDISP", "display", &priv);
  *pobject = nv_object(priv);
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/nvf0.c b/drivers/gpu/drm/nouveau/core/engine/disp/nvf0.c
index 42aa6b9..05fee10 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/nvf0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/nvf0.c
@@ -41,7 +41,7 @@ nvf0_disp_sclass[] = {
 
 static struct nouveau_oclass
 nvf0_disp_base_oclass[] = {
- { NVF0_DISP_CLASS, &nvd0_disp_base_ofuncs, nva3_disp_base_omthds },
+ { NVF0_DISP_CLASS, &nvd0_disp_base_ofuncs, nvd0_disp_base_omthds },
  {}
 };
 
@@ -54,9 +54,6 @@ nvf0_disp_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  int heads = nv_rd32(parent, 0x022448);
  int ret;
 
- if (nv_rd32(parent, 0x022500) & 0x00000001)
-  return -ENODEV;
-
  ret = nouveau_disp_create(parent, engine, oclass, heads,
       "PDISP", "display", &priv);
  *pobject = nv_object(priv);
diff --git a/drivers/gpu/drm/nouveau/core/engine/disp/vga.c b/drivers/gpu/drm/nouveau/core/engine/disp/vga.c
index 5a1c684..8836c3c 100644
--- a/drivers/gpu/drm/nouveau/core/engine/disp/vga.c
+++ b/drivers/gpu/drm/nouveau/core/engine/disp/vga.c
@@ -138,10 +138,15 @@ nv_wrvgai(void *obj, int head, u16 port, u8 index, u8 value)
 bool
 nv_lockvgac(void *obj, bool lock)
 {
+ struct nouveau_device *dev = nv_device(obj);
+
  bool locked = !nv_rdvgac(obj, 0, 0x1f);
  u8 data = lock ? 0x99 : 0x57;
- nv_wrvgac(obj, 0, 0x1f, data);
- if (nv_device(obj)->chipset == 0x11) {
+ if (dev->card_type < NV_50)
+  nv_wrvgac(obj, 0, 0x1f, data);
+ else
+  nv_wrvgac(obj, 0, 0x3f, data);
+ if (dev->chipset == 0x11) {
   if (!(nv_rd32(obj, 0x001084) & 0x10000000))
    nv_wrvgac(obj, 1, 0x1f, data);
  }
diff --git a/drivers/gpu/drm/nouveau/core/engine/fifo/nv108.c b/drivers/gpu/drm/nouveau/core/engine/fifo/nv108.c
new file mode 100644
index 0000000..09362a5
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/engine/fifo/nv108.c
@@ -0,0 +1,37 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+
+#include "nve0.h"
+
+struct nouveau_oclass *
+nv108_fifo_oclass = &(struct nve0_fifo_impl) {
+ .base.handle = NV_ENGINE(FIFO, 0x08),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nve0_fifo_ctor,
+  .dtor = nve0_fifo_dtor,
+  .init = nve0_fifo_init,
+  .fini = _nouveau_fifo_fini,
+ },
+ .channels = 1024,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/engine/fifo/nvc0.c b/drivers/gpu/drm/nouveau/core/engine/fifo/nvc0.c
index 9ac94d4..b22a33f 100644
--- a/drivers/gpu/drm/nouveau/core/engine/fifo/nvc0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/fifo/nvc0.c
@@ -33,6 +33,7 @@
 
 #include <subdev/timer.h>
 #include <subdev/bar.h>
+#include <subdev/fb.h>
 #include <subdev/vm.h>
 
 #include <engine/dmaobj.h>
diff --git a/drivers/gpu/drm/nouveau/core/engine/fifo/nve0.c b/drivers/gpu/drm/nouveau/core/engine/fifo/nve0.c
index 04f4129..54c1b5b 100644
--- a/drivers/gpu/drm/nouveau/core/engine/fifo/nve0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/fifo/nve0.c
@@ -33,10 +33,12 @@
 
 #include <subdev/timer.h>
 #include <subdev/bar.h>
+#include <subdev/fb.h>
 #include <subdev/vm.h>
 
 #include <engine/dmaobj.h>
-#include <engine/fifo.h>
+
+#include "nve0.h"
 
 #define _(a,b) { (a), ((1ULL << (a)) | (b)) }
 static const struct {
@@ -56,8 +58,8 @@ static const struct {
 #define FIFO_ENGINE_NR ARRAY_SIZE(fifo_engine)
 
 struct nve0_fifo_engn {
- struct nouveau_gpuobj *playlist[2];
- int cur_playlist;
+ struct nouveau_gpuobj *runlist[2];
+ int cur_runlist;
 };
 
 struct nve0_fifo_priv {
@@ -86,7 +88,7 @@ struct nve0_fifo_chan {
  ******************************************************************************/
 
 static void
-nve0_fifo_playlist_update(struct nve0_fifo_priv *priv, u32 engine)
+nve0_fifo_runlist_update(struct nve0_fifo_priv *priv, u32 engine)
 {
  struct nouveau_bar *bar = nouveau_bar(priv);
  struct nve0_fifo_engn *engn = &priv->engine[engine];
@@ -95,8 +97,8 @@ nve0_fifo_playlist_update(struct nve0_fifo_priv *priv, u32 engine)
  int i, p;
 
  mutex_lock(&nv_subdev(priv)->mutex);
- cur = engn->playlist[engn->cur_playlist];
- engn->cur_playlist = !engn->cur_playlist;
+ cur = engn->runlist[engn->cur_runlist];
+ engn->cur_runlist = !engn->cur_runlist;
 
  for (i = 0, p = 0; i < priv->base.max; i++) {
   u32 ctrl = nv_rd32(priv, 0x800004 + (i * 8)) & 0x001f0001;
@@ -110,8 +112,8 @@ nve0_fifo_playlist_update(struct nve0_fifo_priv *priv, u32 engine)
 
  nv_wr32(priv, 0x002270, cur->addr >> 12);
  nv_wr32(priv, 0x002274, (engine << 20) | (p >> 3));
- if (!nv_wait(priv, 0x002284 + (engine * 4), 0x00100000, 0x00000000))
-  nv_error(priv, "playlist %d update timeout\n", engine);
+ if (!nv_wait(priv, 0x002284 + (engine * 8), 0x00100000, 0x00000000))
+  nv_error(priv, "runlist %d update timeout\n", engine);
  mutex_unlock(&nv_subdev(priv)->mutex);
 }
 
@@ -278,7 +280,7 @@ nve0_fifo_chan_init(struct nouveau_object *object)
  nv_mask(priv, 0x800004 + (chid * 8), 0x000f0000, chan->engine << 16);
  nv_wr32(priv, 0x800000 + (chid * 8), 0x80000000 | base->addr >> 12);
  nv_mask(priv, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
- nve0_fifo_playlist_update(priv, chan->engine);
+ nve0_fifo_runlist_update(priv, chan->engine);
  nv_mask(priv, 0x800004 + (chid * 8), 0x00000400, 0x00000400);
  return 0;
 }
@@ -291,7 +293,7 @@ nve0_fifo_chan_fini(struct nouveau_object *object, bool suspend)
  u32 chid = chan->base.chid;
 
  nv_mask(priv, 0x800004 + (chid * 8), 0x00000800, 0x00000800);
- nve0_fifo_playlist_update(priv, chan->engine);
+ nve0_fifo_runlist_update(priv, chan->engine);
  nv_wr32(priv, 0x800000 + (chid * 8), 0x00000000);
 
  return nouveau_fifo_channel_fini(&chan->base, suspend);
@@ -375,54 +377,189 @@ nve0_fifo_cclass = {
  * PFIFO engine
  ******************************************************************************/
 
-static const struct nouveau_enum nve0_fifo_fault_unit[] = {
+static const struct nouveau_enum nve0_fifo_sched_reason[] = {
+ { 0x0a, "CTXSW_TIMEOUT" },
+ {}
+};
+
+static const struct nouveau_enum nve0_fifo_fault_engine[] = {
+ { 0x00, "GR", NULL, NVDEV_ENGINE_GR },
+ { 0x03, "IFB" },
+ { 0x04, "BAR1", NULL, NVDEV_SUBDEV_BAR },
+ { 0x05, "BAR3", NULL, NVDEV_SUBDEV_INSTMEM },
+ { 0x07, "PBDMA0", NULL, NVDEV_ENGINE_FIFO },
+ { 0x08, "PBDMA1", NULL, NVDEV_ENGINE_FIFO },
+ { 0x09, "PBDMA2", NULL, NVDEV_ENGINE_FIFO },
+ { 0x10, "MSVLD", NULL, NVDEV_ENGINE_BSP },
+ { 0x11, "MSPPP", NULL, NVDEV_ENGINE_PPP },
+ { 0x13, "PERF" },
+ { 0x14, "MSPDEC", NULL, NVDEV_ENGINE_VP },
+ { 0x15, "CE0", NULL, NVDEV_ENGINE_COPY0 },
+ { 0x16, "CE1", NULL, NVDEV_ENGINE_COPY1 },
+ { 0x17, "PMU" },
+ { 0x19, "MSENC", NULL, NVDEV_ENGINE_VENC },
+ { 0x1b, "CE2", NULL, NVDEV_ENGINE_COPY2 },
  {}
 };
 
 static const struct nouveau_enum nve0_fifo_fault_reason[] = {
- { 0x00, "PT_NOT_PRESENT" },
- { 0x01, "PT_TOO_SHORT" },
- { 0x02, "PAGE_NOT_PRESENT" },
- { 0x03, "VM_LIMIT_EXCEEDED" },
- { 0x04, "NO_CHANNEL" },
- { 0x05, "PAGE_SYSTEM_ONLY" },
- { 0x06, "PAGE_READ_ONLY" },
- { 0x0a, "COMPRESSED_SYSRAM" },
- { 0x0c, "INVALID_STORAGE_TYPE" },
+ { 0x00, "PDE" },
+ { 0x01, "PDE_SIZE" },
+ { 0x02, "PTE" },
+ { 0x03, "VA_LIMIT_VIOLATION" },
+ { 0x04, "UNBOUND_INST_BLOCK" },
+ { 0x05, "PRIV_VIOLATION" },
+ { 0x06, "RO_VIOLATION" },
+ { 0x07, "WO_VIOLATION" },
+ { 0x08, "PITCH_MASK_VIOLATION" },
+ { 0x09, "WORK_CREATION" },
+ { 0x0a, "UNSUPPORTED_APERTURE" },
+ { 0x0b, "COMPRESSION_FAILURE" },
+ { 0x0c, "UNSUPPORTED_KIND" },
+ { 0x0d, "REGION_VIOLATION" },
+ { 0x0e, "BOTH_PTES_VALID" },
+ { 0x0f, "INFO_TYPE_POISONED" },
  {}
 };
 
 static const struct nouveau_enum nve0_fifo_fault_hubclient[] = {
+ { 0x00, "VIP" },
+ { 0x01, "CE0" },
+ { 0x02, "CE1" },
+ { 0x03, "DNISO" },
+ { 0x04, "FE" },
+ { 0x05, "FECS" },
+ { 0x06, "HOST" },
+ { 0x07, "HOST_CPU" },
+ { 0x08, "HOST_CPU_NB" },
+ { 0x09, "ISO" },
+ { 0x0a, "MMU" },
+ { 0x0b, "MSPDEC" },
+ { 0x0c, "MSPPP" },
+ { 0x0d, "MSVLD" },
+ { 0x0e, "NISO" },
+ { 0x0f, "P2P" },
+ { 0x10, "PD" },
+ { 0x11, "PERF" },
+ { 0x12, "PMU" },
+ { 0x13, "RASTERTWOD" },
+ { 0x14, "SCC" },
+ { 0x15, "SCC_NB" },
+ { 0x16, "SEC" },
+ { 0x17, "SSYNC" },
+ { 0x18, "GR_COPY" },
+ { 0x19, "CE2" },
+ { 0x1a, "XV" },
+ { 0x1b, "MMU_NB" },
+ { 0x1c, "MSENC" },
+ { 0x1d, "DFALCON" },
+ { 0x1e, "SKED" },
+ { 0x1f, "AFALCON" },
  {}
 };
 
 static const struct nouveau_enum nve0_fifo_fault_gpcclient[] = {
+ { 0x00, "L1_0" }, { 0x01, "T1_0" }, { 0x02, "PE_0" },
+ { 0x03, "L1_1" }, { 0x04, "T1_1" }, { 0x05, "PE_1" },
+ { 0x06, "L1_2" }, { 0x07, "T1_2" }, { 0x08, "PE_2" },
+ { 0x09, "L1_3" }, { 0x0a, "T1_3" }, { 0x0b, "PE_3" },
+ { 0x0c, "RAST" },
+ { 0x0d, "GCC" },
+ { 0x0e, "GPCCS" },
+ { 0x0f, "PROP_0" },
+ { 0x10, "PROP_1" },
+ { 0x11, "PROP_2" },
+ { 0x12, "PROP_3" },
+ { 0x13, "L1_4" }, { 0x14, "T1_4" }, { 0x15, "PE_4" },
+ { 0x16, "L1_5" }, { 0x17, "T1_5" }, { 0x18, "PE_5" },
+ { 0x19, "L1_6" }, { 0x1a, "T1_6" }, { 0x1b, "PE_6" },
+ { 0x1c, "L1_7" }, { 0x1d, "T1_7" }, { 0x1e, "PE_7" },
+ { 0x1f, "GPM" },
+ { 0x20, "LTP_UTLB_0" },
+ { 0x21, "LTP_UTLB_1" },
+ { 0x22, "LTP_UTLB_2" },
+ { 0x23, "LTP_UTLB_3" },
+ { 0x24, "GPC_RGG_UTLB" },
  {}
 };
 
-static const struct nouveau_bitfield nve0_fifo_subfifo_intr[] = {
- { 0x00200000, "ILLEGAL_MTHD" },
- { 0x00800000, "EMPTY_SUBC" },
+static const struct nouveau_bitfield nve0_fifo_pbdma_intr[] = {
+ { 0x00000001, "MEMREQ" },
+ { 0x00000002, "MEMACK_TIMEOUT" },
+ { 0x00000004, "MEMACK_EXTRA" },
+ { 0x00000008, "MEMDAT_TIMEOUT" },
+ { 0x00000010, "MEMDAT_EXTRA" },
+ { 0x00000020, "MEMFLUSH" },
+ { 0x00000040, "MEMOP" },
+ { 0x00000080, "LBCONNECT" },
+ { 0x00000100, "LBREQ" },
+ { 0x00000200, "LBACK_TIMEOUT" },
+ { 0x00000400, "LBACK_EXTRA" },
+ { 0x00000800, "LBDAT_TIMEOUT" },
+ { 0x00001000, "LBDAT_EXTRA" },
+ { 0x00002000, "GPFIFO" },
+ { 0x00004000, "GPPTR" },
+ { 0x00008000, "GPENTRY" },
+ { 0x00010000, "GPCRC" },
+ { 0x00020000, "PBPTR" },
+ { 0x00040000, "PBENTRY" },
+ { 0x00080000, "PBCRC" },
+ { 0x00100000, "XBARCONNECT" },
+ { 0x00200000, "METHOD" },
+ { 0x00400000, "METHODCRC" },
+ { 0x00800000, "DEVICE" },
+ { 0x02000000, "SEMAPHORE" },
+ { 0x04000000, "ACQUIRE" },
+ { 0x08000000, "PRI" },
+ { 0x20000000, "NO_CTXSW_SEG" },
+ { 0x40000000, "PBSEG" },
+ { 0x80000000, "SIGNATURE" },
  {}
 };
 
 static void
-nve0_fifo_isr_vm_fault(struct nve0_fifo_priv *priv, int unit)
+nve0_fifo_intr_sched(struct nve0_fifo_priv *priv)
+{
+ u32 intr = nv_rd32(priv, 0x00254c);
+ u32 code = intr & 0x000000ff;
+ nv_error(priv, "SCHED_ERROR [");
+ nouveau_enum_print(nve0_fifo_sched_reason, code);
+ pr_cont("]\n");
+}
+
+static void
+nve0_fifo_intr_chsw(struct nve0_fifo_priv *priv)
+{
+ u32 stat = nv_rd32(priv, 0x00256c);
+ nv_error(priv, "CHSW_ERROR 0x%08x\n", stat);
+ nv_wr32(priv, 0x00256c, stat);
+}
+
+static void
+nve0_fifo_intr_dropped_fault(struct nve0_fifo_priv *priv)
+{
+ u32 stat = nv_rd32(priv, 0x00259c);
+ nv_error(priv, "DROPPED_MMU_FAULT 0x%08x\n", stat);
+}
+
+static void
+nve0_fifo_intr_fault(struct nve0_fifo_priv *priv, int unit)
 {
  u32 inst = nv_rd32(priv, 0x2800 + (unit * 0x10));
  u32 valo = nv_rd32(priv, 0x2804 + (unit * 0x10));
  u32 vahi = nv_rd32(priv, 0x2808 + (unit * 0x10));
  u32 stat = nv_rd32(priv, 0x280c + (unit * 0x10));
  u32 client = (stat & 0x00001f00) >> 8;
- const struct nouveau_enum *en;
- struct nouveau_engine *engine;
+ struct nouveau_engine *engine = NULL;
  struct nouveau_object *engctx = NULL;
+ const struct nouveau_enum *en;
+ const char *name = "unknown";
 
  nv_error(priv, "PFIFO: %s fault at 0x%010llx [", (stat & 0x00000080) ?
          "write" : "read", (u64)vahi << 32 | valo);
  nouveau_enum_print(nve0_fifo_fault_reason, stat & 0x0000000f);
  pr_cont("] from ");
- en = nouveau_enum_print(nve0_fifo_fault_unit, unit);
+ en = nouveau_enum_print(nve0_fifo_fault_engine, unit);
  if (stat & 0x00000040) {
   pr_cont("/");
   nouveau_enum_print(nve0_fifo_fault_hubclient, client);
@@ -432,14 +569,22 @@ nve0_fifo_isr_vm_fault(struct nve0_fifo_priv *priv, int unit)
  }
 
  if (en && en->data2) {
-  engine = nouveau_engine(priv, en->data2);
-  if (engine)
-   engctx = nouveau_engctx_get(engine, inst);
-
+  if (en->data2 == NVDEV_SUBDEV_BAR) {
+   nv_mask(priv, 0x001704, 0x00000000, 0x00000000);
+   name = "BAR1";
+  } else
+  if (en->data2 == NVDEV_SUBDEV_INSTMEM) {
+   nv_mask(priv, 0x001714, 0x00000000, 0x00000000);
+   name = "BAR3";
+  } else {
+   engine = nouveau_engine(priv, en->data2);
+   if (engine) {
+    engctx = nouveau_engctx_get(engine, inst);
+    name   = nouveau_client_name(engctx);
+   }
+  }
  }
-
- pr_cont(" on channel 0x%010llx [%s]\n", (u64)inst << 12,
-   nouveau_client_name(engctx));
+ pr_cont(" on channel 0x%010llx [%s]\n", (u64)inst << 12, name);
 
  nouveau_engctx_put(engctx);
 }
@@ -471,7 +616,7 @@ out:
 }
 
 static void
-nve0_fifo_isr_subfifo_intr(struct nve0_fifo_priv *priv, int unit)
+nve0_fifo_intr_pbdma(struct nve0_fifo_priv *priv, int unit)
 {
  u32 stat = nv_rd32(priv, 0x040108 + (unit * 0x2000));
  u32 addr = nv_rd32(priv, 0x0400c0 + (unit * 0x2000));
@@ -487,11 +632,11 @@ nve0_fifo_isr_subfifo_intr(struct nve0_fifo_priv *priv, int unit)
  }
 
  if (show) {
-  nv_error(priv, "SUBFIFO%d:", unit);
-  nouveau_bitfield_print(nve0_fifo_subfifo_intr, show);
+  nv_error(priv, "PBDMA%d:", unit);
+  nouveau_bitfield_print(nve0_fifo_pbdma_intr, show);
   pr_cont("\n");
   nv_error(priv,
-    "SUBFIFO%d: ch %d [%s] subc %d mthd 0x%04x data 0x%08x\n",
+    "PBDMA%d: ch %d [%s] subc %d mthd 0x%04x data 0x%08x\n",
     unit, chid,
     nouveau_client_name_for_fifo_chid(&priv->base, chid),
     subc, mthd, data);
@@ -508,19 +653,56 @@ nve0_fifo_intr(struct nouveau_subdev *subdev)
  u32 mask = nv_rd32(priv, 0x002140);
  u32 stat = nv_rd32(priv, 0x002100) & mask;
 
+ if (stat & 0x00000001) {
+  u32 stat = nv_rd32(priv, 0x00252c);
+  nv_error(priv, "BIND_ERROR 0x%08x\n", stat);
+  nv_wr32(priv, 0x002100, 0x00000001);
+  stat &= ~0x00000001;
+ }
+
+ if (stat & 0x00000010) {
+  nv_error(priv, "PIO_ERROR\n");
+  nv_wr32(priv, 0x002100, 0x00000010);
+  stat &= ~0x00000010;
+ }
+
  if (stat & 0x00000100) {
-  nv_warn(priv, "unknown status 0x00000100\n");
+  nve0_fifo_intr_sched(priv);
   nv_wr32(priv, 0x002100, 0x00000100);
   stat &= ~0x00000100;
  }
 
+ if (stat & 0x00010000) {
+  nve0_fifo_intr_chsw(priv);
+  nv_wr32(priv, 0x002100, 0x00010000);
+  stat &= ~0x00010000;
+ }
+
+ if (stat & 0x00800000) {
+  nv_error(priv, "FB_FLUSH_TIMEOUT\n");
+  nv_wr32(priv, 0x002100, 0x00800000);
+  stat &= ~0x00800000;
+ }
+
+ if (stat & 0x01000000) {
+  nv_error(priv, "LB_ERROR\n");
+  nv_wr32(priv, 0x002100, 0x01000000);
+  stat &= ~0x01000000;
+ }
+
+ if (stat & 0x08000000) {
+  nve0_fifo_intr_dropped_fault(priv);
+  nv_wr32(priv, 0x002100, 0x08000000);
+  stat &= ~0x08000000;
+ }
+
  if (stat & 0x10000000) {
   u32 units = nv_rd32(priv, 0x00259c);
   u32 u = units;
 
   while (u) {
    int i = ffs(u) - 1;
-   nve0_fifo_isr_vm_fault(priv, i);
+   nve0_fifo_intr_fault(priv, i);
    u &= ~(1 << i);
   }
 
@@ -529,22 +711,28 @@ nve0_fifo_intr(struct nouveau_subdev *subdev)
  }
 
  if (stat & 0x20000000) {
-  u32 units = nv_rd32(priv, 0x0025a0);
-  u32 u = units;
+  u32 mask = nv_rd32(priv, 0x0025a0);
+  u32 temp = mask;
 
-  while (u) {
-   int i = ffs(u) - 1;
-   nve0_fifo_isr_subfifo_intr(priv, i);
-   u &= ~(1 << i);
+  while (temp) {
+   u32 unit = ffs(temp) - 1;
+   nve0_fifo_intr_pbdma(priv, unit);
+   temp &= ~(1 << unit);
   }
 
-  nv_wr32(priv, 0x0025a0, units);
+  nv_wr32(priv, 0x0025a0, mask);
   stat &= ~0x20000000;
  }
 
  if (stat & 0x40000000) {
-  nv_warn(priv, "unknown status 0x40000000\n");
-  nv_mask(priv, 0x002a00, 0x00000000, 0x00000000);
+  u32 mask = nv_mask(priv, 0x002a00, 0x00000000, 0x00000000);
+
+  while (mask) {
+   u32 engn = ffs(mask) - 1;
+   /* runlist event, not currently used */
+   mask &= ~(1 << engn);
+  }
+
   stat &= ~0x40000000;
  }
 
@@ -575,53 +763,52 @@ nve0_fifo_uevent_disable(struct nouveau_event *event, int index)
  nv_mask(priv, 0x002140, 0x80000000, 0x00000000);
 }
 
-static int
-nve0_fifo_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
-        struct nouveau_oclass *oclass, void *data, u32 size,
-        struct nouveau_object **pobject)
+int
+nve0_fifo_fini(struct nouveau_object *object, bool suspend)
 {
- struct nve0_fifo_priv *priv;
- int ret, i;
+ struct nve0_fifo_priv *priv = (void *)object;
+ int ret;
 
- ret = nouveau_fifo_create(parent, engine, oclass, 0, 4095, &priv);
- *pobject = nv_object(priv);
+ ret = nouveau_fifo_fini(&priv->base, suspend);
  if (ret)
   return ret;
 
- for (i = 0; i < FIFO_ENGINE_NR; i++) {
-  ret = nouveau_gpuobj_new(nv_object(priv), NULL, 0x8000, 0x1000,
-      0, &priv->engine[i].playlist[0]);
-  if (ret)
-   return ret;
+ /* allow mmu fault interrupts, even when we're not using fifo */
+ nv_mask(priv, 0x002140, 0x10000000, 0x10000000);
+ return 0;
+}
 
-  ret = nouveau_gpuobj_new(nv_object(priv), NULL, 0x8000, 0x1000,
-      0, &priv->engine[i].playlist[1]);
-  if (ret)
-   return ret;
- }
+int
+nve0_fifo_init(struct nouveau_object *object)
+{
+ struct nve0_fifo_priv *priv = (void *)object;
+ int ret, i;
 
- ret = nouveau_gpuobj_new(nv_object(priv), NULL, 4096 * 0x200, 0x1000,
-     NVOBJ_FLAG_ZERO_ALLOC, &priv->user.mem);
+ ret = nouveau_fifo_init(&priv->base);
  if (ret)
   return ret;
 
- ret = nouveau_gpuobj_map(priv->user.mem, NV_MEM_ACCESS_RW,
-    &priv->user.bar);
- if (ret)
-  return ret;
+ /* enable all available PBDMA units */
+ nv_wr32(priv, 0x000204, 0xffffffff);
+ priv->spoon_nr = hweight32(nv_rd32(priv, 0x000204));
+ nv_debug(priv, "%d PBDMA unit(s)\n", priv->spoon_nr);
 
- priv->base.uevent->enable = nve0_fifo_uevent_enable;
- priv->base.uevent->disable = nve0_fifo_uevent_disable;
- priv->base.uevent->priv = priv;
+ /* PBDMA[n] */
+ for (i = 0; i < priv->spoon_nr; i++) {
+  nv_mask(priv, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
+  nv_wr32(priv, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
+  nv_wr32(priv, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
+ }
 
- nv_subdev(priv)->unit = 0x00000100;
- nv_subdev(priv)->intr = nve0_fifo_intr;
- nv_engine(priv)->cclass = &nve0_fifo_cclass;
- nv_engine(priv)->sclass = nve0_fifo_sclass;
+ nv_wr32(priv, 0x002254, 0x10000000 | priv->user.bar.offset >> 12);
+
+ nv_wr32(priv, 0x002a00, 0xffffffff);
+ nv_wr32(priv, 0x002100, 0xffffffff);
+ nv_wr32(priv, 0x002140, 0x3fffffff);
  return 0;
 }
 
-static void
+void
 nve0_fifo_dtor(struct nouveau_object *object)
 {
  struct nve0_fifo_priv *priv = (void *)object;
@@ -631,50 +818,69 @@ nve0_fifo_dtor(struct nouveau_object *object)
  nouveau_gpuobj_ref(NULL, &priv->user.mem);
 
  for (i = 0; i < FIFO_ENGINE_NR; i++) {
-  nouveau_gpuobj_ref(NULL, &priv->engine[i].playlist[1]);
-  nouveau_gpuobj_ref(NULL, &priv->engine[i].playlist[0]);
+  nouveau_gpuobj_ref(NULL, &priv->engine[i].runlist[1]);
+  nouveau_gpuobj_ref(NULL, &priv->engine[i].runlist[0]);
  }
 
  nouveau_fifo_destroy(&priv->base);
 }
 
-static int
-nve0_fifo_init(struct nouveau_object *object)
+int
+nve0_fifo_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
+        struct nouveau_oclass *oclass, void *data, u32 size,
+        struct nouveau_object **pobject)
 {
- struct nve0_fifo_priv *priv = (void *)object;
+ struct nve0_fifo_impl *impl = (void *)oclass;
+ struct nve0_fifo_priv *priv;
  int ret, i;
 
- ret = nouveau_fifo_init(&priv->base);
+ ret = nouveau_fifo_create(parent, engine, oclass, 0,
+      impl->channels - 1, &priv);
+ *pobject = nv_object(priv);
  if (ret)
   return ret;
 
- /* enable all available PSUBFIFOs */
- nv_wr32(priv, 0x000204, 0xffffffff);
- priv->spoon_nr = hweight32(nv_rd32(priv, 0x000204));
- nv_debug(priv, "%d subfifo(s)\n", priv->spoon_nr);
+ for (i = 0; i < FIFO_ENGINE_NR; i++) {
+  ret = nouveau_gpuobj_new(nv_object(priv), NULL, 0x8000, 0x1000,
+      0, &priv->engine[i].runlist[0]);
+  if (ret)
+   return ret;
 
- /* PSUBFIFO[n] */
- for (i = 0; i < priv->spoon_nr; i++) {
-  nv_mask(priv, 0x04013c + (i * 0x2000), 0x10000100, 0x00000000);
-  nv_wr32(priv, 0x040108 + (i * 0x2000), 0xffffffff); /* INTR */
-  nv_wr32(priv, 0x04010c + (i * 0x2000), 0xfffffeff); /* INTREN */
+  ret = nouveau_gpuobj_new(nv_object(priv), NULL, 0x8000, 0x1000,
+      0, &priv->engine[i].runlist[1]);
+  if (ret)
+   return ret;
  }
 
- nv_wr32(priv, 0x002254, 0x10000000 | priv->user.bar.offset >> 12);
+ ret = nouveau_gpuobj_new(nv_object(priv), NULL, 4096 * 0x200, 0x1000,
+     NVOBJ_FLAG_ZERO_ALLOC, &priv->user.mem);
+ if (ret)
+  return ret;
 
- nv_wr32(priv, 0x002a00, 0xffffffff);
- nv_wr32(priv, 0x002100, 0xffffffff);
- nv_wr32(priv, 0x002140, 0x3fffffff);
+ ret = nouveau_gpuobj_map(priv->user.mem, NV_MEM_ACCESS_RW,
+    &priv->user.bar);
+ if (ret)
+  return ret;
+
+ priv->base.uevent->enable = nve0_fifo_uevent_enable;
+ priv->base.uevent->disable = nve0_fifo_uevent_disable;
+ priv->base.uevent->priv = priv;
+
+ nv_subdev(priv)->unit = 0x00000100;
+ nv_subdev(priv)->intr = nve0_fifo_intr;
+ nv_engine(priv)->cclass = &nve0_fifo_cclass;
+ nv_engine(priv)->sclass = nve0_fifo_sclass;
  return 0;
 }
 
 struct nouveau_oclass *
-nve0_fifo_oclass = &(struct nouveau_oclass) {
- .handle = NV_ENGINE(FIFO, 0xe0),
- .ofuncs = &(struct nouveau_ofuncs) {
+nve0_fifo_oclass = &(struct nve0_fifo_impl) {
+ .base.handle = NV_ENGINE(FIFO, 0xe0),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
   .ctor = nve0_fifo_ctor,
   .dtor = nve0_fifo_dtor,
   .init = nve0_fifo_init,
-  .fini = _nouveau_fifo_fini,
+  .fini = nve0_fifo_fini,
  },
-};
+ .channels = 4096,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/engine/fifo/nve0.h b/drivers/gpu/drm/nouveau/core/engine/fifo/nve0.h
new file mode 100644
index 0000000..014344e
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/engine/fifo/nve0.h
@@ -0,0 +1,17 @@
+#ifndef __NVKM_FIFO_NVE0_H__
+#define __NVKM_FIFO_NVE0_H__
+
+#include <engine/fifo.h>
+
+int  nve0_fifo_ctor(struct nouveau_object *, struct nouveau_object *,
+      struct nouveau_oclass *, void *, u32,
+      struct nouveau_object **);
+void nve0_fifo_dtor(struct nouveau_object *);
+int  nve0_fifo_init(struct nouveau_object *);
+
+struct nve0_fifo_impl {
+ struct nouveau_oclass base;
+ u32 channels;
+};
+
+#endif
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/ctxnv108.c b/drivers/gpu/drm/nouveau/core/engine/graph/ctxnv108.c
new file mode 100644
index 0000000..a86bd33
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/ctxnv108.c
@@ -0,0 +1,1408 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs <bskeggs@redhat.com>
+ */
+
+#include "nvc0.h"
+
+static struct nvc0_graph_init
+nv108_grctx_init_icmd[] = {
+ { 0x001000,   1, 0x01, 0x00000004 },
+ { 0x000039,   3, 0x01, 0x00000000 },
+ { 0x0000a9,   1, 0x01, 0x0000ffff },
+ { 0x000038,   1, 0x01, 0x0fac6881 },
+ { 0x00003d,   1, 0x01, 0x00000001 },
+ { 0x0000e8,   8, 0x01, 0x00000400 },
+ { 0x000078,   8, 0x01, 0x00000300 },
+ { 0x000050,   1, 0x01, 0x00000011 },
+ { 0x000058,   8, 0x01, 0x00000008 },
+ { 0x000208,   8, 0x01, 0x00000001 },
+ { 0x000081,   1, 0x01, 0x00000001 },
+ { 0x000085,   1, 0x01, 0x00000004 },
+ { 0x000088,   1, 0x01, 0x00000400 },
+ { 0x000090,   1, 0x01, 0x00000300 },
+ { 0x000098,   1, 0x01, 0x00001001 },
+ { 0x0000e3,   1, 0x01, 0x00000001 },
+ { 0x0000da,   1, 0x01, 0x00000001 },
+ { 0x0000f8,   1, 0x01, 0x00000003 },
+ { 0x0000fa,   1, 0x01, 0x00000001 },
+ { 0x00009f,   4, 0x01, 0x0000ffff },
+ { 0x0000b1,   1, 0x01, 0x00000001 },
+ { 0x0000ad,   1, 0x01, 0x0000013e },
+ { 0x0000e1,   1, 0x01, 0x00000010 },
+ { 0x000290,  16, 0x01, 0x00000000 },
+ { 0x0003b0,  16, 0x01, 0x00000000 },
+ { 0x0002a0,  16, 0x01, 0x00000000 },
+ { 0x000420,  16, 0x01, 0x00000000 },
+ { 0x0002b0,  16, 0x01, 0x00000000 },
+ { 0x000430,  16, 0x01, 0x00000000 },
+ { 0x0002c0,  16, 0x01, 0x00000000 },
+ { 0x0004d0,  16, 0x01, 0x00000000 },
+ { 0x000720,  16, 0x01, 0x00000000 },
+ { 0x0008c0,  16, 0x01, 0x00000000 },
+ { 0x000890,  16, 0x01, 0x00000000 },
+ { 0x0008e0,  16, 0x01, 0x00000000 },
+ { 0x0008a0,  16, 0x01, 0x00000000 },
+ { 0x0008f0,  16, 0x01, 0x00000000 },
+ { 0x00094c,   1, 0x01, 0x000000ff },
+ { 0x00094d,   1, 0x01, 0xffffffff },
+ { 0x00094e,   1, 0x01, 0x00000002 },
+ { 0x0002ec,   1, 0x01, 0x00000001 },
+ { 0x0002f2,   2, 0x01, 0x00000001 },
+ { 0x0002f5,   1, 0x01, 0x00000001 },
+ { 0x0002f7,   1, 0x01, 0x00000001 },
+ { 0x000303,   1, 0x01, 0x00000001 },
+ { 0x0002e6,   1, 0x01, 0x00000001 },
+ { 0x000466,   1, 0x01, 0x00000052 },
+ { 0x000301,   1, 0x01, 0x3f800000 },
+ { 0x000304,   1, 0x01, 0x30201000 },
+ { 0x000305,   1, 0x01, 0x70605040 },
+ { 0x000306,   1, 0x01, 0xb8a89888 },
+ { 0x000307,   1, 0x01, 0xf8e8d8c8 },
+ { 0x00030a,   1, 0x01, 0x00ffff00 },
+ { 0x00030b,   1, 0x01, 0x0000001a },
+ { 0x00030c,   1, 0x01, 0x00000001 },
+ { 0x000318,   1, 0x01, 0x00000001 },
+ { 0x000340,   1, 0x01, 0x00000000 },
+ { 0x000375,   1, 0x01, 0x00000001 },
+ { 0x00037d,   1, 0x01, 0x00000006 },
+ { 0x0003a0,   1, 0x01, 0x00000002 },
+ { 0x0003aa,   1, 0x01, 0x00000001 },
+ { 0x0003a9,   1, 0x01, 0x00000001 },
+ { 0x000380,   1, 0x01, 0x00000001 },
+ { 0x000383,   1, 0x01, 0x00000011 },
+ { 0x000360,   1, 0x01, 0x00000040 },
+ { 0x000366,   2, 0x01, 0x00000000 },
+ { 0x000368,   1, 0x01, 0x00000fff },
+ { 0x000370,   2, 0x01, 0x00000000 },
+ { 0x000372,   1, 0x01, 0x000fffff },
+ { 0x00037a,   1, 0x01, 0x00000012 },
+ { 0x000619,   1, 0x01, 0x00000003 },
+ { 0x000811,   1, 0x01, 0x00000003 },
+ { 0x000812,   1, 0x01, 0x00000004 },
+ { 0x000813,   1, 0x01, 0x00000006 },
+ { 0x000814,   1, 0x01, 0x00000008 },
+ { 0x000815,   1, 0x01, 0x0000000b },
+ { 0x000800,   6, 0x01, 0x00000001 },
+ { 0x000632,   1, 0x01, 0x00000001 },
+ { 0x000633,   1, 0x01, 0x00000002 },
+ { 0x000634,   1, 0x01, 0x00000003 },
+ { 0x000635,   1, 0x01, 0x00000004 },
+ { 0x000654,   1, 0x01, 0x3f800000 },
+ { 0x000657,   1, 0x01, 0x3f800000 },
+ { 0x000655,   2, 0x01, 0x3f800000 },
+ { 0x0006cd,   1, 0x01, 0x3f800000 },
+ { 0x0007f5,   1, 0x01, 0x3f800000 },
+ { 0x0007dc,   1, 0x01, 0x39291909 },
+ { 0x0007dd,   1, 0x01, 0x79695949 },
+ { 0x0007de,   1, 0x01, 0xb9a99989 },
+ { 0x0007df,   1, 0x01, 0xf9e9d9c9 },
+ { 0x0007e8,   1, 0x01, 0x00003210 },
+ { 0x0007e9,   1, 0x01, 0x00007654 },
+ { 0x0007ea,   1, 0x01, 0x00000098 },
+ { 0x0007ec,   1, 0x01, 0x39291909 },
+ { 0x0007ed,   1, 0x01, 0x79695949 },
+ { 0x0007ee,   1, 0x01, 0xb9a99989 },
+ { 0x0007ef,   1, 0x01, 0xf9e9d9c9 },
+ { 0x0007f0,   1, 0x01, 0x00003210 },
+ { 0x0007f1,   1, 0x01, 0x00007654 },
+ { 0x0007f2,   1, 0x01, 0x00000098 },
+ { 0x0005a5,   1, 0x01, 0x00000001 },
+ { 0x000980, 128, 0x01, 0x00000000 },
+ { 0x000468,   1, 0x01, 0x00000004 },
+ { 0x00046c,   1, 0x01, 0x00000001 },
+ { 0x000470,  96, 0x01, 0x00000000 },
+ { 0x000510,  16, 0x01, 0x3f800000 },
+ { 0x000520,   1, 0x01, 0x000002b6 },
+ { 0x000529,   1, 0x01, 0x00000001 },
+ { 0x000530,  16, 0x01, 0xffff0000 },
+ { 0x000585,   1, 0x01, 0x0000003f },
+ { 0x000576,   1, 0x01, 0x00000003 },
+ { 0x00057b,   1, 0x01, 0x00000059 },
+ { 0x000586,   1, 0x01, 0x00000040 },
+ { 0x000582,   2, 0x01, 0x00000080 },
+ { 0x0005c2,   1, 0x01, 0x00000001 },
+ { 0x000638,   2, 0x01, 0x00000001 },
+ { 0x00063a,   1, 0x01, 0x00000002 },
+ { 0x00063b,   2, 0x01, 0x00000001 },
+ { 0x00063d,   1, 0x01, 0x00000002 },
+ { 0x00063e,   1, 0x01, 0x00000001 },
+ { 0x0008b8,   8, 0x01, 0x00000001 },
+ { 0x000900,   8, 0x01, 0x00000001 },
+ { 0x000908,   8, 0x01, 0x00000002 },
+ { 0x000910,  16, 0x01, 0x00000001 },
+ { 0x000920,   8, 0x01, 0x00000002 },
+ { 0x000928,   8, 0x01, 0x00000001 },
+ { 0x000662,   1, 0x01, 0x00000001 },
+ { 0x000648,   9, 0x01, 0x00000001 },
+ { 0x000658,   1, 0x01, 0x0000000f },
+ { 0x0007ff,   1, 0x01, 0x0000000a },
+ { 0x00066a,   1, 0x01, 0x40000000 },
+ { 0x00066b,   1, 0x01, 0x10000000 },
+ { 0x00066c,   2, 0x01, 0xffff0000 },
+ { 0x0007af,   2, 0x01, 0x00000008 },
+ { 0x0007f6,   1, 0x01, 0x00000001 },
+ { 0x00080b,   1, 0x01, 0x00000002 },
+ { 0x0006b2,   1, 0x01, 0x00000055 },
+ { 0x0007ad,   1, 0x01, 0x00000003 },
+ { 0x000937,   1, 0x01, 0x00000001 },
+ { 0x000971,   1, 0x01, 0x00000008 },
+ { 0x000972,   1, 0x01, 0x00000040 },
+ { 0x000973,   1, 0x01, 0x0000012c },
+ { 0x00097c,   1, 0x01, 0x00000040 },
+ { 0x000979,   1, 0x01, 0x00000003 },
+ { 0x000975,   1, 0x01, 0x00000020 },
+ { 0x000976,   1, 0x01, 0x00000001 },
+ { 0x000977,   1, 0x01, 0x00000020 },
+ { 0x000978,   1, 0x01, 0x00000001 },
+ { 0x000957,   1, 0x01, 0x00000003 },
+ { 0x00095e,   1, 0x01, 0x20164010 },
+ { 0x00095f,   1, 0x01, 0x00000020 },
+ { 0x000a0d,   1, 0x01, 0x00000006 },
+ { 0x00097d,   1, 0x01, 0x00000020 },
+ { 0x000683,   1, 0x01, 0x00000006 },
+ { 0x000685,   1, 0x01, 0x003fffff },
+ { 0x000687,   1, 0x01, 0x003fffff },
+ { 0x0006a0,   1, 0x01, 0x00000005 },
+ { 0x000840,   1, 0x01, 0x00400008 },
+ { 0x000841,   1, 0x01, 0x08000080 },
+ { 0x000842,   1, 0x01, 0x00400008 },
+ { 0x000843,   1, 0x01, 0x08000080 },
+ { 0x0006aa,   1, 0x01, 0x00000001 },
+ { 0x0006ab,   1, 0x01, 0x00000002 },
+ { 0x0006ac,   1, 0x01, 0x00000080 },
+ { 0x0006ad,   2, 0x01, 0x00000100 },
+ { 0x0006b1,   1, 0x01, 0x00000011 },
+ { 0x0006bb,   1, 0x01, 0x000000cf },
+ { 0x0006ce,   1, 0x01, 0x2a712488 },
+ { 0x000739,   1, 0x01, 0x4085c000 },
+ { 0x00073a,   1, 0x01, 0x00000080 },
+ { 0x000786,   1, 0x01, 0x80000100 },
+ { 0x00073c,   1, 0x01, 0x00010100 },
+ { 0x00073d,   1, 0x01, 0x02800000 },
+ { 0x000787,   1, 0x01, 0x000000cf },
+ { 0x00078c,   1, 0x01, 0x00000008 },
+ { 0x000792,   1, 0x01, 0x00000001 },
+ { 0x000794,   3, 0x01, 0x00000001 },
+ { 0x000797,   1, 0x01, 0x000000cf },
+ { 0x000836,   1, 0x01, 0x00000001 },
+ { 0x00079a,   1, 0x01, 0x00000002 },
+ { 0x000833,   1, 0x01, 0x04444480 },
+ { 0x0007a1,   1, 0x01, 0x00000001 },
+ { 0x0007a3,   3, 0x01, 0x00000001 },
+ { 0x000831,   1, 0x01, 0x00000004 },
+ { 0x000b07,   1, 0x01, 0x00000002 },
+ { 0x000b08,   2, 0x01, 0x00000100 },
+ { 0x000b0a,   1, 0x01, 0x00000001 },
+ { 0x000a04,   1, 0x01, 0x000000ff },
+ { 0x000a0b,   1, 0x01, 0x00000040 },
+ { 0x00097f,   1, 0x01, 0x00000100 },
+ { 0x000a02,   1, 0x01, 0x00000001 },
+ { 0x000809,   1, 0x01, 0x00000007 },
+ { 0x00c221,   1, 0x01, 0x00000040 },
+ { 0x00c1b0,   8, 0x01, 0x0000000f },
+ { 0x00c1b8,   1, 0x01, 0x0fac6881 },
+ { 0x00c1b9,   1, 0x01, 0x00fac688 },
+ { 0x00c401,   1, 0x01, 0x00000001 },
+ { 0x00c402,   1, 0x01, 0x00010001 },
+ { 0x00c403,   2, 0x01, 0x00000001 },
+ { 0x00c40e,   1, 0x01, 0x00000020 },
+ { 0x00c500,   1, 0x01, 0x00000003 },
+ { 0x01e100,   1, 0x01, 0x00000001 },
+ { 0x001000,   1, 0x01, 0x00000002 },
+ { 0x0006aa,   1, 0x01, 0x00000001 },
+ { 0x0006ad,   2, 0x01, 0x00000100 },
+ { 0x0006b1,   1, 0x01, 0x00000011 },
+ { 0x00078c,   1, 0x01, 0x00000008 },
+ { 0x000792,   1, 0x01, 0x00000001 },
+ { 0x000794,   3, 0x01, 0x00000001 },
+ { 0x000797,   1, 0x01, 0x000000cf },
+ { 0x00079a,   1, 0x01, 0x00000002 },
+ { 0x0007a1,   1, 0x01, 0x00000001 },
+ { 0x0007a3,   3, 0x01, 0x00000001 },
+ { 0x000831,   1, 0x01, 0x00000004 },
+ { 0x01e100,   1, 0x01, 0x00000001 },
+ { 0x001000,   1, 0x01, 0x00000008 },
+ { 0x000039,   3, 0x01, 0x00000000 },
+ { 0x000380,   1, 0x01, 0x00000001 },
+ { 0x000366,   2, 0x01, 0x00000000 },
+ { 0x000368,   1, 0x01, 0x00000fff },
+ { 0x000370,   2, 0x01, 0x00000000 },
+ { 0x000372,   1, 0x01, 0x000fffff },
+ { 0x000813,   1, 0x01, 0x00000006 },
+ { 0x000814,   1, 0x01, 0x00000008 },
+ { 0x000957,   1, 0x01, 0x00000003 },
+ { 0x000b07,   1, 0x01, 0x00000002 },
+ { 0x000b08,   2, 0x01, 0x00000100 },
+ { 0x000b0a,   1, 0x01, 0x00000001 },
+ { 0x000a04,   1, 0x01, 0x000000ff },
+ { 0x000a0b,   1, 0x01, 0x00000040 },
+ { 0x00097f,   1, 0x01, 0x00000100 },
+ { 0x000a02,   1, 0x01, 0x00000001 },
+ { 0x000809,   1, 0x01, 0x00000007 },
+ { 0x00c221,   1, 0x01, 0x00000040 },
+ { 0x00c401,   1, 0x01, 0x00000001 },
+ { 0x00c402,   1, 0x01, 0x00010001 },
+ { 0x00c403,   2, 0x01, 0x00000001 },
+ { 0x00c40e,   1, 0x01, 0x00000020 },
+ { 0x00c500,   1, 0x01, 0x00000003 },
+ { 0x01e100,   1, 0x01, 0x00000001 },
+ { 0x001000,   1, 0x01, 0x00000001 },
+ { 0x000b07,   1, 0x01, 0x00000002 },
+ { 0x000b08,   2, 0x01, 0x00000100 },
+ { 0x000b0a,   1, 0x01, 0x00000001 },
+ { 0x01e100,   1, 0x01, 0x00000001 },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_grctx_init_a197[] = {
+ { 0x000800,   1, 0x04, 0x00000000 },
+ { 0x000840,   1, 0x04, 0x00000000 },
+ { 0x000880,   1, 0x04, 0x00000000 },
+ { 0x0008c0,   1, 0x04, 0x00000000 },
+ { 0x000900,   1, 0x04, 0x00000000 },
+ { 0x000940,   1, 0x04, 0x00000000 },
+ { 0x000980,   1, 0x04, 0x00000000 },
+ { 0x0009c0,   1, 0x04, 0x00000000 },
+ { 0x000804,   1, 0x04, 0x00000000 },
+ { 0x000844,   1, 0x04, 0x00000000 },
+ { 0x000884,   1, 0x04, 0x00000000 },
+ { 0x0008c4,   1, 0x04, 0x00000000 },
+ { 0x000904,   1, 0x04, 0x00000000 },
+ { 0x000944,   1, 0x04, 0x00000000 },
+ { 0x000984,   1, 0x04, 0x00000000 },
+ { 0x0009c4,   1, 0x04, 0x00000000 },
+ { 0x000808,   1, 0x04, 0x00000400 },
+ { 0x000848,   1, 0x04, 0x00000400 },
+ { 0x000888,   1, 0x04, 0x00000400 },
+ { 0x0008c8,   1, 0x04, 0x00000400 },
+ { 0x000908,   1, 0x04, 0x00000400 },
+ { 0x000948,   1, 0x04, 0x00000400 },
+ { 0x000988,   1, 0x04, 0x00000400 },
+ { 0x0009c8,   1, 0x04, 0x00000400 },
+ { 0x00080c,   1, 0x04, 0x00000300 },
+ { 0x00084c,   1, 0x04, 0x00000300 },
+ { 0x00088c,   1, 0x04, 0x00000300 },
+ { 0x0008cc,   1, 0x04, 0x00000300 },
+ { 0x00090c,   1, 0x04, 0x00000300 },
+ { 0x00094c,   1, 0x04, 0x00000300 },
+ { 0x00098c,   1, 0x04, 0x00000300 },
+ { 0x0009cc,   1, 0x04, 0x00000300 },
+ { 0x000810,   1, 0x04, 0x000000cf },
+ { 0x000850,   1, 0x04, 0x00000000 },
+ { 0x000890,   1, 0x04, 0x00000000 },
+ { 0x0008d0,   1, 0x04, 0x00000000 },
+ { 0x000910,   1, 0x04, 0x00000000 },
+ { 0x000950,   1, 0x04, 0x00000000 },
+ { 0x000990,   1, 0x04, 0x00000000 },
+ { 0x0009d0,   1, 0x04, 0x00000000 },
+ { 0x000814,   1, 0x04, 0x00000040 },
+ { 0x000854,   1, 0x04, 0x00000040 },
+ { 0x000894,   1, 0x04, 0x00000040 },
+ { 0x0008d4,   1, 0x04, 0x00000040 },
+ { 0x000914,   1, 0x04, 0x00000040 },
+ { 0x000954,   1, 0x04, 0x00000040 },
+ { 0x000994,   1, 0x04, 0x00000040 },
+ { 0x0009d4,   1, 0x04, 0x00000040 },
+ { 0x000818,   1, 0x04, 0x00000001 },
+ { 0x000858,   1, 0x04, 0x00000001 },
+ { 0x000898,   1, 0x04, 0x00000001 },
+ { 0x0008d8,   1, 0x04, 0x00000001 },
+ { 0x000918,   1, 0x04, 0x00000001 },
+ { 0x000958,   1, 0x04, 0x00000001 },
+ { 0x000998,   1, 0x04, 0x00000001 },
+ { 0x0009d8,   1, 0x04, 0x00000001 },
+ { 0x00081c,   1, 0x04, 0x00000000 },
+ { 0x00085c,   1, 0x04, 0x00000000 },
+ { 0x00089c,   1, 0x04, 0x00000000 },
+ { 0x0008dc,   1, 0x04, 0x00000000 },
+ { 0x00091c,   1, 0x04, 0x00000000 },
+ { 0x00095c,   1, 0x04, 0x00000000 },
+ { 0x00099c,   1, 0x04, 0x00000000 },
+ { 0x0009dc,   1, 0x04, 0x00000000 },
+ { 0x000820,   1, 0x04, 0x00000000 },
+ { 0x000860,   1, 0x04, 0x00000000 },
+ { 0x0008a0,   1, 0x04, 0x00000000 },
+ { 0x0008e0,   1, 0x04, 0x00000000 },
+ { 0x000920,   1, 0x04, 0x00000000 },
+ { 0x000960,   1, 0x04, 0x00000000 },
+ { 0x0009a0,   1, 0x04, 0x00000000 },
+ { 0x0009e0,   1, 0x04, 0x00000000 },
+ { 0x001c00,   1, 0x04, 0x00000000 },
+ { 0x001c10,   1, 0x04, 0x00000000 },
+ { 0x001c20,   1, 0x04, 0x00000000 },
+ { 0x001c30,   1, 0x04, 0x00000000 },
+ { 0x001c40,   1, 0x04, 0x00000000 },
+ { 0x001c50,   1, 0x04, 0x00000000 },
+ { 0x001c60,   1, 0x04, 0x00000000 },
+ { 0x001c70,   1, 0x04, 0x00000000 },
+ { 0x001c80,   1, 0x04, 0x00000000 },
+ { 0x001c90,   1, 0x04, 0x00000000 },
+ { 0x001ca0,   1, 0x04, 0x00000000 },
+ { 0x001cb0,   1, 0x04, 0x00000000 },
+ { 0x001cc0,   1, 0x04, 0x00000000 },
+ { 0x001cd0,   1, 0x04, 0x00000000 },
+ { 0x001ce0,   1, 0x04, 0x00000000 },
+ { 0x001cf0,   1, 0x04, 0x00000000 },
+ { 0x001c04,   1, 0x04, 0x00000000 },
+ { 0x001c14,   1, 0x04, 0x00000000 },
+ { 0x001c24,   1, 0x04, 0x00000000 },
+ { 0x001c34,   1, 0x04, 0x00000000 },
+ { 0x001c44,   1, 0x04, 0x00000000 },
+ { 0x001c54,   1, 0x04, 0x00000000 },
+ { 0x001c64,   1, 0x04, 0x00000000 },
+ { 0x001c74,   1, 0x04, 0x00000000 },
+ { 0x001c84,   1, 0x04, 0x00000000 },
+ { 0x001c94,   1, 0x04, 0x00000000 },
+ { 0x001ca4,   1, 0x04, 0x00000000 },
+ { 0x001cb4,   1, 0x04, 0x00000000 },
+ { 0x001cc4,   1, 0x04, 0x00000000 },
+ { 0x001cd4,   1, 0x04, 0x00000000 },
+ { 0x001ce4,   1, 0x04, 0x00000000 },
+ { 0x001cf4,   1, 0x04, 0x00000000 },
+ { 0x001c08,   1, 0x04, 0x00000000 },
+ { 0x001c18,   1, 0x04, 0x00000000 },
+ { 0x001c28,   1, 0x04, 0x00000000 },
+ { 0x001c38,   1, 0x04, 0x00000000 },
+ { 0x001c48,   1, 0x04, 0x00000000 },
+ { 0x001c58,   1, 0x04, 0x00000000 },
+ { 0x001c68,   1, 0x04, 0x00000000 },
+ { 0x001c78,   1, 0x04, 0x00000000 },
+ { 0x001c88,   1, 0x04, 0x00000000 },
+ { 0x001c98,   1, 0x04, 0x00000000 },
+ { 0x001ca8,   1, 0x04, 0x00000000 },
+ { 0x001cb8,   1, 0x04, 0x00000000 },
+ { 0x001cc8,   1, 0x04, 0x00000000 },
+ { 0x001cd8,   1, 0x04, 0x00000000 },
+ { 0x001ce8,   1, 0x04, 0x00000000 },
+ { 0x001cf8,   1, 0x04, 0x00000000 },
+ { 0x001c0c,   1, 0x04, 0x00000000 },
+ { 0x001c1c,   1, 0x04, 0x00000000 },
+ { 0x001c2c,   1, 0x04, 0x00000000 },
+ { 0x001c3c,   1, 0x04, 0x00000000 },
+ { 0x001c4c,   1, 0x04, 0x00000000 },
+ { 0x001c5c,   1, 0x04, 0x00000000 },
+ { 0x001c6c,   1, 0x04, 0x00000000 },
+ { 0x001c7c,   1, 0x04, 0x00000000 },
+ { 0x001c8c,   1, 0x04, 0x00000000 },
+ { 0x001c9c,   1, 0x04, 0x00000000 },
+ { 0x001cac,   1, 0x04, 0x00000000 },
+ { 0x001cbc,   1, 0x04, 0x00000000 },
+ { 0x001ccc,   1, 0x04, 0x00000000 },
+ { 0x001cdc,   1, 0x04, 0x00000000 },
+ { 0x001cec,   1, 0x04, 0x00000000 },
+ { 0x001cfc,   2, 0x04, 0x00000000 },
+ { 0x001d10,   1, 0x04, 0x00000000 },
+ { 0x001d20,   1, 0x04, 0x00000000 },
+ { 0x001d30,   1, 0x04, 0x00000000 },
+ { 0x001d40,   1, 0x04, 0x00000000 },
+ { 0x001d50,   1, 0x04, 0x00000000 },
+ { 0x001d60,   1, 0x04, 0x00000000 },
+ { 0x001d70,   1, 0x04, 0x00000000 },
+ { 0x001d80,   1, 0x04, 0x00000000 },
+ { 0x001d90,   1, 0x04, 0x00000000 },
+ { 0x001da0,   1, 0x04, 0x00000000 },
+ { 0x001db0,   1, 0x04, 0x00000000 },
+ { 0x001dc0,   1, 0x04, 0x00000000 },
+ { 0x001dd0,   1, 0x04, 0x00000000 },
+ { 0x001de0,   1, 0x04, 0x00000000 },
+ { 0x001df0,   1, 0x04, 0x00000000 },
+ { 0x001d04,   1, 0x04, 0x00000000 },
+ { 0x001d14,   1, 0x04, 0x00000000 },
+ { 0x001d24,   1, 0x04, 0x00000000 },
+ { 0x001d34,   1, 0x04, 0x00000000 },
+ { 0x001d44,   1, 0x04, 0x00000000 },
+ { 0x001d54,   1, 0x04, 0x00000000 },
+ { 0x001d64,   1, 0x04, 0x00000000 },
+ { 0x001d74,   1, 0x04, 0x00000000 },
+ { 0x001d84,   1, 0x04, 0x00000000 },
+ { 0x001d94,   1, 0x04, 0x00000000 },
+ { 0x001da4,   1, 0x04, 0x00000000 },
+ { 0x001db4,   1, 0x04, 0x00000000 },
+ { 0x001dc4,   1, 0x04, 0x00000000 },
+ { 0x001dd4,   1, 0x04, 0x00000000 },
+ { 0x001de4,   1, 0x04, 0x00000000 },
+ { 0x001df4,   1, 0x04, 0x00000000 },
+ { 0x001d08,   1, 0x04, 0x00000000 },
+ { 0x001d18,   1, 0x04, 0x00000000 },
+ { 0x001d28,   1, 0x04, 0x00000000 },
+ { 0x001d38,   1, 0x04, 0x00000000 },
+ { 0x001d48,   1, 0x04, 0x00000000 },
+ { 0x001d58,   1, 0x04, 0x00000000 },
+ { 0x001d68,   1, 0x04, 0x00000000 },
+ { 0x001d78,   1, 0x04, 0x00000000 },
+ { 0x001d88,   1, 0x04, 0x00000000 },
+ { 0x001d98,   1, 0x04, 0x00000000 },
+ { 0x001da8,   1, 0x04, 0x00000000 },
+ { 0x001db8,   1, 0x04, 0x00000000 },
+ { 0x001dc8,   1, 0x04, 0x00000000 },
+ { 0x001dd8,   1, 0x04, 0x00000000 },
+ { 0x001de8,   1, 0x04, 0x00000000 },
+ { 0x001df8,   1, 0x04, 0x00000000 },
+ { 0x001d0c,   1, 0x04, 0x00000000 },
+ { 0x001d1c,   1, 0x04, 0x00000000 },
+ { 0x001d2c,   1, 0x04, 0x00000000 },
+ { 0x001d3c,   1, 0x04, 0x00000000 },
+ { 0x001d4c,   1, 0x04, 0x00000000 },
+ { 0x001d5c,   1, 0x04, 0x00000000 },
+ { 0x001d6c,   1, 0x04, 0x00000000 },
+ { 0x001d7c,   1, 0x04, 0x00000000 },
+ { 0x001d8c,   1, 0x04, 0x00000000 },
+ { 0x001d9c,   1, 0x04, 0x00000000 },
+ { 0x001dac,   1, 0x04, 0x00000000 },
+ { 0x001dbc,   1, 0x04, 0x00000000 },
+ { 0x001dcc,   1, 0x04, 0x00000000 },
+ { 0x001ddc,   1, 0x04, 0x00000000 },
+ { 0x001dec,   1, 0x04, 0x00000000 },
+ { 0x001dfc,   1, 0x04, 0x00000000 },
+ { 0x001f00,   1, 0x04, 0x00000000 },
+ { 0x001f08,   1, 0x04, 0x00000000 },
+ { 0x001f10,   1, 0x04, 0x00000000 },
+ { 0x001f18,   1, 0x04, 0x00000000 },
+ { 0x001f20,   1, 0x04, 0x00000000 },
+ { 0x001f28,   1, 0x04, 0x00000000 },
+ { 0x001f30,   1, 0x04, 0x00000000 },
+ { 0x001f38,   1, 0x04, 0x00000000 },
+ { 0x001f40,   1, 0x04, 0x00000000 },
+ { 0x001f48,   1, 0x04, 0x00000000 },
+ { 0x001f50,   1, 0x04, 0x00000000 },
+ { 0x001f58,   1, 0x04, 0x00000000 },
+ { 0x001f60,   1, 0x04, 0x00000000 },
+ { 0x001f68,   1, 0x04, 0x00000000 },
+ { 0x001f70,   1, 0x04, 0x00000000 },
+ { 0x001f78,   1, 0x04, 0x00000000 },
+ { 0x001f04,   1, 0x04, 0x00000000 },
+ { 0x001f0c,   1, 0x04, 0x00000000 },
+ { 0x001f14,   1, 0x04, 0x00000000 },
+ { 0x001f1c,   1, 0x04, 0x00000000 },
+ { 0x001f24,   1, 0x04, 0x00000000 },
+ { 0x001f2c,   1, 0x04, 0x00000000 },
+ { 0x001f34,   1, 0x04, 0x00000000 },
+ { 0x001f3c,   1, 0x04, 0x00000000 },
+ { 0x001f44,   1, 0x04, 0x00000000 },
+ { 0x001f4c,   1, 0x04, 0x00000000 },
+ { 0x001f54,   1, 0x04, 0x00000000 },
+ { 0x001f5c,   1, 0x04, 0x00000000 },
+ { 0x001f64,   1, 0x04, 0x00000000 },
+ { 0x001f6c,   1, 0x04, 0x00000000 },
+ { 0x001f74,   1, 0x04, 0x00000000 },
+ { 0x001f7c,   2, 0x04, 0x00000000 },
+ { 0x001f88,   1, 0x04, 0x00000000 },
+ { 0x001f90,   1, 0x04, 0x00000000 },
+ { 0x001f98,   1, 0x04, 0x00000000 },
+ { 0x001fa0,   1, 0x04, 0x00000000 },
+ { 0x001fa8,   1, 0x04, 0x00000000 },
+ { 0x001fb0,   1, 0x04, 0x00000000 },
+ { 0x001fb8,   1, 0x04, 0x00000000 },
+ { 0x001fc0,   1, 0x04, 0x00000000 },
+ { 0x001fc8,   1, 0x04, 0x00000000 },
+ { 0x001fd0,   1, 0x04, 0x00000000 },
+ { 0x001fd8,   1, 0x04, 0x00000000 },
+ { 0x001fe0,   1, 0x04, 0x00000000 },
+ { 0x001fe8,   1, 0x04, 0x00000000 },
+ { 0x001ff0,   1, 0x04, 0x00000000 },
+ { 0x001ff8,   1, 0x04, 0x00000000 },
+ { 0x001f84,   1, 0x04, 0x00000000 },
+ { 0x001f8c,   1, 0x04, 0x00000000 },
+ { 0x001f94,   1, 0x04, 0x00000000 },
+ { 0x001f9c,   1, 0x04, 0x00000000 },
+ { 0x001fa4,   1, 0x04, 0x00000000 },
+ { 0x001fac,   1, 0x04, 0x00000000 },
+ { 0x001fb4,   1, 0x04, 0x00000000 },
+ { 0x001fbc,   1, 0x04, 0x00000000 },
+ { 0x001fc4,   1, 0x04, 0x00000000 },
+ { 0x001fcc,   1, 0x04, 0x00000000 },
+ { 0x001fd4,   1, 0x04, 0x00000000 },
+ { 0x001fdc,   1, 0x04, 0x00000000 },
+ { 0x001fe4,   1, 0x04, 0x00000000 },
+ { 0x001fec,   1, 0x04, 0x00000000 },
+ { 0x001ff4,   1, 0x04, 0x00000000 },
+ { 0x001ffc,   2, 0x04, 0x00000000 },
+ { 0x002040,   1, 0x04, 0x00000011 },
+ { 0x002080,   1, 0x04, 0x00000020 },
+ { 0x0020c0,   1, 0x04, 0x00000030 },
+ { 0x002100,   1, 0x04, 0x00000040 },
+ { 0x002140,   1, 0x04, 0x00000051 },
+ { 0x00200c,   1, 0x04, 0x00000001 },
+ { 0x00204c,   1, 0x04, 0x00000001 },
+ { 0x00208c,   1, 0x04, 0x00000001 },
+ { 0x0020cc,   1, 0x04, 0x00000001 },
+ { 0x00210c,   1, 0x04, 0x00000001 },
+ { 0x00214c,   1, 0x04, 0x00000001 },
+ { 0x002010,   1, 0x04, 0x00000000 },
+ { 0x002050,   1, 0x04, 0x00000000 },
+ { 0x002090,   1, 0x04, 0x00000001 },
+ { 0x0020d0,   1, 0x04, 0x00000002 },
+ { 0x002110,   1, 0x04, 0x00000003 },
+ { 0x002150,   1, 0x04, 0x00000004 },
+ { 0x000380,   1, 0x04, 0x00000000 },
+ { 0x0003a0,   1, 0x04, 0x00000000 },
+ { 0x0003c0,   1, 0x04, 0x00000000 },
+ { 0x0003e0,   1, 0x04, 0x00000000 },
+ { 0x000384,   1, 0x04, 0x00000000 },
+ { 0x0003a4,   1, 0x04, 0x00000000 },
+ { 0x0003c4,   1, 0x04, 0x00000000 },
+ { 0x0003e4,   1, 0x04, 0x00000000 },
+ { 0x000388,   1, 0x04, 0x00000000 },
+ { 0x0003a8,   1, 0x04, 0x00000000 },
+ { 0x0003c8,   1, 0x04, 0x00000000 },
+ { 0x0003e8,   1, 0x04, 0x00000000 },
+ { 0x00038c,   1, 0x04, 0x00000000 },
+ { 0x0003ac,   1, 0x04, 0x00000000 },
+ { 0x0003cc,   1, 0x04, 0x00000000 },
+ { 0x0003ec,   1, 0x04, 0x00000000 },
+ { 0x000700,   1, 0x04, 0x00000000 },
+ { 0x000710,   1, 0x04, 0x00000000 },
+ { 0x000720,   1, 0x04, 0x00000000 },
+ { 0x000730,   1, 0x04, 0x00000000 },
+ { 0x000704,   1, 0x04, 0x00000000 },
+ { 0x000714,   1, 0x04, 0x00000000 },
+ { 0x000724,   1, 0x04, 0x00000000 },
+ { 0x000734,   1, 0x04, 0x00000000 },
+ { 0x000708,   1, 0x04, 0x00000000 },
+ { 0x000718,   1, 0x04, 0x00000000 },
+ { 0x000728,   1, 0x04, 0x00000000 },
+ { 0x000738,   1, 0x04, 0x00000000 },
+ { 0x002800, 128, 0x04, 0x00000000 },
+ { 0x000a00,   1, 0x04, 0x00000000 },
+ { 0x000a20,   1, 0x04, 0x00000000 },
+ { 0x000a40,   1, 0x04, 0x00000000 },
+ { 0x000a60,   1, 0x04, 0x00000000 },
+ { 0x000a80,   1, 0x04, 0x00000000 },
+ { 0x000aa0,   1, 0x04, 0x00000000 },
+ { 0x000ac0,   1, 0x04, 0x00000000 },
+ { 0x000ae0,   1, 0x04, 0x00000000 },
+ { 0x000b00,   1, 0x04, 0x00000000 },
+ { 0x000b20,   1, 0x04, 0x00000000 },
+ { 0x000b40,   1, 0x04, 0x00000000 },
+ { 0x000b60,   1, 0x04, 0x00000000 },
+ { 0x000b80,   1, 0x04, 0x00000000 },
+ { 0x000ba0,   1, 0x04, 0x00000000 },
+ { 0x000bc0,   1, 0x04, 0x00000000 },
+ { 0x000be0,   1, 0x04, 0x00000000 },
+ { 0x000a04,   1, 0x04, 0x00000000 },
+ { 0x000a24,   1, 0x04, 0x00000000 },
+ { 0x000a44,   1, 0x04, 0x00000000 },
+ { 0x000a64,   1, 0x04, 0x00000000 },
+ { 0x000a84,   1, 0x04, 0x00000000 },
+ { 0x000aa4,   1, 0x04, 0x00000000 },
+ { 0x000ac4,   1, 0x04, 0x00000000 },
+ { 0x000ae4,   1, 0x04, 0x00000000 },
+ { 0x000b04,   1, 0x04, 0x00000000 },
+ { 0x000b24,   1, 0x04, 0x00000000 },
+ { 0x000b44,   1, 0x04, 0x00000000 },
+ { 0x000b64,   1, 0x04, 0x00000000 },
+ { 0x000b84,   1, 0x04, 0x00000000 },
+ { 0x000ba4,   1, 0x04, 0x00000000 },
+ { 0x000bc4,   1, 0x04, 0x00000000 },
+ { 0x000be4,   1, 0x04, 0x00000000 },
+ { 0x000a08,   1, 0x04, 0x00000000 },
+ { 0x000a28,   1, 0x04, 0x00000000 },
+ { 0x000a48,   1, 0x04, 0x00000000 },
+ { 0x000a68,   1, 0x04, 0x00000000 },
+ { 0x000a88,   1, 0x04, 0x00000000 },
+ { 0x000aa8,   1, 0x04, 0x00000000 },
+ { 0x000ac8,   1, 0x04, 0x00000000 },
+ { 0x000ae8,   1, 0x04, 0x00000000 },
+ { 0x000b08,   1, 0x04, 0x00000000 },
+ { 0x000b28,   1, 0x04, 0x00000000 },
+ { 0x000b48,   1, 0x04, 0x00000000 },
+ { 0x000b68,   1, 0x04, 0x00000000 },
+ { 0x000b88,   1, 0x04, 0x00000000 },
+ { 0x000ba8,   1, 0x04, 0x00000000 },
+ { 0x000bc8,   1, 0x04, 0x00000000 },
+ { 0x000be8,   1, 0x04, 0x00000000 },
+ { 0x000a0c,   1, 0x04, 0x00000000 },
+ { 0x000a2c,   1, 0x04, 0x00000000 },
+ { 0x000a4c,   1, 0x04, 0x00000000 },
+ { 0x000a6c,   1, 0x04, 0x00000000 },
+ { 0x000a8c,   1, 0x04, 0x00000000 },
+ { 0x000aac,   1, 0x04, 0x00000000 },
+ { 0x000acc,   1, 0x04, 0x00000000 },
+ { 0x000aec,   1, 0x04, 0x00000000 },
+ { 0x000b0c,   1, 0x04, 0x00000000 },
+ { 0x000b2c,   1, 0x04, 0x00000000 },
+ { 0x000b4c,   1, 0x04, 0x00000000 },
+ { 0x000b6c,   1, 0x04, 0x00000000 },
+ { 0x000b8c,   1, 0x04, 0x00000000 },
+ { 0x000bac,   1, 0x04, 0x00000000 },
+ { 0x000bcc,   1, 0x04, 0x00000000 },
+ { 0x000bec,   1, 0x04, 0x00000000 },
+ { 0x000a10,   1, 0x04, 0x00000000 },
+ { 0x000a30,   1, 0x04, 0x00000000 },
+ { 0x000a50,   1, 0x04, 0x00000000 },
+ { 0x000a70,   1, 0x04, 0x00000000 },
+ { 0x000a90,   1, 0x04, 0x00000000 },
+ { 0x000ab0,   1, 0x04, 0x00000000 },
+ { 0x000ad0,   1, 0x04, 0x00000000 },
+ { 0x000af0,   1, 0x04, 0x00000000 },
+ { 0x000b10,   1, 0x04, 0x00000000 },
+ { 0x000b30,   1, 0x04, 0x00000000 },
+ { 0x000b50,   1, 0x04, 0x00000000 },
+ { 0x000b70,   1, 0x04, 0x00000000 },
+ { 0x000b90,   1, 0x04, 0x00000000 },
+ { 0x000bb0,   1, 0x04, 0x00000000 },
+ { 0x000bd0,   1, 0x04, 0x00000000 },
+ { 0x000bf0,   1, 0x04, 0x00000000 },
+ { 0x000a14,   1, 0x04, 0x00000000 },
+ { 0x000a34,   1, 0x04, 0x00000000 },
+ { 0x000a54,   1, 0x04, 0x00000000 },
+ { 0x000a74,   1, 0x04, 0x00000000 },
+ { 0x000a94,   1, 0x04, 0x00000000 },
+ { 0x000ab4,   1, 0x04, 0x00000000 },
+ { 0x000ad4,   1, 0x04, 0x00000000 },
+ { 0x000af4,   1, 0x04, 0x00000000 },
+ { 0x000b14,   1, 0x04, 0x00000000 },
+ { 0x000b34,   1, 0x04, 0x00000000 },
+ { 0x000b54,   1, 0x04, 0x00000000 },
+ { 0x000b74,   1, 0x04, 0x00000000 },
+ { 0x000b94,   1, 0x04, 0x00000000 },
+ { 0x000bb4,   1, 0x04, 0x00000000 },
+ { 0x000bd4,   1, 0x04, 0x00000000 },
+ { 0x000bf4,   1, 0x04, 0x00000000 },
+ { 0x000c00,   1, 0x04, 0x00000000 },
+ { 0x000c10,   1, 0x04, 0x00000000 },
+ { 0x000c20,   1, 0x04, 0x00000000 },
+ { 0x000c30,   1, 0x04, 0x00000000 },
+ { 0x000c40,   1, 0x04, 0x00000000 },
+ { 0x000c50,   1, 0x04, 0x00000000 },
+ { 0x000c60,   1, 0x04, 0x00000000 },
+ { 0x000c70,   1, 0x04, 0x00000000 },
+ { 0x000c80,   1, 0x04, 0x00000000 },
+ { 0x000c90,   1, 0x04, 0x00000000 },
+ { 0x000ca0,   1, 0x04, 0x00000000 },
+ { 0x000cb0,   1, 0x04, 0x00000000 },
+ { 0x000cc0,   1, 0x04, 0x00000000 },
+ { 0x000cd0,   1, 0x04, 0x00000000 },
+ { 0x000ce0,   1, 0x04, 0x00000000 },
+ { 0x000cf0,   1, 0x04, 0x00000000 },
+ { 0x000c04,   1, 0x04, 0x00000000 },
+ { 0x000c14,   1, 0x04, 0x00000000 },
+ { 0x000c24,   1, 0x04, 0x00000000 },
+ { 0x000c34,   1, 0x04, 0x00000000 },
+ { 0x000c44,   1, 0x04, 0x00000000 },
+ { 0x000c54,   1, 0x04, 0x00000000 },
+ { 0x000c64,   1, 0x04, 0x00000000 },
+ { 0x000c74,   1, 0x04, 0x00000000 },
+ { 0x000c84,   1, 0x04, 0x00000000 },
+ { 0x000c94,   1, 0x04, 0x00000000 },
+ { 0x000ca4,   1, 0x04, 0x00000000 },
+ { 0x000cb4,   1, 0x04, 0x00000000 },
+ { 0x000cc4,   1, 0x04, 0x00000000 },
+ { 0x000cd4,   1, 0x04, 0x00000000 },
+ { 0x000ce4,   1, 0x04, 0x00000000 },
+ { 0x000cf4,   1, 0x04, 0x00000000 },
+ { 0x000c08,   1, 0x04, 0x00000000 },
+ { 0x000c18,   1, 0x04, 0x00000000 },
+ { 0x000c28,   1, 0x04, 0x00000000 },
+ { 0x000c38,   1, 0x04, 0x00000000 },
+ { 0x000c48,   1, 0x04, 0x00000000 },
+ { 0x000c58,   1, 0x04, 0x00000000 },
+ { 0x000c68,   1, 0x04, 0x00000000 },
+ { 0x000c78,   1, 0x04, 0x00000000 },
+ { 0x000c88,   1, 0x04, 0x00000000 },
+ { 0x000c98,   1, 0x04, 0x00000000 },
+ { 0x000ca8,   1, 0x04, 0x00000000 },
+ { 0x000cb8,   1, 0x04, 0x00000000 },
+ { 0x000cc8,   1, 0x04, 0x00000000 },
+ { 0x000cd8,   1, 0x04, 0x00000000 },
+ { 0x000ce8,   1, 0x04, 0x00000000 },
+ { 0x000cf8,   1, 0x04, 0x00000000 },
+ { 0x000c0c,   1, 0x04, 0x3f800000 },
+ { 0x000c1c,   1, 0x04, 0x3f800000 },
+ { 0x000c2c,   1, 0x04, 0x3f800000 },
+ { 0x000c3c,   1, 0x04, 0x3f800000 },
+ { 0x000c4c,   1, 0x04, 0x3f800000 },
+ { 0x000c5c,   1, 0x04, 0x3f800000 },
+ { 0x000c6c,   1, 0x04, 0x3f800000 },
+ { 0x000c7c,   1, 0x04, 0x3f800000 },
+ { 0x000c8c,   1, 0x04, 0x3f800000 },
+ { 0x000c9c,   1, 0x04, 0x3f800000 },
+ { 0x000cac,   1, 0x04, 0x3f800000 },
+ { 0x000cbc,   1, 0x04, 0x3f800000 },
+ { 0x000ccc,   1, 0x04, 0x3f800000 },
+ { 0x000cdc,   1, 0x04, 0x3f800000 },
+ { 0x000cec,   1, 0x04, 0x3f800000 },
+ { 0x000cfc,   1, 0x04, 0x3f800000 },
+ { 0x000d00,   1, 0x04, 0xffff0000 },
+ { 0x000d08,   1, 0x04, 0xffff0000 },
+ { 0x000d10,   1, 0x04, 0xffff0000 },
+ { 0x000d18,   1, 0x04, 0xffff0000 },
+ { 0x000d20,   1, 0x04, 0xffff0000 },
+ { 0x000d28,   1, 0x04, 0xffff0000 },
+ { 0x000d30,   1, 0x04, 0xffff0000 },
+ { 0x000d38,   1, 0x04, 0xffff0000 },
+ { 0x000d04,   1, 0x04, 0xffff0000 },
+ { 0x000d0c,   1, 0x04, 0xffff0000 },
+ { 0x000d14,   1, 0x04, 0xffff0000 },
+ { 0x000d1c,   1, 0x04, 0xffff0000 },
+ { 0x000d24,   1, 0x04, 0xffff0000 },
+ { 0x000d2c,   1, 0x04, 0xffff0000 },
+ { 0x000d34,   1, 0x04, 0xffff0000 },
+ { 0x000d3c,   1, 0x04, 0xffff0000 },
+ { 0x000e00,   1, 0x04, 0x00000000 },
+ { 0x000e10,   1, 0x04, 0x00000000 },
+ { 0x000e20,   1, 0x04, 0x00000000 },
+ { 0x000e30,   1, 0x04, 0x00000000 },
+ { 0x000e40,   1, 0x04, 0x00000000 },
+ { 0x000e50,   1, 0x04, 0x00000000 },
+ { 0x000e60,   1, 0x04, 0x00000000 },
+ { 0x000e70,   1, 0x04, 0x00000000 },
+ { 0x000e80,   1, 0x04, 0x00000000 },
+ { 0x000e90,   1, 0x04, 0x00000000 },
+ { 0x000ea0,   1, 0x04, 0x00000000 },
+ { 0x000eb0,   1, 0x04, 0x00000000 },
+ { 0x000ec0,   1, 0x04, 0x00000000 },
+ { 0x000ed0,   1, 0x04, 0x00000000 },
+ { 0x000ee0,   1, 0x04, 0x00000000 },
+ { 0x000ef0,   1, 0x04, 0x00000000 },
+ { 0x000e04,   1, 0x04, 0xffff0000 },
+ { 0x000e14,   1, 0x04, 0xffff0000 },
+ { 0x000e24,   1, 0x04, 0xffff0000 },
+ { 0x000e34,   1, 0x04, 0xffff0000 },
+ { 0x000e44,   1, 0x04, 0xffff0000 },
+ { 0x000e54,   1, 0x04, 0xffff0000 },
+ { 0x000e64,   1, 0x04, 0xffff0000 },
+ { 0x000e74,   1, 0x04, 0xffff0000 },
+ { 0x000e84,   1, 0x04, 0xffff0000 },
+ { 0x000e94,   1, 0x04, 0xffff0000 },
+ { 0x000ea4,   1, 0x04, 0xffff0000 },
+ { 0x000eb4,   1, 0x04, 0xffff0000 },
+ { 0x000ec4,   1, 0x04, 0xffff0000 },
+ { 0x000ed4,   1, 0x04, 0xffff0000 },
+ { 0x000ee4,   1, 0x04, 0xffff0000 },
+ { 0x000ef4,   1, 0x04, 0xffff0000 },
+ { 0x000e08,   1, 0x04, 0xffff0000 },
+ { 0x000e18,   1, 0x04, 0xffff0000 },
+ { 0x000e28,   1, 0x04, 0xffff0000 },
+ { 0x000e38,   1, 0x04, 0xffff0000 },
+ { 0x000e48,   1, 0x04, 0xffff0000 },
+ { 0x000e58,   1, 0x04, 0xffff0000 },
+ { 0x000e68,   1, 0x04, 0xffff0000 },
+ { 0x000e78,   1, 0x04, 0xffff0000 },
+ { 0x000e88,   1, 0x04, 0xffff0000 },
+ { 0x000e98,   1, 0x04, 0xffff0000 },
+ { 0x000ea8,   1, 0x04, 0xffff0000 },
+ { 0x000eb8,   1, 0x04, 0xffff0000 },
+ { 0x000ec8,   1, 0x04, 0xffff0000 },
+ { 0x000ed8,   1, 0x04, 0xffff0000 },
+ { 0x000ee8,   1, 0x04, 0xffff0000 },
+ { 0x000ef8,   1, 0x04, 0xffff0000 },
+ { 0x000d40,   1, 0x04, 0x00000000 },
+ { 0x000d48,   1, 0x04, 0x00000000 },
+ { 0x000d50,   1, 0x04, 0x00000000 },
+ { 0x000d58,   1, 0x04, 0x00000000 },
+ { 0x000d44,   1, 0x04, 0x00000000 },
+ { 0x000d4c,   1, 0x04, 0x00000000 },
+ { 0x000d54,   1, 0x04, 0x00000000 },
+ { 0x000d5c,   1, 0x04, 0x00000000 },
+ { 0x001e00,   1, 0x04, 0x00000001 },
+ { 0x001e20,   1, 0x04, 0x00000001 },
+ { 0x001e40,   1, 0x04, 0x00000001 },
+ { 0x001e60,   1, 0x04, 0x00000001 },
+ { 0x001e80,   1, 0x04, 0x00000001 },
+ { 0x001ea0,   1, 0x04, 0x00000001 },
+ { 0x001ec0,   1, 0x04, 0x00000001 },
+ { 0x001ee0,   1, 0x04, 0x00000001 },
+ { 0x001e04,   1, 0x04, 0x00000001 },
+ { 0x001e24,   1, 0x04, 0x00000001 },
+ { 0x001e44,   1, 0x04, 0x00000001 },
+ { 0x001e64,   1, 0x04, 0x00000001 },
+ { 0x001e84,   1, 0x04, 0x00000001 },
+ { 0x001ea4,   1, 0x04, 0x00000001 },
+ { 0x001ec4,   1, 0x04, 0x00000001 },
+ { 0x001ee4,   1, 0x04, 0x00000001 },
+ { 0x001e08,   1, 0x04, 0x00000002 },
+ { 0x001e28,   1, 0x04, 0x00000002 },
+ { 0x001e48,   1, 0x04, 0x00000002 },
+ { 0x001e68,   1, 0x04, 0x00000002 },
+ { 0x001e88,   1, 0x04, 0x00000002 },
+ { 0x001ea8,   1, 0x04, 0x00000002 },
+ { 0x001ec8,   1, 0x04, 0x00000002 },
+ { 0x001ee8,   1, 0x04, 0x00000002 },
+ { 0x001e0c,   1, 0x04, 0x00000001 },
+ { 0x001e2c,   1, 0x04, 0x00000001 },
+ { 0x001e4c,   1, 0x04, 0x00000001 },
+ { 0x001e6c,   1, 0x04, 0x00000001 },
+ { 0x001e8c,   1, 0x04, 0x00000001 },
+ { 0x001eac,   1, 0x04, 0x00000001 },
+ { 0x001ecc,   1, 0x04, 0x00000001 },
+ { 0x001eec,   1, 0x04, 0x00000001 },
+ { 0x001e10,   1, 0x04, 0x00000001 },
+ { 0x001e30,   1, 0x04, 0x00000001 },
+ { 0x001e50,   1, 0x04, 0x00000001 },
+ { 0x001e70,   1, 0x04, 0x00000001 },
+ { 0x001e90,   1, 0x04, 0x00000001 },
+ { 0x001eb0,   1, 0x04, 0x00000001 },
+ { 0x001ed0,   1, 0x04, 0x00000001 },
+ { 0x001ef0,   1, 0x04, 0x00000001 },
+ { 0x001e14,   1, 0x04, 0x00000002 },
+ { 0x001e34,   1, 0x04, 0x00000002 },
+ { 0x001e54,   1, 0x04, 0x00000002 },
+ { 0x001e74,   1, 0x04, 0x00000002 },
+ { 0x001e94,   1, 0x04, 0x00000002 },
+ { 0x001eb4,   1, 0x04, 0x00000002 },
+ { 0x001ed4,   1, 0x04, 0x00000002 },
+ { 0x001ef4,   1, 0x04, 0x00000002 },
+ { 0x001e18,   1, 0x04, 0x00000001 },
+ { 0x001e38,   1, 0x04, 0x00000001 },
+ { 0x001e58,   1, 0x04, 0x00000001 },
+ { 0x001e78,   1, 0x04, 0x00000001 },
+ { 0x001e98,   1, 0x04, 0x00000001 },
+ { 0x001eb8,   1, 0x04, 0x00000001 },
+ { 0x001ed8,   1, 0x04, 0x00000001 },
+ { 0x001ef8,   1, 0x04, 0x00000001 },
+ { 0x003400, 128, 0x04, 0x00000000 },
+ { 0x00030c,   1, 0x04, 0x00000001 },
+ { 0x001944,   1, 0x04, 0x00000000 },
+ { 0x001514,   1, 0x04, 0x00000000 },
+ { 0x000d68,   1, 0x04, 0x0000ffff },
+ { 0x00121c,   1, 0x04, 0x0fac6881 },
+ { 0x000fac,   1, 0x04, 0x00000001 },
+ { 0x001538,   1, 0x04, 0x00000001 },
+ { 0x000fe0,   2, 0x04, 0x00000000 },
+ { 0x000fe8,   1, 0x04, 0x00000014 },
+ { 0x000fec,   1, 0x04, 0x00000040 },
+ { 0x000ff0,   1, 0x04, 0x00000000 },
+ { 0x00179c,   1, 0x04, 0x00000000 },
+ { 0x001228,   1, 0x04, 0x00000400 },
+ { 0x00122c,   1, 0x04, 0x00000300 },
+ { 0x001230,   1, 0x04, 0x00010001 },
+ { 0x0007f8,   1, 0x04, 0x00000000 },
+ { 0x0015b4,   1, 0x04, 0x00000001 },
+ { 0x0015cc,   1, 0x04, 0x00000000 },
+ { 0x001534,   1, 0x04, 0x00000000 },
+ { 0x000fb0,   1, 0x04, 0x00000000 },
+ { 0x0015d0,   1, 0x04, 0x00000000 },
+ { 0x00153c,   1, 0x04, 0x00000000 },
+ { 0x0016b4,   1, 0x04, 0x00000003 },
+ { 0x000fbc,   4, 0x04, 0x0000ffff },
+ { 0x000df8,   2, 0x04, 0x00000000 },
+ { 0x001948,   1, 0x04, 0x00000000 },
+ { 0x001970,   1, 0x04, 0x00000001 },
+ { 0x00161c,   1, 0x04, 0x000009f0 },
+ { 0x000dcc,   1, 0x04, 0x00000010 },
+ { 0x00163c,   1, 0x04, 0x00000000 },
+ { 0x0015e4,   1, 0x04, 0x00000000 },
+ { 0x001160,  32, 0x04, 0x25e00040 },
+ { 0x001880,  32, 0x04, 0x00000000 },
+ { 0x000f84,   2, 0x04, 0x00000000 },
+ { 0x0017c8,   2, 0x04, 0x00000000 },
+ { 0x0017d0,   1, 0x04, 0x000000ff },
+ { 0x0017d4,   1, 0x04, 0xffffffff },
+ { 0x0017d8,   1, 0x04, 0x00000002 },
+ { 0x0017dc,   1, 0x04, 0x00000000 },
+ { 0x0015f4,   2, 0x04, 0x00000000 },
+ { 0x001434,   2, 0x04, 0x00000000 },
+ { 0x000d74,   1, 0x04, 0x00000000 },
+ { 0x000dec,   1, 0x04, 0x00000001 },
+ { 0x0013a4,   1, 0x04, 0x00000000 },
+ { 0x001318,   1, 0x04, 0x00000001 },
+ { 0x001644,   1, 0x04, 0x00000000 },
+ { 0x000748,   1, 0x04, 0x00000000 },
+ { 0x000de8,   1, 0x04, 0x00000000 },
+ { 0x001648,   1, 0x04, 0x00000000 },
+ { 0x0012a4,   1, 0x04, 0x00000000 },
+ { 0x001120,   4, 0x04, 0x00000000 },
+ { 0x001118,   1, 0x04, 0x00000000 },
+ { 0x00164c,   1, 0x04, 0x00000000 },
+ { 0x001658,   1, 0x04, 0x00000000 },
+ { 0x001910,   1, 0x04, 0x00000290 },
+ { 0x001518,   1, 0x04, 0x00000000 },
+ { 0x00165c,   1, 0x04, 0x00000001 },
+ { 0x001520,   1, 0x04, 0x00000000 },
+ { 0x001604,   1, 0x04, 0x00000000 },
+ { 0x001570,   1, 0x04, 0x00000000 },
+ { 0x0013b0,   2, 0x04, 0x3f800000 },
+ { 0x00020c,   1, 0x04, 0x00000000 },
+ { 0x001670,   1, 0x04, 0x30201000 },
+ { 0x001674,   1, 0x04, 0x70605040 },
+ { 0x001678,   1, 0x04, 0xb8a89888 },
+ { 0x00167c,   1, 0x04, 0xf8e8d8c8 },
+ { 0x00166c,   1, 0x04, 0x00000000 },
+ { 0x001680,   1, 0x04, 0x00ffff00 },
+ { 0x0012d0,   1, 0x04, 0x00000003 },
+ { 0x0012d4,   1, 0x04, 0x00000002 },
+ { 0x001684,   2, 0x04, 0x00000000 },
+ { 0x000dac,   2, 0x04, 0x00001b02 },
+ { 0x000db4,   1, 0x04, 0x00000000 },
+ { 0x00168c,   1, 0x04, 0x00000000 },
+ { 0x0015bc,   1, 0x04, 0x00000000 },
+ { 0x00156c,   1, 0x04, 0x00000000 },
+ { 0x00187c,   1, 0x04, 0x00000000 },
+ { 0x001110,   1, 0x04, 0x00000001 },
+ { 0x000dc0,   3, 0x04, 0x00000000 },
+ { 0x001234,   1, 0x04, 0x00000000 },
+ { 0x001690,   1, 0x04, 0x00000000 },
+ { 0x0012ac,   1, 0x04, 0x00000001 },
+ { 0x0002c4,   1, 0x04, 0x00000000 },
+ { 0x000790,   5, 0x04, 0x00000000 },
+ { 0x00077c,   1, 0x04, 0x00000000 },
+ { 0x001000,   1, 0x04, 0x00000010 },
+ { 0x0010fc,   1, 0x04, 0x00000000 },
+ { 0x001290,   1, 0x04, 0x00000000 },
+ { 0x000218,   1, 0x04, 0x00000010 },
+ { 0x0012d8,   1, 0x04, 0x00000000 },
+ { 0x0012dc,   1, 0x04, 0x00000010 },
+ { 0x000d94,   1, 0x04, 0x00000001 },
+ { 0x00155c,   2, 0x04, 0x00000000 },
+ { 0x001564,   1, 0x04, 0x00000fff },
+ { 0x001574,   2, 0x04, 0x00000000 },
+ { 0x00157c,   1, 0x04, 0x000fffff },
+ { 0x001354,   1, 0x04, 0x00000000 },
+ { 0x001610,   1, 0x04, 0x00000012 },
+ { 0x001608,   2, 0x04, 0x00000000 },
+ { 0x00260c,   1, 0x04, 0x00000000 },
+ { 0x0007ac,   1, 0x04, 0x00000000 },
+ { 0x00162c,   1, 0x04, 0x00000003 },
+ { 0x000210,   1, 0x04, 0x00000000 },
+ { 0x000320,   1, 0x04, 0x00000000 },
+ { 0x000324,   6, 0x04, 0x3f800000 },
+ { 0x000750,   1, 0x04, 0x00000000 },
+ { 0x000760,   1, 0x04, 0x39291909 },
+ { 0x000764,   1, 0x04, 0x79695949 },
+ { 0x000768,   1, 0x04, 0xb9a99989 },
+ { 0x00076c,   1, 0x04, 0xf9e9d9c9 },
+ { 0x000770,   1, 0x04, 0x30201000 },
+ { 0x000774,   1, 0x04, 0x70605040 },
+ { 0x000778,   1, 0x04, 0x00009080 },
+ { 0x000780,   1, 0x04, 0x39291909 },
+ { 0x000784,   1, 0x04, 0x79695949 },
+ { 0x000788,   1, 0x04, 0xb9a99989 },
+ { 0x00078c,   1, 0x04, 0xf9e9d9c9 },
+ { 0x0007d0,   1, 0x04, 0x30201000 },
+ { 0x0007d4,   1, 0x04, 0x70605040 },
+ { 0x0007d8,   1, 0x04, 0x00009080 },
+ { 0x00037c,   1, 0x04, 0x00000001 },
+ { 0x000740,   2, 0x04, 0x00000000 },
+ { 0x002600,   1, 0x04, 0x00000000 },
+ { 0x001918,   1, 0x04, 0x00000000 },
+ { 0x00191c,   1, 0x04, 0x00000900 },
+ { 0x001920,   1, 0x04, 0x00000405 },
+ { 0x001308,   1, 0x04, 0x00000001 },
+ { 0x001924,   1, 0x04, 0x00000000 },
+ { 0x0013ac,   1, 0x04, 0x00000000 },
+ { 0x00192c,   1, 0x04, 0x00000001 },
+ { 0x00193c,   1, 0x04, 0x00002c1c },
+ { 0x000d7c,   1, 0x04, 0x00000000 },
+ { 0x000f8c,   1, 0x04, 0x00000000 },
+ { 0x0002c0,   1, 0x04, 0x00000001 },
+ { 0x001510,   1, 0x04, 0x00000000 },
+ { 0x001940,   1, 0x04, 0x00000000 },
+ { 0x000ff4,   2, 0x04, 0x00000000 },
+ { 0x00194c,   2, 0x04, 0x00000000 },
+ { 0x001968,   1, 0x04, 0x00000000 },
+ { 0x001590,   1, 0x04, 0x0000003f },
+ { 0x0007e8,   4, 0x04, 0x00000000 },
+ { 0x00196c,   1, 0x04, 0x00000011 },
+ { 0x0002e4,   1, 0x04, 0x0000b001 },
+ { 0x00036c,   2, 0x04, 0x00000000 },
+ { 0x00197c,   1, 0x04, 0x00000000 },
+ { 0x000fcc,   2, 0x04, 0x00000000 },
+ { 0x0002d8,   1, 0x04, 0x00000040 },
+ { 0x001980,   1, 0x04, 0x00000080 },
+ { 0x001504,   1, 0x04, 0x00000080 },
+ { 0x001984,   1, 0x04, 0x00000000 },
+ { 0x000300,   1, 0x04, 0x00000001 },
+ { 0x0013a8,   1, 0x04, 0x00000000 },
+ { 0x0012ec,   1, 0x04, 0x00000000 },
+ { 0x001310,   1, 0x04, 0x00000000 },
+ { 0x001314,   1, 0x04, 0x00000001 },
+ { 0x001380,   1, 0x04, 0x00000000 },
+ { 0x001384,   4, 0x04, 0x00000001 },
+ { 0x001394,   1, 0x04, 0x00000000 },
+ { 0x00139c,   1, 0x04, 0x00000000 },
+ { 0x001398,   1, 0x04, 0x00000000 },
+ { 0x001594,   1, 0x04, 0x00000000 },
+ { 0x001598,   4, 0x04, 0x00000001 },
+ { 0x000f54,   3, 0x04, 0x00000000 },
+ { 0x0019bc,   1, 0x04, 0x00000000 },
+ { 0x000f9c,   2, 0x04, 0x00000000 },
+ { 0x0012cc,   1, 0x04, 0x00000000 },
+ { 0x0012e8,   1, 0x04, 0x00000000 },
+ { 0x00130c,   1, 0x04, 0x00000001 },
+ { 0x001360,   8, 0x04, 0x00000000 },
+ { 0x00133c,   2, 0x04, 0x00000001 },
+ { 0x001344,   1, 0x04, 0x00000002 },
+ { 0x001348,   2, 0x04, 0x00000001 },
+ { 0x001350,   1, 0x04, 0x00000002 },
+ { 0x001358,   1, 0x04, 0x00000001 },
+ { 0x0012e4,   1, 0x04, 0x00000000 },
+ { 0x00131c,   4, 0x04, 0x00000000 },
+ { 0x0019c0,   1, 0x04, 0x00000000 },
+ { 0x001140,   1, 0x04, 0x00000000 },
+ { 0x0019c4,   1, 0x04, 0x00000000 },
+ { 0x0019c8,   1, 0x04, 0x00001500 },
+ { 0x00135c,   1, 0x04, 0x00000000 },
+ { 0x000f90,   1, 0x04, 0x00000000 },
+ { 0x0019e0,   8, 0x04, 0x00000001 },
+ { 0x0019cc,   1, 0x04, 0x00000001 },
+ { 0x0015b8,   1, 0x04, 0x00000000 },
+ { 0x001a00,   1, 0x04, 0x00001111 },
+ { 0x001a04,   7, 0x04, 0x00000000 },
+ { 0x000d6c,   2, 0x04, 0xffff0000 },
+ { 0x0010f8,   1, 0x04, 0x00001010 },
+ { 0x000d80,   5, 0x04, 0x00000000 },
+ { 0x000da0,   1, 0x04, 0x00000000 },
+ { 0x0007a4,   2, 0x04, 0x00000000 },
+ { 0x001508,   1, 0x04, 0x80000000 },
+ { 0x00150c,   1, 0x04, 0x40000000 },
+ { 0x001668,   1, 0x04, 0x00000000 },
+ { 0x000318,   2, 0x04, 0x00000008 },
+ { 0x000d9c,   1, 0x04, 0x00000001 },
+ { 0x000ddc,   1, 0x04, 0x00000002 },
+ { 0x000374,   1, 0x04, 0x00000000 },
+ { 0x000378,   1, 0x04, 0x00000020 },
+ { 0x0007dc,   1, 0x04, 0x00000000 },
+ { 0x00074c,   1, 0x04, 0x00000055 },
+ { 0x001420,   1, 0x04, 0x00000003 },
+ { 0x0017bc,   2, 0x04, 0x00000000 },
+ { 0x0017c4,   1, 0x04, 0x00000001 },
+ { 0x001008,   1, 0x04, 0x00000008 },
+ { 0x00100c,   1, 0x04, 0x00000040 },
+ { 0x001010,   1, 0x04, 0x0000012c },
+ { 0x000d60,   1, 0x04, 0x00000040 },
+ { 0x00075c,   1, 0x04, 0x00000003 },
+ { 0x001018,   1, 0x04, 0x00000020 },
+ { 0x00101c,   1, 0x04, 0x00000001 },
+ { 0x001020,   1, 0x04, 0x00000020 },
+ { 0x001024,   1, 0x04, 0x00000001 },
+ { 0x001444,   3, 0x04, 0x00000000 },
+ { 0x000360,   1, 0x04, 0x20164010 },
+ { 0x000364,   1, 0x04, 0x00000020 },
+ { 0x000368,   1, 0x04, 0x00000000 },
+ { 0x000de4,   1, 0x04, 0x00000000 },
+ { 0x000204,   1, 0x04, 0x00000006 },
+ { 0x000208,   1, 0x04, 0x00000000 },
+ { 0x0002cc,   2, 0x04, 0x003fffff },
+ { 0x001220,   1, 0x04, 0x00000005 },
+ { 0x000fdc,   1, 0x04, 0x00000000 },
+ { 0x000f98,   1, 0x04, 0x00400008 },
+ { 0x001284,   1, 0x04, 0x08000080 },
+ { 0x001450,   1, 0x04, 0x00400008 },
+ { 0x001454,   1, 0x04, 0x08000080 },
+ { 0x000214,   1, 0x04, 0x00000000 },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_grctx_init_unk40xx[] = {
+ { 0x404004,   8, 0x04, 0x00000000 },
+ { 0x404024,   1, 0x04, 0x0000e000 },
+ { 0x404028,   8, 0x04, 0x00000000 },
+ { 0x4040a8,   8, 0x04, 0x00000000 },
+ { 0x4040c8,   1, 0x04, 0xf800008f },
+ { 0x4040d0,   6, 0x04, 0x00000000 },
+ { 0x4040e8,   1, 0x04, 0x00001000 },
+ { 0x4040f8,   1, 0x04, 0x00000000 },
+ { 0x404100,  10, 0x04, 0x00000000 },
+ { 0x404130,   2, 0x04, 0x00000000 },
+ { 0x404138,   1, 0x04, 0x20000040 },
+ { 0x404150,   1, 0x04, 0x0000002e },
+ { 0x404154,   1, 0x04, 0x00000400 },
+ { 0x404158,   1, 0x04, 0x00000200 },
+ { 0x404164,   1, 0x04, 0x00000055 },
+ { 0x40417c,   2, 0x04, 0x00000000 },
+ { 0x404194,   1, 0x04, 0x01000700 },
+ { 0x4041a0,   4, 0x04, 0x00000000 },
+ { 0x404200,   1, 0x04, 0x0000a197 },
+ { 0x404204,   1, 0x04, 0x0000a1c0 },
+ { 0x404208,   1, 0x04, 0x0000a140 },
+ { 0x40420c,   1, 0x04, 0x0000902d },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_grctx_init_unk58xx[] = {
+ { 0x405800,   1, 0x04, 0x0f8000bf },
+ { 0x405830,   1, 0x04, 0x02180648 },
+ { 0x405834,   1, 0x04, 0x08000000 },
+ { 0x405838,   1, 0x04, 0x00000000 },
+ { 0x405854,   1, 0x04, 0x00000000 },
+ { 0x405870,   4, 0x04, 0x00000001 },
+ { 0x405a00,   2, 0x04, 0x00000000 },
+ { 0x405a18,   1, 0x04, 0x00000000 },
+ { 0x405a1c,   1, 0x04, 0x000000ff },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_grctx_init_unk64xx[] = {
+ { 0x4064a8,   1, 0x04, 0x00000000 },
+ { 0x4064ac,   1, 0x04, 0x00003fff },
+ { 0x4064b0,   3, 0x04, 0x00000000 },
+ { 0x4064c0,   1, 0x04, 0x802000f0 },
+ { 0x4064c4,   1, 0x04, 0x0192ffff },
+ { 0x4064c8,   1, 0x04, 0x00c20200 },
+ { 0x4064cc,   9, 0x04, 0x00000000 },
+ { 0x4064fc,   1, 0x04, 0x0000022a },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_grctx_init_unk78xx[] = {
+ { 0x407804,   1, 0x04, 0x00000063 },
+ { 0x40780c,   1, 0x04, 0x0a418820 },
+ { 0x407810,   1, 0x04, 0x062080e6 },
+ { 0x407814,   1, 0x04, 0x020398a4 },
+ { 0x407818,   1, 0x04, 0x0e629062 },
+ { 0x40781c,   1, 0x04, 0x0a418820 },
+ { 0x407820,   1, 0x04, 0x000000e6 },
+ { 0x4078bc,   1, 0x04, 0x00000103 },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_grctx_init_unk88xx[] = {
+ { 0x408800,   1, 0x04, 0x32802a3c },
+ { 0x408804,   1, 0x04, 0x00000040 },
+ { 0x408808,   1, 0x04, 0x1003e005 },
+ { 0x408840,   1, 0x04, 0x0000000b },
+ { 0x408900,   1, 0x04, 0xb080b801 },
+ { 0x408904,   1, 0x04, 0x62000001 },
+ { 0x408908,   1, 0x04, 0x02c8102f },
+ { 0x408980,   1, 0x04, 0x0000011d },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_grctx_init_gpc_0[] = {
+ { 0x418380,   1, 0x04, 0x00000016 },
+ { 0x418400,   1, 0x04, 0x38005e00 },
+ { 0x418404,   1, 0x04, 0x71e0ffff },
+ { 0x41840c,   1, 0x04, 0x00001008 },
+ { 0x418410,   1, 0x04, 0x0fff0fff },
+ { 0x418414,   1, 0x04, 0x02200fff },
+ { 0x418450,   6, 0x04, 0x00000000 },
+ { 0x418468,   1, 0x04, 0x00000001 },
+ { 0x41846c,   2, 0x04, 0x00000000 },
+ { 0x418600,   1, 0x04, 0x0000007f },
+ { 0x418684,   1, 0x04, 0x0000001f },
+ { 0x418700,   1, 0x04, 0x00000002 },
+ { 0x418704,   2, 0x04, 0x00000080 },
+ { 0x41870c,   2, 0x04, 0x00000000 },
+ { 0x418800,   1, 0x04, 0x7006863a },
+ { 0x418808,   1, 0x04, 0x00000000 },
+ { 0x41880c,   1, 0x04, 0x00000030 },
+ { 0x418810,   1, 0x04, 0x00000000 },
+ { 0x418828,   1, 0x04, 0x00000044 },
+ { 0x418830,   1, 0x04, 0x10000001 },
+ { 0x4188d8,   1, 0x04, 0x00000008 },
+ { 0x4188e0,   1, 0x04, 0x01000000 },
+ { 0x4188e8,   5, 0x04, 0x00000000 },
+ { 0x4188fc,   1, 0x04, 0x20100058 },
+ { 0x41891c,   1, 0x04, 0x00ff00ff },
+ { 0x418924,   1, 0x04, 0x00000000 },
+ { 0x418928,   1, 0x04, 0x00ffff00 },
+ { 0x41892c,   1, 0x04, 0x0000ff00 },
+ { 0x418b00,   1, 0x04, 0x0000001e },
+ { 0x418b08,   1, 0x04, 0x0a418820 },
+ { 0x418b0c,   1, 0x04, 0x062080e6 },
+ { 0x418b10,   1, 0x04, 0x020398a4 },
+ { 0x418b14,   1, 0x04, 0x0e629062 },
+ { 0x418b18,   1, 0x04, 0x0a418820 },
+ { 0x418b1c,   1, 0x04, 0x000000e6 },
+ { 0x418bb8,   1, 0x04, 0x00000103 },
+ { 0x418c08,   1, 0x04, 0x00000001 },
+ { 0x418c10,   8, 0x04, 0x00000000 },
+ { 0x418c40,   1, 0x04, 0xffffffff },
+ { 0x418c6c,   1, 0x04, 0x00000001 },
+ { 0x418c80,   1, 0x04, 0x2020000c },
+ { 0x418c8c,   1, 0x04, 0x00000001 },
+ { 0x418d24,   1, 0x04, 0x00000000 },
+ { 0x419000,   1, 0x04, 0x00000780 },
+ { 0x419004,   2, 0x04, 0x00000000 },
+ { 0x419014,   1, 0x04, 0x00000004 },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_grctx_init_tpc[] = {
+ { 0x419848,   1, 0x04, 0x00000000 },
+ { 0x419864,   1, 0x04, 0x00000129 },
+ { 0x419888,   1, 0x04, 0x00000000 },
+ { 0x419a00,   1, 0x04, 0x000100f0 },
+ { 0x419a04,   1, 0x04, 0x00000001 },
+ { 0x419a08,   1, 0x04, 0x00000421 },
+ { 0x419a0c,   1, 0x04, 0x00120000 },
+ { 0x419a10,   1, 0x04, 0x00000000 },
+ { 0x419a14,   1, 0x04, 0x00000200 },
+ { 0x419a1c,   1, 0x04, 0x0000c000 },
+ { 0x419a20,   1, 0x04, 0x00000800 },
+ { 0x419a30,   1, 0x04, 0x00000001 },
+ { 0x419ac4,   1, 0x04, 0x0037f440 },
+ { 0x419c00,   1, 0x04, 0x0000001a },
+ { 0x419c04,   1, 0x04, 0x80000006 },
+ { 0x419c08,   1, 0x04, 0x00000002 },
+ { 0x419c20,   1, 0x04, 0x00000000 },
+ { 0x419c24,   1, 0x04, 0x00084210 },
+ { 0x419c28,   1, 0x04, 0x3efbefbe },
+ { 0x419ce8,   1, 0x04, 0x00000000 },
+ { 0x419cf4,   1, 0x04, 0x00000203 },
+ { 0x419e04,   1, 0x04, 0x00000000 },
+ { 0x419e08,   1, 0x04, 0x0000001d },
+ { 0x419e0c,   1, 0x04, 0x00000000 },
+ { 0x419e10,   1, 0x04, 0x00001c02 },
+ { 0x419e44,   1, 0x04, 0x0013eff2 },
+ { 0x419e48,   1, 0x04, 0x00000000 },
+ { 0x419e4c,   1, 0x04, 0x0000007f },
+ { 0x419e50,   2, 0x04, 0x00000000 },
+ { 0x419e58,   1, 0x04, 0x00000001 },
+ { 0x419e5c,   3, 0x04, 0x00000000 },
+ { 0x419e68,   1, 0x04, 0x00000002 },
+ { 0x419e6c,  12, 0x04, 0x00000000 },
+ { 0x419eac,   1, 0x04, 0x00001f8f },
+ { 0x419eb0,   1, 0x04, 0x0db00da0 },
+ { 0x419eb8,   1, 0x04, 0x00000000 },
+ { 0x419ec8,   1, 0x04, 0x0001304f },
+ { 0x419f30,   4, 0x04, 0x00000000 },
+ { 0x419f40,   1, 0x04, 0x00000018 },
+ { 0x419f44,   3, 0x04, 0x00000000 },
+ { 0x419f58,   1, 0x04, 0x00000020 },
+ { 0x419f70,   1, 0x04, 0x00000000 },
+ { 0x419f78,   1, 0x04, 0x000001eb },
+ { 0x419f7c,   1, 0x04, 0x00000404 },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_grctx_init_unk[] = {
+ { 0x41be24,   1, 0x04, 0x00000006 },
+ { 0x41bec0,   1, 0x04, 0x10000000 },
+ { 0x41bec4,   1, 0x04, 0x00037f7f },
+ { 0x41bee4,   1, 0x04, 0x00000000 },
+ { 0x41bef0,   1, 0x04, 0x000003ff },
+ { 0x41bf00,   1, 0x04, 0x0a418820 },
+ { 0x41bf04,   1, 0x04, 0x062080e6 },
+ { 0x41bf08,   1, 0x04, 0x020398a4 },
+ { 0x41bf0c,   1, 0x04, 0x0e629062 },
+ { 0x41bf10,   1, 0x04, 0x0a418820 },
+ { 0x41bf14,   1, 0x04, 0x000000e6 },
+ { 0x41bfd0,   1, 0x04, 0x00900103 },
+ { 0x41bfe0,   1, 0x04, 0x00400001 },
+ { 0x41bfe4,   1, 0x04, 0x00000000 },
+ {}
+};
+
+static void
+nv108_grctx_generate_mods(struct nvc0_graph_priv *priv, struct nvc0_grctx *info)
+{
+ u32 magic[GPC_MAX][2];
+ u32 offset;
+ int gpc;
+
+ mmio_data(0x003000, 0x0100, NV_MEM_ACCESS_RW | NV_MEM_ACCESS_SYS);
+ mmio_data(0x008000, 0x0100, NV_MEM_ACCESS_RW | NV_MEM_ACCESS_SYS);
+ mmio_data(0x060000, 0x1000, NV_MEM_ACCESS_RW);
+ mmio_list(0x40800c, 0x00000000,  8, 1);
+ mmio_list(0x408010, 0x80000000,  0, 0);
+ mmio_list(0x419004, 0x00000000,  8, 1);
+ mmio_list(0x419008, 0x00000000,  0, 0);
+ mmio_list(0x408004, 0x00000000,  8, 0);
+ mmio_list(0x408008, 0x80000030,  0, 0);
+ mmio_list(0x418808, 0x00000000,  8, 0);
+ mmio_list(0x41880c, 0x80000030,  0, 0);
+ mmio_list(0x418810, 0x80000000, 12, 2);
+ mmio_list(0x419848, 0x10000000, 12, 2);
+
+ mmio_list(0x405830, 0x02180648,  0, 0);
+ mmio_list(0x4064c4, 0x0192ffff,  0, 0);
+
+ for (gpc = 0, offset = 0; gpc < priv->gpc_nr; gpc++) {
+  u16 magic0 = 0x0218 * priv->tpc_nr[gpc];
+  u16 magic1 = 0x0648 * priv->tpc_nr[gpc];
+  magic[gpc][0]  = 0x10000000 | (magic0 << 16) | offset;
+  magic[gpc][1]  = 0x00000000 | (magic1 << 16);
+  offset += 0x0324 * priv->tpc_nr[gpc];
+ }
+
+ for (gpc = 0; gpc < priv->gpc_nr; gpc++) {
+  mmio_list(GPC_UNIT(gpc, 0x30c0), magic[gpc][0], 0, 0);
+  mmio_list(GPC_UNIT(gpc, 0x30e4), magic[gpc][1] | offset, 0, 0);
+  offset += 0x07ff * priv->tpc_nr[gpc];
+ }
+
+ mmio_list(0x17e91c, 0x0b040a0b, 0, 0);
+ mmio_list(0x17e920, 0x00090d08, 0, 0);
+}
+
+static struct nvc0_graph_init *
+nv108_grctx_init_hub[] = {
+ nvc0_grctx_init_base,
+ nv108_grctx_init_unk40xx,
+ nvf0_grctx_init_unk44xx,
+ nve4_grctx_init_unk46xx,
+ nve4_grctx_init_unk47xx,
+ nv108_grctx_init_unk58xx,
+ nvf0_grctx_init_unk5bxx,
+ nvf0_grctx_init_unk60xx,
+ nv108_grctx_init_unk64xx,
+ nv108_grctx_init_unk78xx,
+ nve4_grctx_init_unk80xx,
+ nv108_grctx_init_unk88xx,
+ NULL
+};
+
+struct nvc0_graph_init *
+nv108_grctx_init_gpc[] = {
+ nv108_grctx_init_gpc_0,
+ nvc0_grctx_init_gpc_1,
+ nv108_grctx_init_tpc,
+ nv108_grctx_init_unk,
+ NULL
+};
+
+struct nvc0_graph_init
+nv108_grctx_init_mthd_magic[] = {
+ { 0x3410, 1, 0x04, 0x8e0e2006 },
+ { 0x3414, 1, 0x04, 0x00000038 },
+ {}
+};
+
+static struct nvc0_graph_mthd
+nv108_grctx_init_mthd[] = {
+ { 0xa197, nv108_grctx_init_a197, },
+ { 0x902d, nvc0_grctx_init_902d, },
+ { 0x902d, nv108_grctx_init_mthd_magic, },
+ {}
+};
+
+struct nouveau_oclass *
+nv108_grctx_oclass = &(struct nvc0_grctx_oclass) {
+ .base.handle = NV_ENGCTX(GR, 0x08),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nvc0_graph_context_ctor,
+  .dtor = nvc0_graph_context_dtor,
+  .init = _nouveau_graph_context_init,
+  .fini = _nouveau_graph_context_fini,
+  .rd32 = _nouveau_graph_context_rd32,
+  .wr32 = _nouveau_graph_context_wr32,
+ },
+ .main = nve4_grctx_generate_main,
+ .mods = nv108_grctx_generate_mods,
+ .unkn = nve4_grctx_generate_unkn,
+ .hub  = nv108_grctx_init_hub,
+ .gpc  = nv108_grctx_init_gpc,
+ .icmd = nv108_grctx_init_icmd,
+ .mthd = nv108_grctx_init_mthd,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/ctxnvf0.c b/drivers/gpu/drm/nouveau/core/engine/graph/ctxnvf0.c
index dcb2ebb..44012c3 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/ctxnvf0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/ctxnvf0.c
@@ -50,7 +50,7 @@ nvf0_grctx_init_unk40xx[] = {
  {}
 };
 
-static struct nvc0_graph_init
+struct nvc0_graph_init
 nvf0_grctx_init_unk44xx[] = {
  { 0x404404,  12, 0x04, 0x00000000 },
  { 0x404438,   1, 0x04, 0x00000000 },
@@ -62,7 +62,7 @@ nvf0_grctx_init_unk44xx[] = {
  {}
 };
 
-static struct nvc0_graph_init
+struct nvc0_graph_init
 nvf0_grctx_init_unk5bxx[] = {
  { 0x405b00,   1, 0x04, 0x00000000 },
  { 0x405b10,   1, 0x04, 0x00001000 },
@@ -70,7 +70,7 @@ nvf0_grctx_init_unk5bxx[] = {
  {}
 };
 
-static struct nvc0_graph_init
+struct nvc0_graph_init
 nvf0_grctx_init_unk60xx[] = {
  { 0x406020,   1, 0x04, 0x034103c1 },
  { 0x406028,   4, 0x04, 0x00000001 },
@@ -286,7 +286,6 @@ nvf0_grctx_init_hub[] = {
  nvf0_grctx_init_unk64xx,
  nve4_grctx_init_unk80xx,
  nvf0_grctx_init_unk88xx,
- nvd9_grctx_init_rop,
  NULL
 };
 
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/com.fuc b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/com.fuc
index 5d24b6d..e148961 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/com.fuc
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/com.fuc
@@ -38,7 +38,7 @@ queue_put:
  cmpu b32 $r8 $r9
  bra ne #queue_put_next
   mov $r15 E_CMD_OVERFLOW
-  call #error
+  call(error)
   ret
 
  // store cmd/data on queue
@@ -92,18 +92,16 @@ queue_get_done:
 // Out: $r15 value
 //
 nv_rd32:
- mov $r11 0x728
- shl b32 $r11 6
  mov b32 $r12 $r14
  bset $r12 31   // MMIO_CTRL_PENDING
- iowr I[$r11 + 0x000] $r12 // MMIO_CTRL
+ nv_iowr(NV_PGRAPH_FECS_MMIO_CTRL, 0, $r12)
  nv_rd32_wait:
-  iord $r12 I[$r11 + 0x000]
+  nv_iord($r12, NV_PGRAPH_FECS_MMIO_CTRL, 0)
   xbit $r12 $r12 31
   bra ne #nv_rd32_wait
  mov $r10 6   // DONE_MMIO_RD
- call #wait_doneo
- iord $r15 I[$r11 + 0x100] // MMIO_RDVAL
+ call(wait_doneo)
+ nv_iord($r15, NV_PGRAPH_FECS_MMIO_RDVAL, 0)
  ret
 
 // nv_wr32 - write 32-bit value to nv register
@@ -112,37 +110,17 @@ nv_rd32:
 //      $r15 value
 //
 nv_wr32:
- mov $r11 0x728
- shl b32 $r11 6
- iowr I[$r11 + 0x200] $r15 // MMIO_WRVAL
+ nv_iowr(NV_PGRAPH_FECS_MMIO_WRVAL, 0, $r15)
  mov b32 $r12 $r14
  bset $r12 31   // MMIO_CTRL_PENDING
  bset $r12 30   // MMIO_CTRL_WRITE
- iowr I[$r11 + 0x000] $r12 // MMIO_CTRL
+ nv_iowr(NV_PGRAPH_FECS_MMIO_CTRL, 0, $r12)
  nv_wr32_wait:
-  iord $r12 I[$r11 + 0x000]
+  nv_iord($r12, NV_PGRAPH_FECS_MMIO_CTRL, 0)
   xbit $r12 $r12 31
   bra ne #nv_wr32_wait
  ret
 
-// (re)set watchdog timer
-//
-// In : $r15 timeout
-//
-watchdog_reset:
- mov $r8 0x430
- shl b32 $r8 6
- bset $r15 31
- iowr I[$r8 + 0x000] $r15
- ret
-
-// clear watchdog timer
-watchdog_clear:
- mov $r8 0x430
- shl b32 $r8 6
- iowr I[$r8 + 0x000] $r0
- ret
-
 // wait_donez - wait on FUC_DONE bit to become clear
 //
 // In : $r10 bit to wait on
@@ -163,13 +141,9 @@ wait_donez:
 //
 wait_doneo:
  trace_set(T_WAIT);
- mov $r8 0x818
- shl b32 $r8 6
- iowr I[$r8 + 0x000] $r10
+ nv_iowr(NV_PGRAPH_FECS_CC_SCRATCH_VAL(6), 0, $r10)
  wait_doneo_e:
-  mov $r8 0x400
-  shl b32 $r8 6
-  iord $r8 I[$r8 + 0x000]
+  nv_iord($r8, NV_PGRAPH_FECS_SIGNAL, 0)
   xbit $r8 $r8 $r10
   bra e #wait_doneo_e
  trace_clr(T_WAIT)
@@ -209,21 +183,18 @@ mmctx_size:
 //
 mmctx_xfer:
  trace_set(T_MMCTX)
- mov $r8 0x710
- shl b32 $r8 6
  clear b32 $r9
  or $r11 $r11
  bra e #mmctx_base_disabled
-  iowr I[$r8 + 0x000] $r11 // MMCTX_BASE
+  nv_iowr(NV_PGRAPH_FECS_MMCTX_BASE, 0, $r11)
   bset $r9 0   // BASE_EN
  mmctx_base_disabled:
  or $r14 $r14
  bra e #mmctx_multi_disabled
-  iowr I[$r8 + 0x200] $r14  // MMCTX_MULTI_STRIDE
-  iowr I[$r8 + 0x300] $r15  // MMCTX_MULTI_MASK
+  nv_iowr(NV_PGRAPH_FECS_MMCTX_MULTI_STRIDE, 0, $r14)
+  nv_iowr(NV_PGRAPH_FECS_MMCTX_MULTI_MASK, 0, $r15)
   bset $r9 1   // MULTI_EN
  mmctx_multi_disabled:
- add b32 $r8 0x100
 
  xbit $r11 $r10 0
  shl b32 $r11 16   // DIR
@@ -231,20 +202,20 @@ mmctx_xfer:
  xbit $r14 $r10 1
  shl b32 $r14 17
  or $r11 $r14   // START_TRIGGER
- iowr I[$r8 + 0x000] $r11 // MMCTX_CTRL
+ nv_iowr(NV_PGRAPH_FECS_MMCTX_CTRL, 0, $r11)
 
  // loop over the mmio list, and send requests to the hw
  mmctx_exec_loop:
   // wait for space in mmctx queue
   mmctx_wait_free:
-   iord $r14 I[$r8 + 0x000] // MMCTX_CTRL
+   nv_iord($r14, NV_PGRAPH_FECS_MMCTX_CTRL, 0)
    and $r14 0x1f
    bra e #mmctx_wait_free
 
   // queue up an entry
   ld b32 $r14 D[$r12]
   or $r14 $r9
-  iowr I[$r8 + 0x300] $r14
+  nv_iowr(NV_PGRAPH_FECS_MMCTX_QUEUE, 0, $r14)
   add b32 $r12 4
   cmpu b32 $r12 $r13
   bra ne #mmctx_exec_loop
@@ -253,22 +224,22 @@ mmctx_xfer:
  bra ne #mmctx_stop
   // wait for queue to empty
   mmctx_fini_wait:
-   iord $r11 I[$r8 + 0x000] // MMCTX_CTRL
+   nv_iord($r11, NV_PGRAPH_FECS_MMCTX_CTRL, 0)
    and $r11 0x1f
    cmpu b32 $r11 0x10
    bra ne #mmctx_fini_wait
   mov $r10 2    // DONE_MMCTX
-  call #wait_donez
+  call(wait_donez)
   bra #mmctx_done
  mmctx_stop:
   xbit $r11 $r10 0
   shl b32 $r11 16   // DIR
   bset $r11 12   // QLIMIT = 0x10
   bset $r11 18   // STOP_TRIGGER
-  iowr I[$r8 + 0x000] $r11 // MMCTX_CTRL
+  nv_iowr(NV_PGRAPH_FECS_MMCTX_CTRL, 0, $r11)
   mmctx_stop_wait:
    // wait for STOP_TRIGGER to clear
-   iord $r11 I[$r8 + 0x000] // MMCTX_CTRL
+   nv_iord($r11, NV_PGRAPH_FECS_MMCTX_CTRL, 0)
    xbit $r11 $r11 18
    bra ne #mmctx_stop_wait
  mmctx_done:
@@ -280,28 +251,24 @@ mmctx_xfer:
 strand_wait:
  push $r10
  mov $r10 2
- call #wait_donez
+ call(wait_donez)
  pop $r10
  ret
 
 // unknown - call before issuing strand commands
 //
 strand_pre:
- mov $r8 0x4afc
- sethi $r8 0x20000
- mov $r9 0xc
- iowr I[$r8] $r9
- call #strand_wait
+ mov $r9 NV_PGRAPH_FECS_STRAND_CMD_ENABLE
+ nv_iowr(NV_PGRAPH_FECS_STRAND_CMD, 0x3f, $r9)
+ call(strand_wait)
  ret
 
 // unknown - call after issuing strand commands
 //
 strand_post:
- mov $r8 0x4afc
- sethi $r8 0x20000
- mov $r9 0xd
- iowr I[$r8] $r9
- call #strand_wait
+ mov $r9 NV_PGRAPH_FECS_STRAND_CMD_DISABLE
+ nv_iowr(NV_PGRAPH_FECS_STRAND_CMD, 0x3f, $r9)
+ call(strand_wait)
  ret
 
 // Selects strand set?!
@@ -309,18 +276,14 @@ strand_post:
 // In: $r14 id
 //
 strand_set:
- mov $r10 0x4ffc
- sethi $r10 0x20000
- sub b32 $r11 $r10 0x500
  mov $r12 0xf
- iowr I[$r10 + 0x000] $r12  // 0x93c = 0xf
- mov $r12 0xb
- iowr I[$r11 + 0x000] $r12  // 0x928 = 0xb
- call #strand_wait
- iowr I[$r10 + 0x000] $r14  // 0x93c = <id>
- mov $r12 0xa
- iowr I[$r11 + 0x000] $r12  // 0x928 = 0xa
- call #strand_wait
+ nv_iowr(NV_PGRAPH_FECS_STRAND_FILTER, 0x3f, $r12)
+ mov $r12 NV_PGRAPH_FECS_STRAND_CMD_DEACTIVATE_FILTER
+ nv_iowr(NV_PGRAPH_FECS_STRAND_CMD, 0x3f, $r12)
+ nv_iowr(NV_PGRAPH_FECS_STRAND_FILTER, 0x3f, $r14)
+ mov $r12 NV_PGRAPH_FECS_STRAND_CMD_ACTIVATE_FILTER
+ nv_iowr(NV_PGRAPH_FECS_STRAND_CMD, 0x3f, $r12)
+ call(strand_wait)
  ret
 
 // Initialise strand context data
@@ -332,30 +295,27 @@ strand_set:
 //
 strand_ctx_init:
  trace_set(T_STRINIT)
- call #strand_pre
+ call(strand_pre)
  mov $r14 3
- call #strand_set
- mov $r10 0x46fc
- sethi $r10 0x20000
- add b32 $r11 $r10 0x400
- iowr I[$r10 + 0x100] $r0 // STRAND_FIRST_GENE = 0
- mov $r12 1
- iowr I[$r11 + 0x000] $r12 // STRAND_CMD = LATCH_FIRST_GENE
- call #strand_wait
+ call(strand_set)
+
+ clear b32 $r12
+ nv_iowr(NV_PGRAPH_FECS_STRAND_SELECT, 0x3f, $r12)
+ mov $r12 NV_PGRAPH_FECS_STRAND_CMD_SEEK
+ nv_iowr(NV_PGRAPH_FECS_STRAND_CMD, 0x3f, $r12)
+ call(strand_wait)
  sub b32 $r12 $r0 1
- iowr I[$r10 + 0x000] $r12 // STRAND_GENE_CNT = 0xffffffff
- mov $r12 2
- iowr I[$r11 + 0x000] $r12 // STRAND_CMD = LATCH_GENE_CNT
- call #strand_wait
- call #strand_post
+ nv_iowr(NV_PGRAPH_FECS_STRAND_DATA, 0x3f, $r12)
+ mov $r12 NV_PGRAPH_FECS_STRAND_CMD_GET_INFO
+ nv_iowr(NV_PGRAPH_FECS_STRAND_CMD, 0x3f, $r12)
+ call(strand_wait)
+ call(strand_post)
 
  // read the size of each strand, poke the context offset of
  // each into STRAND_{SAVE,LOAD}_SWBASE now, no need to worry
  // about it later then.
- mov $r8 0x880
- shl b32 $r8 6
- iord $r9 I[$r8 + 0x000]  // STRANDS
- add b32 $r8 0x2200
+ nv_mkio($r8, NV_PGRAPH_FECS_STRAND_SAVE_SWBASE, 0x00)
+ nv_iord($r9, NV_PGRAPH_FECS_STRANDS_CNT, 0x00)
  shr b32 $r14 $r15 8
  ctx_init_strand_loop:
   iowr I[$r8 + 0x000] $r14 // STRAND_SAVE_SWBASE
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpc.fuc b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpc.fuc
index 5547c1b..96cbcea 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpc.fuc
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpc.fuc
@@ -58,12 +58,9 @@ mmio_list_base:
 //
 error:
  push $r14
- mov $r14 -0x67ec  // 0x9814
- sethi $r14 0x400000
- call #nv_wr32  // HUB_CTXCTL_CC_SCRATCH[5] = error code
- add b32 $r14 0x41c
+ nv_wr32(NV_PGRAPH_FECS_CC_SCRATCH_VAL(5), $r15)
  mov $r15 1
- call #nv_wr32  // HUB_CTXCTL_INTR_UP_SET
+ nv_wr32(NV_PGRAPH_FECS_INTR_UP_SET, $r15)
  pop $r14
  ret
 
@@ -84,46 +81,40 @@ init:
  mov $sp $r0
 
  // enable fifo access
- mov $r1 0x1200
- mov $r2 2
- iowr I[$r1 + 0x000] $r2  // FIFO_ENABLE
+ mov $r2 NV_PGRAPH_GPCX_GPCCS_ACCESS_FIFO
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_ACCESS, 0, $r2)
 
  // setup i0 handler, and route all interrupts to it
  mov $r1 #ih
  mov $iv0 $r1
- mov $r1 0x400
- iowr I[$r1 + 0x300] $r0  // INTR_DISPATCH
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_INTR_ROUTE, 0, $r0)
 
  // enable fifo interrupt
- mov $r2 4
- iowr I[$r1 + 0x000] $r2  // INTR_EN_SET
+ mov $r2 NV_PGRAPH_GPCX_GPCCS_INTR_EN_SET_FIFO
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_INTR_EN_SET, 0, $r2)
 
  // enable interrupts
  bset $flags ie0
 
  // figure out which GPC we are, and how many TPCs we have
- mov $r1 0x608
- shl b32 $r1 6
- iord $r2 I[$r1 + 0x000]  // UNITS
+ nv_iord($r2, NV_PGRAPH_GPCX_GPCCS_UNITS, 0)
  mov $r3 1
  and $r2 0x1f
  shl b32 $r3 $r2
  sub b32 $r3 1
  st b32 D[$r0 + #tpc_count] $r2
  st b32 D[$r0 + #tpc_mask] $r3
- add b32 $r1 0x400
- iord $r2 I[$r1 + 0x000]  // MYINDEX
+ nv_iord($r2, NV_PGRAPH_GPCX_GPCCS_MYINDEX, 0)
  st b32 D[$r0 + #gpc_id] $r2
 
 #if NV_PGRAPH_GPCX_UNK__SIZE > 0
  // figure out which, and how many, UNKs are actually present
- mov $r14 0x0c30
- sethi $r14 0x500000
+ imm32($r14, 0x500c30)
  clear b32 $r2
  clear b32 $r3
  clear b32 $r4
  init_unk_loop:
-  call #nv_rd32
+  call(nv_rd32)
   cmp b32 $r15 0
   bra z #init_unk_next
    mov $r15 1
@@ -146,23 +137,21 @@ init:
 
  // set mmctx base addresses now so we don't have to do it later,
  // they don't currently ever change
- mov $r4 0x700
- shl b32 $r4 6
  shr b32 $r5 $r2 8
- iowr I[$r4 + 0x000] $r5  // MMCTX_SAVE_SWBASE
- iowr I[$r4 + 0x100] $r5  // MMCTX_LOAD_SWBASE
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_MMCTX_SAVE_SWBASE, 0, $r5)
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_MMCTX_LOAD_SWBASE, 0, $r5)
 
  // calculate GPC mmio context size
  ld b32 $r14 D[$r0 + #gpc_mmio_list_head]
  ld b32 $r15 D[$r0 + #gpc_mmio_list_tail]
- call #mmctx_size
+ call(mmctx_size)
  add b32 $r2 $r15
  add b32 $r3 $r15
 
  // calculate per-TPC mmio context size
  ld b32 $r14 D[$r0 + #tpc_mmio_list_head]
  ld b32 $r15 D[$r0 + #tpc_mmio_list_tail]
- call #mmctx_size
+ call(mmctx_size)
  ld b32 $r14 D[$r0 + #tpc_count]
  mulu $r14 $r15
  add b32 $r2 $r14
@@ -172,7 +161,7 @@ init:
  // calculate per-UNK mmio context size
  ld b32 $r14 D[$r0 + #unk_mmio_list_head]
  ld b32 $r15 D[$r0 + #unk_mmio_list_tail]
- call #mmctx_size
+ call(mmctx_size)
  ld b32 $r14 D[$r0 + #unk_count]
  mulu $r14 $r15
  add b32 $r2 $r14
@@ -180,9 +169,8 @@ init:
 #endif
 
  // round up base/size to 256 byte boundary (for strand SWBASE)
- add b32 $r4 0x1300
  shr b32 $r3 2
- iowr I[$r4 + 0x000] $r3  // MMCTX_LOAD_COUNT, wtf for?!?
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_MMCTX_LOAD_COUNT, 0, $r3) // wtf for?!
  shr b32 $r2 8
  shr b32 $r3 6
  add b32 $r2 1
@@ -192,7 +180,7 @@ init:
 
  // calculate size of strand context data
  mov b32 $r15 $r2
- call #strand_ctx_init
+ call(strand_ctx_init)
  add b32 $r3 $r15
 
  // save context size, and tell HUB we're done
@@ -208,7 +196,7 @@ main:
  bset $flags $p0
  sleep $p0
  mov $r13 #cmd_queue
- call #queue_get
+ call(queue_get)
  bra $p1 #main
 
  // 0x0000-0x0003 are all context transfers
@@ -224,13 +212,13 @@ main:
   or $r1 $r14
   mov $flags $r1
   // transfer context data
-  call #ctx_xfer
+  call(ctx_xfer)
   bra #main
 
  main_not_ctx_xfer:
  shl b32 $r15 $r14 16
  or $r15 E_BAD_COMMAND
- call #error
+ call(error)
  bra #main
 
 // interrupt handler
@@ -247,22 +235,20 @@ ih:
  clear b32 $r0
 
  // incoming fifo command?
- iord $r10 I[$r0 + 0x200] // INTR
- and $r11 $r10 0x00000004
+ nv_iord($r10, NV_PGRAPH_GPCX_GPCCS_INTR, 0)
+ and $r11 $r10 NV_PGRAPH_GPCX_GPCCS_INTR_FIFO
  bra e #ih_no_fifo
   // queue incoming fifo command for later processing
-  mov $r11 0x1900
   mov $r13 #cmd_queue
-  iord $r14 I[$r11 + 0x100] // FIFO_CMD
-  iord $r15 I[$r11 + 0x000] // FIFO_DATA
-  call #queue_put
-  add b32 $r11 0x400
+  nv_iord($r14, NV_PGRAPH_GPCX_GPCCS_FIFO_CMD, 0)
+  nv_iord($r15, NV_PGRAPH_GPCX_GPCCS_FIFO_DATA, 0)
+  call(queue_put)
   mov $r14 1
-  iowr I[$r11 + 0x000] $r14 // FIFO_ACK
+  nv_iowr(NV_PGRAPH_GPCX_GPCCS_FIFO_ACK, 0, $r14)
 
  // ack, and wake up main()
  ih_no_fifo:
- iowr I[$r0 + 0x100] $r10 // INTR_ACK
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_INTR_ACK, 0, $r10)
 
  pop $r15
  pop $r14
@@ -283,9 +269,7 @@ hub_barrier_done:
  mov $r15 1
  ld b32 $r14 D[$r0 + #gpc_id]
  shl b32 $r15 $r14
- mov $r14 -0x6be8  // 0x409418 - HUB_BAR_SET
- sethi $r14 0x400000
- call #nv_wr32
+ nv_wr32(0x409418, $r15) // 0x409418 - HUB_BAR_SET
  ret
 
 // Disables various things, waits a bit, and re-enables them..
@@ -295,16 +279,15 @@ hub_barrier_done:
 // funny things happen.
 //
 ctx_redswitch:
- mov $r14 0x614
- shl b32 $r14 6
- mov $r15 0x020
- iowr I[$r14] $r15 // GPC_RED_SWITCH = POWER
- mov $r15 8
+ mov $r15 NV_PGRAPH_GPCX_GPCCS_RED_SWITCH_POWER
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_RED_SWITCH, 0, $r15)
+ mov $r14 8
  ctx_redswitch_delay:
-  sub b32 $r15 1
+  sub b32 $r14 1
   bra ne #ctx_redswitch_delay
- mov $r15 0xa20
- iowr I[$r14] $r15 // GPC_RED_SWITCH = UNK11, ENABLE, POWER
+ or $r15 NV_PGRAPH_GPCX_GPCCS_RED_SWITCH_UNK11
+ or $r15 NV_PGRAPH_GPCX_GPCCS_RED_SWITCH_ENABLE
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_RED_SWITCH, 0, $r15)
  ret
 
 // Transfer GPC context data between GPU and storage area
@@ -317,46 +300,37 @@ ctx_redswitch:
 //
 ctx_xfer:
  // set context base address
- mov $r1 0xa04
- shl b32 $r1 6
- iowr I[$r1 + 0x000] $r15// MEM_BASE
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_MEM_BASE, 0, $r15)
  bra not $p1 #ctx_xfer_not_load
-  call #ctx_redswitch
+  call(ctx_redswitch)
  ctx_xfer_not_load:
 
  // strands
- mov $r1 0x4afc
- sethi $r1 0x20000
- mov $r2 0xc
- iowr I[$r1] $r2  // STRAND_CMD(0x3f) = 0x0c
- call #strand_wait
- mov $r2 0x47fc
- sethi $r2 0x20000
- iowr I[$r2] $r0  // STRAND_FIRST_GENE(0x3f) = 0x00
- xbit $r2 $flags $p1
- add b32 $r2 3
- iowr I[$r1] $r2  // STRAND_CMD(0x3f) = 0x03/0x04 (SAVE/LOAD)
+ call(strand_pre)
+ clear b32 $r2
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_STRAND_SELECT, 0x3f, $r2)
+ xbit $r2 $flags $p1 // SAVE/LOAD
+ add b32 $r2 NV_PGRAPH_GPCX_GPCCS_STRAND_CMD_SAVE
+ nv_iowr(NV_PGRAPH_GPCX_GPCCS_STRAND_CMD, 0x3f, $r2)
 
  // mmio context
  xbit $r10 $flags $p1 // direction
  or $r10 2  // first
- mov $r11 0x0000
- sethi $r11 0x500000
+ imm32($r11,0x500000)
  ld b32 $r12 D[$r0 + #gpc_id]
  shl b32 $r12 15
  add b32 $r11 $r12 // base = NV_PGRAPH_GPCn
  ld b32 $r12 D[$r0 + #gpc_mmio_list_head]
  ld b32 $r13 D[$r0 + #gpc_mmio_list_tail]
  mov $r14 0  // not multi
- call #mmctx_xfer
+ call(mmctx_xfer)
 
  // per-TPC mmio context
  xbit $r10 $flags $p1 // direction
 #if !NV_PGRAPH_GPCX_UNK__SIZE
  or $r10 4  // last
 #endif
- mov $r11 0x4000
- sethi $r11 0x500000 // base = NV_PGRAPH_GPC0_TPC0
+ imm32($r11, 0x504000)
  ld b32 $r12 D[$r0 + #gpc_id]
  shl b32 $r12 15
  add b32 $r11 $r12 // base = NV_PGRAPH_GPCn_TPC0
@@ -364,14 +338,13 @@ ctx_xfer:
  ld b32 $r13 D[$r0 + #tpc_mmio_list_tail]
  ld b32 $r15 D[$r0 + #tpc_mask]
  mov $r14 0x800  // stride = 0x800
- call #mmctx_xfer
+ call(mmctx_xfer)
 
 #if NV_PGRAPH_GPCX_UNK__SIZE > 0
  // per-UNK mmio context
  xbit $r10 $flags $p1 // direction
  or $r10 4  // last
- mov $r11 0x3000
- sethi $r11 0x500000 // base = NV_PGRAPH_GPC0_UNK0
+ imm32($r11, 0x503000)
  ld b32 $r12 D[$r0 + #gpc_id]
  shl b32 $r12 15
  add b32 $r11 $r12 // base = NV_PGRAPH_GPCn_UNK0
@@ -379,11 +352,11 @@ ctx_xfer:
  ld b32 $r13 D[$r0 + #unk_mmio_list_tail]
  ld b32 $r15 D[$r0 + #unk_mask]
  mov $r14 0x200  // stride = 0x200
- call #mmctx_xfer
+ call(mmctx_xfer)
 #endif
 
  // wait for strands to finish
- call #strand_wait
+ call(strand_wait)
 
  // if load, or a save without a load following, do some
  // unknown stuff that's done after finishing a block of
@@ -391,14 +364,10 @@ ctx_xfer:
  bra $p1 #ctx_xfer_post
  bra not $p2 #ctx_xfer_done
  ctx_xfer_post:
-  mov $r1 0x4afc
-  sethi $r1 0x20000
-  mov $r2 0xd
-  iowr I[$r1] $r2  // STRAND_CMD(0x3f) = 0x0d
-  call #strand_wait
+  call(strand_post)
 
  // mark completion in HUB's barrier
  ctx_xfer_done:
- call #hub_barrier_done
+ call(hub_barrier_done)
  ret
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnv108.fuc5 b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnv108.fuc5
new file mode 100644
index 0000000..bd30262
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnv108.fuc5
@@ -0,0 +1,42 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs <bskeggs@redhat.com>
+ */
+
+#define NV_PGRAPH_GPCX_UNK__SIZE                                     0x00000001
+
+#define CHIPSET GK208
+#include "macros.fuc"
+
+.section #nv108_grgpc_data
+#define INCLUDE_DATA
+#include "com.fuc"
+#include "gpc.fuc"
+#undef INCLUDE_DATA
+
+.section #nv108_grgpc_code
+#define INCLUDE_CODE
+bra #init
+#include "com.fuc"
+#include "gpc.fuc"
+.align 256
+#undef INCLUDE_CODE
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnv108.fuc5.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnv108.fuc5.h
new file mode 100644
index 0000000..27dc128
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnv108.fuc5.h
@@ -0,0 +1,473 @@
+uint32_t nv108_grgpc_data[] = {
+/* 0x0000: gpc_mmio_list_head */
+ 0x0000006c,
+/* 0x0004: gpc_mmio_list_tail */
+/* 0x0004: tpc_mmio_list_head */
+ 0x0000006c,
+/* 0x0008: tpc_mmio_list_tail */
+/* 0x0008: unk_mmio_list_head */
+ 0x0000006c,
+/* 0x000c: unk_mmio_list_tail */
+ 0x0000006c,
+/* 0x0010: gpc_id */
+ 0x00000000,
+/* 0x0014: tpc_count */
+ 0x00000000,
+/* 0x0018: tpc_mask */
+ 0x00000000,
+/* 0x001c: unk_count */
+ 0x00000000,
+/* 0x0020: unk_mask */
+ 0x00000000,
+/* 0x0024: cmd_queue */
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+};
+
+uint32_t nv108_grgpc_code[] = {
+ 0x03140ef5,
+/* 0x0004: queue_put */
+ 0x9800d898,
+ 0x86f001d9,
+ 0xf489a408,
+ 0x020f0b1b,
+ 0x0002f87e,
+/* 0x001a: queue_put_next */
+ 0x98c400f8,
+ 0x0384b607,
+ 0xb6008dbb,
+ 0x8eb50880,
+ 0x018fb500,
+ 0xf00190b6,
+ 0xd9b50f94,
+/* 0x0037: queue_get */
+ 0xf400f801,
+ 0xd8980131,
+ 0x01d99800,
+ 0x0bf489a4,
+ 0x0789c421,
+ 0xbb0394b6,
+ 0x90b6009d,
+ 0x009e9808,
+ 0xb6019f98,
+ 0x84f00180,
+ 0x00d8b50f,
+/* 0x0063: queue_get_done */
+ 0xf80132f4,
+/* 0x0065: nv_rd32 */
+ 0xf0ecb200,
+ 0x00801fc9,
+ 0x0cf601ca,
+/* 0x0073: nv_rd32_wait */
+ 0x8c04bd00,
+ 0xcf01ca00,
+ 0xccc800cc,
+ 0xf61bf41f,
+ 0xec7e060a,
+ 0x008f0000,
+ 0xffcf01cb,
+/* 0x008f: nv_wr32 */
+ 0x8000f800,
+ 0xf601cc00,
+ 0x04bd000f,
+ 0xc9f0ecb2,
+ 0x1ec9f01f,
+ 0x01ca0080,
+ 0xbd000cf6,
+/* 0x00a9: nv_wr32_wait */
+ 0xca008c04,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f61b,
+/* 0x00b8: wait_donez */
+ 0x99f094bd,
+ 0x37008000,
+ 0x0009f602,
+ 0x008004bd,
+ 0x0af60206,
+/* 0x00cf: wait_donez_ne */
+ 0x8804bd00,
+ 0xcf010000,
+ 0x8aff0088,
+ 0xf61bf488,
+ 0x99f094bd,
+ 0x17008000,
+ 0x0009f602,
+ 0x00f804bd,
+/* 0x00ec: wait_doneo */
+ 0x99f094bd,
+ 0x37008000,
+ 0x0009f602,
+ 0x008004bd,
+ 0x0af60206,
+/* 0x0103: wait_doneo_e */
+ 0x8804bd00,
+ 0xcf010000,
+ 0x8aff0088,
+ 0xf60bf488,
+ 0x99f094bd,
+ 0x17008000,
+ 0x0009f602,
+ 0x00f804bd,
+/* 0x0120: mmctx_size */
+/* 0x0122: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0x1bf4efa4,
+ 0xf89fb2ec,
+/* 0x013d: mmctx_xfer */
+ 0xf094bd00,
+ 0x00800199,
+ 0x09f60237,
+ 0xbd04bd00,
+ 0x05bbfd94,
+ 0x800f0bf4,
+ 0xf601c400,
+ 0x04bd000b,
+/* 0x015f: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0xc6008018,
+ 0x000ef601,
+ 0x008004bd,
+ 0x0ff601c7,
+ 0xf004bd00,
+/* 0x017a: mmctx_multi_disabled */
+ 0xabc80199,
+ 0x10b4b600,
+ 0xc80cb9f0,
+ 0xe4b601ae,
+ 0x05befd11,
+ 0x01c50080,
+ 0xbd000bf6,
+/* 0x0195: mmctx_exec_loop */
+/* 0x0195: mmctx_wait_free */
+ 0xc5008e04,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f60b,
+ 0x05e9fd00,
+ 0x01c80080,
+ 0xbd000ef6,
+ 0x04c0b604,
+ 0x1bf4cda4,
+ 0x02abc8df,
+/* 0x01bf: mmctx_fini_wait */
+ 0x8b1c1bf4,
+ 0xcf01c500,
+ 0xb4f000bb,
+ 0x10b4b01f,
+ 0x0af31bf4,
+ 0x00b87e02,
+ 0x250ef400,
+/* 0x01d8: mmctx_stop */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x12b9f00c,
+ 0x01c50080,
+ 0xbd000bf6,
+/* 0x01ed: mmctx_stop_wait */
+ 0xc5008b04,
+ 0x00bbcf01,
+ 0xf412bbc8,
+/* 0x01fa: mmctx_done */
+ 0x94bdf61b,
+ 0x800199f0,
+ 0xf6021700,
+ 0x04bd0009,
+/* 0x020a: strand_wait */
+ 0xa0f900f8,
+ 0xb87e020a,
+ 0xa0fc0000,
+/* 0x0216: strand_pre */
+ 0x0c0900f8,
+ 0x024afc80,
+ 0xbd0009f6,
+ 0x020a7e04,
+/* 0x0227: strand_post */
+ 0x0900f800,
+ 0x4afc800d,
+ 0x0009f602,
+ 0x0a7e04bd,
+ 0x00f80002,
+/* 0x0238: strand_set */
+ 0xfc800f0c,
+ 0x0cf6024f,
+ 0x0c04bd00,
+ 0x4afc800b,
+ 0x000cf602,
+ 0xfc8004bd,
+ 0x0ef6024f,
+ 0x0c04bd00,
+ 0x4afc800a,
+ 0x000cf602,
+ 0x0a7e04bd,
+ 0x00f80002,
+/* 0x0268: strand_ctx_init */
+ 0x99f094bd,
+ 0x37008003,
+ 0x0009f602,
+ 0x167e04bd,
+ 0x030e0002,
+ 0x0002387e,
+ 0xfc80c4bd,
+ 0x0cf60247,
+ 0x0c04bd00,
+ 0x4afc8001,
+ 0x000cf602,
+ 0x0a7e04bd,
+ 0x0c920002,
+ 0x46fc8001,
+ 0x000cf602,
+ 0x020c04bd,
+ 0x024afc80,
+ 0xbd000cf6,
+ 0x020a7e04,
+ 0x02277e00,
+ 0x42008800,
+ 0x20008902,
+ 0x0099cf02,
+/* 0x02c7: ctx_init_strand_loop */
+ 0xf608fe95,
+ 0x8ef6008e,
+ 0x808acf40,
+ 0xb606a5b6,
+ 0xeabb01a0,
+ 0x0480b600,
+ 0xf40192b6,
+ 0xe4b6e81b,
+ 0xf2efbc08,
+ 0x99f094bd,
+ 0x17008003,
+ 0x0009f602,
+ 0x00f804bd,
+/* 0x02f8: error */
+ 0xffb2e0f9,
+ 0x4098148e,
+ 0x00008f7e,
+ 0xffb2010f,
+ 0x409c1c8e,
+ 0x00008f7e,
+ 0x00f8e0fc,
+/* 0x0314: init */
+ 0x04fe04bd,
+ 0x40020200,
+ 0x02f61200,
+ 0x4104bd00,
+ 0x10fe0465,
+ 0x07004000,
+ 0xbd0000f6,
+ 0x40040204,
+ 0x02f60400,
+ 0xf404bd00,
+ 0x00821031,
+ 0x22cf0182,
+ 0xf0010300,
+ 0x32bb1f24,
+ 0x0132b604,
+ 0xb50502b5,
+ 0x00820603,
+ 0x22cf0186,
+ 0x0402b500,
+ 0x500c308e,
+ 0x34bd24bd,
+/* 0x036a: init_unk_loop */
+ 0x657e44bd,
+ 0xf6b00000,
+ 0x0e0bf400,
+ 0xf2bb010f,
+ 0x054ffd04,
+/* 0x037f: init_unk_next */
+ 0xb60130b6,
+ 0xe0b60120,
+ 0x0126b004,
+/* 0x038b: init_unk_done */
+ 0xb5e21bf4,
+ 0x04b50703,
+ 0x01008208,
+ 0x0022cf02,
+ 0x259534bd,
+ 0xc0008008,
+ 0x0005f601,
+ 0x008004bd,
+ 0x05f601c1,
+ 0x9804bd00,
+ 0x0f98000e,
+ 0x01207e01,
+ 0x002fbb00,
+ 0x98003fbb,
+ 0x0f98010e,
+ 0x01207e02,
+ 0x050e9800,
+ 0xbb00effd,
+ 0x3ebb002e,
+ 0x020e9800,
+ 0x7e030f98,
+ 0x98000120,
+ 0xeffd070e,
+ 0x002ebb00,
+ 0xb6003ebb,
+ 0x00800235,
+ 0x03f601d3,
+ 0xb604bd00,
+ 0x35b60825,
+ 0x0120b606,
+ 0xb60130b6,
+ 0x34b60824,
+ 0x7e2fb208,
+ 0xbb000268,
+ 0x0080003f,
+ 0x03f60201,
+ 0xbd04bd00,
+ 0x1f29f024,
+ 0x02300080,
+ 0xbd0002f6,
+/* 0x0429: main */
+ 0x0031f404,
+ 0x0d0028f4,
+ 0x00377e24,
+ 0xf401f400,
+ 0xf404e4b0,
+ 0x81fe1d18,
+ 0xbd060201,
+ 0x0412fd20,
+ 0xfd01e4b6,
+ 0x18fe051e,
+ 0x04fc7e00,
+ 0xd40ef400,
+/* 0x0458: main_not_ctx_xfer */
+ 0xf010ef94,
+ 0xf87e01f5,
+ 0x0ef40002,
+/* 0x0465: ih */
+ 0xfe80f9c7,
+ 0x80f90188,
+ 0xa0f990f9,
+ 0xd0f9b0f9,
+ 0xf0f9e0f9,
+ 0x004a04bd,
+ 0x00aacf02,
+ 0xf404abc4,
+ 0x240d1f0b,
+ 0xcf1a004e,
+ 0x004f00ee,
+ 0x00ffcf19,
+ 0x0000047e,
+ 0x0040010e,
+ 0x000ef61d,
+/* 0x04a2: ih_no_fifo */
+ 0x004004bd,
+ 0x000af601,
+ 0xf0fc04bd,
+ 0xd0fce0fc,
+ 0xa0fcb0fc,
+ 0x80fc90fc,
+ 0xfc0088fe,
+ 0x0032f480,
+/* 0x04c2: hub_barrier_done */
+ 0x010f01f8,
+ 0xbb040e98,
+ 0xffb204fe,
+ 0x4094188e,
+ 0x00008f7e,
+/* 0x04d6: ctx_redswitch */
+ 0x200f00f8,
+ 0x01850080,
+ 0xbd000ff6,
+/* 0x04e3: ctx_redswitch_delay */
+ 0xb6080e04,
+ 0x1bf401e2,
+ 0x00f5f1fd,
+ 0x00f5f108,
+ 0x85008002,
+ 0x000ff601,
+ 0x00f804bd,
+/* 0x04fc: ctx_xfer */
+ 0x02810080,
+ 0xbd000ff6,
+ 0x0711f404,
+ 0x0004d67e,
+/* 0x050c: ctx_xfer_not_load */
+ 0x0002167e,
+ 0xfc8024bd,
+ 0x02f60247,
+ 0xf004bd00,
+ 0x20b6012c,
+ 0x4afc8003,
+ 0x0002f602,
+ 0xacf004bd,
+ 0x02a5f001,
+ 0x5000008b,
+ 0xb6040c98,
+ 0xbcbb0fc4,
+ 0x000c9800,
+ 0x0e010d98,
+ 0x013d7e00,
+ 0x01acf000,
+ 0x5040008b,
+ 0xb6040c98,
+ 0xbcbb0fc4,
+ 0x010c9800,
+ 0x98020d98,
+ 0x004e060f,
+ 0x013d7e08,
+ 0x01acf000,
+ 0x8b04a5f0,
+ 0x98503000,
+ 0xc4b6040c,
+ 0x00bcbb0f,
+ 0x98020c98,
+ 0x0f98030d,
+ 0x02004e08,
+ 0x00013d7e,
+ 0x00020a7e,
+ 0xf40601f4,
+/* 0x0596: ctx_xfer_post */
+ 0x277e0712,
+/* 0x059a: ctx_xfer_done */
+ 0xc27e0002,
+ 0x00f80004,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+};
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvc0.fuc.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvc0.fuc.h
index f2b0dea..0e7b01e 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvc0.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvc0.fuc.h
@@ -37,14 +37,14 @@ uint32_t nvc0_grgpc_data[] = {
 };
 
 uint32_t nvc0_grgpc_code[] = {
- 0x03180ef5,
+ 0x03a10ef5,
 /* 0x0004: queue_put */
  0x9800d898,
  0x86f001d9,
  0x0489b808,
  0xf00c1bf4,
  0x21f502f7,
- 0x00f802fe,
+ 0x00f8037e,
 /* 0x001c: queue_put_next */
  0xb60798c4,
  0x8dbb0384,
@@ -68,184 +68,214 @@ uint32_t nvc0_grgpc_code[] = {
 /* 0x0066: queue_get_done */
  0x00f80132,
 /* 0x0068: nv_rd32 */
- 0x0728b7f1,
- 0xb906b4b6,
- 0xc9f002ec,
- 0x00bcd01f,
-/* 0x0078: nv_rd32_wait */
- 0xc800bccf,
- 0x1bf41fcc,
- 0x06a7f0fa,
- 0x010921f5,
- 0xf840bfcf,
-/* 0x008d: nv_wr32 */
- 0x28b7f100,
- 0x06b4b607,
- 0xb980bfd0,
- 0xc9f002ec,
- 0x1ec9f01f,
-/* 0x00a3: nv_wr32_wait */
- 0xcf00bcd0,
- 0xccc800bc,
- 0xfa1bf41f,
-/* 0x00ae: watchdog_reset */
- 0x87f100f8,
- 0x84b60430,
- 0x1ff9f006,
- 0xf8008fd0,
-/* 0x00bd: watchdog_clear */
- 0x3087f100,
- 0x0684b604,
- 0xf80080d0,
-/* 0x00c9: wait_donez */
- 0xf094bd00,
- 0x07f10099,
- 0x03f00f00,
- 0x0009d002,
- 0x07f104bd,
- 0x03f00600,
- 0x000ad002,
-/* 0x00e6: wait_donez_ne */
- 0x87f104bd,
- 0x83f00000,
- 0x0088cf01,
- 0xf4888aff,
- 0x94bdf31b,
- 0xf10099f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0109: wait_doneo */
- 0xf094bd00,
+ 0xf002ecb9,
+ 0x07f11fc9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x007a: nv_rd32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0xa7f0f31b,
+ 0x1021f506,
+ 0x00f7f101,
+ 0x01f3f0cb,
+ 0xf800ffcf,
+/* 0x009d: nv_wr32 */
+ 0x0007f100,
+ 0x0103f0cc,
+ 0xbd000fd0,
+ 0x02ecb904,
+ 0xf01fc9f0,
+ 0x07f11ec9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x00be: nv_wr32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f31b,
+/* 0x00d0: wait_donez */
+ 0x99f094bd,
+ 0x0007f100,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x00ed: wait_donez_ne */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x1bf4888a,
+ 0xf094bdf3,
  0x07f10099,
- 0x03f00f00,
+ 0x03f01700,
  0x0009d002,
- 0x87f104bd,
- 0x84b60818,
- 0x008ad006,
-/* 0x0124: wait_doneo_e */
- 0x040087f1,
- 0xcf0684b6,
- 0x8aff0088,
- 0xf30bf488,
+ 0x00f804bd,
+/* 0x0110: wait_doneo */
  0x99f094bd,
  0x0007f100,
- 0x0203f017,
+ 0x0203f00f,
  0xbd0009d0,
-/* 0x0147: mmctx_size */
- 0xbd00f804,
-/* 0x0149: nv_mmctx_size_loop */
- 0x00e89894,
- 0xb61a85b6,
- 0x84b60180,
- 0x0098bb02,
- 0xb804e0b6,
- 0x1bf404ef,
- 0x029fb9eb,
-/* 0x0166: mmctx_xfer */
- 0x94bd00f8,
- 0xf10199f0,
- 0xf00f0007,
- 0x09d00203,
- 0xf104bd00,
- 0xb6071087,
- 0x94bd0684,
- 0xf405bbfd,
- 0x8bd0090b,
- 0x0099f000,
-/* 0x018c: mmctx_base_disabled */
- 0xf405eefd,
- 0x8ed00c0b,
- 0xc08fd080,
-/* 0x019b: mmctx_multi_disabled */
- 0xb70199f0,
- 0xc8010080,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x012d: wait_doneo_e */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x0bf4888a,
+ 0xf094bdf3,
+ 0x07f10099,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0150: mmctx_size */
+/* 0x0152: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0xf404efb8,
+ 0x9fb9eb1b,
+/* 0x016f: mmctx_xfer */
+ 0xbd00f802,
+ 0x0199f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0xbbfd94bd,
+ 0x120bf405,
+ 0xc40007f1,
+ 0xd00103f0,
+ 0x04bd000b,
+/* 0x0197: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0x0007f11e,
+ 0x0103f0c6,
+ 0xbd000ed0,
+ 0x0007f104,
+ 0x0103f0c7,
+ 0xbd000fd0,
+ 0x0199f004,
+/* 0x01b8: mmctx_multi_disabled */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x01aec80c,
+ 0xfd11e4b6,
+ 0x07f105be,
+ 0x03f0c500,
+ 0x000bd001,
+/* 0x01d6: mmctx_exec_loop */
+/* 0x01d6: mmctx_wait_free */
+ 0xe7f104bd,
+ 0xe3f0c500,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f30b,
+ 0x05e9fd00,
+ 0xc80007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+ 0xb804c0b6,
+ 0x1bf404cd,
+ 0x02abc8d8,
+/* 0x0207: mmctx_fini_wait */
+ 0xf11f1bf4,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x1fb4f000,
+ 0xf410b4b0,
+ 0xa7f0f01b,
+ 0xd021f402,
+/* 0x0223: mmctx_stop */
+ 0xc82b0ef4,
  0xb4b600ab,
  0x0cb9f010,
- 0xb601aec8,
- 0xbefd11e4,
- 0x008bd005,
-/* 0x01b4: mmctx_exec_loop */
-/* 0x01b4: mmctx_wait_free */
- 0xf0008ecf,
- 0x0bf41fe4,
- 0x00ce98fa,
- 0xd005e9fd,
- 0xc0b6c08e,
- 0x04cdb804,
- 0xc8e81bf4,
- 0x1bf402ab,
-/* 0x01d5: mmctx_fini_wait */
- 0x008bcf18,
- 0xb01fb4f0,
- 0x1bf410b4,
- 0x02a7f0f7,
- 0xf4c921f4,
-/* 0x01ea: mmctx_stop */
- 0xabc81b0e,
- 0x10b4b600,
- 0xf00cb9f0,
- 0x8bd012b9,
-/* 0x01f9: mmctx_stop_wait */
- 0x008bcf00,
- 0xf412bbc8,
-/* 0x0202: mmctx_done */
- 0x94bdfa1b,
- 0xf10199f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0215: strand_wait */
- 0xf0a0f900,
- 0x21f402a7,
- 0xf8a0fcc9,
-/* 0x0221: strand_pre */
- 0xfc87f100,
- 0x0283f04a,
- 0xd00c97f0,
- 0x21f50089,
- 0x00f80215,
-/* 0x0234: strand_post */
- 0x4afc87f1,
- 0xf00283f0,
- 0x89d00d97,
- 0x1521f500,
-/* 0x0247: strand_set */
- 0xf100f802,
- 0xf04ffca7,
- 0xaba202a3,
- 0xc7f00500,
- 0x00acd00f,
- 0xd00bc7f0,
- 0x21f500bc,
- 0xaed00215,
- 0x0ac7f000,
- 0xf500bcd0,
- 0xf8021521,
-/* 0x0271: strand_ctx_init */
- 0xf094bd00,
- 0x07f10399,
- 0x03f00f00,
+ 0xf112b9f0,
+ 0xf0c50007,
+ 0x0bd00103,
+/* 0x023b: mmctx_stop_wait */
+ 0xf104bd00,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x12bbc800,
+/* 0x024b: mmctx_done */
+ 0xbdf31bf4,
+ 0x0199f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x025e: strand_wait */
+ 0xa0f900f8,
+ 0xf402a7f0,
+ 0xa0fcd021,
+/* 0x026a: strand_pre */
+ 0x97f000f8,
+ 0xfc07f10c,
+ 0x0203f04a,
+ 0xbd0009d0,
+ 0x5e21f504,
+/* 0x027f: strand_post */
+ 0xf000f802,
+ 0x07f10d97,
+ 0x03f04afc,
  0x0009d002,
  0x21f504bd,
- 0xe7f00221,
- 0x4721f503,
- 0xfca7f102,
- 0x02a3f046,
- 0x0400aba0,
- 0xf040a0d0,
- 0xbcd001c7,
- 0x1521f500,
- 0x010c9202,
- 0xf000acd0,
- 0xbcd002c7,
- 0x1521f500,
- 0x3421f502,
- 0x8087f102,
- 0x0684b608,
- 0xb70089cf,
- 0x95220080,
-/* 0x02ca: ctx_init_strand_loop */
+ 0x00f8025e,
+/* 0x0294: strand_set */
+ 0xf10fc7f0,
+ 0xf04ffc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f10bc7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x07f104bd,
+ 0x03f04ffc,
+ 0x000ed002,
+ 0xc7f004bd,
+ 0xfc07f10a,
+ 0x0203f04a,
+ 0xbd000cd0,
+ 0x5e21f504,
+/* 0x02d3: strand_ctx_init */
+ 0xbd00f802,
+ 0x0399f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0x026a21f5,
+ 0xf503e7f0,
+ 0xbd029421,
+ 0xfc07f1c4,
+ 0x0203f047,
+ 0xbd000cd0,
+ 0x01c7f004,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd000c,
+ 0x025e21f5,
+ 0xf1010c92,
+ 0xf046fc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f102c7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x21f504bd,
+ 0x21f5025e,
+ 0x87f1027f,
+ 0x83f04200,
+ 0x0097f102,
+ 0x0293f020,
+ 0x950099cf,
+/* 0x034a: ctx_init_strand_loop */
  0x8ed008fe,
  0x408ed000,
  0xb6808acf,
@@ -259,167 +289,199 @@ uint32_t nvc0_grgpc_code[] = {
  0x170007f1,
  0xd00203f0,
  0x04bd0009,
-/* 0x02fe: error */
+/* 0x037e: error */
  0xe0f900f8,
- 0x9814e7f1,
- 0xf440e3f0,
- 0xe0b78d21,
- 0xf7f0041c,
- 0x8d21f401,
- 0x00f8e0fc,
-/* 0x0318: init */
- 0x04fe04bd,
- 0x0017f100,
- 0x0227f012,
- 0xf10012d0,
- 0xfe042617,
- 0x17f10010,
- 0x10d00400,
- 0x0427f0c0,
- 0xf40012d0,
- 0x17f11031,
- 0x14b60608,
- 0x0012cf06,
+ 0xf102ffb9,
+ 0xf09814e7,
+ 0x21f440e3,
+ 0x01f7f09d,
+ 0xf102ffb9,
+ 0xf09c1ce7,
+ 0x21f440e3,
+ 0xf8e0fc9d,
+/* 0x03a1: init */
+ 0xfe04bd00,
+ 0x27f00004,
+ 0x0007f102,
+ 0x0003f012,
+ 0xbd0002d0,
+ 0xd517f104,
+ 0x0010fe04,
+ 0x070007f1,
+ 0xd00003f0,
+ 0x04bd0000,
+ 0xf10427f0,
+ 0xf0040007,
+ 0x02d00003,
+ 0xf404bd00,
+ 0x27f11031,
+ 0x23f08200,
+ 0x0022cf01,
  0xf00137f0,
  0x32bb1f24,
  0x0132b604,
  0x80050280,
- 0x10b70603,
- 0x12cf0400,
- 0x04028000,
- 0x010027f1,
- 0xcf0223f0,
- 0x34bd0022,
- 0x070047f1,
- 0x950644b6,
- 0x45d00825,
- 0x4045d000,
- 0x98000e98,
- 0x21f5010f,
- 0x2fbb0147,
- 0x003fbb00,
- 0x98010e98,
- 0x21f5020f,
- 0x0e980147,
- 0x00effd05,
- 0xbb002ebb,
- 0x40b7003e,
- 0x35b61300,
- 0x0043d002,
- 0xb60825b6,
- 0x20b60635,
- 0x0130b601,
- 0xb60824b6,
- 0x2fb90834,
- 0x7121f502,
- 0x003fbb02,
- 0x010007f1,
+ 0x27f10603,
+ 0x23f08600,
+ 0x0022cf01,
+ 0xf1040280,
+ 0xf0010027,
+ 0x22cf0223,
+ 0x9534bd00,
+ 0x07f10825,
+ 0x03f0c000,
+ 0x0005d001,
+ 0x07f104bd,
+ 0x03f0c100,
+ 0x0005d001,
+ 0x0e9804bd,
+ 0x010f9800,
+ 0x015021f5,
+ 0xbb002fbb,
+ 0x0e98003f,
+ 0x020f9801,
+ 0x015021f5,
+ 0xfd050e98,
+ 0x2ebb00ef,
+ 0x003ebb00,
+ 0xf10235b6,
+ 0xf0d30007,
+ 0x03d00103,
+ 0xb604bd00,
+ 0x35b60825,
+ 0x0120b606,
+ 0xb60130b6,
+ 0x34b60824,
+ 0x022fb908,
+ 0x02d321f5,
+ 0xf1003fbb,
+ 0xf0010007,
+ 0x03d00203,
+ 0xbd04bd00,
+ 0x1f29f024,
+ 0x080007f1,
  0xd00203f0,
- 0x04bd0003,
- 0x29f024bd,
- 0x0007f11f,
- 0x0203f008,
- 0xbd0002d0,
-/* 0x03e9: main */
- 0x0031f404,
- 0xf00028f4,
- 0x21f41cd7,
- 0xf401f439,
- 0xf404e4b0,
- 0x81fe1e18,
- 0x0627f001,
- 0x12fd20bd,
- 0x01e4b604,
- 0xfe051efd,
- 0x21f50018,
- 0x0ef404ad,
-/* 0x0419: main_not_ctx_xfer */
- 0x10ef94d3,
- 0xf501f5f0,
- 0xf402fe21,
-/* 0x0426: ih */
- 0x80f9c60e,
- 0xf90188fe,
- 0xf990f980,
- 0xf9b0f9a0,
- 0xf9e0f9d0,
- 0xcf04bdf0,
- 0xabc4800a,
- 0x1d0bf404,
- 0x1900b7f1,
- 0xcf1cd7f0,
- 0xbfcf40be,
+ 0x04bd0002,
+/* 0x0498: main */
+ 0xf40031f4,
+ 0xd7f00028,
+ 0x3921f41c,
+ 0xb0f401f4,
+ 0x18f404e4,
+ 0x0181fe1e,
+ 0xbd0627f0,
+ 0x0412fd20,
+ 0xfd01e4b6,
+ 0x18fe051e,
+ 0x8d21f500,
+ 0xd30ef405,
+/* 0x04c8: main_not_ctx_xfer */
+ 0xf010ef94,
+ 0x21f501f5,
+ 0x0ef4037e,
+/* 0x04d5: ih */
+ 0xfe80f9c6,
+ 0x80f90188,
+ 0xa0f990f9,
+ 0xd0f9b0f9,
+ 0xf0f9e0f9,
+ 0xa7f104bd,
+ 0xa3f00200,
+ 0x00aacf00,
+ 0xf404abc4,
+ 0xd7f02c0b,
+ 0x00e7f11c,
+ 0x00e3f01a,
+ 0xf100eecf,
+ 0xf01900f7,
+ 0xffcf00f3,
  0x0421f400,
- 0x0400b0b7,
- 0xd001e7f0,
-/* 0x045e: ih_no_fifo */
- 0x0ad000be,
- 0xfcf0fc40,
- 0xfcd0fce0,
- 0xfca0fcb0,
- 0xfe80fc90,
- 0x80fc0088,
- 0xf80032f4,
-/* 0x0479: hub_barrier_done */
- 0x01f7f001,
- 0xbb040e98,
- 0xe7f104fe,
- 0xe3f09418,
- 0x8d21f440,
-/* 0x048e: ctx_redswitch */
- 0xe7f100f8,
- 0xe4b60614,
- 0x20f7f006,
- 0xf000efd0,
-/* 0x049e: ctx_redswitch_delay */
- 0xf2b608f7,
- 0xfd1bf401,
- 0x0a20f7f1,
- 0xf800efd0,
-/* 0x04ad: ctx_xfer */
- 0x0417f100,
- 0x0614b60a,
- 0xf4001fd0,
- 0x21f50711,
-/* 0x04be: ctx_xfer_not_load */
- 0x17f1048e,
- 0x13f04afc,
- 0x0c27f002,
- 0xf50012d0,
- 0xf1021521,
- 0xf047fc27,
- 0x20d00223,
- 0x012cf000,
- 0xd00320b6,
- 0xacf00012,
- 0x02a5f001,
- 0xf000b7f0,
- 0x0c9850b3,
- 0x0fc4b604,
- 0x9800bcbb,
- 0x0d98000c,
- 0x00e7f001,
- 0x016621f5,
+ 0xf101e7f0,
+ 0xf01d0007,
+ 0x0ed00003,
+/* 0x0523: ih_no_fifo */
+ 0xf104bd00,
+ 0xf0010007,
+ 0x0ad00003,
+ 0xfc04bd00,
+ 0xfce0fcf0,
+ 0xfcb0fcd0,
+ 0xfc90fca0,
+ 0x0088fe80,
+ 0x32f480fc,
+/* 0x0547: hub_barrier_done */
+ 0xf001f800,
+ 0x0e9801f7,
+ 0x04febb04,
+ 0xf102ffb9,
+ 0xf09418e7,
+ 0x21f440e3,
+/* 0x055f: ctx_redswitch */
+ 0xf000f89d,
+ 0x07f120f7,
+ 0x03f08500,
+ 0x000fd001,
+ 0xe7f004bd,
+/* 0x0571: ctx_redswitch_delay */
+ 0x01e2b608,
+ 0xf1fd1bf4,
+ 0xf10800f5,
+ 0xf10200f5,
+ 0xf0850007,
+ 0x0fd00103,
+ 0xf804bd00,
+/* 0x058d: ctx_xfer */
+ 0x0007f100,
+ 0x0203f081,
+ 0xbd000fd0,
+ 0x0711f404,
+ 0x055f21f5,
+/* 0x05a0: ctx_xfer_not_load */
+ 0x026a21f5,
+ 0x07f124bd,
+ 0x03f047fc,
+ 0x0002d002,
+ 0x2cf004bd,
+ 0x0320b601,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd0002,
  0xf001acf0,
- 0xb7f104a5,
- 0xb3f04000,
+ 0xb7f102a5,
+ 0xb3f00000,
  0x040c9850,
  0xbb0fc4b6,
  0x0c9800bc,
- 0x020d9801,
- 0xf1060f98,
- 0xf50800e7,
- 0xf5016621,
- 0xf4021521,
- 0x12f40601,
-/* 0x0535: ctx_xfer_post */
- 0xfc17f114,
- 0x0213f04a,
- 0xd00d27f0,
- 0x21f50012,
-/* 0x0546: ctx_xfer_done */
- 0x21f50215,
- 0x00f80479,
+ 0x010d9800,
+ 0xf500e7f0,
+ 0xf0016f21,
+ 0xa5f001ac,
+ 0x00b7f104,
+ 0x50b3f040,
+ 0xb6040c98,
+ 0xbcbb0fc4,
+ 0x010c9800,
+ 0x98020d98,
+ 0xe7f1060f,
+ 0x21f50800,
+ 0x21f5016f,
+ 0x01f4025e,
+ 0x0712f406,
+/* 0x0618: ctx_xfer_post */
+ 0x027f21f5,
+/* 0x061c: ctx_xfer_done */
+ 0x054721f5,
+ 0x000000f8,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvd7.fuc.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvd7.fuc.h
index dd346c2..84dd32d 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvd7.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvd7.fuc.h
@@ -41,14 +41,14 @@ uint32_t nvd7_grgpc_data[] = {
 };
 
 uint32_t nvd7_grgpc_code[] = {
- 0x03180ef5,
+ 0x03a10ef5,
 /* 0x0004: queue_put */
  0x9800d898,
  0x86f001d9,
  0x0489b808,
  0xf00c1bf4,
  0x21f502f7,
- 0x00f802fe,
+ 0x00f8037e,
 /* 0x001c: queue_put_next */
  0xb60798c4,
  0x8dbb0384,
@@ -72,184 +72,214 @@ uint32_t nvd7_grgpc_code[] = {
 /* 0x0066: queue_get_done */
  0x00f80132,
 /* 0x0068: nv_rd32 */
- 0x0728b7f1,
- 0xb906b4b6,
- 0xc9f002ec,
- 0x00bcd01f,
-/* 0x0078: nv_rd32_wait */
- 0xc800bccf,
- 0x1bf41fcc,
- 0x06a7f0fa,
- 0x010921f5,
- 0xf840bfcf,
-/* 0x008d: nv_wr32 */
- 0x28b7f100,
- 0x06b4b607,
- 0xb980bfd0,
- 0xc9f002ec,
- 0x1ec9f01f,
-/* 0x00a3: nv_wr32_wait */
- 0xcf00bcd0,
- 0xccc800bc,
- 0xfa1bf41f,
-/* 0x00ae: watchdog_reset */
- 0x87f100f8,
- 0x84b60430,
- 0x1ff9f006,
- 0xf8008fd0,
-/* 0x00bd: watchdog_clear */
- 0x3087f100,
- 0x0684b604,
- 0xf80080d0,
-/* 0x00c9: wait_donez */
- 0xf094bd00,
- 0x07f10099,
- 0x03f00f00,
- 0x0009d002,
- 0x07f104bd,
- 0x03f00600,
- 0x000ad002,
-/* 0x00e6: wait_donez_ne */
- 0x87f104bd,
- 0x83f00000,
- 0x0088cf01,
- 0xf4888aff,
- 0x94bdf31b,
- 0xf10099f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0109: wait_doneo */
- 0xf094bd00,
+ 0xf002ecb9,
+ 0x07f11fc9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x007a: nv_rd32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0xa7f0f31b,
+ 0x1021f506,
+ 0x00f7f101,
+ 0x01f3f0cb,
+ 0xf800ffcf,
+/* 0x009d: nv_wr32 */
+ 0x0007f100,
+ 0x0103f0cc,
+ 0xbd000fd0,
+ 0x02ecb904,
+ 0xf01fc9f0,
+ 0x07f11ec9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x00be: nv_wr32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f31b,
+/* 0x00d0: wait_donez */
+ 0x99f094bd,
+ 0x0007f100,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x00ed: wait_donez_ne */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x1bf4888a,
+ 0xf094bdf3,
  0x07f10099,
- 0x03f00f00,
+ 0x03f01700,
  0x0009d002,
- 0x87f104bd,
- 0x84b60818,
- 0x008ad006,
-/* 0x0124: wait_doneo_e */
- 0x040087f1,
- 0xcf0684b6,
- 0x8aff0088,
- 0xf30bf488,
+ 0x00f804bd,
+/* 0x0110: wait_doneo */
  0x99f094bd,
  0x0007f100,
- 0x0203f017,
+ 0x0203f00f,
  0xbd0009d0,
-/* 0x0147: mmctx_size */
- 0xbd00f804,
-/* 0x0149: nv_mmctx_size_loop */
- 0x00e89894,
- 0xb61a85b6,
- 0x84b60180,
- 0x0098bb02,
- 0xb804e0b6,
- 0x1bf404ef,
- 0x029fb9eb,
-/* 0x0166: mmctx_xfer */
- 0x94bd00f8,
- 0xf10199f0,
- 0xf00f0007,
- 0x09d00203,
- 0xf104bd00,
- 0xb6071087,
- 0x94bd0684,
- 0xf405bbfd,
- 0x8bd0090b,
- 0x0099f000,
-/* 0x018c: mmctx_base_disabled */
- 0xf405eefd,
- 0x8ed00c0b,
- 0xc08fd080,
-/* 0x019b: mmctx_multi_disabled */
- 0xb70199f0,
- 0xc8010080,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x012d: wait_doneo_e */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x0bf4888a,
+ 0xf094bdf3,
+ 0x07f10099,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0150: mmctx_size */
+/* 0x0152: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0xf404efb8,
+ 0x9fb9eb1b,
+/* 0x016f: mmctx_xfer */
+ 0xbd00f802,
+ 0x0199f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0xbbfd94bd,
+ 0x120bf405,
+ 0xc40007f1,
+ 0xd00103f0,
+ 0x04bd000b,
+/* 0x0197: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0x0007f11e,
+ 0x0103f0c6,
+ 0xbd000ed0,
+ 0x0007f104,
+ 0x0103f0c7,
+ 0xbd000fd0,
+ 0x0199f004,
+/* 0x01b8: mmctx_multi_disabled */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x01aec80c,
+ 0xfd11e4b6,
+ 0x07f105be,
+ 0x03f0c500,
+ 0x000bd001,
+/* 0x01d6: mmctx_exec_loop */
+/* 0x01d6: mmctx_wait_free */
+ 0xe7f104bd,
+ 0xe3f0c500,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f30b,
+ 0x05e9fd00,
+ 0xc80007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+ 0xb804c0b6,
+ 0x1bf404cd,
+ 0x02abc8d8,
+/* 0x0207: mmctx_fini_wait */
+ 0xf11f1bf4,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x1fb4f000,
+ 0xf410b4b0,
+ 0xa7f0f01b,
+ 0xd021f402,
+/* 0x0223: mmctx_stop */
+ 0xc82b0ef4,
  0xb4b600ab,
  0x0cb9f010,
- 0xb601aec8,
- 0xbefd11e4,
- 0x008bd005,
-/* 0x01b4: mmctx_exec_loop */
-/* 0x01b4: mmctx_wait_free */
- 0xf0008ecf,
- 0x0bf41fe4,
- 0x00ce98fa,
- 0xd005e9fd,
- 0xc0b6c08e,
- 0x04cdb804,
- 0xc8e81bf4,
- 0x1bf402ab,
-/* 0x01d5: mmctx_fini_wait */
- 0x008bcf18,
- 0xb01fb4f0,
- 0x1bf410b4,
- 0x02a7f0f7,
- 0xf4c921f4,
-/* 0x01ea: mmctx_stop */
- 0xabc81b0e,
- 0x10b4b600,
- 0xf00cb9f0,
- 0x8bd012b9,
-/* 0x01f9: mmctx_stop_wait */
- 0x008bcf00,
- 0xf412bbc8,
-/* 0x0202: mmctx_done */
- 0x94bdfa1b,
- 0xf10199f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0215: strand_wait */
- 0xf0a0f900,
- 0x21f402a7,
- 0xf8a0fcc9,
-/* 0x0221: strand_pre */
- 0xfc87f100,
- 0x0283f04a,
- 0xd00c97f0,
- 0x21f50089,
- 0x00f80215,
-/* 0x0234: strand_post */
- 0x4afc87f1,
- 0xf00283f0,
- 0x89d00d97,
- 0x1521f500,
-/* 0x0247: strand_set */
- 0xf100f802,
- 0xf04ffca7,
- 0xaba202a3,
- 0xc7f00500,
- 0x00acd00f,
- 0xd00bc7f0,
- 0x21f500bc,
- 0xaed00215,
- 0x0ac7f000,
- 0xf500bcd0,
- 0xf8021521,
-/* 0x0271: strand_ctx_init */
- 0xf094bd00,
- 0x07f10399,
- 0x03f00f00,
+ 0xf112b9f0,
+ 0xf0c50007,
+ 0x0bd00103,
+/* 0x023b: mmctx_stop_wait */
+ 0xf104bd00,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x12bbc800,
+/* 0x024b: mmctx_done */
+ 0xbdf31bf4,
+ 0x0199f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x025e: strand_wait */
+ 0xa0f900f8,
+ 0xf402a7f0,
+ 0xa0fcd021,
+/* 0x026a: strand_pre */
+ 0x97f000f8,
+ 0xfc07f10c,
+ 0x0203f04a,
+ 0xbd0009d0,
+ 0x5e21f504,
+/* 0x027f: strand_post */
+ 0xf000f802,
+ 0x07f10d97,
+ 0x03f04afc,
  0x0009d002,
  0x21f504bd,
- 0xe7f00221,
- 0x4721f503,
- 0xfca7f102,
- 0x02a3f046,
- 0x0400aba0,
- 0xf040a0d0,
- 0xbcd001c7,
- 0x1521f500,
- 0x010c9202,
- 0xf000acd0,
- 0xbcd002c7,
- 0x1521f500,
- 0x3421f502,
- 0x8087f102,
- 0x0684b608,
- 0xb70089cf,
- 0x95220080,
-/* 0x02ca: ctx_init_strand_loop */
+ 0x00f8025e,
+/* 0x0294: strand_set */
+ 0xf10fc7f0,
+ 0xf04ffc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f10bc7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x07f104bd,
+ 0x03f04ffc,
+ 0x000ed002,
+ 0xc7f004bd,
+ 0xfc07f10a,
+ 0x0203f04a,
+ 0xbd000cd0,
+ 0x5e21f504,
+/* 0x02d3: strand_ctx_init */
+ 0xbd00f802,
+ 0x0399f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0x026a21f5,
+ 0xf503e7f0,
+ 0xbd029421,
+ 0xfc07f1c4,
+ 0x0203f047,
+ 0xbd000cd0,
+ 0x01c7f004,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd000c,
+ 0x025e21f5,
+ 0xf1010c92,
+ 0xf046fc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f102c7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x21f504bd,
+ 0x21f5025e,
+ 0x87f1027f,
+ 0x83f04200,
+ 0x0097f102,
+ 0x0293f020,
+ 0x950099cf,
+/* 0x034a: ctx_init_strand_loop */
  0x8ed008fe,
  0x408ed000,
  0xb6808acf,
@@ -263,198 +293,230 @@ uint32_t nvd7_grgpc_code[] = {
  0x170007f1,
  0xd00203f0,
  0x04bd0009,
-/* 0x02fe: error */
+/* 0x037e: error */
  0xe0f900f8,
- 0x9814e7f1,
- 0xf440e3f0,
- 0xe0b78d21,
- 0xf7f0041c,
- 0x8d21f401,
- 0x00f8e0fc,
-/* 0x0318: init */
- 0x04fe04bd,
- 0x0017f100,
- 0x0227f012,
- 0xf10012d0,
- 0xfe047017,
- 0x17f10010,
- 0x10d00400,
- 0x0427f0c0,
- 0xf40012d0,
- 0x17f11031,
- 0x14b60608,
- 0x0012cf06,
+ 0xf102ffb9,
+ 0xf09814e7,
+ 0x21f440e3,
+ 0x01f7f09d,
+ 0xf102ffb9,
+ 0xf09c1ce7,
+ 0x21f440e3,
+ 0xf8e0fc9d,
+/* 0x03a1: init */
+ 0xfe04bd00,
+ 0x27f00004,
+ 0x0007f102,
+ 0x0003f012,
+ 0xbd0002d0,
+ 0x1f17f104,
+ 0x0010fe05,
+ 0x070007f1,
+ 0xd00003f0,
+ 0x04bd0000,
+ 0xf10427f0,
+ 0xf0040007,
+ 0x02d00003,
+ 0xf404bd00,
+ 0x27f11031,
+ 0x23f08200,
+ 0x0022cf01,
  0xf00137f0,
  0x32bb1f24,
  0x0132b604,
  0x80050280,
- 0x10b70603,
- 0x12cf0400,
- 0x04028000,
- 0x0c30e7f1,
- 0xbd50e3f0,
- 0xbd34bd24,
-/* 0x0371: init_unk_loop */
- 0x6821f444,
- 0xf400f6b0,
- 0xf7f00f0b,
- 0x04f2bb01,
- 0xb6054ffd,
-/* 0x0386: init_unk_next */
- 0x20b60130,
- 0x04e0b601,
- 0xf40126b0,
-/* 0x0392: init_unk_done */
- 0x0380e21b,
- 0x08048007,
- 0x010027f1,
- 0xcf0223f0,
- 0x34bd0022,
- 0x070047f1,
- 0x950644b6,
- 0x45d00825,
- 0x4045d000,
- 0x98000e98,
- 0x21f5010f,
- 0x2fbb0147,
- 0x003fbb00,
- 0x98010e98,
- 0x21f5020f,
- 0x0e980147,
- 0x00effd05,
- 0xbb002ebb,
- 0x0e98003e,
- 0x030f9802,
- 0x014721f5,
- 0xfd070e98,
+ 0x27f10603,
+ 0x23f08600,
+ 0x0022cf01,
+ 0xf1040280,
+ 0xf00c30e7,
+ 0x24bd50e3,
+ 0x44bd34bd,
+/* 0x0410: init_unk_loop */
+ 0xb06821f4,
+ 0x0bf400f6,
+ 0x01f7f00f,
+ 0xfd04f2bb,
+ 0x30b6054f,
+/* 0x0425: init_unk_next */
+ 0x0120b601,
+ 0xb004e0b6,
+ 0x1bf40126,
+/* 0x0431: init_unk_done */
+ 0x070380e2,
+ 0xf1080480,
+ 0xf0010027,
+ 0x22cf0223,
+ 0x9534bd00,
+ 0x07f10825,
+ 0x03f0c000,
+ 0x0005d001,
+ 0x07f104bd,
+ 0x03f0c100,
+ 0x0005d001,
+ 0x0e9804bd,
+ 0x010f9800,
+ 0x015021f5,
+ 0xbb002fbb,
+ 0x0e98003f,
+ 0x020f9801,
+ 0x015021f5,
+ 0xfd050e98,
  0x2ebb00ef,
  0x003ebb00,
- 0x130040b7,
- 0xd00235b6,
- 0x25b60043,
- 0x0635b608,
- 0xb60120b6,
- 0x24b60130,
- 0x0834b608,
- 0xf5022fb9,
- 0xbb027121,
- 0x07f1003f,
- 0x03f00100,
- 0x0003d002,
- 0x24bd04bd,
- 0xf11f29f0,
- 0xf0080007,
- 0x02d00203,
-/* 0x0433: main */
+ 0x98020e98,
+ 0x21f5030f,
+ 0x0e980150,
+ 0x00effd07,
+ 0xbb002ebb,
+ 0x35b6003e,
+ 0x0007f102,
+ 0x0103f0d3,
+ 0xbd0003d0,
+ 0x0825b604,
+ 0xb60635b6,
+ 0x30b60120,
+ 0x0824b601,
+ 0xb90834b6,
+ 0x21f5022f,
+ 0x3fbb02d3,
+ 0x0007f100,
+ 0x0203f001,
+ 0xbd0003d0,
+ 0xf024bd04,
+ 0x07f11f29,
+ 0x03f00800,
+ 0x0002d002,
+/* 0x04e2: main */
+ 0x31f404bd,
+ 0x0028f400,
+ 0xf424d7f0,
+ 0x01f43921,
+ 0x04e4b0f4,
+ 0xfe1e18f4,
+ 0x27f00181,
+ 0xfd20bd06,
+ 0xe4b60412,
+ 0x051efd01,
+ 0xf50018fe,
+ 0xf405d721,
+/* 0x0512: main_not_ctx_xfer */
+ 0xef94d30e,
+ 0x01f5f010,
+ 0x037e21f5,
+/* 0x051f: ih */
+ 0xf9c60ef4,
+ 0x0188fe80,
+ 0x90f980f9,
+ 0xb0f9a0f9,
+ 0xe0f9d0f9,
+ 0x04bdf0f9,
+ 0x0200a7f1,
+ 0xcf00a3f0,
+ 0xabc400aa,
+ 0x2c0bf404,
+ 0xf124d7f0,
+ 0xf01a00e7,
+ 0xeecf00e3,
+ 0x00f7f100,
+ 0x00f3f019,
+ 0xf400ffcf,
+ 0xe7f00421,
+ 0x0007f101,
+ 0x0003f01d,
+ 0xbd000ed0,
+/* 0x056d: ih_no_fifo */
+ 0x0007f104,
+ 0x0003f001,
+ 0xbd000ad0,
+ 0xfcf0fc04,
+ 0xfcd0fce0,
+ 0xfca0fcb0,
+ 0xfe80fc90,
+ 0x80fc0088,
+ 0xf80032f4,
+/* 0x0591: hub_barrier_done */
+ 0x01f7f001,
+ 0xbb040e98,
+ 0xffb904fe,
+ 0x18e7f102,
+ 0x40e3f094,
+ 0xf89d21f4,
+/* 0x05a9: ctx_redswitch */
+ 0x20f7f000,
+ 0x850007f1,
+ 0xd00103f0,
+ 0x04bd000f,
+/* 0x05bb: ctx_redswitch_delay */
+ 0xb608e7f0,
+ 0x1bf401e2,
+ 0x00f5f1fd,
+ 0x00f5f108,
+ 0x0007f102,
+ 0x0103f085,
+ 0xbd000fd0,
+/* 0x05d7: ctx_xfer */
+ 0xf100f804,
+ 0xf0810007,
+ 0x0fd00203,
  0xf404bd00,
- 0x28f40031,
- 0x24d7f000,
- 0xf43921f4,
- 0xe4b0f401,
- 0x1e18f404,
- 0xf00181fe,
- 0x20bd0627,
- 0xb60412fd,
- 0x1efd01e4,
- 0x0018fe05,
- 0x04f721f5,
-/* 0x0463: main_not_ctx_xfer */
- 0x94d30ef4,
- 0xf5f010ef,
- 0xfe21f501,
- 0xc60ef402,
-/* 0x0470: ih */
- 0x88fe80f9,
- 0xf980f901,
- 0xf9a0f990,
- 0xf9d0f9b0,
- 0xbdf0f9e0,
- 0x800acf04,
- 0xf404abc4,
- 0xb7f11d0b,
- 0xd7f01900,
- 0x40becf24,
- 0xf400bfcf,
- 0xb0b70421,
- 0xe7f00400,
- 0x00bed001,
-/* 0x04a8: ih_no_fifo */
- 0xfc400ad0,
- 0xfce0fcf0,
- 0xfcb0fcd0,
- 0xfc90fca0,
- 0x0088fe80,
- 0x32f480fc,
-/* 0x04c3: hub_barrier_done */
- 0xf001f800,
- 0x0e9801f7,
- 0x04febb04,
- 0x9418e7f1,
- 0xf440e3f0,
- 0x00f88d21,
-/* 0x04d8: ctx_redswitch */
- 0x0614e7f1,
- 0xf006e4b6,
- 0xefd020f7,
- 0x08f7f000,
-/* 0x04e8: ctx_redswitch_delay */
- 0xf401f2b6,
- 0xf7f1fd1b,
- 0xefd00a20,
-/* 0x04f7: ctx_xfer */
- 0xf100f800,
- 0xb60a0417,
- 0x1fd00614,
- 0x0711f400,
- 0x04d821f5,
-/* 0x0508: ctx_xfer_not_load */
- 0x4afc17f1,
- 0xf00213f0,
- 0x12d00c27,
- 0x1521f500,
- 0xfc27f102,
- 0x0223f047,
- 0xf00020d0,
- 0x20b6012c,
- 0x0012d003,
- 0xf001acf0,
- 0xb7f002a5,
- 0x50b3f000,
- 0xb6040c98,
- 0xbcbb0fc4,
- 0x000c9800,
- 0xf0010d98,
- 0x21f500e7,
- 0xacf00166,
- 0x00b7f101,
- 0x50b3f040,
- 0xb6040c98,
- 0xbcbb0fc4,
- 0x010c9800,
- 0x98020d98,
- 0xe7f1060f,
- 0x21f50800,
- 0xacf00166,
- 0x04a5f001,
- 0x3000b7f1,
+ 0x21f50711,
+/* 0x05ea: ctx_xfer_not_load */
+ 0x21f505a9,
+ 0x24bd026a,
+ 0x47fc07f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xb6012cf0,
+ 0x07f10320,
+ 0x03f04afc,
+ 0x0002d002,
+ 0xacf004bd,
+ 0x02a5f001,
+ 0x0000b7f1,
  0x9850b3f0,
  0xc4b6040c,
  0x00bcbb0f,
- 0x98020c98,
- 0x0f98030d,
- 0x00e7f108,
- 0x6621f502,
- 0x1521f501,
- 0x0601f402,
-/* 0x05a3: ctx_xfer_post */
- 0xf11412f4,
- 0xf04afc17,
- 0x27f00213,
- 0x0012d00d,
- 0x021521f5,
-/* 0x05b4: ctx_xfer_done */
- 0x04c321f5,
- 0x000000f8,
+ 0x98000c98,
+ 0xe7f0010d,
+ 0x6f21f500,
+ 0x01acf001,
+ 0x4000b7f1,
+ 0x9850b3f0,
+ 0xc4b6040c,
+ 0x00bcbb0f,
+ 0x98010c98,
+ 0x0f98020d,
+ 0x00e7f106,
+ 0x6f21f508,
+ 0x01acf001,
+ 0xf104a5f0,
+ 0xf03000b7,
+ 0x0c9850b3,
+ 0x0fc4b604,
+ 0x9800bcbb,
+ 0x0d98020c,
+ 0x080f9803,
+ 0x0200e7f1,
+ 0x016f21f5,
+ 0x025e21f5,
+ 0xf40601f4,
+/* 0x0686: ctx_xfer_post */
+ 0x21f50712,
+/* 0x068a: ctx_xfer_done */
+ 0x21f5027f,
+ 0x00f80591,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnve0.fuc.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnve0.fuc.h
index 7ff5ef6..b6da800 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnve0.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnve0.fuc.h
@@ -41,14 +41,14 @@ uint32_t nve0_grgpc_data[] = {
 };
 
 uint32_t nve0_grgpc_code[] = {
- 0x03180ef5,
+ 0x03a10ef5,
 /* 0x0004: queue_put */
  0x9800d898,
  0x86f001d9,
  0x0489b808,
  0xf00c1bf4,
  0x21f502f7,
- 0x00f802fe,
+ 0x00f8037e,
 /* 0x001c: queue_put_next */
  0xb60798c4,
  0x8dbb0384,
@@ -72,184 +72,214 @@ uint32_t nve0_grgpc_code[] = {
 /* 0x0066: queue_get_done */
  0x00f80132,
 /* 0x0068: nv_rd32 */
- 0x0728b7f1,
- 0xb906b4b6,
- 0xc9f002ec,
- 0x00bcd01f,
-/* 0x0078: nv_rd32_wait */
- 0xc800bccf,
- 0x1bf41fcc,
- 0x06a7f0fa,
- 0x010921f5,
- 0xf840bfcf,
-/* 0x008d: nv_wr32 */
- 0x28b7f100,
- 0x06b4b607,
- 0xb980bfd0,
- 0xc9f002ec,
- 0x1ec9f01f,
-/* 0x00a3: nv_wr32_wait */
- 0xcf00bcd0,
- 0xccc800bc,
- 0xfa1bf41f,
-/* 0x00ae: watchdog_reset */
- 0x87f100f8,
- 0x84b60430,
- 0x1ff9f006,
- 0xf8008fd0,
-/* 0x00bd: watchdog_clear */
- 0x3087f100,
- 0x0684b604,
- 0xf80080d0,
-/* 0x00c9: wait_donez */
- 0xf094bd00,
- 0x07f10099,
- 0x03f00f00,
- 0x0009d002,
- 0x07f104bd,
- 0x03f00600,
- 0x000ad002,
-/* 0x00e6: wait_donez_ne */
- 0x87f104bd,
- 0x83f00000,
- 0x0088cf01,
- 0xf4888aff,
- 0x94bdf31b,
- 0xf10099f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0109: wait_doneo */
- 0xf094bd00,
+ 0xf002ecb9,
+ 0x07f11fc9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x007a: nv_rd32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0xa7f0f31b,
+ 0x1021f506,
+ 0x00f7f101,
+ 0x01f3f0cb,
+ 0xf800ffcf,
+/* 0x009d: nv_wr32 */
+ 0x0007f100,
+ 0x0103f0cc,
+ 0xbd000fd0,
+ 0x02ecb904,
+ 0xf01fc9f0,
+ 0x07f11ec9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x00be: nv_wr32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f31b,
+/* 0x00d0: wait_donez */
+ 0x99f094bd,
+ 0x0007f100,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x00ed: wait_donez_ne */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x1bf4888a,
+ 0xf094bdf3,
  0x07f10099,
- 0x03f00f00,
+ 0x03f01700,
  0x0009d002,
- 0x87f104bd,
- 0x84b60818,
- 0x008ad006,
-/* 0x0124: wait_doneo_e */
- 0x040087f1,
- 0xcf0684b6,
- 0x8aff0088,
- 0xf30bf488,
+ 0x00f804bd,
+/* 0x0110: wait_doneo */
  0x99f094bd,
  0x0007f100,
- 0x0203f017,
+ 0x0203f00f,
  0xbd0009d0,
-/* 0x0147: mmctx_size */
- 0xbd00f804,
-/* 0x0149: nv_mmctx_size_loop */
- 0x00e89894,
- 0xb61a85b6,
- 0x84b60180,
- 0x0098bb02,
- 0xb804e0b6,
- 0x1bf404ef,
- 0x029fb9eb,
-/* 0x0166: mmctx_xfer */
- 0x94bd00f8,
- 0xf10199f0,
- 0xf00f0007,
- 0x09d00203,
- 0xf104bd00,
- 0xb6071087,
- 0x94bd0684,
- 0xf405bbfd,
- 0x8bd0090b,
- 0x0099f000,
-/* 0x018c: mmctx_base_disabled */
- 0xf405eefd,
- 0x8ed00c0b,
- 0xc08fd080,
-/* 0x019b: mmctx_multi_disabled */
- 0xb70199f0,
- 0xc8010080,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x012d: wait_doneo_e */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x0bf4888a,
+ 0xf094bdf3,
+ 0x07f10099,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0150: mmctx_size */
+/* 0x0152: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0xf404efb8,
+ 0x9fb9eb1b,
+/* 0x016f: mmctx_xfer */
+ 0xbd00f802,
+ 0x0199f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0xbbfd94bd,
+ 0x120bf405,
+ 0xc40007f1,
+ 0xd00103f0,
+ 0x04bd000b,
+/* 0x0197: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0x0007f11e,
+ 0x0103f0c6,
+ 0xbd000ed0,
+ 0x0007f104,
+ 0x0103f0c7,
+ 0xbd000fd0,
+ 0x0199f004,
+/* 0x01b8: mmctx_multi_disabled */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x01aec80c,
+ 0xfd11e4b6,
+ 0x07f105be,
+ 0x03f0c500,
+ 0x000bd001,
+/* 0x01d6: mmctx_exec_loop */
+/* 0x01d6: mmctx_wait_free */
+ 0xe7f104bd,
+ 0xe3f0c500,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f30b,
+ 0x05e9fd00,
+ 0xc80007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+ 0xb804c0b6,
+ 0x1bf404cd,
+ 0x02abc8d8,
+/* 0x0207: mmctx_fini_wait */
+ 0xf11f1bf4,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x1fb4f000,
+ 0xf410b4b0,
+ 0xa7f0f01b,
+ 0xd021f402,
+/* 0x0223: mmctx_stop */
+ 0xc82b0ef4,
  0xb4b600ab,
  0x0cb9f010,
- 0xb601aec8,
- 0xbefd11e4,
- 0x008bd005,
-/* 0x01b4: mmctx_exec_loop */
-/* 0x01b4: mmctx_wait_free */
- 0xf0008ecf,
- 0x0bf41fe4,
- 0x00ce98fa,
- 0xd005e9fd,
- 0xc0b6c08e,
- 0x04cdb804,
- 0xc8e81bf4,
- 0x1bf402ab,
-/* 0x01d5: mmctx_fini_wait */
- 0x008bcf18,
- 0xb01fb4f0,
- 0x1bf410b4,
- 0x02a7f0f7,
- 0xf4c921f4,
-/* 0x01ea: mmctx_stop */
- 0xabc81b0e,
- 0x10b4b600,
- 0xf00cb9f0,
- 0x8bd012b9,
-/* 0x01f9: mmctx_stop_wait */
- 0x008bcf00,
- 0xf412bbc8,
-/* 0x0202: mmctx_done */
- 0x94bdfa1b,
- 0xf10199f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0215: strand_wait */
- 0xf0a0f900,
- 0x21f402a7,
- 0xf8a0fcc9,
-/* 0x0221: strand_pre */
- 0xfc87f100,
- 0x0283f04a,
- 0xd00c97f0,
- 0x21f50089,
- 0x00f80215,
-/* 0x0234: strand_post */
- 0x4afc87f1,
- 0xf00283f0,
- 0x89d00d97,
- 0x1521f500,
-/* 0x0247: strand_set */
- 0xf100f802,
- 0xf04ffca7,
- 0xaba202a3,
- 0xc7f00500,
- 0x00acd00f,
- 0xd00bc7f0,
- 0x21f500bc,
- 0xaed00215,
- 0x0ac7f000,
- 0xf500bcd0,
- 0xf8021521,
-/* 0x0271: strand_ctx_init */
- 0xf094bd00,
- 0x07f10399,
- 0x03f00f00,
+ 0xf112b9f0,
+ 0xf0c50007,
+ 0x0bd00103,
+/* 0x023b: mmctx_stop_wait */
+ 0xf104bd00,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x12bbc800,
+/* 0x024b: mmctx_done */
+ 0xbdf31bf4,
+ 0x0199f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x025e: strand_wait */
+ 0xa0f900f8,
+ 0xf402a7f0,
+ 0xa0fcd021,
+/* 0x026a: strand_pre */
+ 0x97f000f8,
+ 0xfc07f10c,
+ 0x0203f04a,
+ 0xbd0009d0,
+ 0x5e21f504,
+/* 0x027f: strand_post */
+ 0xf000f802,
+ 0x07f10d97,
+ 0x03f04afc,
  0x0009d002,
  0x21f504bd,
- 0xe7f00221,
- 0x4721f503,
- 0xfca7f102,
- 0x02a3f046,
- 0x0400aba0,
- 0xf040a0d0,
- 0xbcd001c7,
- 0x1521f500,
- 0x010c9202,
- 0xf000acd0,
- 0xbcd002c7,
- 0x1521f500,
- 0x3421f502,
- 0x8087f102,
- 0x0684b608,
- 0xb70089cf,
- 0x95220080,
-/* 0x02ca: ctx_init_strand_loop */
+ 0x00f8025e,
+/* 0x0294: strand_set */
+ 0xf10fc7f0,
+ 0xf04ffc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f10bc7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x07f104bd,
+ 0x03f04ffc,
+ 0x000ed002,
+ 0xc7f004bd,
+ 0xfc07f10a,
+ 0x0203f04a,
+ 0xbd000cd0,
+ 0x5e21f504,
+/* 0x02d3: strand_ctx_init */
+ 0xbd00f802,
+ 0x0399f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0x026a21f5,
+ 0xf503e7f0,
+ 0xbd029421,
+ 0xfc07f1c4,
+ 0x0203f047,
+ 0xbd000cd0,
+ 0x01c7f004,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd000c,
+ 0x025e21f5,
+ 0xf1010c92,
+ 0xf046fc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f102c7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x21f504bd,
+ 0x21f5025e,
+ 0x87f1027f,
+ 0x83f04200,
+ 0x0097f102,
+ 0x0293f020,
+ 0x950099cf,
+/* 0x034a: ctx_init_strand_loop */
  0x8ed008fe,
  0x408ed000,
  0xb6808acf,
@@ -263,198 +293,230 @@ uint32_t nve0_grgpc_code[] = {
  0x170007f1,
  0xd00203f0,
  0x04bd0009,
-/* 0x02fe: error */
+/* 0x037e: error */
  0xe0f900f8,
- 0x9814e7f1,
- 0xf440e3f0,
- 0xe0b78d21,
- 0xf7f0041c,
- 0x8d21f401,
- 0x00f8e0fc,
-/* 0x0318: init */
- 0x04fe04bd,
- 0x0017f100,
- 0x0227f012,
- 0xf10012d0,
- 0xfe047017,
- 0x17f10010,
- 0x10d00400,
- 0x0427f0c0,
- 0xf40012d0,
- 0x17f11031,
- 0x14b60608,
- 0x0012cf06,
+ 0xf102ffb9,
+ 0xf09814e7,
+ 0x21f440e3,
+ 0x01f7f09d,
+ 0xf102ffb9,
+ 0xf09c1ce7,
+ 0x21f440e3,
+ 0xf8e0fc9d,
+/* 0x03a1: init */
+ 0xfe04bd00,
+ 0x27f00004,
+ 0x0007f102,
+ 0x0003f012,
+ 0xbd0002d0,
+ 0x1f17f104,
+ 0x0010fe05,
+ 0x070007f1,
+ 0xd00003f0,
+ 0x04bd0000,
+ 0xf10427f0,
+ 0xf0040007,
+ 0x02d00003,
+ 0xf404bd00,
+ 0x27f11031,
+ 0x23f08200,
+ 0x0022cf01,
  0xf00137f0,
  0x32bb1f24,
  0x0132b604,
  0x80050280,
- 0x10b70603,
- 0x12cf0400,
- 0x04028000,
- 0x0c30e7f1,
- 0xbd50e3f0,
- 0xbd34bd24,
-/* 0x0371: init_unk_loop */
- 0x6821f444,
- 0xf400f6b0,
- 0xf7f00f0b,
- 0x04f2bb01,
- 0xb6054ffd,
-/* 0x0386: init_unk_next */
- 0x20b60130,
- 0x04e0b601,
- 0xf40126b0,
-/* 0x0392: init_unk_done */
- 0x0380e21b,
- 0x08048007,
- 0x010027f1,
- 0xcf0223f0,
- 0x34bd0022,
- 0x070047f1,
- 0x950644b6,
- 0x45d00825,
- 0x4045d000,
- 0x98000e98,
- 0x21f5010f,
- 0x2fbb0147,
- 0x003fbb00,
- 0x98010e98,
- 0x21f5020f,
- 0x0e980147,
- 0x00effd05,
- 0xbb002ebb,
- 0x0e98003e,
- 0x030f9802,
- 0x014721f5,
- 0xfd070e98,
+ 0x27f10603,
+ 0x23f08600,
+ 0x0022cf01,
+ 0xf1040280,
+ 0xf00c30e7,
+ 0x24bd50e3,
+ 0x44bd34bd,
+/* 0x0410: init_unk_loop */
+ 0xb06821f4,
+ 0x0bf400f6,
+ 0x01f7f00f,
+ 0xfd04f2bb,
+ 0x30b6054f,
+/* 0x0425: init_unk_next */
+ 0x0120b601,
+ 0xb004e0b6,
+ 0x1bf40126,
+/* 0x0431: init_unk_done */
+ 0x070380e2,
+ 0xf1080480,
+ 0xf0010027,
+ 0x22cf0223,
+ 0x9534bd00,
+ 0x07f10825,
+ 0x03f0c000,
+ 0x0005d001,
+ 0x07f104bd,
+ 0x03f0c100,
+ 0x0005d001,
+ 0x0e9804bd,
+ 0x010f9800,
+ 0x015021f5,
+ 0xbb002fbb,
+ 0x0e98003f,
+ 0x020f9801,
+ 0x015021f5,
+ 0xfd050e98,
  0x2ebb00ef,
  0x003ebb00,
- 0x130040b7,
- 0xd00235b6,
- 0x25b60043,
- 0x0635b608,
- 0xb60120b6,
- 0x24b60130,
- 0x0834b608,
- 0xf5022fb9,
- 0xbb027121,
- 0x07f1003f,
- 0x03f00100,
- 0x0003d002,
- 0x24bd04bd,
- 0xf11f29f0,
- 0xf0080007,
- 0x02d00203,
-/* 0x0433: main */
+ 0x98020e98,
+ 0x21f5030f,
+ 0x0e980150,
+ 0x00effd07,
+ 0xbb002ebb,
+ 0x35b6003e,
+ 0x0007f102,
+ 0x0103f0d3,
+ 0xbd0003d0,
+ 0x0825b604,
+ 0xb60635b6,
+ 0x30b60120,
+ 0x0824b601,
+ 0xb90834b6,
+ 0x21f5022f,
+ 0x3fbb02d3,
+ 0x0007f100,
+ 0x0203f001,
+ 0xbd0003d0,
+ 0xf024bd04,
+ 0x07f11f29,
+ 0x03f00800,
+ 0x0002d002,
+/* 0x04e2: main */
+ 0x31f404bd,
+ 0x0028f400,
+ 0xf424d7f0,
+ 0x01f43921,
+ 0x04e4b0f4,
+ 0xfe1e18f4,
+ 0x27f00181,
+ 0xfd20bd06,
+ 0xe4b60412,
+ 0x051efd01,
+ 0xf50018fe,
+ 0xf405d721,
+/* 0x0512: main_not_ctx_xfer */
+ 0xef94d30e,
+ 0x01f5f010,
+ 0x037e21f5,
+/* 0x051f: ih */
+ 0xf9c60ef4,
+ 0x0188fe80,
+ 0x90f980f9,
+ 0xb0f9a0f9,
+ 0xe0f9d0f9,
+ 0x04bdf0f9,
+ 0x0200a7f1,
+ 0xcf00a3f0,
+ 0xabc400aa,
+ 0x2c0bf404,
+ 0xf124d7f0,
+ 0xf01a00e7,
+ 0xeecf00e3,
+ 0x00f7f100,
+ 0x00f3f019,
+ 0xf400ffcf,
+ 0xe7f00421,
+ 0x0007f101,
+ 0x0003f01d,
+ 0xbd000ed0,
+/* 0x056d: ih_no_fifo */
+ 0x0007f104,
+ 0x0003f001,
+ 0xbd000ad0,
+ 0xfcf0fc04,
+ 0xfcd0fce0,
+ 0xfca0fcb0,
+ 0xfe80fc90,
+ 0x80fc0088,
+ 0xf80032f4,
+/* 0x0591: hub_barrier_done */
+ 0x01f7f001,
+ 0xbb040e98,
+ 0xffb904fe,
+ 0x18e7f102,
+ 0x40e3f094,
+ 0xf89d21f4,
+/* 0x05a9: ctx_redswitch */
+ 0x20f7f000,
+ 0x850007f1,
+ 0xd00103f0,
+ 0x04bd000f,
+/* 0x05bb: ctx_redswitch_delay */
+ 0xb608e7f0,
+ 0x1bf401e2,
+ 0x00f5f1fd,
+ 0x00f5f108,
+ 0x0007f102,
+ 0x0103f085,
+ 0xbd000fd0,
+/* 0x05d7: ctx_xfer */
+ 0xf100f804,
+ 0xf0810007,
+ 0x0fd00203,
  0xf404bd00,
- 0x28f40031,
- 0x24d7f000,
- 0xf43921f4,
- 0xe4b0f401,
- 0x1e18f404,
- 0xf00181fe,
- 0x20bd0627,
- 0xb60412fd,
- 0x1efd01e4,
- 0x0018fe05,
- 0x04f721f5,
-/* 0x0463: main_not_ctx_xfer */
- 0x94d30ef4,
- 0xf5f010ef,
- 0xfe21f501,
- 0xc60ef402,
-/* 0x0470: ih */
- 0x88fe80f9,
- 0xf980f901,
- 0xf9a0f990,
- 0xf9d0f9b0,
- 0xbdf0f9e0,
- 0x800acf04,
- 0xf404abc4,
- 0xb7f11d0b,
- 0xd7f01900,
- 0x40becf24,
- 0xf400bfcf,
- 0xb0b70421,
- 0xe7f00400,
- 0x00bed001,
-/* 0x04a8: ih_no_fifo */
- 0xfc400ad0,
- 0xfce0fcf0,
- 0xfcb0fcd0,
- 0xfc90fca0,
- 0x0088fe80,
- 0x32f480fc,
-/* 0x04c3: hub_barrier_done */
- 0xf001f800,
- 0x0e9801f7,
- 0x04febb04,
- 0x9418e7f1,
- 0xf440e3f0,
- 0x00f88d21,
-/* 0x04d8: ctx_redswitch */
- 0x0614e7f1,
- 0xf006e4b6,
- 0xefd020f7,
- 0x08f7f000,
-/* 0x04e8: ctx_redswitch_delay */
- 0xf401f2b6,
- 0xf7f1fd1b,
- 0xefd00a20,
-/* 0x04f7: ctx_xfer */
- 0xf100f800,
- 0xb60a0417,
- 0x1fd00614,
- 0x0711f400,
- 0x04d821f5,
-/* 0x0508: ctx_xfer_not_load */
- 0x4afc17f1,
- 0xf00213f0,
- 0x12d00c27,
- 0x1521f500,
- 0xfc27f102,
- 0x0223f047,
- 0xf00020d0,
- 0x20b6012c,
- 0x0012d003,
- 0xf001acf0,
- 0xb7f002a5,
- 0x50b3f000,
- 0xb6040c98,
- 0xbcbb0fc4,
- 0x000c9800,
- 0xf0010d98,
- 0x21f500e7,
- 0xacf00166,
- 0x00b7f101,
- 0x50b3f040,
- 0xb6040c98,
- 0xbcbb0fc4,
- 0x010c9800,
- 0x98020d98,
- 0xe7f1060f,
- 0x21f50800,
- 0xacf00166,
- 0x04a5f001,
- 0x3000b7f1,
+ 0x21f50711,
+/* 0x05ea: ctx_xfer_not_load */
+ 0x21f505a9,
+ 0x24bd026a,
+ 0x47fc07f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xb6012cf0,
+ 0x07f10320,
+ 0x03f04afc,
+ 0x0002d002,
+ 0xacf004bd,
+ 0x02a5f001,
+ 0x0000b7f1,
  0x9850b3f0,
  0xc4b6040c,
  0x00bcbb0f,
- 0x98020c98,
- 0x0f98030d,
- 0x00e7f108,
- 0x6621f502,
- 0x1521f501,
- 0x0601f402,
-/* 0x05a3: ctx_xfer_post */
- 0xf11412f4,
- 0xf04afc17,
- 0x27f00213,
- 0x0012d00d,
- 0x021521f5,
-/* 0x05b4: ctx_xfer_done */
- 0x04c321f5,
- 0x000000f8,
+ 0x98000c98,
+ 0xe7f0010d,
+ 0x6f21f500,
+ 0x01acf001,
+ 0x4000b7f1,
+ 0x9850b3f0,
+ 0xc4b6040c,
+ 0x00bcbb0f,
+ 0x98010c98,
+ 0x0f98020d,
+ 0x00e7f106,
+ 0x6f21f508,
+ 0x01acf001,
+ 0xf104a5f0,
+ 0xf03000b7,
+ 0x0c9850b3,
+ 0x0fc4b604,
+ 0x9800bcbb,
+ 0x0d98020c,
+ 0x080f9803,
+ 0x0200e7f1,
+ 0x016f21f5,
+ 0x025e21f5,
+ 0xf40601f4,
+/* 0x0686: ctx_xfer_post */
+ 0x21f50712,
+/* 0x068a: ctx_xfer_done */
+ 0x21f5027f,
+ 0x00f80591,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvf0.fuc.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvf0.fuc.h
index f870507..6316eba 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvf0.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/gpcnvf0.fuc.h
@@ -41,14 +41,14 @@ uint32_t nvf0_grgpc_data[] = {
 };
 
 uint32_t nvf0_grgpc_code[] = {
- 0x03180ef5,
+ 0x03a10ef5,
 /* 0x0004: queue_put */
  0x9800d898,
  0x86f001d9,
  0x0489b808,
  0xf00c1bf4,
  0x21f502f7,
- 0x00f802fe,
+ 0x00f8037e,
 /* 0x001c: queue_put_next */
  0xb60798c4,
  0x8dbb0384,
@@ -72,184 +72,214 @@ uint32_t nvf0_grgpc_code[] = {
 /* 0x0066: queue_get_done */
  0x00f80132,
 /* 0x0068: nv_rd32 */
- 0x0728b7f1,
- 0xb906b4b6,
- 0xc9f002ec,
- 0x00bcd01f,
-/* 0x0078: nv_rd32_wait */
- 0xc800bccf,
- 0x1bf41fcc,
- 0x06a7f0fa,
- 0x010921f5,
- 0xf840bfcf,
-/* 0x008d: nv_wr32 */
- 0x28b7f100,
- 0x06b4b607,
- 0xb980bfd0,
- 0xc9f002ec,
- 0x1ec9f01f,
-/* 0x00a3: nv_wr32_wait */
- 0xcf00bcd0,
- 0xccc800bc,
- 0xfa1bf41f,
-/* 0x00ae: watchdog_reset */
- 0x87f100f8,
- 0x84b60430,
- 0x1ff9f006,
- 0xf8008fd0,
-/* 0x00bd: watchdog_clear */
- 0x3087f100,
- 0x0684b604,
- 0xf80080d0,
-/* 0x00c9: wait_donez */
- 0xf094bd00,
- 0x07f10099,
- 0x03f03700,
- 0x0009d002,
- 0x07f104bd,
- 0x03f00600,
- 0x000ad002,
-/* 0x00e6: wait_donez_ne */
- 0x87f104bd,
- 0x83f00000,
- 0x0088cf01,
- 0xf4888aff,
- 0x94bdf31b,
- 0xf10099f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0109: wait_doneo */
- 0xf094bd00,
+ 0xf002ecb9,
+ 0x07f11fc9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x007a: nv_rd32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0xa7f0f31b,
+ 0x1021f506,
+ 0x00f7f101,
+ 0x01f3f0cb,
+ 0xf800ffcf,
+/* 0x009d: nv_wr32 */
+ 0x0007f100,
+ 0x0103f0cc,
+ 0xbd000fd0,
+ 0x02ecb904,
+ 0xf01fc9f0,
+ 0x07f11ec9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x00be: nv_wr32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f31b,
+/* 0x00d0: wait_donez */
+ 0x99f094bd,
+ 0x0007f100,
+ 0x0203f037,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x00ed: wait_donez_ne */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x1bf4888a,
+ 0xf094bdf3,
  0x07f10099,
- 0x03f03700,
+ 0x03f01700,
  0x0009d002,
- 0x87f104bd,
- 0x84b60818,
- 0x008ad006,
-/* 0x0124: wait_doneo_e */
- 0x040087f1,
- 0xcf0684b6,
- 0x8aff0088,
- 0xf30bf488,
+ 0x00f804bd,
+/* 0x0110: wait_doneo */
  0x99f094bd,
  0x0007f100,
- 0x0203f017,
+ 0x0203f037,
  0xbd0009d0,
-/* 0x0147: mmctx_size */
- 0xbd00f804,
-/* 0x0149: nv_mmctx_size_loop */
- 0x00e89894,
- 0xb61a85b6,
- 0x84b60180,
- 0x0098bb02,
- 0xb804e0b6,
- 0x1bf404ef,
- 0x029fb9eb,
-/* 0x0166: mmctx_xfer */
- 0x94bd00f8,
- 0xf10199f0,
- 0xf0370007,
- 0x09d00203,
- 0xf104bd00,
- 0xb6071087,
- 0x94bd0684,
- 0xf405bbfd,
- 0x8bd0090b,
- 0x0099f000,
-/* 0x018c: mmctx_base_disabled */
- 0xf405eefd,
- 0x8ed00c0b,
- 0xc08fd080,
-/* 0x019b: mmctx_multi_disabled */
- 0xb70199f0,
- 0xc8010080,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x012d: wait_doneo_e */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x0bf4888a,
+ 0xf094bdf3,
+ 0x07f10099,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0150: mmctx_size */
+/* 0x0152: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0xf404efb8,
+ 0x9fb9eb1b,
+/* 0x016f: mmctx_xfer */
+ 0xbd00f802,
+ 0x0199f094,
+ 0x370007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0xbbfd94bd,
+ 0x120bf405,
+ 0xc40007f1,
+ 0xd00103f0,
+ 0x04bd000b,
+/* 0x0197: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0x0007f11e,
+ 0x0103f0c6,
+ 0xbd000ed0,
+ 0x0007f104,
+ 0x0103f0c7,
+ 0xbd000fd0,
+ 0x0199f004,
+/* 0x01b8: mmctx_multi_disabled */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x01aec80c,
+ 0xfd11e4b6,
+ 0x07f105be,
+ 0x03f0c500,
+ 0x000bd001,
+/* 0x01d6: mmctx_exec_loop */
+/* 0x01d6: mmctx_wait_free */
+ 0xe7f104bd,
+ 0xe3f0c500,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f30b,
+ 0x05e9fd00,
+ 0xc80007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+ 0xb804c0b6,
+ 0x1bf404cd,
+ 0x02abc8d8,
+/* 0x0207: mmctx_fini_wait */
+ 0xf11f1bf4,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x1fb4f000,
+ 0xf410b4b0,
+ 0xa7f0f01b,
+ 0xd021f402,
+/* 0x0223: mmctx_stop */
+ 0xc82b0ef4,
  0xb4b600ab,
  0x0cb9f010,
- 0xb601aec8,
- 0xbefd11e4,
- 0x008bd005,
-/* 0x01b4: mmctx_exec_loop */
-/* 0x01b4: mmctx_wait_free */
- 0xf0008ecf,
- 0x0bf41fe4,
- 0x00ce98fa,
- 0xd005e9fd,
- 0xc0b6c08e,
- 0x04cdb804,
- 0xc8e81bf4,
- 0x1bf402ab,
-/* 0x01d5: mmctx_fini_wait */
- 0x008bcf18,
- 0xb01fb4f0,
- 0x1bf410b4,
- 0x02a7f0f7,
- 0xf4c921f4,
-/* 0x01ea: mmctx_stop */
- 0xabc81b0e,
- 0x10b4b600,
- 0xf00cb9f0,
- 0x8bd012b9,
-/* 0x01f9: mmctx_stop_wait */
- 0x008bcf00,
- 0xf412bbc8,
-/* 0x0202: mmctx_done */
- 0x94bdfa1b,
- 0xf10199f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0215: strand_wait */
- 0xf0a0f900,
- 0x21f402a7,
- 0xf8a0fcc9,
-/* 0x0221: strand_pre */
- 0xfc87f100,
- 0x0283f04a,
- 0xd00c97f0,
- 0x21f50089,
- 0x00f80215,
-/* 0x0234: strand_post */
- 0x4afc87f1,
- 0xf00283f0,
- 0x89d00d97,
- 0x1521f500,
-/* 0x0247: strand_set */
- 0xf100f802,
- 0xf04ffca7,
- 0xaba202a3,
- 0xc7f00500,
- 0x00acd00f,
- 0xd00bc7f0,
- 0x21f500bc,
- 0xaed00215,
- 0x0ac7f000,
- 0xf500bcd0,
- 0xf8021521,
-/* 0x0271: strand_ctx_init */
- 0xf094bd00,
- 0x07f10399,
- 0x03f03700,
+ 0xf112b9f0,
+ 0xf0c50007,
+ 0x0bd00103,
+/* 0x023b: mmctx_stop_wait */
+ 0xf104bd00,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x12bbc800,
+/* 0x024b: mmctx_done */
+ 0xbdf31bf4,
+ 0x0199f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x025e: strand_wait */
+ 0xa0f900f8,
+ 0xf402a7f0,
+ 0xa0fcd021,
+/* 0x026a: strand_pre */
+ 0x97f000f8,
+ 0xfc07f10c,
+ 0x0203f04a,
+ 0xbd0009d0,
+ 0x5e21f504,
+/* 0x027f: strand_post */
+ 0xf000f802,
+ 0x07f10d97,
+ 0x03f04afc,
  0x0009d002,
  0x21f504bd,
- 0xe7f00221,
- 0x4721f503,
- 0xfca7f102,
- 0x02a3f046,
- 0x0400aba0,
- 0xf040a0d0,
- 0xbcd001c7,
- 0x1521f500,
- 0x010c9202,
- 0xf000acd0,
- 0xbcd002c7,
- 0x1521f500,
- 0x3421f502,
- 0x8087f102,
- 0x0684b608,
- 0xb70089cf,
- 0x95220080,
-/* 0x02ca: ctx_init_strand_loop */
+ 0x00f8025e,
+/* 0x0294: strand_set */
+ 0xf10fc7f0,
+ 0xf04ffc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f10bc7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x07f104bd,
+ 0x03f04ffc,
+ 0x000ed002,
+ 0xc7f004bd,
+ 0xfc07f10a,
+ 0x0203f04a,
+ 0xbd000cd0,
+ 0x5e21f504,
+/* 0x02d3: strand_ctx_init */
+ 0xbd00f802,
+ 0x0399f094,
+ 0x370007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0x026a21f5,
+ 0xf503e7f0,
+ 0xbd029421,
+ 0xfc07f1c4,
+ 0x0203f047,
+ 0xbd000cd0,
+ 0x01c7f004,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd000c,
+ 0x025e21f5,
+ 0xf1010c92,
+ 0xf046fc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f102c7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x21f504bd,
+ 0x21f5025e,
+ 0x87f1027f,
+ 0x83f04200,
+ 0x0097f102,
+ 0x0293f020,
+ 0x950099cf,
+/* 0x034a: ctx_init_strand_loop */
  0x8ed008fe,
  0x408ed000,
  0xb6808acf,
@@ -263,198 +293,230 @@ uint32_t nvf0_grgpc_code[] = {
  0x170007f1,
  0xd00203f0,
  0x04bd0009,
-/* 0x02fe: error */
+/* 0x037e: error */
  0xe0f900f8,
- 0x9814e7f1,
- 0xf440e3f0,
- 0xe0b78d21,
- 0xf7f0041c,
- 0x8d21f401,
- 0x00f8e0fc,
-/* 0x0318: init */
- 0x04fe04bd,
- 0x0017f100,
- 0x0227f012,
- 0xf10012d0,
- 0xfe047017,
- 0x17f10010,
- 0x10d00400,
- 0x0427f0c0,
- 0xf40012d0,
- 0x17f11031,
- 0x14b60608,
- 0x0012cf06,
+ 0xf102ffb9,
+ 0xf09814e7,
+ 0x21f440e3,
+ 0x01f7f09d,
+ 0xf102ffb9,
+ 0xf09c1ce7,
+ 0x21f440e3,
+ 0xf8e0fc9d,
+/* 0x03a1: init */
+ 0xfe04bd00,
+ 0x27f00004,
+ 0x0007f102,
+ 0x0003f012,
+ 0xbd0002d0,
+ 0x1f17f104,
+ 0x0010fe05,
+ 0x070007f1,
+ 0xd00003f0,
+ 0x04bd0000,
+ 0xf10427f0,
+ 0xf0040007,
+ 0x02d00003,
+ 0xf404bd00,
+ 0x27f11031,
+ 0x23f08200,
+ 0x0022cf01,
  0xf00137f0,
  0x32bb1f24,
  0x0132b604,
  0x80050280,
- 0x10b70603,
- 0x12cf0400,
- 0x04028000,
- 0x0c30e7f1,
- 0xbd50e3f0,
- 0xbd34bd24,
-/* 0x0371: init_unk_loop */
- 0x6821f444,
- 0xf400f6b0,
- 0xf7f00f0b,
- 0x04f2bb01,
- 0xb6054ffd,
-/* 0x0386: init_unk_next */
- 0x20b60130,
- 0x04e0b601,
- 0xf40226b0,
-/* 0x0392: init_unk_done */
- 0x0380e21b,
- 0x08048007,
- 0x010027f1,
- 0xcf0223f0,
- 0x34bd0022,
- 0x070047f1,
- 0x950644b6,
- 0x45d00825,
- 0x4045d000,
- 0x98000e98,
- 0x21f5010f,
- 0x2fbb0147,
- 0x003fbb00,
- 0x98010e98,
- 0x21f5020f,
- 0x0e980147,
- 0x00effd05,
- 0xbb002ebb,
- 0x0e98003e,
- 0x030f9802,
- 0x014721f5,
- 0xfd070e98,
+ 0x27f10603,
+ 0x23f08600,
+ 0x0022cf01,
+ 0xf1040280,
+ 0xf00c30e7,
+ 0x24bd50e3,
+ 0x44bd34bd,
+/* 0x0410: init_unk_loop */
+ 0xb06821f4,
+ 0x0bf400f6,
+ 0x01f7f00f,
+ 0xfd04f2bb,
+ 0x30b6054f,
+/* 0x0425: init_unk_next */
+ 0x0120b601,
+ 0xb004e0b6,
+ 0x1bf40226,
+/* 0x0431: init_unk_done */
+ 0x070380e2,
+ 0xf1080480,
+ 0xf0010027,
+ 0x22cf0223,
+ 0x9534bd00,
+ 0x07f10825,
+ 0x03f0c000,
+ 0x0005d001,
+ 0x07f104bd,
+ 0x03f0c100,
+ 0x0005d001,
+ 0x0e9804bd,
+ 0x010f9800,
+ 0x015021f5,
+ 0xbb002fbb,
+ 0x0e98003f,
+ 0x020f9801,
+ 0x015021f5,
+ 0xfd050e98,
  0x2ebb00ef,
  0x003ebb00,
- 0x130040b7,
- 0xd00235b6,
- 0x25b60043,
- 0x0635b608,
- 0xb60120b6,
- 0x24b60130,
- 0x0834b608,
- 0xf5022fb9,
- 0xbb027121,
- 0x07f1003f,
- 0x03f00100,
- 0x0003d002,
- 0x24bd04bd,
- 0xf11f29f0,
- 0xf0300007,
- 0x02d00203,
-/* 0x0433: main */
+ 0x98020e98,
+ 0x21f5030f,
+ 0x0e980150,
+ 0x00effd07,
+ 0xbb002ebb,
+ 0x35b6003e,
+ 0x0007f102,
+ 0x0103f0d3,
+ 0xbd0003d0,
+ 0x0825b604,
+ 0xb60635b6,
+ 0x30b60120,
+ 0x0824b601,
+ 0xb90834b6,
+ 0x21f5022f,
+ 0x3fbb02d3,
+ 0x0007f100,
+ 0x0203f001,
+ 0xbd0003d0,
+ 0xf024bd04,
+ 0x07f11f29,
+ 0x03f03000,
+ 0x0002d002,
+/* 0x04e2: main */
+ 0x31f404bd,
+ 0x0028f400,
+ 0xf424d7f0,
+ 0x01f43921,
+ 0x04e4b0f4,
+ 0xfe1e18f4,
+ 0x27f00181,
+ 0xfd20bd06,
+ 0xe4b60412,
+ 0x051efd01,
+ 0xf50018fe,
+ 0xf405d721,
+/* 0x0512: main_not_ctx_xfer */
+ 0xef94d30e,
+ 0x01f5f010,
+ 0x037e21f5,
+/* 0x051f: ih */
+ 0xf9c60ef4,
+ 0x0188fe80,
+ 0x90f980f9,
+ 0xb0f9a0f9,
+ 0xe0f9d0f9,
+ 0x04bdf0f9,
+ 0x0200a7f1,
+ 0xcf00a3f0,
+ 0xabc400aa,
+ 0x2c0bf404,
+ 0xf124d7f0,
+ 0xf01a00e7,
+ 0xeecf00e3,
+ 0x00f7f100,
+ 0x00f3f019,
+ 0xf400ffcf,
+ 0xe7f00421,
+ 0x0007f101,
+ 0x0003f01d,
+ 0xbd000ed0,
+/* 0x056d: ih_no_fifo */
+ 0x0007f104,
+ 0x0003f001,
+ 0xbd000ad0,
+ 0xfcf0fc04,
+ 0xfcd0fce0,
+ 0xfca0fcb0,
+ 0xfe80fc90,
+ 0x80fc0088,
+ 0xf80032f4,
+/* 0x0591: hub_barrier_done */
+ 0x01f7f001,
+ 0xbb040e98,
+ 0xffb904fe,
+ 0x18e7f102,
+ 0x40e3f094,
+ 0xf89d21f4,
+/* 0x05a9: ctx_redswitch */
+ 0x20f7f000,
+ 0x850007f1,
+ 0xd00103f0,
+ 0x04bd000f,
+/* 0x05bb: ctx_redswitch_delay */
+ 0xb608e7f0,
+ 0x1bf401e2,
+ 0x00f5f1fd,
+ 0x00f5f108,
+ 0x0007f102,
+ 0x0103f085,
+ 0xbd000fd0,
+/* 0x05d7: ctx_xfer */
+ 0xf100f804,
+ 0xf0810007,
+ 0x0fd00203,
  0xf404bd00,
- 0x28f40031,
- 0x24d7f000,
- 0xf43921f4,
- 0xe4b0f401,
- 0x1e18f404,
- 0xf00181fe,
- 0x20bd0627,
- 0xb60412fd,
- 0x1efd01e4,
- 0x0018fe05,
- 0x04f721f5,
-/* 0x0463: main_not_ctx_xfer */
- 0x94d30ef4,
- 0xf5f010ef,
- 0xfe21f501,
- 0xc60ef402,
-/* 0x0470: ih */
- 0x88fe80f9,
- 0xf980f901,
- 0xf9a0f990,
- 0xf9d0f9b0,
- 0xbdf0f9e0,
- 0x800acf04,
- 0xf404abc4,
- 0xb7f11d0b,
- 0xd7f01900,
- 0x40becf24,
- 0xf400bfcf,
- 0xb0b70421,
- 0xe7f00400,
- 0x00bed001,
-/* 0x04a8: ih_no_fifo */
- 0xfc400ad0,
- 0xfce0fcf0,
- 0xfcb0fcd0,
- 0xfc90fca0,
- 0x0088fe80,
- 0x32f480fc,
-/* 0x04c3: hub_barrier_done */
- 0xf001f800,
- 0x0e9801f7,
- 0x04febb04,
- 0x9418e7f1,
- 0xf440e3f0,
- 0x00f88d21,
-/* 0x04d8: ctx_redswitch */
- 0x0614e7f1,
- 0xf006e4b6,
- 0xefd020f7,
- 0x08f7f000,
-/* 0x04e8: ctx_redswitch_delay */
- 0xf401f2b6,
- 0xf7f1fd1b,
- 0xefd00a20,
-/* 0x04f7: ctx_xfer */
- 0xf100f800,
- 0xb60a0417,
- 0x1fd00614,
- 0x0711f400,
- 0x04d821f5,
-/* 0x0508: ctx_xfer_not_load */
- 0x4afc17f1,
- 0xf00213f0,
- 0x12d00c27,
- 0x1521f500,
- 0xfc27f102,
- 0x0223f047,
- 0xf00020d0,
- 0x20b6012c,
- 0x0012d003,
- 0xf001acf0,
- 0xb7f002a5,
- 0x50b3f000,
- 0xb6040c98,
- 0xbcbb0fc4,
- 0x000c9800,
- 0xf0010d98,
- 0x21f500e7,
- 0xacf00166,
- 0x00b7f101,
- 0x50b3f040,
- 0xb6040c98,
- 0xbcbb0fc4,
- 0x010c9800,
- 0x98020d98,
- 0xe7f1060f,
- 0x21f50800,
- 0xacf00166,
- 0x04a5f001,
- 0x3000b7f1,
+ 0x21f50711,
+/* 0x05ea: ctx_xfer_not_load */
+ 0x21f505a9,
+ 0x24bd026a,
+ 0x47fc07f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xb6012cf0,
+ 0x07f10320,
+ 0x03f04afc,
+ 0x0002d002,
+ 0xacf004bd,
+ 0x02a5f001,
+ 0x0000b7f1,
  0x9850b3f0,
  0xc4b6040c,
  0x00bcbb0f,
- 0x98020c98,
- 0x0f98030d,
- 0x00e7f108,
- 0x6621f502,
- 0x1521f501,
- 0x0601f402,
-/* 0x05a3: ctx_xfer_post */
- 0xf11412f4,
- 0xf04afc17,
- 0x27f00213,
- 0x0012d00d,
- 0x021521f5,
-/* 0x05b4: ctx_xfer_done */
- 0x04c321f5,
- 0x000000f8,
+ 0x98000c98,
+ 0xe7f0010d,
+ 0x6f21f500,
+ 0x01acf001,
+ 0x4000b7f1,
+ 0x9850b3f0,
+ 0xc4b6040c,
+ 0x00bcbb0f,
+ 0x98010c98,
+ 0x0f98020d,
+ 0x00e7f106,
+ 0x6f21f508,
+ 0x01acf001,
+ 0xf104a5f0,
+ 0xf03000b7,
+ 0x0c9850b3,
+ 0x0fc4b604,
+ 0x9800bcbb,
+ 0x0d98020c,
+ 0x080f9803,
+ 0x0200e7f1,
+ 0x016f21f5,
+ 0x025e21f5,
+ 0xf40601f4,
+/* 0x0686: ctx_xfer_post */
+ 0x21f50712,
+/* 0x068a: ctx_xfer_done */
+ 0x21f5027f,
+ 0x00f80591,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hub.fuc b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hub.fuc
index b82d2ae..c8ddb8d 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hub.fuc
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hub.fuc
@@ -68,60 +68,57 @@ error:
 //
 init:
  clear b32 $r0
- mov $sp $r0
  mov $xdbase $r0
 
+ // setup stack
+ nv_iord($r1, NV_PGRAPH_FECS_CAPS, 0)
+ extr $r1 $r1 9:17
+ shl b32 $r1 8
+ mov $sp $r1
+
  // enable fifo access
- mov $r1 0x1200
- mov $r2 2
- iowr I[$r1 + 0x000] $r2 // FIFO_ENABLE
+ mov $r2 NV_PGRAPH_FECS_ACCESS_FIFO
+ nv_iowr(NV_PGRAPH_FECS_ACCESS, 0, $r2)
 
  // setup i0 handler, and route all interrupts to it
  mov $r1 #ih
  mov $iv0 $r1
- mov $r1 0x400
- iowr I[$r1 + 0x300] $r0 // INTR_DISPATCH
 
- // route HUB_CHANNEL_SWITCH to fuc interrupt 8
- mov $r3 0x404
- shl b32 $r3 6
- mov $r2 0x2003  // { HUB_CHANNEL_SWITCH, ZERO } -> intr 8
- iowr I[$r3 + 0x000] $r2
+ clear b32 $r2
+ nv_iowr(NV_PGRAPH_FECS_INTR_ROUTE, 0, $r2)
+
+ // route HUB_CHSW_PULSE to fuc interrupt 8
+ mov $r2 0x2003  // { HUB_CHSW_PULSE, ZERO } -> intr 8
+ nv_iowr(NV_PGRAPH_FECS_IROUTE, 0, $r2)
 
  // not sure what these are, route them because NVIDIA does, and
  // the IRQ handler will signal the host if we ever get one.. we
  // may find out if/why we need to handle these if so..
  //
- mov $r2 0x2004
- iowr I[$r3 + 0x004] $r2 // { 0x04, ZERO } -> intr 9
- mov $r2 0x200b
- iowr I[$r3 + 0x008] $r2 // { 0x0b, ZERO } -> intr 10
- mov $r2 0x200c
- iowr I[$r3 + 0x01c] $r2 // { 0x0c, ZERO } -> intr 15
+ mov $r2 0x2004  // { 0x04, ZERO } -> intr 9
+ nv_iowr(NV_PGRAPH_FECS_IROUTE, 1, $r2)
+ mov $r2 0x200b  // { HUB_FIRMWARE_MTHD, ZERO } -> intr 10
+ nv_iowr(NV_PGRAPH_FECS_IROUTE, 2, $r2)
+ mov $r2 0x200c  // { 0x0c, ZERO } -> intr 15
+ nv_iowr(NV_PGRAPH_FECS_IROUTE, 7, $r2)
 
  // enable all INTR_UP interrupts
- mov $r2 0xc24
- shl b32 $r2 6
- not b32 $r3 $r0
- iowr I[$r2] $r3
+ sub b32 $r3 $r0 1
+ nv_iowr(NV_PGRAPH_FECS_INTR_UP_EN, 0, $r3)
 
- // enable fifo, ctxsw, 9, 10, 15 interrupts
- mov $r2 -0x78fc  // 0x8704
- sethi $r2 0
- iowr I[$r1 + 0x000] $r2 // INTR_EN_SET
+ // enable fifo, ctxsw, 9, fwmthd, 15 interrupts
+ imm32($r2, 0x8704)
+ nv_iowr(NV_PGRAPH_FECS_INTR_EN_SET, 0, $r2)
 
  // fifo level triggered, rest edge
- sub b32 $r1 0x100
- mov $r2 4
- iowr I[$r1] $r2
+ mov $r2 NV_PGRAPH_FECS_INTR_MODE_FIFO_LEVEL
+ nv_iowr(NV_PGRAPH_FECS_INTR_MODE, 0, $r2)
 
  // enable interrupts
  bset $flags ie0
 
  // fetch enabled GPC/ROP counts
- mov $r14 -0x69fc // 0x409604
- sethi $r14 0x400000
- call #nv_rd32
+ nv_rd32($r14, 0x409604)
  extr $r1 $r15 16:20
  st b32 D[$r0 + #rop_count] $r1
  and $r15 0x1f
@@ -131,37 +128,40 @@ init:
  mov $r1 1
  shl b32 $r1 $r15
  sub b32 $r1 1
- mov $r2 0x40c
- shl b32 $r2 6
- iowr I[$r2 + 0x000] $r1
- iowr I[$r2 + 0x100] $r1
+ nv_iowr(NV_PGRAPH_FECS_BAR_MASK0, 0, $r1)
+ nv_iowr(NV_PGRAPH_FECS_BAR_MASK1, 0, $r1)
 
  // context size calculation, reserve first 256 bytes for use by fuc
  mov $r1 256
 
+ //
+ mov $r15 2
+ call(ctx_4170s)
+ call(ctx_4170w)
+ mov $r15 0x10
+ call(ctx_86c)
+
  // calculate size of mmio context data
  ld b32 $r14 D[$r0 + #hub_mmio_list_head]
  ld b32 $r15 D[$r0 + #hub_mmio_list_tail]
- call #mmctx_size
+ call(mmctx_size)
 
  // set mmctx base addresses now so we don't have to do it later,
  // they don't (currently) ever change
- mov $r3 0x700
- shl b32 $r3 6
  shr b32 $r4 $r1 8
- iowr I[$r3 + 0x000] $r4  // MMCTX_SAVE_SWBASE
- iowr I[$r3 + 0x100] $r4  // MMCTX_LOAD_SWBASE
+ nv_iowr(NV_PGRAPH_FECS_MMCTX_SAVE_SWBASE, 0, $r4)
+ nv_iowr(NV_PGRAPH_FECS_MMCTX_LOAD_SWBASE, 0, $r4)
  add b32 $r3 0x1300
  add b32 $r1 $r15
  shr b32 $r15 2
- iowr I[$r3 + 0x000] $r15 // MMCTX_LOAD_COUNT, wtf for?!?
+ nv_iowr(NV_PGRAPH_FECS_MMCTX_LOAD_COUNT, 0, $r15) // wtf??
 
  // strands, base offset needs to be aligned to 256 bytes
  shr b32 $r1 8
  add b32 $r1 1
  shl b32 $r1 8
  mov b32 $r15 $r1
- call #strand_ctx_init
+ call(strand_ctx_init)
  add b32 $r1 $r15
 
  // initialise each GPC in sequence by passing in the offset of its
@@ -173,30 +173,29 @@ init:
  // in GPCn_CC_SCRATCH[1]
  //
  ld b32 $r3 D[$r0 + #gpc_count]
- mov $r4 0x2000
- sethi $r4 0x500000
+ imm32($r4, 0x502000)
  init_gpc:
   // setup, and start GPC ucode running
   add b32 $r14 $r4 0x804
   mov b32 $r15 $r1
-  call #nv_wr32   // CC_SCRATCH[1] = ctx offset
+  call(nv_wr32)   // CC_SCRATCH[1] = ctx offset
   add b32 $r14 $r4 0x10c
   clear b32 $r15
-  call #nv_wr32
+  call(nv_wr32)
   add b32 $r14 $r4 0x104
-  call #nv_wr32   // ENTRY
+  call(nv_wr32)   // ENTRY
   add b32 $r14 $r4 0x100
   mov $r15 2   // CTRL_START_TRIGGER
-  call #nv_wr32   // CTRL
+  call(nv_wr32)   // CTRL
 
   // wait for it to complete, and adjust context size
   add b32 $r14 $r4 0x800
   init_gpc_wait:
-   call #nv_rd32
+   call(nv_rd32)
    xbit $r15 $r15 31
    bra e #init_gpc_wait
   add b32 $r14 $r4 0x804
-  call #nv_rd32
+  call(nv_rd32)
   add b32 $r1 $r15
 
   // next!
@@ -204,6 +203,12 @@ init:
   sub b32 $r3 1
   bra ne #init_gpc
 
+ //
+ mov $r15 0
+ call(ctx_86c)
+ mov $r15 0
+ call(ctx_4170s)
+
  // save context size, and tell host we're ready
  nv_iowr(NV_PGRAPH_FECS_CC_SCRATCH_VAL(1), 0, $r1)
  clear b32 $r1
@@ -218,17 +223,15 @@ main:
  bset $flags $p0
  sleep $p0
  mov $r13 #cmd_queue
- call #queue_get
+ call(queue_get)
  bra $p1 #main
 
  // context switch, requested by GPU?
  cmpu b32 $r14 0x4001
  bra ne #main_not_ctx_switch
   trace_set(T_AUTO)
-  mov $r1 0xb00
-  shl b32 $r1 6
-  iord $r2 I[$r1 + 0x100]  // CHAN_NEXT
-  iord $r1 I[$r1 + 0x000]  // CHAN_CUR
+  nv_iord($r1, NV_PGRAPH_FECS_CHAN_ADDR, 0)
+  nv_iord($r2, NV_PGRAPH_FECS_CHAN_NEXT, 0)
 
   xbit $r3 $r1 31
   bra e #chsw_no_prev
@@ -239,12 +242,12 @@ main:
     trace_set(T_SAVE)
     bclr $flags $p1
     bset $flags $p2
-    call #ctx_xfer
+    call(ctx_xfer)
     trace_clr(T_SAVE);
     pop $r2
     trace_set(T_LOAD);
     bset $flags $p1
-    call #ctx_xfer
+    call(ctx_xfer)
     trace_clr(T_LOAD);
     bra #chsw_done
    chsw_prev_no_next:
@@ -252,25 +255,21 @@ main:
     mov b32 $r2 $r1
     bclr $flags $p1
     bclr $flags $p2
-    call #ctx_xfer
+    call(ctx_xfer)
     pop $r2
-    mov $r1 0xb00
-    shl b32 $r1 6
-    iowr I[$r1] $r2
+    nv_iowr(NV_PGRAPH_FECS_CHAN_ADDR, 0, $r2)
     bra #chsw_done
   chsw_no_prev:
    xbit $r3 $r2 31
    bra e #chsw_done
     bset $flags $p1
     bclr $flags $p2
-    call #ctx_xfer
+    call(ctx_xfer)
 
   // ack the context switch request
   chsw_done:
-  mov $r1 0xb0c
-  shl b32 $r1 6
-  mov $r2 1
-  iowr I[$r1 + 0x000] $r2  // 0x409b0c
+  mov $r2 NV_PGRAPH_FECS_CHSW_ACK
+  nv_iowr(NV_PGRAPH_FECS_CHSW, 0, $r2)
   trace_clr(T_AUTO)
   bra #main
 
@@ -279,7 +278,7 @@ main:
  cmpu b32 $r14 0x0001
  bra ne #main_not_ctx_chan
   mov b32 $r2 $r15
-  call #ctx_chan
+  call(ctx_chan)
   bra #main_done
 
  // request to store current channel context?
@@ -289,14 +288,14 @@ main:
   trace_set(T_SAVE)
   bclr $flags $p1
   bclr $flags $p2
-  call #ctx_xfer
+  call(ctx_xfer)
   trace_clr(T_SAVE)
   bra #main_done
 
  main_not_ctx_save:
   shl b32 $r15 $r14 16
   or $r15 E_BAD_COMMAND
-  call #error
+  call(error)
   bra #main
 
  main_done:
@@ -319,41 +318,46 @@ ih:
  clear b32 $r0
 
  // incoming fifo command?
- iord $r10 I[$r0 + 0x200] // INTR
- and $r11 $r10 0x00000004
+ nv_iord($r10, NV_PGRAPH_FECS_INTR, 0)
+ and $r11 $r10 NV_PGRAPH_FECS_INTR_FIFO
  bra e #ih_no_fifo
   // queue incoming fifo command for later processing
-  mov $r11 0x1900
   mov $r13 #cmd_queue
-  iord $r14 I[$r11 + 0x100] // FIFO_CMD
-  iord $r15 I[$r11 + 0x000] // FIFO_DATA
-  call #queue_put
+  nv_iord($r14, NV_PGRAPH_FECS_FIFO_CMD, 0)
+  nv_iord($r15, NV_PGRAPH_FECS_FIFO_DATA, 0)
+  call(queue_put)
   add b32 $r11 0x400
   mov $r14 1
-  iowr I[$r11 + 0x000] $r14 // FIFO_ACK
+  nv_iowr(NV_PGRAPH_FECS_FIFO_ACK, 0, $r14)
 
  // context switch request?
  ih_no_fifo:
- and $r11 $r10 0x00000100
+ and $r11 $r10 NV_PGRAPH_FECS_INTR_CHSW
  bra e #ih_no_ctxsw
   // enqueue a context switch for later processing
   mov $r13 #cmd_queue
   mov $r14 0x4001
-  call #queue_put
+  call(queue_put)
 
- // anything we didn't handle, bring it to the host's attention
+ // firmware method?
  ih_no_ctxsw:
- mov $r11 0x104
+ and $r11 $r10 NV_PGRAPH_FECS_INTR_FWMTHD
+ bra e #ih_no_fwmthd
+  // none we handle, ack, and fall-through to unhandled
+  mov $r11 0x100
+  nv_wr32(0x400144, $r11)
+
+ // anything we didn't handle, bring it to the host's attention
+ ih_no_fwmthd:
+ mov $r11 0x104 // FIFO | CHSW
  not b32 $r11
  and $r11 $r10 $r11
  bra e #ih_no_other
-  mov $r10 0xc1c
-  shl b32 $r10 6
-  iowr I[$r10] $r11 // INTR_UP_SET
+  nv_iowr(NV_PGRAPH_FECS_INTR_UP_SET, 0, $r11)
 
  // ack, and wake up main()
  ih_no_other:
- iowr I[$r0 + 0x100] $r10 // INTR_ACK
+ nv_iowr(NV_PGRAPH_FECS_INTR_ACK, 0, $r10)
 
  pop $r15
  pop $r14
@@ -370,12 +374,10 @@ ih:
 #if CHIPSET < GK100
 // Not real sure, but, MEM_CMD 7 will hang forever if this isn't done
 ctx_4160s:
- mov $r14 0x4160
- sethi $r14 0x400000
  mov $r15 1
- call #nv_wr32
+ nv_wr32(0x404160, $r15)
  ctx_4160s_wait:
-  call #nv_rd32
+  nv_rd32($r15, 0x404160)
   xbit $r15 $r15 4
   bra e #ctx_4160s_wait
  ret
@@ -384,10 +386,8 @@ ctx_4160s:
 // to hang with STATUS=0x00000007 until it's cleared.. fbcon can
 // still function with it set however...
 ctx_4160c:
- mov $r14 0x4160
- sethi $r14 0x400000
  clear b32 $r15
- call #nv_wr32
+ nv_wr32(0x404160, $r15)
  ret
 #endif
 
@@ -396,18 +396,14 @@ ctx_4160c:
 // In: $r15 value to set 0x404170 to
 //
 ctx_4170s:
- mov $r14 0x4170
- sethi $r14 0x400000
  or $r15 0x10
- call #nv_wr32
+ nv_wr32(0x404170, $r15)
  ret
 
 // Waits for a ctx_4170s() call to complete
 //
 ctx_4170w:
- mov $r14 0x4170
- sethi $r14 0x400000
- call #nv_rd32
+ nv_rd32($r15, 0x404170)
  and $r15 0x10
  bra ne #ctx_4170w
  ret
@@ -419,16 +415,18 @@ ctx_4170w:
 // funny things happen.
 //
 ctx_redswitch:
- mov $r14 0x614
- shl b32 $r14 6
- mov $r15 0x270
- iowr I[$r14] $r15 // HUB_RED_SWITCH = ENABLE_GPC, POWER_ALL
+ mov $r14 NV_PGRAPH_FECS_RED_SWITCH_ENABLE_GPC
+ or  $r14 NV_PGRAPH_FECS_RED_SWITCH_POWER_ROP
+ or  $r14 NV_PGRAPH_FECS_RED_SWITCH_POWER_GPC
+ or  $r14 NV_PGRAPH_FECS_RED_SWITCH_POWER_MAIN
+ nv_iowr(NV_PGRAPH_FECS_RED_SWITCH, 0, $r14)
  mov $r15 8
  ctx_redswitch_delay:
   sub b32 $r15 1
   bra ne #ctx_redswitch_delay
- mov $r15 0x770
- iowr I[$r14] $r15 // HUB_RED_SWITCH = ENABLE_ALL, POWER_ALL
+ or  $r14 NV_PGRAPH_FECS_RED_SWITCH_ENABLE_ROP
+ or  $r14 NV_PGRAPH_FECS_RED_SWITCH_ENABLE_MAIN
+ nv_iowr(NV_PGRAPH_FECS_RED_SWITCH, 0, $r14)
  ret
 
 // Not a clue what this is for, except that unless the value is 0x10, the
@@ -437,15 +435,18 @@ ctx_redswitch:
 // In: $r15 value to set to (0x00/0x10 are used)
 //
 ctx_86c:
- mov $r14 0x86c
- shl b32 $r14 6
- iowr I[$r14] $r15 // HUB(0x86c) = val
- mov $r14 -0x75ec
- sethi $r14 0x400000
- call #nv_wr32  // ROP(0xa14) = val
- mov $r14 -0x5794
- sethi $r14 0x410000
- call #nv_wr32  // GPC(0x86c) = val
+ nv_iowr(NV_PGRAPH_FECS_UNK86C, 0, $r15)
+ nv_wr32(0x408a14, $r15)
+ nv_wr32(NV_PGRAPH_GPCX_GPCCS_UNK86C, $r15)
+ ret
+
+// In: $r15 NV_PGRAPH_FECS_MEM_CMD_*
+ctx_mem:
+ nv_iowr(NV_PGRAPH_FECS_MEM_CMD, 0, $r15)
+ ctx_mem_wait:
+  nv_iord($r15, NV_PGRAPH_FECS_MEM_CMD, 0)
+  or $r15 $r15
+  bra ne #ctx_mem_wait
  ret
 
 // ctx_load - load's a channel's ctxctl data, and selects its vm
@@ -457,23 +458,14 @@ ctx_load:
 
  // switch to channel, somewhat magic in parts..
  mov $r10 12  // DONE_UNK12
- call #wait_donez
- mov $r1 0xa24
- shl b32 $r1 6
- iowr I[$r1 + 0x000] $r0 // 0x409a24
- mov $r3 0xb00
- shl b32 $r3 6
- iowr I[$r3 + 0x100] $r2 // CHAN_NEXT
- mov $r1 0xa0c
- shl b32 $r1 6
- mov $r4 7
- iowr I[$r1 + 0x000] $r2 // MEM_CHAN
- iowr I[$r1 + 0x100] $r4 // MEM_CMD
- ctx_chan_wait_0:
-  iord $r4 I[$r1 + 0x100]
-  and $r4 0x1f
-  bra ne #ctx_chan_wait_0
- iowr I[$r3 + 0x000] $r2 // CHAN_CUR
+ call(wait_donez)
+ clear b32 $r15
+ nv_iowr(0x409a24, 0, $r15)
+ nv_iowr(NV_PGRAPH_FECS_CHAN_NEXT, 0, $r2)
+ nv_iowr(NV_PGRAPH_FECS_MEM_CHAN, 0, $r2)
+ mov $r15 NV_PGRAPH_FECS_MEM_CMD_LOAD_CHAN
+ call(ctx_mem)
+ nv_iowr(NV_PGRAPH_FECS_CHAN_ADDR, 0, $r2)
 
  // load channel header, fetch PGRAPH context pointer
  mov $xtargets $r0
@@ -482,14 +474,10 @@ ctx_load:
  add b32 $r2 2
 
  trace_set(T_LCHAN)
- mov $r1 0xa04
- shl b32 $r1 6
- iowr I[$r1 + 0x000] $r2  // MEM_BASE
- mov $r1 0xa20
- shl b32 $r1 6
- mov $r2 0x0002
- sethi $r2 0x80000000
- iowr I[$r1 + 0x000] $r2  // MEM_TARGET = vram
+ nv_iowr(NV_PGRAPH_FECS_MEM_BASE, 0, $r2)
+ imm32($r2, NV_PGRAPH_FECS_MEM_TARGET_UNK31)
+ or  $r2 NV_PGRAPH_FECS_MEM_TARGET_AS_VRAM
+ nv_iowr(NV_PGRAPH_FECS_MEM_TARGET, 0, $r2)
  mov $r1 0x10   // chan + 0x0210
  mov $r2 #xfer_data
  sethi $r2 0x00020000  // 16 bytes
@@ -507,13 +495,9 @@ ctx_load:
 
  // set transfer base to start of context, and fetch context header
  trace_set(T_LCTXH)
- mov $r2 0xa04
- shl b32 $r2 6
- iowr I[$r2 + 0x000] $r1  // MEM_BASE
- mov $r2 1
- mov $r1 0xa20
- shl b32 $r1 6
- iowr I[$r1 + 0x000] $r2  // MEM_TARGET = vm
+ nv_iowr(NV_PGRAPH_FECS_MEM_BASE, 0, $r1)
+ mov $r2 NV_PGRAPH_FECS_MEM_TARGET_AS_VM
+ nv_iowr(NV_PGRAPH_FECS_MEM_TARGET, 0, $r2)
  mov $r1 #chan_data
  sethi $r1 0x00060000  // 256 bytes
  xdld $r0 $r1
@@ -532,21 +516,15 @@ ctx_load:
 //
 ctx_chan:
 #if CHIPSET < GK100
- call #ctx_4160s
+ call(ctx_4160s)
 #endif
- call #ctx_load
+ call(ctx_load)
  mov $r10 12   // DONE_UNK12
- call #wait_donez
- mov $r1 0xa10
- shl b32 $r1 6
- mov $r2 5
- iowr I[$r1 + 0x000] $r2  // MEM_CMD = 5 (???)
- ctx_chan_wait:
-  iord $r2 I[$r1 + 0x000]
-  or $r2 $r2
-  bra ne #ctx_chan_wait
+ call(wait_donez)
+ mov $r15 5 // MEM_CMD 5 ???
+ call(ctx_mem)
 #if CHIPSET < GK100
- call #ctx_4160c
+ call(ctx_4160c)
 #endif
  ret
 
@@ -562,9 +540,7 @@ ctx_chan:
 ctx_mmio_exec:
  // set transfer base to be the mmio list
  ld b32 $r3 D[$r0 + #chan_mmio_address]
- mov $r2 0xa04
- shl b32 $r2 6
- iowr I[$r2 + 0x000] $r3  // MEM_BASE
+ nv_iowr(NV_PGRAPH_FECS_MEM_BASE, 0, $r3)
 
  clear b32 $r3
  ctx_mmio_loop:
@@ -580,7 +556,7 @@ ctx_mmio_exec:
   ctx_mmio_pull:
   ld b32 $r14 D[$r4 + #xfer_data + 0x00]
   ld b32 $r15 D[$r4 + #xfer_data + 0x04]
-  call #nv_wr32
+  call(nv_wr32)
 
   // next!
   add b32 $r3 8
@@ -590,7 +566,7 @@ ctx_mmio_exec:
  // set transfer base back to the current context
  ctx_mmio_done:
  ld b32 $r3 D[$r0 + #ctx_current]
- iowr I[$r2 + 0x000] $r3  // MEM_BASE
+ nv_iowr(NV_PGRAPH_FECS_MEM_BASE, 0, $r3)
 
  // disable the mmio list now, we don't need/want to execute it again
  st b32 D[$r0 + #chan_mmio_count] $r0
@@ -610,12 +586,10 @@ ctx_mmio_exec:
 //
 ctx_xfer:
  // according to mwk, some kind of wait for idle
- mov $r15 0xc00
- shl b32 $r15 6
  mov $r14 4
- iowr I[$r15 + 0x200] $r14
+ nv_iowr(0x409c08, 0, $r14)
  ctx_xfer_idle:
-  iord $r14 I[$r15 + 0x000]
+  nv_iord($r14, 0x409c00, 0)
   and $r14 0x2000
   bra ne #ctx_xfer_idle
 
@@ -623,50 +597,42 @@ ctx_xfer:
  bra $p2 #ctx_xfer_pre_load
  ctx_xfer_pre:
   mov $r15 0x10
-  call #ctx_86c
+  call(ctx_86c)
 #if CHIPSET < GK100
-  call #ctx_4160s
+  call(ctx_4160s)
 #endif
   bra not $p1 #ctx_xfer_exec
 
  ctx_xfer_pre_load:
   mov $r15 2
-  call #ctx_4170s
-  call #ctx_4170w
-  call #ctx_redswitch
+  call(ctx_4170s)
+  call(ctx_4170w)
+  call(ctx_redswitch)
   clear b32 $r15
-  call #ctx_4170s
-  call #ctx_load
+  call(ctx_4170s)
+  call(ctx_load)
 
  // fetch context pointer, and initiate xfer on all GPCs
  ctx_xfer_exec:
  ld b32 $r1 D[$r0 + #ctx_current]
- mov $r2 0x414
- shl b32 $r2 6
- iowr I[$r2 + 0x000] $r0 // BAR_STATUS = reset
- mov $r14 -0x5b00
- sethi $r14 0x410000
- mov b32 $r15 $r1
- call #nv_wr32  // GPC_BCAST_WRCMD_DATA = ctx pointer
- add b32 $r14 4
+
+ clear b32 $r2
+ nv_iowr(NV_PGRAPH_FECS_BAR, 0, $r2)
+
+ nv_wr32(0x41a500, $r1) // GPC_BCAST_WRCMD_DATA = ctx pointer
  xbit $r15 $flags $p1
  xbit $r2 $flags $p2
  shl b32 $r2 1
  or $r15 $r2
- call #nv_wr32  // GPC_BCAST_WRCMD_CMD = GPC_XFER(type)
+ nv_wr32(0x41a504, $r15) // GPC_BCAST_WRCMD_CMD = GPC_XFER(type)
 
  // strands
- mov $r1 0x4afc
- sethi $r1 0x20000
- mov $r2 0xc
- iowr I[$r1] $r2  // STRAND_CMD(0x3f) = 0x0c
- call #strand_wait
- mov $r2 0x47fc
- sethi $r2 0x20000
- iowr I[$r2] $r0  // STRAND_FIRST_GENE(0x3f) = 0x00
- xbit $r2 $flags $p1
- add b32 $r2 3
- iowr I[$r1] $r2  // STRAND_CMD(0x3f) = 0x03/0x04 (SAVE/LOAD)
+ call(strand_pre)
+ clear b32 $r2
+ nv_iowr(NV_PGRAPH_FECS_STRAND_SELECT, 0x3f, $r2)
+ xbit $r2 $flags $p1 // SAVE/LOAD
+ add b32 $r2 NV_PGRAPH_FECS_STRAND_CMD_SAVE
+ nv_iowr(NV_PGRAPH_FECS_STRAND_CMD, 0x3f, $r2)
 
  // mmio context
  xbit $r10 $flags $p1 // direction
@@ -675,48 +641,42 @@ ctx_xfer:
  ld b32 $r12 D[$r0 + #hub_mmio_list_head]
  ld b32 $r13 D[$r0 + #hub_mmio_list_tail]
  mov $r14 0  // not multi
- call #mmctx_xfer
+ call(mmctx_xfer)
 
  // wait for GPCs to all complete
  mov $r10 8  // DONE_BAR
- call #wait_doneo
+ call(wait_doneo)
 
  // wait for strand xfer to complete
- call #strand_wait
+ call(strand_wait)
 
  // post-op
  bra $p1 #ctx_xfer_post
   mov $r10 12  // DONE_UNK12
-  call #wait_donez
-  mov $r1 0xa10
-  shl b32 $r1 6
-  mov $r2 5
-  iowr I[$r1] $r2  // MEM_CMD
-  ctx_xfer_post_save_wait:
-   iord $r2 I[$r1]
-   or $r2 $r2
-   bra ne #ctx_xfer_post_save_wait
+  call(wait_donez)
+  mov $r15 5 // MEM_CMD 5 ???
+  call(ctx_mem)
 
  bra $p2 #ctx_xfer_done
  ctx_xfer_post:
   mov $r15 2
-  call #ctx_4170s
+  call(ctx_4170s)
   clear b32 $r15
-  call #ctx_86c
-  call #strand_post
-  call #ctx_4170w
+  call(ctx_86c)
+  call(strand_post)
+  call(ctx_4170w)
   clear b32 $r15
-  call #ctx_4170s
+  call(ctx_4170s)
 
   bra not $p1 #ctx_xfer_no_post_mmio
   ld b32 $r1 D[$r0 + #chan_mmio_count]
   or $r1 $r1
   bra e #ctx_xfer_no_post_mmio
-   call #ctx_mmio_exec
+   call(ctx_mmio_exec)
 
   ctx_xfer_no_post_mmio:
 #if CHIPSET < GK100
-  call #ctx_4160c
+  call(ctx_4160c)
 #endif
 
  ctx_xfer_done:
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnv108.fuc5 b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnv108.fuc5
new file mode 100644
index 0000000..7c5d256
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnv108.fuc5
@@ -0,0 +1,40 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs <bskeggs@redhat.com>
+ */
+
+#define CHIPSET GK208
+#include "macros.fuc"
+
+.section #nv108_grhub_data
+#define INCLUDE_DATA
+#include "com.fuc"
+#include "hub.fuc"
+#undef INCLUDE_DATA
+
+.section #nv108_grhub_code
+#define INCLUDE_CODE
+bra #init
+#include "com.fuc"
+#include "hub.fuc"
+.align 256
+#undef INCLUDE_CODE
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnv108.fuc5.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnv108.fuc5.h
new file mode 100644
index 0000000..4750984
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnv108.fuc5.h
@@ -0,0 +1,916 @@
+uint32_t nv108_grhub_data[] = {
+/* 0x0000: hub_mmio_list_head */
+ 0x00000300,
+/* 0x0004: hub_mmio_list_tail */
+ 0x00000304,
+/* 0x0008: gpc_count */
+ 0x00000000,
+/* 0x000c: rop_count */
+ 0x00000000,
+/* 0x0010: cmd_queue */
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+/* 0x0058: ctx_current */
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+/* 0x0100: chan_data */
+/* 0x0100: chan_mmio_count */
+ 0x00000000,
+/* 0x0104: chan_mmio_address */
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+/* 0x0200: xfer_data */
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+/* 0x0300: hub_mmio_list_base */
+ 0x0417e91c,
+};
+
+uint32_t nv108_grhub_code[] = {
+ 0x030e0ef5,
+/* 0x0004: queue_put */
+ 0x9800d898,
+ 0x86f001d9,
+ 0xf489a408,
+ 0x020f0b1b,
+ 0x0002f87e,
+/* 0x001a: queue_put_next */
+ 0x98c400f8,
+ 0x0384b607,
+ 0xb6008dbb,
+ 0x8eb50880,
+ 0x018fb500,
+ 0xf00190b6,
+ 0xd9b50f94,
+/* 0x0037: queue_get */
+ 0xf400f801,
+ 0xd8980131,
+ 0x01d99800,
+ 0x0bf489a4,
+ 0x0789c421,
+ 0xbb0394b6,
+ 0x90b6009d,
+ 0x009e9808,
+ 0xb6019f98,
+ 0x84f00180,
+ 0x00d8b50f,
+/* 0x0063: queue_get_done */
+ 0xf80132f4,
+/* 0x0065: nv_rd32 */
+ 0xf0ecb200,
+ 0x00801fc9,
+ 0x0cf601ca,
+/* 0x0073: nv_rd32_wait */
+ 0x8c04bd00,
+ 0xcf01ca00,
+ 0xccc800cc,
+ 0xf61bf41f,
+ 0xec7e060a,
+ 0x008f0000,
+ 0xffcf01cb,
+/* 0x008f: nv_wr32 */
+ 0x8000f800,
+ 0xf601cc00,
+ 0x04bd000f,
+ 0xc9f0ecb2,
+ 0x1ec9f01f,
+ 0x01ca0080,
+ 0xbd000cf6,
+/* 0x00a9: nv_wr32_wait */
+ 0xca008c04,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f61b,
+/* 0x00b8: wait_donez */
+ 0x99f094bd,
+ 0x37008000,
+ 0x0009f602,
+ 0x008004bd,
+ 0x0af60206,
+/* 0x00cf: wait_donez_ne */
+ 0x8804bd00,
+ 0xcf010000,
+ 0x8aff0088,
+ 0xf61bf488,
+ 0x99f094bd,
+ 0x17008000,
+ 0x0009f602,
+ 0x00f804bd,
+/* 0x00ec: wait_doneo */
+ 0x99f094bd,
+ 0x37008000,
+ 0x0009f602,
+ 0x008004bd,
+ 0x0af60206,
+/* 0x0103: wait_doneo_e */
+ 0x8804bd00,
+ 0xcf010000,
+ 0x8aff0088,
+ 0xf60bf488,
+ 0x99f094bd,
+ 0x17008000,
+ 0x0009f602,
+ 0x00f804bd,
+/* 0x0120: mmctx_size */
+/* 0x0122: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0x1bf4efa4,
+ 0xf89fb2ec,
+/* 0x013d: mmctx_xfer */
+ 0xf094bd00,
+ 0x00800199,
+ 0x09f60237,
+ 0xbd04bd00,
+ 0x05bbfd94,
+ 0x800f0bf4,
+ 0xf601c400,
+ 0x04bd000b,
+/* 0x015f: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0xc6008018,
+ 0x000ef601,
+ 0x008004bd,
+ 0x0ff601c7,
+ 0xf004bd00,
+/* 0x017a: mmctx_multi_disabled */
+ 0xabc80199,
+ 0x10b4b600,
+ 0xc80cb9f0,
+ 0xe4b601ae,
+ 0x05befd11,
+ 0x01c50080,
+ 0xbd000bf6,
+/* 0x0195: mmctx_exec_loop */
+/* 0x0195: mmctx_wait_free */
+ 0xc5008e04,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f60b,
+ 0x05e9fd00,
+ 0x01c80080,
+ 0xbd000ef6,
+ 0x04c0b604,
+ 0x1bf4cda4,
+ 0x02abc8df,
+/* 0x01bf: mmctx_fini_wait */
+ 0x8b1c1bf4,
+ 0xcf01c500,
+ 0xb4f000bb,
+ 0x10b4b01f,
+ 0x0af31bf4,
+ 0x00b87e02,
+ 0x250ef400,
+/* 0x01d8: mmctx_stop */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x12b9f00c,
+ 0x01c50080,
+ 0xbd000bf6,
+/* 0x01ed: mmctx_stop_wait */
+ 0xc5008b04,
+ 0x00bbcf01,
+ 0xf412bbc8,
+/* 0x01fa: mmctx_done */
+ 0x94bdf61b,
+ 0x800199f0,
+ 0xf6021700,
+ 0x04bd0009,
+/* 0x020a: strand_wait */
+ 0xa0f900f8,
+ 0xb87e020a,
+ 0xa0fc0000,
+/* 0x0216: strand_pre */
+ 0x0c0900f8,
+ 0x024afc80,
+ 0xbd0009f6,
+ 0x020a7e04,
+/* 0x0227: strand_post */
+ 0x0900f800,
+ 0x4afc800d,
+ 0x0009f602,
+ 0x0a7e04bd,
+ 0x00f80002,
+/* 0x0238: strand_set */
+ 0xfc800f0c,
+ 0x0cf6024f,
+ 0x0c04bd00,
+ 0x4afc800b,
+ 0x000cf602,
+ 0xfc8004bd,
+ 0x0ef6024f,
+ 0x0c04bd00,
+ 0x4afc800a,
+ 0x000cf602,
+ 0x0a7e04bd,
+ 0x00f80002,
+/* 0x0268: strand_ctx_init */
+ 0x99f094bd,
+ 0x37008003,
+ 0x0009f602,
+ 0x167e04bd,
+ 0x030e0002,
+ 0x0002387e,
+ 0xfc80c4bd,
+ 0x0cf60247,
+ 0x0c04bd00,
+ 0x4afc8001,
+ 0x000cf602,
+ 0x0a7e04bd,
+ 0x0c920002,
+ 0x46fc8001,
+ 0x000cf602,
+ 0x020c04bd,
+ 0x024afc80,
+ 0xbd000cf6,
+ 0x020a7e04,
+ 0x02277e00,
+ 0x42008800,
+ 0x20008902,
+ 0x0099cf02,
+/* 0x02c7: ctx_init_strand_loop */
+ 0xf608fe95,
+ 0x8ef6008e,
+ 0x808acf40,
+ 0xb606a5b6,
+ 0xeabb01a0,
+ 0x0480b600,
+ 0xf40192b6,
+ 0xe4b6e81b,
+ 0xf2efbc08,
+ 0x99f094bd,
+ 0x17008003,
+ 0x0009f602,
+ 0x00f804bd,
+/* 0x02f8: error */
+ 0x02050080,
+ 0xbd000ff6,
+ 0x80010f04,
+ 0xf6030700,
+ 0x04bd000f,
+/* 0x030e: init */
+ 0x04bd00f8,
+ 0x410007fe,
+ 0x11cf4200,
+ 0x0911e700,
+ 0x0814b601,
+ 0x020014fe,
+ 0x12004002,
+ 0xbd0002f6,
+ 0x05c94104,
+ 0xbd0010fe,
+ 0x07004024,
+ 0xbd0002f6,
+ 0x20034204,
+ 0x01010080,
+ 0xbd0002f6,
+ 0x20044204,
+ 0x01010480,
+ 0xbd0002f6,
+ 0x200b4204,
+ 0x01010880,
+ 0xbd0002f6,
+ 0x200c4204,
+ 0x01011c80,
+ 0xbd0002f6,
+ 0x01039204,
+ 0x03090080,
+ 0xbd0003f6,
+ 0x87044204,
+ 0xf6040040,
+ 0x04bd0002,
+ 0x00400402,
+ 0x0002f603,
+ 0x31f404bd,
+ 0x96048e10,
+ 0x00657e40,
+ 0xc7feb200,
+ 0x01b590f1,
+ 0x1ff4f003,
+ 0x01020fb5,
+ 0x041fbb01,
+ 0x800112b6,
+ 0xf6010300,
+ 0x04bd0001,
+ 0x01040080,
+ 0xbd0001f6,
+ 0x01004104,
+ 0x627e020f,
+ 0x717e0006,
+ 0x100f0006,
+ 0x0006b37e,
+ 0x98000e98,
+ 0x207e010f,
+ 0x14950001,
+ 0xc0008008,
+ 0x0004f601,
+ 0x008004bd,
+ 0x04f601c1,
+ 0xb704bd00,
+ 0xbb130030,
+ 0xf5b6001f,
+ 0xd3008002,
+ 0x000ff601,
+ 0x15b604bd,
+ 0x0110b608,
+ 0xb20814b6,
+ 0x02687e1f,
+ 0x001fbb00,
+ 0x84020398,
+/* 0x041f: init_gpc */
+ 0xb8502000,
+ 0x0008044e,
+ 0x8f7e1fb2,
+ 0x4eb80000,
+ 0xbd00010c,
+ 0x008f7ef4,
+ 0x044eb800,
+ 0x8f7e0001,
+ 0x4eb80000,
+ 0x0f000100,
+ 0x008f7e02,
+ 0x004eb800,
+/* 0x044e: init_gpc_wait */
+ 0x657e0008,
+ 0xffc80000,
+ 0xf90bf41f,
+ 0x08044eb8,
+ 0x00657e00,
+ 0x001fbb00,
+ 0x800040b7,
+ 0xf40132b6,
+ 0x000fb41b,
+ 0x0006b37e,
+ 0x627e000f,
+ 0x00800006,
+ 0x01f60201,
+ 0xbd04bd00,
+ 0x1f19f014,
+ 0x02300080,
+ 0xbd0001f6,
+/* 0x0491: main */
+ 0x0031f404,
+ 0x0d0028f4,
+ 0x00377e10,
+ 0xf401f400,
+ 0x4001e4b1,
+ 0x00c71bf5,
+ 0x99f094bd,
+ 0x37008004,
+ 0x0009f602,
+ 0x008104bd,
+ 0x11cf02c0,
+ 0xc1008200,
+ 0x0022cf02,
+ 0xf41f13c8,
+ 0x23c8770b,
+ 0x550bf41f,
+ 0x12b220f9,
+ 0x99f094bd,
+ 0x37008007,
+ 0x0009f602,
+ 0x32f404bd,
+ 0x0231f401,
+ 0x0008367e,
+ 0x99f094bd,
+ 0x17008007,
+ 0x0009f602,
+ 0x20fc04bd,
+ 0x99f094bd,
+ 0x37008006,
+ 0x0009f602,
+ 0x31f404bd,
+ 0x08367e01,
+ 0xf094bd00,
+ 0x00800699,
+ 0x09f60217,
+ 0xf404bd00,
+/* 0x0522: chsw_prev_no_next */
+ 0x20f92f0e,
+ 0x32f412b2,
+ 0x0232f401,
+ 0x0008367e,
+ 0x008020fc,
+ 0x02f602c0,
+ 0xf404bd00,
+/* 0x053e: chsw_no_prev */
+ 0x23c8130e,
+ 0x0d0bf41f,
+ 0xf40131f4,
+ 0x367e0232,
+/* 0x054e: chsw_done */
+ 0x01020008,
+ 0x02c30080,
+ 0xbd0002f6,
+ 0xf094bd04,
+ 0x00800499,
+ 0x09f60217,
+ 0xf504bd00,
+/* 0x056b: main_not_ctx_switch */
+ 0xb0ff2a0e,
+ 0x1bf401e4,
+ 0x7ef2b20c,
+ 0xf40007d6,
+/* 0x057a: main_not_ctx_chan */
+ 0xe4b0400e,
+ 0x2c1bf402,
+ 0x99f094bd,
+ 0x37008007,
+ 0x0009f602,
+ 0x32f404bd,
+ 0x0232f401,
+ 0x0008367e,
+ 0x99f094bd,
+ 0x17008007,
+ 0x0009f602,
+ 0x0ef404bd,
+/* 0x05a9: main_not_ctx_save */
+ 0x10ef9411,
+ 0x7e01f5f0,
+ 0xf50002f8,
+/* 0x05b7: main_done */
+ 0xbdfede0e,
+ 0x1f29f024,
+ 0x02300080,
+ 0xbd0002f6,
+ 0xcc0ef504,
+/* 0x05c9: ih */
+ 0xfe80f9fe,
+ 0x80f90188,
+ 0xa0f990f9,
+ 0xd0f9b0f9,
+ 0xf0f9e0f9,
+ 0x004a04bd,
+ 0x00aacf02,
+ 0xf404abc4,
+ 0x100d230b,
+ 0xcf1a004e,
+ 0x004f00ee,
+ 0x00ffcf19,
+ 0x0000047e,
+ 0x0400b0b7,
+ 0x0040010e,
+ 0x000ef61d,
+/* 0x060a: ih_no_fifo */
+ 0xabe404bd,
+ 0x0bf40100,
+ 0x4e100d0c,
+ 0x047e4001,
+/* 0x061a: ih_no_ctxsw */
+ 0xabe40000,
+ 0x0bf40400,
+ 0x01004b10,
+ 0x448ebfb2,
+ 0x8f7e4001,
+/* 0x062e: ih_no_fwmthd */
+ 0x044b0000,
+ 0xffb0bd01,
+ 0x0bf4b4ab,
+ 0x0700800c,
+ 0x000bf603,
+/* 0x0642: ih_no_other */
+ 0x004004bd,
+ 0x000af601,
+ 0xf0fc04bd,
+ 0xd0fce0fc,
+ 0xa0fcb0fc,
+ 0x80fc90fc,
+ 0xfc0088fe,
+ 0x0032f480,
+/* 0x0662: ctx_4170s */
+ 0xf5f001f8,
+ 0x8effb210,
+ 0x7e404170,
+ 0xf800008f,
+/* 0x0671: ctx_4170w */
+ 0x41708e00,
+ 0x00657e40,
+ 0xf0ffb200,
+ 0x1bf410f4,
+/* 0x0683: ctx_redswitch */
+ 0x4e00f8f3,
+ 0xe5f00200,
+ 0x20e5f040,
+ 0x8010e5f0,
+ 0xf6018500,
+ 0x04bd000e,
+/* 0x069a: ctx_redswitch_delay */
+ 0xf2b6080f,
+ 0xfd1bf401,
+ 0x0400e5f1,
+ 0x0100e5f1,
+ 0x01850080,
+ 0xbd000ef6,
+/* 0x06b3: ctx_86c */
+ 0x8000f804,
+ 0xf6022300,
+ 0x04bd000f,
+ 0x148effb2,
+ 0x8f7e408a,
+ 0xffb20000,
+ 0x41a88c8e,
+ 0x00008f7e,
+/* 0x06d2: ctx_mem */
+ 0x008000f8,
+ 0x0ff60284,
+/* 0x06db: ctx_mem_wait */
+ 0x8f04bd00,
+ 0xcf028400,
+ 0xfffd00ff,
+ 0xf61bf405,
+/* 0x06ea: ctx_load */
+ 0x94bd00f8,
+ 0x800599f0,
+ 0xf6023700,
+ 0x04bd0009,
+ 0xb87e0c0a,
+ 0xf4bd0000,
+ 0x02890080,
+ 0xbd000ff6,
+ 0xc1008004,
+ 0x0002f602,
+ 0x008004bd,
+ 0x02f60283,
+ 0x0f04bd00,
+ 0x06d27e07,
+ 0xc0008000,
+ 0x0002f602,
+ 0x0bfe04bd,
+ 0x1f2af000,
+ 0xb60424b6,
+ 0x94bd0220,
+ 0x800899f0,
+ 0xf6023700,
+ 0x04bd0009,
+ 0x02810080,
+ 0xbd0002f6,
+ 0x0000d204,
+ 0x25f08000,
+ 0x88008002,
+ 0x0002f602,
+ 0x100104bd,
+ 0xf0020042,
+ 0x12fa0223,
+ 0xbd03f805,
+ 0x0899f094,
+ 0x02170080,
+ 0xbd0009f6,
+ 0x81019804,
+ 0x981814b6,
+ 0x25b68002,
+ 0x0512fd08,
+ 0xbd1601b5,
+ 0x0999f094,
+ 0x02370080,
+ 0xbd0009f6,
+ 0x81008004,
+ 0x0001f602,
+ 0x010204bd,
+ 0x02880080,
+ 0xbd0002f6,
+ 0x01004104,
+ 0xfa0613f0,
+ 0x03f80501,
+ 0x99f094bd,
+ 0x17008009,
+ 0x0009f602,
+ 0x94bd04bd,
+ 0x800599f0,
+ 0xf6021700,
+ 0x04bd0009,
+/* 0x07d6: ctx_chan */
+ 0xea7e00f8,
+ 0x0c0a0006,
+ 0x0000b87e,
+ 0xd27e050f,
+ 0x00f80006,
+/* 0x07e8: ctx_mmio_exec */
+ 0x80410398,
+ 0xf6028100,
+ 0x04bd0003,
+/* 0x07f6: ctx_mmio_loop */
+ 0x34c434bd,
+ 0x0e1bf4ff,
+ 0xf0020045,
+ 0x35fa0653,
+/* 0x0807: ctx_mmio_pull */
+ 0x9803f805,
+ 0x4f98804e,
+ 0x008f7e81,
+ 0x0830b600,
+ 0xf40112b6,
+/* 0x081a: ctx_mmio_done */
+ 0x0398df1b,
+ 0x81008016,
+ 0x0003f602,
+ 0x00b504bd,
+ 0x01004140,
+ 0xfa0613f0,
+ 0x03f80601,
+/* 0x0836: ctx_xfer */
+ 0x040e00f8,
+ 0x03020080,
+ 0xbd000ef6,
+/* 0x0841: ctx_xfer_idle */
+ 0x00008e04,
+ 0x00eecf03,
+ 0x2000e4f1,
+ 0xf4f51bf4,
+ 0x02f40611,
+/* 0x0855: ctx_xfer_pre */
+ 0x7e100f0c,
+ 0xf40006b3,
+/* 0x085e: ctx_xfer_pre_load */
+ 0x020f1b11,
+ 0x0006627e,
+ 0x0006717e,
+ 0x0006837e,
+ 0x627ef4bd,
+ 0xea7e0006,
+/* 0x0876: ctx_xfer_exec */
+ 0x01980006,
+ 0x8024bd16,
+ 0xf6010500,
+ 0x04bd0002,
+ 0x008e1fb2,
+ 0x8f7e41a5,
+ 0xfcf00000,
+ 0x022cf001,
+ 0xfd0124b6,
+ 0xffb205f2,
+ 0x41a5048e,
+ 0x00008f7e,
+ 0x0002167e,
+ 0xfc8024bd,
+ 0x02f60247,
+ 0xf004bd00,
+ 0x20b6012c,
+ 0x4afc8003,
+ 0x0002f602,
+ 0xacf004bd,
+ 0x06a5f001,
+ 0x0c98000b,
+ 0x010d9800,
+ 0x3d7e000e,
+ 0x080a0001,
+ 0x0000ec7e,
+ 0x00020a7e,
+ 0x0a1201f4,
+ 0x00b87e0c,
+ 0x7e050f00,
+ 0xf40006d2,
+/* 0x08f2: ctx_xfer_post */
+ 0x020f2d02,
+ 0x0006627e,
+ 0xb37ef4bd,
+ 0x277e0006,
+ 0x717e0002,
+ 0xf4bd0006,
+ 0x0006627e,
+ 0x981011f4,
+ 0x11fd4001,
+ 0x070bf405,
+ 0x0007e87e,
+/* 0x091c: ctx_xfer_no_post_mmio */
+/* 0x091c: ctx_xfer_done */
+ 0x000000f8,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+};
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvc0.fuc.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvc0.fuc.h
index b59f694..132f684 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvc0.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvc0.fuc.h
@@ -206,14 +206,14 @@ uint32_t nvc0_grhub_data[] = {
 };
 
 uint32_t nvc0_grhub_code[] = {
- 0x031b0ef5,
+ 0x039b0ef5,
 /* 0x0004: queue_put */
  0x9800d898,
  0x86f001d9,
  0x0489b808,
  0xf00c1bf4,
  0x21f502f7,
- 0x00f802fe,
+ 0x00f8037e,
 /* 0x001c: queue_put_next */
  0xb60798c4,
  0x8dbb0384,
@@ -237,184 +237,214 @@ uint32_t nvc0_grhub_code[] = {
 /* 0x0066: queue_get_done */
  0x00f80132,
 /* 0x0068: nv_rd32 */
- 0x0728b7f1,
- 0xb906b4b6,
- 0xc9f002ec,
- 0x00bcd01f,
-/* 0x0078: nv_rd32_wait */
- 0xc800bccf,
- 0x1bf41fcc,
- 0x06a7f0fa,
- 0x010921f5,
- 0xf840bfcf,
-/* 0x008d: nv_wr32 */
- 0x28b7f100,
- 0x06b4b607,
- 0xb980bfd0,
- 0xc9f002ec,
- 0x1ec9f01f,
-/* 0x00a3: nv_wr32_wait */
- 0xcf00bcd0,
- 0xccc800bc,
- 0xfa1bf41f,
-/* 0x00ae: watchdog_reset */
- 0x87f100f8,
- 0x84b60430,
- 0x1ff9f006,
- 0xf8008fd0,
-/* 0x00bd: watchdog_clear */
- 0x3087f100,
- 0x0684b604,
- 0xf80080d0,
-/* 0x00c9: wait_donez */
- 0xf094bd00,
- 0x07f10099,
- 0x03f00f00,
- 0x0009d002,
- 0x07f104bd,
- 0x03f00600,
- 0x000ad002,
-/* 0x00e6: wait_donez_ne */
- 0x87f104bd,
- 0x83f00000,
- 0x0088cf01,
- 0xf4888aff,
- 0x94bdf31b,
- 0xf10099f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0109: wait_doneo */
- 0xf094bd00,
+ 0xf002ecb9,
+ 0x07f11fc9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x007a: nv_rd32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0xa7f0f31b,
+ 0x1021f506,
+ 0x00f7f101,
+ 0x01f3f0cb,
+ 0xf800ffcf,
+/* 0x009d: nv_wr32 */
+ 0x0007f100,
+ 0x0103f0cc,
+ 0xbd000fd0,
+ 0x02ecb904,
+ 0xf01fc9f0,
+ 0x07f11ec9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x00be: nv_wr32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f31b,
+/* 0x00d0: wait_donez */
+ 0x99f094bd,
+ 0x0007f100,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x00ed: wait_donez_ne */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x1bf4888a,
+ 0xf094bdf3,
  0x07f10099,
- 0x03f00f00,
+ 0x03f01700,
  0x0009d002,
- 0x87f104bd,
- 0x84b60818,
- 0x008ad006,
-/* 0x0124: wait_doneo_e */
- 0x040087f1,
- 0xcf0684b6,
- 0x8aff0088,
- 0xf30bf488,
+ 0x00f804bd,
+/* 0x0110: wait_doneo */
  0x99f094bd,
  0x0007f100,
- 0x0203f017,
+ 0x0203f00f,
  0xbd0009d0,
-/* 0x0147: mmctx_size */
- 0xbd00f804,
-/* 0x0149: nv_mmctx_size_loop */
- 0x00e89894,
- 0xb61a85b6,
- 0x84b60180,
- 0x0098bb02,
- 0xb804e0b6,
- 0x1bf404ef,
- 0x029fb9eb,
-/* 0x0166: mmctx_xfer */
- 0x94bd00f8,
- 0xf10199f0,
- 0xf00f0007,
- 0x09d00203,
- 0xf104bd00,
- 0xb6071087,
- 0x94bd0684,
- 0xf405bbfd,
- 0x8bd0090b,
- 0x0099f000,
-/* 0x018c: mmctx_base_disabled */
- 0xf405eefd,
- 0x8ed00c0b,
- 0xc08fd080,
-/* 0x019b: mmctx_multi_disabled */
- 0xb70199f0,
- 0xc8010080,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x012d: wait_doneo_e */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x0bf4888a,
+ 0xf094bdf3,
+ 0x07f10099,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0150: mmctx_size */
+/* 0x0152: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0xf404efb8,
+ 0x9fb9eb1b,
+/* 0x016f: mmctx_xfer */
+ 0xbd00f802,
+ 0x0199f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0xbbfd94bd,
+ 0x120bf405,
+ 0xc40007f1,
+ 0xd00103f0,
+ 0x04bd000b,
+/* 0x0197: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0x0007f11e,
+ 0x0103f0c6,
+ 0xbd000ed0,
+ 0x0007f104,
+ 0x0103f0c7,
+ 0xbd000fd0,
+ 0x0199f004,
+/* 0x01b8: mmctx_multi_disabled */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x01aec80c,
+ 0xfd11e4b6,
+ 0x07f105be,
+ 0x03f0c500,
+ 0x000bd001,
+/* 0x01d6: mmctx_exec_loop */
+/* 0x01d6: mmctx_wait_free */
+ 0xe7f104bd,
+ 0xe3f0c500,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f30b,
+ 0x05e9fd00,
+ 0xc80007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+ 0xb804c0b6,
+ 0x1bf404cd,
+ 0x02abc8d8,
+/* 0x0207: mmctx_fini_wait */
+ 0xf11f1bf4,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x1fb4f000,
+ 0xf410b4b0,
+ 0xa7f0f01b,
+ 0xd021f402,
+/* 0x0223: mmctx_stop */
+ 0xc82b0ef4,
  0xb4b600ab,
  0x0cb9f010,
- 0xb601aec8,
- 0xbefd11e4,
- 0x008bd005,
-/* 0x01b4: mmctx_exec_loop */
-/* 0x01b4: mmctx_wait_free */
- 0xf0008ecf,
- 0x0bf41fe4,
- 0x00ce98fa,
- 0xd005e9fd,
- 0xc0b6c08e,
- 0x04cdb804,
- 0xc8e81bf4,
- 0x1bf402ab,
-/* 0x01d5: mmctx_fini_wait */
- 0x008bcf18,
- 0xb01fb4f0,
- 0x1bf410b4,
- 0x02a7f0f7,
- 0xf4c921f4,
-/* 0x01ea: mmctx_stop */
- 0xabc81b0e,
- 0x10b4b600,
- 0xf00cb9f0,
- 0x8bd012b9,
-/* 0x01f9: mmctx_stop_wait */
- 0x008bcf00,
- 0xf412bbc8,
-/* 0x0202: mmctx_done */
- 0x94bdfa1b,
- 0xf10199f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0215: strand_wait */
- 0xf0a0f900,
- 0x21f402a7,
- 0xf8a0fcc9,
-/* 0x0221: strand_pre */
- 0xfc87f100,
- 0x0283f04a,
- 0xd00c97f0,
- 0x21f50089,
- 0x00f80215,
-/* 0x0234: strand_post */
- 0x4afc87f1,
- 0xf00283f0,
- 0x89d00d97,
- 0x1521f500,
-/* 0x0247: strand_set */
- 0xf100f802,
- 0xf04ffca7,
- 0xaba202a3,
- 0xc7f00500,
- 0x00acd00f,
- 0xd00bc7f0,
- 0x21f500bc,
- 0xaed00215,
- 0x0ac7f000,
- 0xf500bcd0,
- 0xf8021521,
-/* 0x0271: strand_ctx_init */
- 0xf094bd00,
- 0x07f10399,
- 0x03f00f00,
+ 0xf112b9f0,
+ 0xf0c50007,
+ 0x0bd00103,
+/* 0x023b: mmctx_stop_wait */
+ 0xf104bd00,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x12bbc800,
+/* 0x024b: mmctx_done */
+ 0xbdf31bf4,
+ 0x0199f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x025e: strand_wait */
+ 0xa0f900f8,
+ 0xf402a7f0,
+ 0xa0fcd021,
+/* 0x026a: strand_pre */
+ 0x97f000f8,
+ 0xfc07f10c,
+ 0x0203f04a,
+ 0xbd0009d0,
+ 0x5e21f504,
+/* 0x027f: strand_post */
+ 0xf000f802,
+ 0x07f10d97,
+ 0x03f04afc,
  0x0009d002,
  0x21f504bd,
- 0xe7f00221,
- 0x4721f503,
- 0xfca7f102,
- 0x02a3f046,
- 0x0400aba0,
- 0xf040a0d0,
- 0xbcd001c7,
- 0x1521f500,
- 0x010c9202,
- 0xf000acd0,
- 0xbcd002c7,
- 0x1521f500,
- 0x3421f502,
- 0x8087f102,
- 0x0684b608,
- 0xb70089cf,
- 0x95220080,
-/* 0x02ca: ctx_init_strand_loop */
+ 0x00f8025e,
+/* 0x0294: strand_set */
+ 0xf10fc7f0,
+ 0xf04ffc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f10bc7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x07f104bd,
+ 0x03f04ffc,
+ 0x000ed002,
+ 0xc7f004bd,
+ 0xfc07f10a,
+ 0x0203f04a,
+ 0xbd000cd0,
+ 0x5e21f504,
+/* 0x02d3: strand_ctx_init */
+ 0xbd00f802,
+ 0x0399f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0x026a21f5,
+ 0xf503e7f0,
+ 0xbd029421,
+ 0xfc07f1c4,
+ 0x0203f047,
+ 0xbd000cd0,
+ 0x01c7f004,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd000c,
+ 0x025e21f5,
+ 0xf1010c92,
+ 0xf046fc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f102c7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x21f504bd,
+ 0x21f5025e,
+ 0x87f1027f,
+ 0x83f04200,
+ 0x0097f102,
+ 0x0293f020,
+ 0x950099cf,
+/* 0x034a: ctx_init_strand_loop */
  0x8ed008fe,
  0x408ed000,
  0xb6808acf,
@@ -428,7 +458,7 @@ uint32_t nvc0_grhub_code[] = {
  0x170007f1,
  0xd00203f0,
  0x04bd0009,
-/* 0x02fe: error */
+/* 0x037e: error */
  0x07f100f8,
  0x03f00500,
  0x000fd002,
@@ -436,82 +466,117 @@ uint32_t nvc0_grhub_code[] = {
  0x0007f101,
  0x0303f007,
  0xbd000fd0,
-/* 0x031b: init */
+/* 0x039b: init */
  0xbd00f804,
- 0x0004fe04,
- 0xf10007fe,
- 0xf0120017,
- 0x12d00227,
- 0xb117f100,
- 0x0010fe05,
- 0x040017f1,
- 0xf1c010d0,
- 0xb6040437,
- 0x27f10634,
- 0x32d02003,
- 0x0427f100,
- 0x0132d020,
+ 0x0007fe04,
+ 0x420017f1,
+ 0xcf0013f0,
+ 0x11e70011,
+ 0x14b60109,
+ 0x0014fe08,
+ 0xf10227f0,
+ 0xf0120007,
+ 0x02d00003,
+ 0xf104bd00,
+ 0xfe06c817,
+ 0x24bd0010,
+ 0x070007f1,
+ 0xd00003f0,
+ 0x04bd0002,
+ 0x200327f1,
+ 0x010007f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0x200427f1,
+ 0x010407f1,
+ 0xd00103f0,
+ 0x04bd0002,
  0x200b27f1,
- 0xf10232d0,
- 0xd0200c27,
- 0x27f10732,
- 0x24b60c24,
- 0x0003b906,
- 0xf10023d0,
+ 0x010807f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0x200c27f1,
+ 0x011c07f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0xf1010392,
+ 0xf0090007,
+ 0x03d00303,
+ 0xf104bd00,
  0xf0870427,
- 0x12d00023,
- 0x0012b700,
- 0x0427f001,
- 0xf40012d0,
- 0xe7f11031,
- 0xe3f09604,
- 0x6821f440,
- 0x8090f1c7,
- 0xf4f00301,
- 0x020f801f,
- 0xbb0117f0,
- 0x12b6041f,
- 0x0c27f101,
- 0x0624b604,
- 0xd00021d0,
- 0x17f14021,
- 0x0e980100,
- 0x010f9800,
- 0x014721f5,
- 0x070037f1,
- 0x950634b6,
- 0x34d00814,
- 0x4034d000,
- 0x130030b7,
- 0xb6001fbb,
- 0x3fd002f5,
- 0x0815b600,
- 0xb60110b6,
- 0x1fb90814,
- 0x7121f502,
- 0x001fbb02,
- 0xf1020398,
- 0xf0200047,
-/* 0x03f6: init_gpc */
- 0x4ea05043,
- 0x1fb90804,
- 0x8d21f402,
- 0x010c4ea0,
- 0x21f4f4bd,
- 0x044ea08d,
- 0x8d21f401,
- 0x01004ea0,
- 0xf402f7f0,
- 0x4ea08d21,
-/* 0x041e: init_gpc_wait */
- 0x21f40800,
- 0x1fffc868,
- 0xa0fa0bf4,
- 0xf408044e,
- 0x1fbb6821,
- 0x0040b700,
- 0x0132b680,
- 0xf1be1bf4,
+ 0x07f10023,
+ 0x03f00400,
+ 0x0002d000,
+ 0x27f004bd,
+ 0x0007f104,
+ 0x0003f003,
+ 0xbd0002d0,
+ 0x1031f404,
+ 0x9604e7f1,
+ 0xf440e3f0,
+ 0xfeb96821,
+ 0x90f1c702,
+ 0xf0030180,
+ 0x0f801ff4,
+ 0x0117f002,
+ 0xb6041fbb,
+ 0x07f10112,
+ 0x03f00300,
+ 0x0001d001,
+ 0x07f104bd,
+ 0x03f00400,
+ 0x0001d001,
+ 0x17f104bd,
+ 0xf7f00100,
+ 0xb521f502,
+ 0xc721f507,
+ 0x10f7f007,
+ 0x081421f5,
+ 0x98000e98,
+ 0x21f5010f,
+ 0x14950150,
+ 0x0007f108,
+ 0x0103f0c0,
+ 0xbd0004d0,
+ 0x0007f104,
+ 0x0103f0c1,
+ 0xbd0004d0,
+ 0x0030b704,
+ 0x001fbb13,
+ 0xf102f5b6,
+ 0xf0d30007,
+ 0x0fd00103,
+ 0xb604bd00,
+ 0x10b60815,
+ 0x0814b601,
+ 0xf5021fb9,
+ 0xbb02d321,
+ 0x0398001f,
+ 0x0047f102,
+ 0x5043f020,
+/* 0x04f4: init_gpc */
+ 0x08044ea0,
+ 0xf4021fb9,
+ 0x4ea09d21,
+ 0xf4bd010c,
+ 0xa09d21f4,
+ 0xf401044e,
+ 0x4ea09d21,
+ 0xf7f00100,
+ 0x9d21f402,
+ 0x08004ea0,
+/* 0x051c: init_gpc_wait */
+ 0xc86821f4,
+ 0x0bf41fff,
+ 0x044ea0fa,
+ 0x6821f408,
+ 0xb7001fbb,
+ 0xb6800040,
+ 0x1bf40132,
+ 0x00f7f0be,
+ 0x081421f5,
+ 0xf500f7f0,
+ 0xf107b521,
  0xf0010007,
  0x01d00203,
  0xbd04bd00,
@@ -519,402 +584,399 @@ uint32_t nvc0_grhub_code[] = {
  0x080007f1,
  0xd00203f0,
  0x04bd0001,
-/* 0x0458: main */
+/* 0x0564: main */
  0xf40031f4,
  0xd7f00028,
  0x3921f410,
  0xb1f401f4,
  0xf54001e4,
- 0xbd00de1b,
+ 0xbd00e91b,
  0x0499f094,
  0x0f0007f1,
  0xd00203f0,
  0x04bd0009,
- 0x0b0017f1,
- 0xcf0614b6,
- 0x11cf4012,
- 0x1f13c800,
- 0x00870bf5,
- 0xf41f23c8,
- 0x20f9620b,
- 0xbd0212b9,
- 0x0799f094,
- 0x0f0007f1,
- 0xd00203f0,
- 0x04bd0009,
- 0xf40132f4,
- 0x21f50231,
- 0x94bd082f,
+ 0xc00017f1,
+ 0xcf0213f0,
+ 0x27f10011,
+ 0x23f0c100,
+ 0x0022cf02,
+ 0xf51f13c8,
+ 0xc800890b,
+ 0x0bf41f23,
+ 0xb920f962,
+ 0x94bd0212,
  0xf10799f0,
- 0xf0170007,
+ 0xf00f0007,
  0x09d00203,
- 0xfc04bd00,
- 0xf094bd20,
- 0x07f10699,
- 0x03f00f00,
- 0x0009d002,
- 0x31f404bd,
- 0x2f21f501,
- 0xf094bd08,
- 0x07f10699,
+ 0xf404bd00,
+ 0x31f40132,
+ 0xe821f502,
+ 0xf094bd09,
+ 0x07f10799,
  0x03f01700,
  0x0009d002,
- 0x0ef404bd,
-/* 0x04f9: chsw_prev_no_next */
- 0xb920f931,
- 0x32f40212,
- 0x0232f401,
- 0x082f21f5,
- 0x17f120fc,
- 0x14b60b00,
- 0x0012d006,
-/* 0x0517: chsw_no_prev */
- 0xc8130ef4,
- 0x0bf41f23,
- 0x0131f40d,
- 0xf50232f4,
-/* 0x0527: chsw_done */
- 0xf1082f21,
- 0xb60b0c17,
- 0x27f00614,
- 0x0012d001,
+ 0x20fc04bd,
  0x99f094bd,
- 0x0007f104,
+ 0x0007f106,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0131f404,
+ 0x09e821f5,
+ 0x99f094bd,
+ 0x0007f106,
  0x0203f017,
  0xbd0009d0,
- 0x130ef504,
-/* 0x0549: main_not_ctx_switch */
- 0x01e4b0ff,
- 0xb90d1bf4,
- 0x21f502f2,
- 0x0ef407bb,
-/* 0x0559: main_not_ctx_chan */
- 0x02e4b046,
- 0xbd321bf4,
- 0x0799f094,
- 0x0f0007f1,
+ 0x330ef404,
+/* 0x060c: chsw_prev_no_next */
+ 0x12b920f9,
+ 0x0132f402,
+ 0xf50232f4,
+ 0xfc09e821,
+ 0x0007f120,
+ 0x0203f0c0,
+ 0xbd0002d0,
+ 0x130ef404,
+/* 0x062c: chsw_no_prev */
+ 0xf41f23c8,
+ 0x31f40d0b,
+ 0x0232f401,
+ 0x09e821f5,
+/* 0x063c: chsw_done */
+ 0xf10127f0,
+ 0xf0c30007,
+ 0x02d00203,
+ 0xbd04bd00,
+ 0x0499f094,
+ 0x170007f1,
  0xd00203f0,
  0x04bd0009,
- 0xf40132f4,
- 0x21f50232,
- 0x94bd082f,
+ 0xff080ef5,
+/* 0x0660: main_not_ctx_switch */
+ 0xf401e4b0,
+ 0xf2b90d1b,
+ 0x7821f502,
+ 0x460ef409,
+/* 0x0670: main_not_ctx_chan */
+ 0xf402e4b0,
+ 0x94bd321b,
  0xf10799f0,
- 0xf0170007,
+ 0xf00f0007,
  0x09d00203,
  0xf404bd00,
-/* 0x058e: main_not_ctx_save */
- 0xef94110e,
- 0x01f5f010,
- 0x02fe21f5,
- 0xfec00ef5,
-/* 0x059c: main_done */
- 0x29f024bd,
- 0x0007f11f,
- 0x0203f008,
- 0xbd0002d0,
- 0xab0ef504,
-/* 0x05b1: ih */
- 0xfe80f9fe,
- 0x80f90188,
- 0xa0f990f9,
- 0xd0f9b0f9,
- 0xf0f9e0f9,
- 0x0acf04bd,
- 0x04abc480,
- 0xf11d0bf4,
- 0xf01900b7,
- 0xbecf10d7,
- 0x00bfcf40,
+ 0x32f40132,
+ 0xe821f502,
+ 0xf094bd09,
+ 0x07f10799,
+ 0x03f01700,
+ 0x0009d002,
+ 0x0ef404bd,
+/* 0x06a5: main_not_ctx_save */
+ 0x10ef9411,
+ 0xf501f5f0,
+ 0xf5037e21,
+/* 0x06b3: main_done */
+ 0xbdfeb50e,
+ 0x1f29f024,
+ 0x080007f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xfea00ef5,
+/* 0x06c8: ih */
+ 0x88fe80f9,
+ 0xf980f901,
+ 0xf9a0f990,
+ 0xf9d0f9b0,
+ 0xbdf0f9e0,
+ 0x00a7f104,
+ 0x00a3f002,
+ 0xc400aacf,
+ 0x0bf404ab,
+ 0x10d7f030,
+ 0x1a00e7f1,
+ 0xcf00e3f0,
+ 0xf7f100ee,
+ 0xf3f01900,
+ 0x00ffcf00,
  0xb70421f4,
  0xf00400b0,
- 0xbed001e7,
-/* 0x05e9: ih_no_fifo */
- 0x00abe400,
- 0x0d0bf401,
- 0xf110d7f0,
- 0xf44001e7,
-/* 0x05fa: ih_no_ctxsw */
- 0xb7f10421,
- 0xb0bd0104,
- 0xf4b4abff,
- 0xa7f10d0b,
- 0xa4b60c1c,
- 0x00abd006,
-/* 0x0610: ih_no_other */
- 0xfc400ad0,
+ 0x07f101e7,
+ 0x03f01d00,
+ 0x000ed000,
+/* 0x071a: ih_no_fifo */
+ 0xabe404bd,
+ 0x0bf40100,
+ 0x10d7f00d,
+ 0x4001e7f1,
+/* 0x072b: ih_no_ctxsw */
+ 0xe40421f4,
+ 0xf40400ab,
+ 0xb7f1140b,
+ 0xbfb90100,
+ 0x44e7f102,
+ 0x40e3f001,
+/* 0x0743: ih_no_fwmthd */
+ 0xf19d21f4,
+ 0xbd0104b7,
+ 0xb4abffb0,
+ 0xf10f0bf4,
+ 0xf0070007,
+ 0x0bd00303,
+/* 0x075b: ih_no_other */
+ 0xf104bd00,
+ 0xf0010007,
+ 0x0ad00003,
+ 0xfc04bd00,
  0xfce0fcf0,
  0xfcb0fcd0,
  0xfc90fca0,
  0x0088fe80,
  0x32f480fc,
-/* 0x062b: ctx_4160s */
- 0xf101f800,
- 0xf04160e7,
- 0xf7f040e3,
- 0x8d21f401,
-/* 0x0638: ctx_4160s_wait */
- 0xc86821f4,
- 0x0bf404ff,
-/* 0x0643: ctx_4160c */
- 0xf100f8fa,
+/* 0x077f: ctx_4160s */
+ 0xf001f800,
+ 0xffb901f7,
+ 0x60e7f102,
+ 0x40e3f041,
+/* 0x078f: ctx_4160s_wait */
+ 0xf19d21f4,
  0xf04160e7,
- 0xf4bd40e3,
- 0xf88d21f4,
-/* 0x0651: ctx_4170s */
- 0x70e7f100,
+ 0x21f440e3,
+ 0x02ffb968,
+ 0xf404ffc8,
+ 0x00f8f00b,
+/* 0x07a4: ctx_4160c */
+ 0xffb9f4bd,
+ 0x60e7f102,
  0x40e3f041,
- 0xf410f5f0,
- 0x00f88d21,
-/* 0x0660: ctx_4170w */
- 0x4170e7f1,
- 0xf440e3f0,
- 0xf4f06821,
- 0xf31bf410,
-/* 0x0672: ctx_redswitch */
- 0xe7f100f8,
- 0xe4b60614,
- 0x70f7f106,
- 0x00efd002,
-/* 0x0683: ctx_redswitch_delay */
- 0xb608f7f0,
- 0x1bf401f2,
- 0x70f7f1fd,
- 0x00efd007,
-/* 0x0692: ctx_86c */
- 0xe7f100f8,
- 0xe4b6086c,
- 0x00efd006,
- 0x8a14e7f1,
- 0xf440e3f0,
- 0xe7f18d21,
- 0xe3f0a86c,
- 0x8d21f441,
-/* 0x06b2: ctx_load */
+ 0xf89d21f4,
+/* 0x07b5: ctx_4170s */
+ 0x10f5f000,
+ 0xf102ffb9,
+ 0xf04170e7,
+ 0x21f440e3,
+/* 0x07c7: ctx_4170w */
+ 0xf100f89d,
+ 0xf04170e7,
+ 0x21f440e3,
+ 0x02ffb968,
+ 0xf410f4f0,
+ 0x00f8f01b,
+/* 0x07dc: ctx_redswitch */
+ 0x0200e7f1,
+ 0xf040e5f0,
+ 0xe5f020e5,
+ 0x0007f110,
+ 0x0103f085,
+ 0xbd000ed0,
+ 0x08f7f004,
+/* 0x07f8: ctx_redswitch_delay */
+ 0xf401f2b6,
+ 0xe5f1fd1b,
+ 0xe5f10400,
+ 0x07f10100,
+ 0x03f08500,
+ 0x000ed001,
+ 0x00f804bd,
+/* 0x0814: ctx_86c */
+ 0x1b0007f1,
+ 0xd00203f0,
+ 0x04bd000f,
+ 0xf102ffb9,
+ 0xf08a14e7,
+ 0x21f440e3,
+ 0x02ffb99d,
+ 0xa86ce7f1,
+ 0xf441e3f0,
+ 0x00f89d21,
+/* 0x083c: ctx_mem */
+ 0x840007f1,
+ 0xd00203f0,
+ 0x04bd000f,
+/* 0x0848: ctx_mem_wait */
+ 0x8400f7f1,
+ 0xcf02f3f0,
+ 0xfffd00ff,
+ 0xf31bf405,
+/* 0x085a: ctx_load */
  0x94bd00f8,
  0xf10599f0,
  0xf00f0007,
  0x09d00203,
  0xf004bd00,
  0x21f40ca7,
- 0x2417f1c9,
- 0x0614b60a,
- 0xf10010d0,
- 0xb60b0037,
- 0x32d00634,
- 0x0c17f140,
- 0x0614b60a,
- 0xd00747f0,
- 0x14d00012,
-/* 0x06ed: ctx_chan_wait_0 */
- 0x4014cf40,
- 0xf41f44f0,
- 0x32d0fa1b,
- 0x000bfe00,
- 0xb61f2af0,
- 0x20b60424,
- 0xf094bd02,
+ 0xf1f4bdd0,
+ 0xf0890007,
+ 0x0fd00203,
+ 0xf104bd00,
+ 0xf0c10007,
+ 0x02d00203,
+ 0xf104bd00,
+ 0xf0830007,
+ 0x02d00203,
+ 0xf004bd00,
+ 0x21f507f7,
+ 0x07f1083c,
+ 0x03f0c000,
+ 0x0002d002,
+ 0x0bfe04bd,
+ 0x1f2af000,
+ 0xb60424b6,
+ 0x94bd0220,
+ 0xf10899f0,
+ 0xf00f0007,
+ 0x09d00203,
+ 0xf104bd00,
+ 0xf0810007,
+ 0x02d00203,
+ 0xf104bd00,
+ 0xf1000027,
+ 0xf0800023,
+ 0x07f10225,
+ 0x03f08800,
+ 0x0002d002,
+ 0x17f004bd,
+ 0x0027f110,
+ 0x0223f002,
+ 0xf80512fa,
+ 0xf094bd03,
  0x07f10899,
- 0x03f00f00,
+ 0x03f01700,
  0x0009d002,
- 0x17f104bd,
- 0x14b60a04,
- 0x0012d006,
- 0x0a2017f1,
- 0xf00614b6,
- 0x23f10227,
- 0x12d08000,
- 0x1017f000,
- 0x020027f1,
- 0xfa0223f0,
- 0x03f80512,
+ 0x019804bd,
+ 0x1814b681,
+ 0xb6800298,
+ 0x12fd0825,
+ 0x16018005,
  0x99f094bd,
- 0x0007f108,
- 0x0203f017,
+ 0x0007f109,
+ 0x0203f00f,
  0xbd0009d0,
- 0x81019804,
- 0x981814b6,
- 0x25b68002,
- 0x0512fd08,
- 0xbd160180,
- 0x0999f094,
- 0x0f0007f1,
- 0xd00203f0,
- 0x04bd0009,
- 0x0a0427f1,
- 0xd00624b6,
- 0x27f00021,
- 0x2017f101,
- 0x0614b60a,
- 0xf10012d0,
- 0xf0010017,
- 0x01fa0613,
- 0xbd03f805,
- 0x0999f094,
- 0x170007f1,
+ 0x0007f104,
+ 0x0203f081,
+ 0xbd0001d0,
+ 0x0127f004,
+ 0x880007f1,
  0xd00203f0,
- 0x04bd0009,
+ 0x04bd0002,
+ 0x010017f1,
+ 0xfa0613f0,
+ 0x03f80501,
  0x99f094bd,
- 0x0007f105,
+ 0x0007f109,
  0x0203f017,
  0xbd0009d0,
-/* 0x07bb: ctx_chan */
- 0xf500f804,
- 0xf5062b21,
- 0xf006b221,
- 0x21f40ca7,
- 0x1017f1c9,
- 0x0614b60a,
- 0xd00527f0,
-/* 0x07d6: ctx_chan_wait */
- 0x12cf0012,
- 0x0522fd00,
- 0xf5fa1bf4,
- 0xf8064321,
-/* 0x07e5: ctx_mmio_exec */
- 0x41039800,
- 0x0a0427f1,
- 0xd00624b6,
- 0x34bd0023,
-/* 0x07f4: ctx_mmio_loop */
+ 0xf094bd04,
+ 0x07f10599,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0978: ctx_chan */
+ 0x077f21f5,
+ 0x085a21f5,
+ 0xf40ca7f0,
+ 0xf7f0d021,
+ 0x3c21f505,
+ 0xa421f508,
+/* 0x0993: ctx_mmio_exec */
+ 0x9800f807,
+ 0x07f14103,
+ 0x03f08100,
+ 0x0003d002,
+ 0x34bd04bd,
+/* 0x09a4: ctx_mmio_loop */
  0xf4ff34c4,
  0x57f10f1b,
  0x53f00200,
  0x0535fa06,
-/* 0x0806: ctx_mmio_pull */
+/* 0x09b6: ctx_mmio_pull */
  0x4e9803f8,
  0x814f9880,
- 0xb68d21f4,
+ 0xb69d21f4,
  0x12b60830,
  0xdf1bf401,
-/* 0x0818: ctx_mmio_done */
- 0xd0160398,
- 0x00800023,
- 0x0017f140,
- 0x0613f001,
- 0xf80601fa,
-/* 0x082f: ctx_xfer */
- 0xf100f803,
- 0xb60c00f7,
- 0xe7f006f4,
- 0x80fed004,
-/* 0x083c: ctx_xfer_idle */
- 0xf100fecf,
- 0xf42000e4,
- 0x11f4f91b,
- 0x1102f406,
-/* 0x084c: ctx_xfer_pre */
- 0xf510f7f0,
- 0xf5069221,
- 0xf4062b21,
-/* 0x085a: ctx_xfer_pre_load */
- 0xf7f01c11,
- 0x5121f502,
- 0x6021f506,
- 0x7221f506,
- 0xf5f4bd06,
- 0xf5065121,
-/* 0x0873: ctx_xfer_exec */
- 0x9806b221,
- 0x27f11601,
- 0x24b60414,
- 0x0020d006,
- 0xa500e7f1,
- 0xb941e3f0,
- 0x21f4021f,
- 0x04e0b68d,
- 0xf001fcf0,
- 0x24b6022c,
- 0x05f2fd01,
- 0xf18d21f4,
- 0xf04afc17,
- 0x27f00213,
- 0x0012d00c,
- 0x021521f5,
- 0x47fc27f1,
- 0xd00223f0,
- 0x2cf00020,
+/* 0x09c8: ctx_mmio_done */
+ 0xf1160398,
+ 0xf0810007,
+ 0x03d00203,
+ 0x8004bd00,
+ 0x17f14000,
+ 0x13f00100,
+ 0x0601fa06,
+ 0x00f803f8,
+/* 0x09e8: ctx_xfer */
+ 0xf104e7f0,
+ 0xf0020007,
+ 0x0ed00303,
+/* 0x09f7: ctx_xfer_idle */
+ 0xf104bd00,
+ 0xf00000e7,
+ 0xeecf03e3,
+ 0x00e4f100,
+ 0xf21bf420,
+ 0xf40611f4,
+/* 0x0a0e: ctx_xfer_pre */
+ 0xf7f01102,
+ 0x1421f510,
+ 0x7f21f508,
+ 0x1c11f407,
+/* 0x0a1c: ctx_xfer_pre_load */
+ 0xf502f7f0,
+ 0xf507b521,
+ 0xf507c721,
+ 0xbd07dc21,
+ 0xb521f5f4,
+ 0x5a21f507,
+/* 0x0a35: ctx_xfer_exec */
+ 0x16019808,
+ 0x07f124bd,
+ 0x03f00500,
+ 0x0002d001,
+ 0x1fb904bd,
+ 0x00e7f102,
+ 0x41e3f0a5,
+ 0xf09d21f4,
+ 0x2cf001fc,
+ 0x0124b602,
+ 0xb905f2fd,
+ 0xe7f102ff,
+ 0xe3f0a504,
+ 0x9d21f441,
+ 0x026a21f5,
+ 0x07f124bd,
+ 0x03f047fc,
+ 0x0002d002,
+ 0x2cf004bd,
  0x0320b601,
- 0xf00012d0,
- 0xa5f001ac,
- 0x00b7f006,
- 0x98000c98,
- 0xe7f0010d,
- 0x6621f500,
- 0x08a7f001,
- 0x010921f5,
- 0x021521f5,
- 0xf02201f4,
- 0x21f40ca7,
- 0x1017f1c9,
- 0x0614b60a,
- 0xd00527f0,
-/* 0x08fa: ctx_xfer_post_save_wait */
- 0x12cf0012,
- 0x0522fd00,
- 0xf4fa1bf4,
-/* 0x0906: ctx_xfer_post */
- 0xf7f03202,
- 0x5121f502,
- 0xf5f4bd06,
- 0xf5069221,
- 0xf5023421,
- 0xbd066021,
- 0x5121f5f4,
- 0x1011f406,
- 0xfd400198,
- 0x0bf40511,
- 0xe521f507,
-/* 0x0931: ctx_xfer_no_post_mmio */
- 0x4321f507,
-/* 0x0935: ctx_xfer_done */
- 0x0000f806,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xf001acf0,
+ 0xb7f006a5,
+ 0x000c9800,
+ 0xf0010d98,
+ 0x21f500e7,
+ 0xa7f0016f,
+ 0x1021f508,
+ 0x5e21f501,
+ 0x1301f402,
+ 0xf40ca7f0,
+ 0xf7f0d021,
+ 0x3c21f505,
+ 0x3202f408,
+/* 0x0ac4: ctx_xfer_post */
+ 0xf502f7f0,
+ 0xbd07b521,
+ 0x1421f5f4,
+ 0x7f21f508,
+ 0xc721f502,
+ 0xf5f4bd07,
+ 0xf407b521,
+ 0x01981011,
+ 0x0511fd40,
+ 0xf5070bf4,
+/* 0x0aef: ctx_xfer_no_post_mmio */
+ 0xf5099321,
+/* 0x0af3: ctx_xfer_done */
+ 0xf807a421,
  0x00000000,
  0x00000000,
  0x00000000,
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvd7.fuc.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvd7.fuc.h
index a1b9f76..84af824 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvd7.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvd7.fuc.h
@@ -206,14 +206,14 @@ uint32_t nvd7_grhub_data[] = {
 };
 
 uint32_t nvd7_grhub_code[] = {
- 0x031b0ef5,
+ 0x039b0ef5,
 /* 0x0004: queue_put */
  0x9800d898,
  0x86f001d9,
  0x0489b808,
  0xf00c1bf4,
  0x21f502f7,
- 0x00f802fe,
+ 0x00f8037e,
 /* 0x001c: queue_put_next */
  0xb60798c4,
  0x8dbb0384,
@@ -237,184 +237,214 @@ uint32_t nvd7_grhub_code[] = {
 /* 0x0066: queue_get_done */
  0x00f80132,
 /* 0x0068: nv_rd32 */
- 0x0728b7f1,
- 0xb906b4b6,
- 0xc9f002ec,
- 0x00bcd01f,
-/* 0x0078: nv_rd32_wait */
- 0xc800bccf,
- 0x1bf41fcc,
- 0x06a7f0fa,
- 0x010921f5,
- 0xf840bfcf,
-/* 0x008d: nv_wr32 */
- 0x28b7f100,
- 0x06b4b607,
- 0xb980bfd0,
- 0xc9f002ec,
- 0x1ec9f01f,
-/* 0x00a3: nv_wr32_wait */
- 0xcf00bcd0,
- 0xccc800bc,
- 0xfa1bf41f,
-/* 0x00ae: watchdog_reset */
- 0x87f100f8,
- 0x84b60430,
- 0x1ff9f006,
- 0xf8008fd0,
-/* 0x00bd: watchdog_clear */
- 0x3087f100,
- 0x0684b604,
- 0xf80080d0,
-/* 0x00c9: wait_donez */
- 0xf094bd00,
- 0x07f10099,
- 0x03f00f00,
- 0x0009d002,
- 0x07f104bd,
- 0x03f00600,
- 0x000ad002,
-/* 0x00e6: wait_donez_ne */
- 0x87f104bd,
- 0x83f00000,
- 0x0088cf01,
- 0xf4888aff,
- 0x94bdf31b,
- 0xf10099f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0109: wait_doneo */
- 0xf094bd00,
+ 0xf002ecb9,
+ 0x07f11fc9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x007a: nv_rd32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0xa7f0f31b,
+ 0x1021f506,
+ 0x00f7f101,
+ 0x01f3f0cb,
+ 0xf800ffcf,
+/* 0x009d: nv_wr32 */
+ 0x0007f100,
+ 0x0103f0cc,
+ 0xbd000fd0,
+ 0x02ecb904,
+ 0xf01fc9f0,
+ 0x07f11ec9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x00be: nv_wr32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f31b,
+/* 0x00d0: wait_donez */
+ 0x99f094bd,
+ 0x0007f100,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x00ed: wait_donez_ne */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x1bf4888a,
+ 0xf094bdf3,
  0x07f10099,
- 0x03f00f00,
+ 0x03f01700,
  0x0009d002,
- 0x87f104bd,
- 0x84b60818,
- 0x008ad006,
-/* 0x0124: wait_doneo_e */
- 0x040087f1,
- 0xcf0684b6,
- 0x8aff0088,
- 0xf30bf488,
+ 0x00f804bd,
+/* 0x0110: wait_doneo */
  0x99f094bd,
  0x0007f100,
- 0x0203f017,
+ 0x0203f00f,
  0xbd0009d0,
-/* 0x0147: mmctx_size */
- 0xbd00f804,
-/* 0x0149: nv_mmctx_size_loop */
- 0x00e89894,
- 0xb61a85b6,
- 0x84b60180,
- 0x0098bb02,
- 0xb804e0b6,
- 0x1bf404ef,
- 0x029fb9eb,
-/* 0x0166: mmctx_xfer */
- 0x94bd00f8,
- 0xf10199f0,
- 0xf00f0007,
- 0x09d00203,
- 0xf104bd00,
- 0xb6071087,
- 0x94bd0684,
- 0xf405bbfd,
- 0x8bd0090b,
- 0x0099f000,
-/* 0x018c: mmctx_base_disabled */
- 0xf405eefd,
- 0x8ed00c0b,
- 0xc08fd080,
-/* 0x019b: mmctx_multi_disabled */
- 0xb70199f0,
- 0xc8010080,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x012d: wait_doneo_e */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x0bf4888a,
+ 0xf094bdf3,
+ 0x07f10099,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0150: mmctx_size */
+/* 0x0152: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0xf404efb8,
+ 0x9fb9eb1b,
+/* 0x016f: mmctx_xfer */
+ 0xbd00f802,
+ 0x0199f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0xbbfd94bd,
+ 0x120bf405,
+ 0xc40007f1,
+ 0xd00103f0,
+ 0x04bd000b,
+/* 0x0197: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0x0007f11e,
+ 0x0103f0c6,
+ 0xbd000ed0,
+ 0x0007f104,
+ 0x0103f0c7,
+ 0xbd000fd0,
+ 0x0199f004,
+/* 0x01b8: mmctx_multi_disabled */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x01aec80c,
+ 0xfd11e4b6,
+ 0x07f105be,
+ 0x03f0c500,
+ 0x000bd001,
+/* 0x01d6: mmctx_exec_loop */
+/* 0x01d6: mmctx_wait_free */
+ 0xe7f104bd,
+ 0xe3f0c500,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f30b,
+ 0x05e9fd00,
+ 0xc80007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+ 0xb804c0b6,
+ 0x1bf404cd,
+ 0x02abc8d8,
+/* 0x0207: mmctx_fini_wait */
+ 0xf11f1bf4,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x1fb4f000,
+ 0xf410b4b0,
+ 0xa7f0f01b,
+ 0xd021f402,
+/* 0x0223: mmctx_stop */
+ 0xc82b0ef4,
  0xb4b600ab,
  0x0cb9f010,
- 0xb601aec8,
- 0xbefd11e4,
- 0x008bd005,
-/* 0x01b4: mmctx_exec_loop */
-/* 0x01b4: mmctx_wait_free */
- 0xf0008ecf,
- 0x0bf41fe4,
- 0x00ce98fa,
- 0xd005e9fd,
- 0xc0b6c08e,
- 0x04cdb804,
- 0xc8e81bf4,
- 0x1bf402ab,
-/* 0x01d5: mmctx_fini_wait */
- 0x008bcf18,
- 0xb01fb4f0,
- 0x1bf410b4,
- 0x02a7f0f7,
- 0xf4c921f4,
-/* 0x01ea: mmctx_stop */
- 0xabc81b0e,
- 0x10b4b600,
- 0xf00cb9f0,
- 0x8bd012b9,
-/* 0x01f9: mmctx_stop_wait */
- 0x008bcf00,
- 0xf412bbc8,
-/* 0x0202: mmctx_done */
- 0x94bdfa1b,
- 0xf10199f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0215: strand_wait */
- 0xf0a0f900,
- 0x21f402a7,
- 0xf8a0fcc9,
-/* 0x0221: strand_pre */
- 0xfc87f100,
- 0x0283f04a,
- 0xd00c97f0,
- 0x21f50089,
- 0x00f80215,
-/* 0x0234: strand_post */
- 0x4afc87f1,
- 0xf00283f0,
- 0x89d00d97,
- 0x1521f500,
-/* 0x0247: strand_set */
- 0xf100f802,
- 0xf04ffca7,
- 0xaba202a3,
- 0xc7f00500,
- 0x00acd00f,
- 0xd00bc7f0,
- 0x21f500bc,
- 0xaed00215,
- 0x0ac7f000,
- 0xf500bcd0,
- 0xf8021521,
-/* 0x0271: strand_ctx_init */
- 0xf094bd00,
- 0x07f10399,
- 0x03f00f00,
+ 0xf112b9f0,
+ 0xf0c50007,
+ 0x0bd00103,
+/* 0x023b: mmctx_stop_wait */
+ 0xf104bd00,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x12bbc800,
+/* 0x024b: mmctx_done */
+ 0xbdf31bf4,
+ 0x0199f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x025e: strand_wait */
+ 0xa0f900f8,
+ 0xf402a7f0,
+ 0xa0fcd021,
+/* 0x026a: strand_pre */
+ 0x97f000f8,
+ 0xfc07f10c,
+ 0x0203f04a,
+ 0xbd0009d0,
+ 0x5e21f504,
+/* 0x027f: strand_post */
+ 0xf000f802,
+ 0x07f10d97,
+ 0x03f04afc,
  0x0009d002,
  0x21f504bd,
- 0xe7f00221,
- 0x4721f503,
- 0xfca7f102,
- 0x02a3f046,
- 0x0400aba0,
- 0xf040a0d0,
- 0xbcd001c7,
- 0x1521f500,
- 0x010c9202,
- 0xf000acd0,
- 0xbcd002c7,
- 0x1521f500,
- 0x3421f502,
- 0x8087f102,
- 0x0684b608,
- 0xb70089cf,
- 0x95220080,
-/* 0x02ca: ctx_init_strand_loop */
+ 0x00f8025e,
+/* 0x0294: strand_set */
+ 0xf10fc7f0,
+ 0xf04ffc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f10bc7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x07f104bd,
+ 0x03f04ffc,
+ 0x000ed002,
+ 0xc7f004bd,
+ 0xfc07f10a,
+ 0x0203f04a,
+ 0xbd000cd0,
+ 0x5e21f504,
+/* 0x02d3: strand_ctx_init */
+ 0xbd00f802,
+ 0x0399f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0x026a21f5,
+ 0xf503e7f0,
+ 0xbd029421,
+ 0xfc07f1c4,
+ 0x0203f047,
+ 0xbd000cd0,
+ 0x01c7f004,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd000c,
+ 0x025e21f5,
+ 0xf1010c92,
+ 0xf046fc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f102c7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x21f504bd,
+ 0x21f5025e,
+ 0x87f1027f,
+ 0x83f04200,
+ 0x0097f102,
+ 0x0293f020,
+ 0x950099cf,
+/* 0x034a: ctx_init_strand_loop */
  0x8ed008fe,
  0x408ed000,
  0xb6808acf,
@@ -428,7 +458,7 @@ uint32_t nvd7_grhub_code[] = {
  0x170007f1,
  0xd00203f0,
  0x04bd0009,
-/* 0x02fe: error */
+/* 0x037e: error */
  0x07f100f8,
  0x03f00500,
  0x000fd002,
@@ -436,82 +466,117 @@ uint32_t nvd7_grhub_code[] = {
  0x0007f101,
  0x0303f007,
  0xbd000fd0,
-/* 0x031b: init */
+/* 0x039b: init */
  0xbd00f804,
- 0x0004fe04,
- 0xf10007fe,
- 0xf0120017,
- 0x12d00227,
- 0xb117f100,
- 0x0010fe05,
- 0x040017f1,
- 0xf1c010d0,
- 0xb6040437,
- 0x27f10634,
- 0x32d02003,
- 0x0427f100,
- 0x0132d020,
+ 0x0007fe04,
+ 0x420017f1,
+ 0xcf0013f0,
+ 0x11e70011,
+ 0x14b60109,
+ 0x0014fe08,
+ 0xf10227f0,
+ 0xf0120007,
+ 0x02d00003,
+ 0xf104bd00,
+ 0xfe06c817,
+ 0x24bd0010,
+ 0x070007f1,
+ 0xd00003f0,
+ 0x04bd0002,
+ 0x200327f1,
+ 0x010007f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0x200427f1,
+ 0x010407f1,
+ 0xd00103f0,
+ 0x04bd0002,
  0x200b27f1,
- 0xf10232d0,
- 0xd0200c27,
- 0x27f10732,
- 0x24b60c24,
- 0x0003b906,
- 0xf10023d0,
+ 0x010807f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0x200c27f1,
+ 0x011c07f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0xf1010392,
+ 0xf0090007,
+ 0x03d00303,
+ 0xf104bd00,
  0xf0870427,
- 0x12d00023,
- 0x0012b700,
- 0x0427f001,
- 0xf40012d0,
- 0xe7f11031,
- 0xe3f09604,
- 0x6821f440,
- 0x8090f1c7,
- 0xf4f00301,
- 0x020f801f,
- 0xbb0117f0,
- 0x12b6041f,
- 0x0c27f101,
- 0x0624b604,
- 0xd00021d0,
- 0x17f14021,
- 0x0e980100,
- 0x010f9800,
- 0x014721f5,
- 0x070037f1,
- 0x950634b6,
- 0x34d00814,
- 0x4034d000,
- 0x130030b7,
- 0xb6001fbb,
- 0x3fd002f5,
- 0x0815b600,
- 0xb60110b6,
- 0x1fb90814,
- 0x7121f502,
- 0x001fbb02,
- 0xf1020398,
- 0xf0200047,
-/* 0x03f6: init_gpc */
- 0x4ea05043,
- 0x1fb90804,
- 0x8d21f402,
- 0x010c4ea0,
- 0x21f4f4bd,
- 0x044ea08d,
- 0x8d21f401,
- 0x01004ea0,
- 0xf402f7f0,
- 0x4ea08d21,
-/* 0x041e: init_gpc_wait */
- 0x21f40800,
- 0x1fffc868,
- 0xa0fa0bf4,
- 0xf408044e,
- 0x1fbb6821,
- 0x0040b700,
- 0x0132b680,
- 0xf1be1bf4,
+ 0x07f10023,
+ 0x03f00400,
+ 0x0002d000,
+ 0x27f004bd,
+ 0x0007f104,
+ 0x0003f003,
+ 0xbd0002d0,
+ 0x1031f404,
+ 0x9604e7f1,
+ 0xf440e3f0,
+ 0xfeb96821,
+ 0x90f1c702,
+ 0xf0030180,
+ 0x0f801ff4,
+ 0x0117f002,
+ 0xb6041fbb,
+ 0x07f10112,
+ 0x03f00300,
+ 0x0001d001,
+ 0x07f104bd,
+ 0x03f00400,
+ 0x0001d001,
+ 0x17f104bd,
+ 0xf7f00100,
+ 0xb521f502,
+ 0xc721f507,
+ 0x10f7f007,
+ 0x081421f5,
+ 0x98000e98,
+ 0x21f5010f,
+ 0x14950150,
+ 0x0007f108,
+ 0x0103f0c0,
+ 0xbd0004d0,
+ 0x0007f104,
+ 0x0103f0c1,
+ 0xbd0004d0,
+ 0x0030b704,
+ 0x001fbb13,
+ 0xf102f5b6,
+ 0xf0d30007,
+ 0x0fd00103,
+ 0xb604bd00,
+ 0x10b60815,
+ 0x0814b601,
+ 0xf5021fb9,
+ 0xbb02d321,
+ 0x0398001f,
+ 0x0047f102,
+ 0x5043f020,
+/* 0x04f4: init_gpc */
+ 0x08044ea0,
+ 0xf4021fb9,
+ 0x4ea09d21,
+ 0xf4bd010c,
+ 0xa09d21f4,
+ 0xf401044e,
+ 0x4ea09d21,
+ 0xf7f00100,
+ 0x9d21f402,
+ 0x08004ea0,
+/* 0x051c: init_gpc_wait */
+ 0xc86821f4,
+ 0x0bf41fff,
+ 0x044ea0fa,
+ 0x6821f408,
+ 0xb7001fbb,
+ 0xb6800040,
+ 0x1bf40132,
+ 0x00f7f0be,
+ 0x081421f5,
+ 0xf500f7f0,
+ 0xf107b521,
  0xf0010007,
  0x01d00203,
  0xbd04bd00,
@@ -519,402 +584,399 @@ uint32_t nvd7_grhub_code[] = {
  0x080007f1,
  0xd00203f0,
  0x04bd0001,
-/* 0x0458: main */
+/* 0x0564: main */
  0xf40031f4,
  0xd7f00028,
  0x3921f410,
  0xb1f401f4,
  0xf54001e4,
- 0xbd00de1b,
+ 0xbd00e91b,
  0x0499f094,
  0x0f0007f1,
  0xd00203f0,
  0x04bd0009,
- 0x0b0017f1,
- 0xcf0614b6,
- 0x11cf4012,
- 0x1f13c800,
- 0x00870bf5,
- 0xf41f23c8,
- 0x20f9620b,
- 0xbd0212b9,
- 0x0799f094,
- 0x0f0007f1,
- 0xd00203f0,
- 0x04bd0009,
- 0xf40132f4,
- 0x21f50231,
- 0x94bd082f,
+ 0xc00017f1,
+ 0xcf0213f0,
+ 0x27f10011,
+ 0x23f0c100,
+ 0x0022cf02,
+ 0xf51f13c8,
+ 0xc800890b,
+ 0x0bf41f23,
+ 0xb920f962,
+ 0x94bd0212,
  0xf10799f0,
- 0xf0170007,
+ 0xf00f0007,
  0x09d00203,
- 0xfc04bd00,
- 0xf094bd20,
- 0x07f10699,
- 0x03f00f00,
- 0x0009d002,
- 0x31f404bd,
- 0x2f21f501,
- 0xf094bd08,
- 0x07f10699,
+ 0xf404bd00,
+ 0x31f40132,
+ 0xe821f502,
+ 0xf094bd09,
+ 0x07f10799,
  0x03f01700,
  0x0009d002,
- 0x0ef404bd,
-/* 0x04f9: chsw_prev_no_next */
- 0xb920f931,
- 0x32f40212,
- 0x0232f401,
- 0x082f21f5,
- 0x17f120fc,
- 0x14b60b00,
- 0x0012d006,
-/* 0x0517: chsw_no_prev */
- 0xc8130ef4,
- 0x0bf41f23,
- 0x0131f40d,
- 0xf50232f4,
-/* 0x0527: chsw_done */
- 0xf1082f21,
- 0xb60b0c17,
- 0x27f00614,
- 0x0012d001,
+ 0x20fc04bd,
  0x99f094bd,
- 0x0007f104,
+ 0x0007f106,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0131f404,
+ 0x09e821f5,
+ 0x99f094bd,
+ 0x0007f106,
  0x0203f017,
  0xbd0009d0,
- 0x130ef504,
-/* 0x0549: main_not_ctx_switch */
- 0x01e4b0ff,
- 0xb90d1bf4,
- 0x21f502f2,
- 0x0ef407bb,
-/* 0x0559: main_not_ctx_chan */
- 0x02e4b046,
- 0xbd321bf4,
- 0x0799f094,
- 0x0f0007f1,
+ 0x330ef404,
+/* 0x060c: chsw_prev_no_next */
+ 0x12b920f9,
+ 0x0132f402,
+ 0xf50232f4,
+ 0xfc09e821,
+ 0x0007f120,
+ 0x0203f0c0,
+ 0xbd0002d0,
+ 0x130ef404,
+/* 0x062c: chsw_no_prev */
+ 0xf41f23c8,
+ 0x31f40d0b,
+ 0x0232f401,
+ 0x09e821f5,
+/* 0x063c: chsw_done */
+ 0xf10127f0,
+ 0xf0c30007,
+ 0x02d00203,
+ 0xbd04bd00,
+ 0x0499f094,
+ 0x170007f1,
  0xd00203f0,
  0x04bd0009,
- 0xf40132f4,
- 0x21f50232,
- 0x94bd082f,
+ 0xff080ef5,
+/* 0x0660: main_not_ctx_switch */
+ 0xf401e4b0,
+ 0xf2b90d1b,
+ 0x7821f502,
+ 0x460ef409,
+/* 0x0670: main_not_ctx_chan */
+ 0xf402e4b0,
+ 0x94bd321b,
  0xf10799f0,
- 0xf0170007,
+ 0xf00f0007,
  0x09d00203,
  0xf404bd00,
-/* 0x058e: main_not_ctx_save */
- 0xef94110e,
- 0x01f5f010,
- 0x02fe21f5,
- 0xfec00ef5,
-/* 0x059c: main_done */
- 0x29f024bd,
- 0x0007f11f,
- 0x0203f008,
- 0xbd0002d0,
- 0xab0ef504,
-/* 0x05b1: ih */
- 0xfe80f9fe,
- 0x80f90188,
- 0xa0f990f9,
- 0xd0f9b0f9,
- 0xf0f9e0f9,
- 0x0acf04bd,
- 0x04abc480,
- 0xf11d0bf4,
- 0xf01900b7,
- 0xbecf10d7,
- 0x00bfcf40,
+ 0x32f40132,
+ 0xe821f502,
+ 0xf094bd09,
+ 0x07f10799,
+ 0x03f01700,
+ 0x0009d002,
+ 0x0ef404bd,
+/* 0x06a5: main_not_ctx_save */
+ 0x10ef9411,
+ 0xf501f5f0,
+ 0xf5037e21,
+/* 0x06b3: main_done */
+ 0xbdfeb50e,
+ 0x1f29f024,
+ 0x080007f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xfea00ef5,
+/* 0x06c8: ih */
+ 0x88fe80f9,
+ 0xf980f901,
+ 0xf9a0f990,
+ 0xf9d0f9b0,
+ 0xbdf0f9e0,
+ 0x00a7f104,
+ 0x00a3f002,
+ 0xc400aacf,
+ 0x0bf404ab,
+ 0x10d7f030,
+ 0x1a00e7f1,
+ 0xcf00e3f0,
+ 0xf7f100ee,
+ 0xf3f01900,
+ 0x00ffcf00,
  0xb70421f4,
  0xf00400b0,
- 0xbed001e7,
-/* 0x05e9: ih_no_fifo */
- 0x00abe400,
- 0x0d0bf401,
- 0xf110d7f0,
- 0xf44001e7,
-/* 0x05fa: ih_no_ctxsw */
- 0xb7f10421,
- 0xb0bd0104,
- 0xf4b4abff,
- 0xa7f10d0b,
- 0xa4b60c1c,
- 0x00abd006,
-/* 0x0610: ih_no_other */
- 0xfc400ad0,
+ 0x07f101e7,
+ 0x03f01d00,
+ 0x000ed000,
+/* 0x071a: ih_no_fifo */
+ 0xabe404bd,
+ 0x0bf40100,
+ 0x10d7f00d,
+ 0x4001e7f1,
+/* 0x072b: ih_no_ctxsw */
+ 0xe40421f4,
+ 0xf40400ab,
+ 0xb7f1140b,
+ 0xbfb90100,
+ 0x44e7f102,
+ 0x40e3f001,
+/* 0x0743: ih_no_fwmthd */
+ 0xf19d21f4,
+ 0xbd0104b7,
+ 0xb4abffb0,
+ 0xf10f0bf4,
+ 0xf0070007,
+ 0x0bd00303,
+/* 0x075b: ih_no_other */
+ 0xf104bd00,
+ 0xf0010007,
+ 0x0ad00003,
+ 0xfc04bd00,
  0xfce0fcf0,
  0xfcb0fcd0,
  0xfc90fca0,
  0x0088fe80,
  0x32f480fc,
-/* 0x062b: ctx_4160s */
- 0xf101f800,
- 0xf04160e7,
- 0xf7f040e3,
- 0x8d21f401,
-/* 0x0638: ctx_4160s_wait */
- 0xc86821f4,
- 0x0bf404ff,
-/* 0x0643: ctx_4160c */
- 0xf100f8fa,
+/* 0x077f: ctx_4160s */
+ 0xf001f800,
+ 0xffb901f7,
+ 0x60e7f102,
+ 0x40e3f041,
+/* 0x078f: ctx_4160s_wait */
+ 0xf19d21f4,
  0xf04160e7,
- 0xf4bd40e3,
- 0xf88d21f4,
-/* 0x0651: ctx_4170s */
- 0x70e7f100,
+ 0x21f440e3,
+ 0x02ffb968,
+ 0xf404ffc8,
+ 0x00f8f00b,
+/* 0x07a4: ctx_4160c */
+ 0xffb9f4bd,
+ 0x60e7f102,
  0x40e3f041,
- 0xf410f5f0,
- 0x00f88d21,
-/* 0x0660: ctx_4170w */
- 0x4170e7f1,
- 0xf440e3f0,
- 0xf4f06821,
- 0xf31bf410,
-/* 0x0672: ctx_redswitch */
- 0xe7f100f8,
- 0xe4b60614,
- 0x70f7f106,
- 0x00efd002,
-/* 0x0683: ctx_redswitch_delay */
- 0xb608f7f0,
- 0x1bf401f2,
- 0x70f7f1fd,
- 0x00efd007,
-/* 0x0692: ctx_86c */
- 0xe7f100f8,
- 0xe4b6086c,
- 0x00efd006,
- 0x8a14e7f1,
- 0xf440e3f0,
- 0xe7f18d21,
- 0xe3f0a86c,
- 0x8d21f441,
-/* 0x06b2: ctx_load */
+ 0xf89d21f4,
+/* 0x07b5: ctx_4170s */
+ 0x10f5f000,
+ 0xf102ffb9,
+ 0xf04170e7,
+ 0x21f440e3,
+/* 0x07c7: ctx_4170w */
+ 0xf100f89d,
+ 0xf04170e7,
+ 0x21f440e3,
+ 0x02ffb968,
+ 0xf410f4f0,
+ 0x00f8f01b,
+/* 0x07dc: ctx_redswitch */
+ 0x0200e7f1,
+ 0xf040e5f0,
+ 0xe5f020e5,
+ 0x0007f110,
+ 0x0103f085,
+ 0xbd000ed0,
+ 0x08f7f004,
+/* 0x07f8: ctx_redswitch_delay */
+ 0xf401f2b6,
+ 0xe5f1fd1b,
+ 0xe5f10400,
+ 0x07f10100,
+ 0x03f08500,
+ 0x000ed001,
+ 0x00f804bd,
+/* 0x0814: ctx_86c */
+ 0x1b0007f1,
+ 0xd00203f0,
+ 0x04bd000f,
+ 0xf102ffb9,
+ 0xf08a14e7,
+ 0x21f440e3,
+ 0x02ffb99d,
+ 0xa86ce7f1,
+ 0xf441e3f0,
+ 0x00f89d21,
+/* 0x083c: ctx_mem */
+ 0x840007f1,
+ 0xd00203f0,
+ 0x04bd000f,
+/* 0x0848: ctx_mem_wait */
+ 0x8400f7f1,
+ 0xcf02f3f0,
+ 0xfffd00ff,
+ 0xf31bf405,
+/* 0x085a: ctx_load */
  0x94bd00f8,
  0xf10599f0,
  0xf00f0007,
  0x09d00203,
  0xf004bd00,
  0x21f40ca7,
- 0x2417f1c9,
- 0x0614b60a,
- 0xf10010d0,
- 0xb60b0037,
- 0x32d00634,
- 0x0c17f140,
- 0x0614b60a,
- 0xd00747f0,
- 0x14d00012,
-/* 0x06ed: ctx_chan_wait_0 */
- 0x4014cf40,
- 0xf41f44f0,
- 0x32d0fa1b,
- 0x000bfe00,
- 0xb61f2af0,
- 0x20b60424,
- 0xf094bd02,
+ 0xf1f4bdd0,
+ 0xf0890007,
+ 0x0fd00203,
+ 0xf104bd00,
+ 0xf0c10007,
+ 0x02d00203,
+ 0xf104bd00,
+ 0xf0830007,
+ 0x02d00203,
+ 0xf004bd00,
+ 0x21f507f7,
+ 0x07f1083c,
+ 0x03f0c000,
+ 0x0002d002,
+ 0x0bfe04bd,
+ 0x1f2af000,
+ 0xb60424b6,
+ 0x94bd0220,
+ 0xf10899f0,
+ 0xf00f0007,
+ 0x09d00203,
+ 0xf104bd00,
+ 0xf0810007,
+ 0x02d00203,
+ 0xf104bd00,
+ 0xf1000027,
+ 0xf0800023,
+ 0x07f10225,
+ 0x03f08800,
+ 0x0002d002,
+ 0x17f004bd,
+ 0x0027f110,
+ 0x0223f002,
+ 0xf80512fa,
+ 0xf094bd03,
  0x07f10899,
- 0x03f00f00,
+ 0x03f01700,
  0x0009d002,
- 0x17f104bd,
- 0x14b60a04,
- 0x0012d006,
- 0x0a2017f1,
- 0xf00614b6,
- 0x23f10227,
- 0x12d08000,
- 0x1017f000,
- 0x020027f1,
- 0xfa0223f0,
- 0x03f80512,
+ 0x019804bd,
+ 0x1814b681,
+ 0xb6800298,
+ 0x12fd0825,
+ 0x16018005,
  0x99f094bd,
- 0x0007f108,
- 0x0203f017,
+ 0x0007f109,
+ 0x0203f00f,
  0xbd0009d0,
- 0x81019804,
- 0x981814b6,
- 0x25b68002,
- 0x0512fd08,
- 0xbd160180,
- 0x0999f094,
- 0x0f0007f1,
- 0xd00203f0,
- 0x04bd0009,
- 0x0a0427f1,
- 0xd00624b6,
- 0x27f00021,
- 0x2017f101,
- 0x0614b60a,
- 0xf10012d0,
- 0xf0010017,
- 0x01fa0613,
- 0xbd03f805,
- 0x0999f094,
- 0x170007f1,
+ 0x0007f104,
+ 0x0203f081,
+ 0xbd0001d0,
+ 0x0127f004,
+ 0x880007f1,
  0xd00203f0,
- 0x04bd0009,
+ 0x04bd0002,
+ 0x010017f1,
+ 0xfa0613f0,
+ 0x03f80501,
  0x99f094bd,
- 0x0007f105,
+ 0x0007f109,
  0x0203f017,
  0xbd0009d0,
-/* 0x07bb: ctx_chan */
- 0xf500f804,
- 0xf5062b21,
- 0xf006b221,
- 0x21f40ca7,
- 0x1017f1c9,
- 0x0614b60a,
- 0xd00527f0,
-/* 0x07d6: ctx_chan_wait */
- 0x12cf0012,
- 0x0522fd00,
- 0xf5fa1bf4,
- 0xf8064321,
-/* 0x07e5: ctx_mmio_exec */
- 0x41039800,
- 0x0a0427f1,
- 0xd00624b6,
- 0x34bd0023,
-/* 0x07f4: ctx_mmio_loop */
+ 0xf094bd04,
+ 0x07f10599,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0978: ctx_chan */
+ 0x077f21f5,
+ 0x085a21f5,
+ 0xf40ca7f0,
+ 0xf7f0d021,
+ 0x3c21f505,
+ 0xa421f508,
+/* 0x0993: ctx_mmio_exec */
+ 0x9800f807,
+ 0x07f14103,
+ 0x03f08100,
+ 0x0003d002,
+ 0x34bd04bd,
+/* 0x09a4: ctx_mmio_loop */
  0xf4ff34c4,
  0x57f10f1b,
  0x53f00200,
  0x0535fa06,
-/* 0x0806: ctx_mmio_pull */
+/* 0x09b6: ctx_mmio_pull */
  0x4e9803f8,
  0x814f9880,
- 0xb68d21f4,
+ 0xb69d21f4,
  0x12b60830,
  0xdf1bf401,
-/* 0x0818: ctx_mmio_done */
- 0xd0160398,
- 0x00800023,
- 0x0017f140,
- 0x0613f001,
- 0xf80601fa,
-/* 0x082f: ctx_xfer */
- 0xf100f803,
- 0xb60c00f7,
- 0xe7f006f4,
- 0x80fed004,
-/* 0x083c: ctx_xfer_idle */
- 0xf100fecf,
- 0xf42000e4,
- 0x11f4f91b,
- 0x1102f406,
-/* 0x084c: ctx_xfer_pre */
- 0xf510f7f0,
- 0xf5069221,
- 0xf4062b21,
-/* 0x085a: ctx_xfer_pre_load */
- 0xf7f01c11,
- 0x5121f502,
- 0x6021f506,
- 0x7221f506,
- 0xf5f4bd06,
- 0xf5065121,
-/* 0x0873: ctx_xfer_exec */
- 0x9806b221,
- 0x27f11601,
- 0x24b60414,
- 0x0020d006,
- 0xa500e7f1,
- 0xb941e3f0,
- 0x21f4021f,
- 0x04e0b68d,
- 0xf001fcf0,
- 0x24b6022c,
- 0x05f2fd01,
- 0xf18d21f4,
- 0xf04afc17,
- 0x27f00213,
- 0x0012d00c,
- 0x021521f5,
- 0x47fc27f1,
- 0xd00223f0,
- 0x2cf00020,
+/* 0x09c8: ctx_mmio_done */
+ 0xf1160398,
+ 0xf0810007,
+ 0x03d00203,
+ 0x8004bd00,
+ 0x17f14000,
+ 0x13f00100,
+ 0x0601fa06,
+ 0x00f803f8,
+/* 0x09e8: ctx_xfer */
+ 0xf104e7f0,
+ 0xf0020007,
+ 0x0ed00303,
+/* 0x09f7: ctx_xfer_idle */
+ 0xf104bd00,
+ 0xf00000e7,
+ 0xeecf03e3,
+ 0x00e4f100,
+ 0xf21bf420,
+ 0xf40611f4,
+/* 0x0a0e: ctx_xfer_pre */
+ 0xf7f01102,
+ 0x1421f510,
+ 0x7f21f508,
+ 0x1c11f407,
+/* 0x0a1c: ctx_xfer_pre_load */
+ 0xf502f7f0,
+ 0xf507b521,
+ 0xf507c721,
+ 0xbd07dc21,
+ 0xb521f5f4,
+ 0x5a21f507,
+/* 0x0a35: ctx_xfer_exec */
+ 0x16019808,
+ 0x07f124bd,
+ 0x03f00500,
+ 0x0002d001,
+ 0x1fb904bd,
+ 0x00e7f102,
+ 0x41e3f0a5,
+ 0xf09d21f4,
+ 0x2cf001fc,
+ 0x0124b602,
+ 0xb905f2fd,
+ 0xe7f102ff,
+ 0xe3f0a504,
+ 0x9d21f441,
+ 0x026a21f5,
+ 0x07f124bd,
+ 0x03f047fc,
+ 0x0002d002,
+ 0x2cf004bd,
  0x0320b601,
- 0xf00012d0,
- 0xa5f001ac,
- 0x00b7f006,
- 0x98000c98,
- 0xe7f0010d,
- 0x6621f500,
- 0x08a7f001,
- 0x010921f5,
- 0x021521f5,
- 0xf02201f4,
- 0x21f40ca7,
- 0x1017f1c9,
- 0x0614b60a,
- 0xd00527f0,
-/* 0x08fa: ctx_xfer_post_save_wait */
- 0x12cf0012,
- 0x0522fd00,
- 0xf4fa1bf4,
-/* 0x0906: ctx_xfer_post */
- 0xf7f03202,
- 0x5121f502,
- 0xf5f4bd06,
- 0xf5069221,
- 0xf5023421,
- 0xbd066021,
- 0x5121f5f4,
- 0x1011f406,
- 0xfd400198,
- 0x0bf40511,
- 0xe521f507,
-/* 0x0931: ctx_xfer_no_post_mmio */
- 0x4321f507,
-/* 0x0935: ctx_xfer_done */
- 0x0000f806,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xf001acf0,
+ 0xb7f006a5,
+ 0x000c9800,
+ 0xf0010d98,
+ 0x21f500e7,
+ 0xa7f0016f,
+ 0x1021f508,
+ 0x5e21f501,
+ 0x1301f402,
+ 0xf40ca7f0,
+ 0xf7f0d021,
+ 0x3c21f505,
+ 0x3202f408,
+/* 0x0ac4: ctx_xfer_post */
+ 0xf502f7f0,
+ 0xbd07b521,
+ 0x1421f5f4,
+ 0x7f21f508,
+ 0xc721f502,
+ 0xf5f4bd07,
+ 0xf407b521,
+ 0x01981011,
+ 0x0511fd40,
+ 0xf5070bf4,
+/* 0x0aef: ctx_xfer_no_post_mmio */
+ 0xf5099321,
+/* 0x0af3: ctx_xfer_done */
+ 0xf807a421,
  0x00000000,
  0x00000000,
  0x00000000,
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnve0.fuc.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnve0.fuc.h
index eb7bc0e..1c179bd 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnve0.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnve0.fuc.h
@@ -206,14 +206,14 @@ uint32_t nve0_grhub_data[] = {
 };
 
 uint32_t nve0_grhub_code[] = {
- 0x031b0ef5,
+ 0x039b0ef5,
 /* 0x0004: queue_put */
  0x9800d898,
  0x86f001d9,
  0x0489b808,
  0xf00c1bf4,
  0x21f502f7,
- 0x00f802fe,
+ 0x00f8037e,
 /* 0x001c: queue_put_next */
  0xb60798c4,
  0x8dbb0384,
@@ -237,184 +237,214 @@ uint32_t nve0_grhub_code[] = {
 /* 0x0066: queue_get_done */
  0x00f80132,
 /* 0x0068: nv_rd32 */
- 0x0728b7f1,
- 0xb906b4b6,
- 0xc9f002ec,
- 0x00bcd01f,
-/* 0x0078: nv_rd32_wait */
- 0xc800bccf,
- 0x1bf41fcc,
- 0x06a7f0fa,
- 0x010921f5,
- 0xf840bfcf,
-/* 0x008d: nv_wr32 */
- 0x28b7f100,
- 0x06b4b607,
- 0xb980bfd0,
- 0xc9f002ec,
- 0x1ec9f01f,
-/* 0x00a3: nv_wr32_wait */
- 0xcf00bcd0,
- 0xccc800bc,
- 0xfa1bf41f,
-/* 0x00ae: watchdog_reset */
- 0x87f100f8,
- 0x84b60430,
- 0x1ff9f006,
- 0xf8008fd0,
-/* 0x00bd: watchdog_clear */
- 0x3087f100,
- 0x0684b604,
- 0xf80080d0,
-/* 0x00c9: wait_donez */
- 0xf094bd00,
- 0x07f10099,
- 0x03f00f00,
- 0x0009d002,
- 0x07f104bd,
- 0x03f00600,
- 0x000ad002,
-/* 0x00e6: wait_donez_ne */
- 0x87f104bd,
- 0x83f00000,
- 0x0088cf01,
- 0xf4888aff,
- 0x94bdf31b,
- 0xf10099f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0109: wait_doneo */
- 0xf094bd00,
+ 0xf002ecb9,
+ 0x07f11fc9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x007a: nv_rd32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0xa7f0f31b,
+ 0x1021f506,
+ 0x00f7f101,
+ 0x01f3f0cb,
+ 0xf800ffcf,
+/* 0x009d: nv_wr32 */
+ 0x0007f100,
+ 0x0103f0cc,
+ 0xbd000fd0,
+ 0x02ecb904,
+ 0xf01fc9f0,
+ 0x07f11ec9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x00be: nv_wr32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f31b,
+/* 0x00d0: wait_donez */
+ 0x99f094bd,
+ 0x0007f100,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x00ed: wait_donez_ne */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x1bf4888a,
+ 0xf094bdf3,
  0x07f10099,
- 0x03f00f00,
+ 0x03f01700,
  0x0009d002,
- 0x87f104bd,
- 0x84b60818,
- 0x008ad006,
-/* 0x0124: wait_doneo_e */
- 0x040087f1,
- 0xcf0684b6,
- 0x8aff0088,
- 0xf30bf488,
+ 0x00f804bd,
+/* 0x0110: wait_doneo */
  0x99f094bd,
  0x0007f100,
- 0x0203f017,
+ 0x0203f00f,
  0xbd0009d0,
-/* 0x0147: mmctx_size */
- 0xbd00f804,
-/* 0x0149: nv_mmctx_size_loop */
- 0x00e89894,
- 0xb61a85b6,
- 0x84b60180,
- 0x0098bb02,
- 0xb804e0b6,
- 0x1bf404ef,
- 0x029fb9eb,
-/* 0x0166: mmctx_xfer */
- 0x94bd00f8,
- 0xf10199f0,
- 0xf00f0007,
- 0x09d00203,
- 0xf104bd00,
- 0xb6071087,
- 0x94bd0684,
- 0xf405bbfd,
- 0x8bd0090b,
- 0x0099f000,
-/* 0x018c: mmctx_base_disabled */
- 0xf405eefd,
- 0x8ed00c0b,
- 0xc08fd080,
-/* 0x019b: mmctx_multi_disabled */
- 0xb70199f0,
- 0xc8010080,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x012d: wait_doneo_e */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x0bf4888a,
+ 0xf094bdf3,
+ 0x07f10099,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0150: mmctx_size */
+/* 0x0152: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0xf404efb8,
+ 0x9fb9eb1b,
+/* 0x016f: mmctx_xfer */
+ 0xbd00f802,
+ 0x0199f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0xbbfd94bd,
+ 0x120bf405,
+ 0xc40007f1,
+ 0xd00103f0,
+ 0x04bd000b,
+/* 0x0197: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0x0007f11e,
+ 0x0103f0c6,
+ 0xbd000ed0,
+ 0x0007f104,
+ 0x0103f0c7,
+ 0xbd000fd0,
+ 0x0199f004,
+/* 0x01b8: mmctx_multi_disabled */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x01aec80c,
+ 0xfd11e4b6,
+ 0x07f105be,
+ 0x03f0c500,
+ 0x000bd001,
+/* 0x01d6: mmctx_exec_loop */
+/* 0x01d6: mmctx_wait_free */
+ 0xe7f104bd,
+ 0xe3f0c500,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f30b,
+ 0x05e9fd00,
+ 0xc80007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+ 0xb804c0b6,
+ 0x1bf404cd,
+ 0x02abc8d8,
+/* 0x0207: mmctx_fini_wait */
+ 0xf11f1bf4,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x1fb4f000,
+ 0xf410b4b0,
+ 0xa7f0f01b,
+ 0xd021f402,
+/* 0x0223: mmctx_stop */
+ 0xc82b0ef4,
  0xb4b600ab,
  0x0cb9f010,
- 0xb601aec8,
- 0xbefd11e4,
- 0x008bd005,
-/* 0x01b4: mmctx_exec_loop */
-/* 0x01b4: mmctx_wait_free */
- 0xf0008ecf,
- 0x0bf41fe4,
- 0x00ce98fa,
- 0xd005e9fd,
- 0xc0b6c08e,
- 0x04cdb804,
- 0xc8e81bf4,
- 0x1bf402ab,
-/* 0x01d5: mmctx_fini_wait */
- 0x008bcf18,
- 0xb01fb4f0,
- 0x1bf410b4,
- 0x02a7f0f7,
- 0xf4c921f4,
-/* 0x01ea: mmctx_stop */
- 0xabc81b0e,
- 0x10b4b600,
- 0xf00cb9f0,
- 0x8bd012b9,
-/* 0x01f9: mmctx_stop_wait */
- 0x008bcf00,
- 0xf412bbc8,
-/* 0x0202: mmctx_done */
- 0x94bdfa1b,
- 0xf10199f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0215: strand_wait */
- 0xf0a0f900,
- 0x21f402a7,
- 0xf8a0fcc9,
-/* 0x0221: strand_pre */
- 0xfc87f100,
- 0x0283f04a,
- 0xd00c97f0,
- 0x21f50089,
- 0x00f80215,
-/* 0x0234: strand_post */
- 0x4afc87f1,
- 0xf00283f0,
- 0x89d00d97,
- 0x1521f500,
-/* 0x0247: strand_set */
- 0xf100f802,
- 0xf04ffca7,
- 0xaba202a3,
- 0xc7f00500,
- 0x00acd00f,
- 0xd00bc7f0,
- 0x21f500bc,
- 0xaed00215,
- 0x0ac7f000,
- 0xf500bcd0,
- 0xf8021521,
-/* 0x0271: strand_ctx_init */
- 0xf094bd00,
- 0x07f10399,
- 0x03f00f00,
+ 0xf112b9f0,
+ 0xf0c50007,
+ 0x0bd00103,
+/* 0x023b: mmctx_stop_wait */
+ 0xf104bd00,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x12bbc800,
+/* 0x024b: mmctx_done */
+ 0xbdf31bf4,
+ 0x0199f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x025e: strand_wait */
+ 0xa0f900f8,
+ 0xf402a7f0,
+ 0xa0fcd021,
+/* 0x026a: strand_pre */
+ 0x97f000f8,
+ 0xfc07f10c,
+ 0x0203f04a,
+ 0xbd0009d0,
+ 0x5e21f504,
+/* 0x027f: strand_post */
+ 0xf000f802,
+ 0x07f10d97,
+ 0x03f04afc,
  0x0009d002,
  0x21f504bd,
- 0xe7f00221,
- 0x4721f503,
- 0xfca7f102,
- 0x02a3f046,
- 0x0400aba0,
- 0xf040a0d0,
- 0xbcd001c7,
- 0x1521f500,
- 0x010c9202,
- 0xf000acd0,
- 0xbcd002c7,
- 0x1521f500,
- 0x3421f502,
- 0x8087f102,
- 0x0684b608,
- 0xb70089cf,
- 0x95220080,
-/* 0x02ca: ctx_init_strand_loop */
+ 0x00f8025e,
+/* 0x0294: strand_set */
+ 0xf10fc7f0,
+ 0xf04ffc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f10bc7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x07f104bd,
+ 0x03f04ffc,
+ 0x000ed002,
+ 0xc7f004bd,
+ 0xfc07f10a,
+ 0x0203f04a,
+ 0xbd000cd0,
+ 0x5e21f504,
+/* 0x02d3: strand_ctx_init */
+ 0xbd00f802,
+ 0x0399f094,
+ 0x0f0007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0x026a21f5,
+ 0xf503e7f0,
+ 0xbd029421,
+ 0xfc07f1c4,
+ 0x0203f047,
+ 0xbd000cd0,
+ 0x01c7f004,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd000c,
+ 0x025e21f5,
+ 0xf1010c92,
+ 0xf046fc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f102c7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x21f504bd,
+ 0x21f5025e,
+ 0x87f1027f,
+ 0x83f04200,
+ 0x0097f102,
+ 0x0293f020,
+ 0x950099cf,
+/* 0x034a: ctx_init_strand_loop */
  0x8ed008fe,
  0x408ed000,
  0xb6808acf,
@@ -428,7 +458,7 @@ uint32_t nve0_grhub_code[] = {
  0x170007f1,
  0xd00203f0,
  0x04bd0009,
-/* 0x02fe: error */
+/* 0x037e: error */
  0x07f100f8,
  0x03f00500,
  0x000fd002,
@@ -436,82 +466,117 @@ uint32_t nve0_grhub_code[] = {
  0x0007f101,
  0x0303f007,
  0xbd000fd0,
-/* 0x031b: init */
+/* 0x039b: init */
  0xbd00f804,
- 0x0004fe04,
- 0xf10007fe,
- 0xf0120017,
- 0x12d00227,
- 0xb117f100,
- 0x0010fe05,
- 0x040017f1,
- 0xf1c010d0,
- 0xb6040437,
- 0x27f10634,
- 0x32d02003,
- 0x0427f100,
- 0x0132d020,
+ 0x0007fe04,
+ 0x420017f1,
+ 0xcf0013f0,
+ 0x11e70011,
+ 0x14b60109,
+ 0x0014fe08,
+ 0xf10227f0,
+ 0xf0120007,
+ 0x02d00003,
+ 0xf104bd00,
+ 0xfe06c817,
+ 0x24bd0010,
+ 0x070007f1,
+ 0xd00003f0,
+ 0x04bd0002,
+ 0x200327f1,
+ 0x010007f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0x200427f1,
+ 0x010407f1,
+ 0xd00103f0,
+ 0x04bd0002,
  0x200b27f1,
- 0xf10232d0,
- 0xd0200c27,
- 0x27f10732,
- 0x24b60c24,
- 0x0003b906,
- 0xf10023d0,
+ 0x010807f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0x200c27f1,
+ 0x011c07f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0xf1010392,
+ 0xf0090007,
+ 0x03d00303,
+ 0xf104bd00,
  0xf0870427,
- 0x12d00023,
- 0x0012b700,
- 0x0427f001,
- 0xf40012d0,
- 0xe7f11031,
- 0xe3f09604,
- 0x6821f440,
- 0x8090f1c7,
- 0xf4f00301,
- 0x020f801f,
- 0xbb0117f0,
- 0x12b6041f,
- 0x0c27f101,
- 0x0624b604,
- 0xd00021d0,
- 0x17f14021,
- 0x0e980100,
- 0x010f9800,
- 0x014721f5,
- 0x070037f1,
- 0x950634b6,
- 0x34d00814,
- 0x4034d000,
- 0x130030b7,
- 0xb6001fbb,
- 0x3fd002f5,
- 0x0815b600,
- 0xb60110b6,
- 0x1fb90814,
- 0x7121f502,
- 0x001fbb02,
- 0xf1020398,
- 0xf0200047,
-/* 0x03f6: init_gpc */
- 0x4ea05043,
- 0x1fb90804,
- 0x8d21f402,
- 0x010c4ea0,
- 0x21f4f4bd,
- 0x044ea08d,
- 0x8d21f401,
- 0x01004ea0,
- 0xf402f7f0,
- 0x4ea08d21,
-/* 0x041e: init_gpc_wait */
- 0x21f40800,
- 0x1fffc868,
- 0xa0fa0bf4,
- 0xf408044e,
- 0x1fbb6821,
- 0x0040b700,
- 0x0132b680,
- 0xf1be1bf4,
+ 0x07f10023,
+ 0x03f00400,
+ 0x0002d000,
+ 0x27f004bd,
+ 0x0007f104,
+ 0x0003f003,
+ 0xbd0002d0,
+ 0x1031f404,
+ 0x9604e7f1,
+ 0xf440e3f0,
+ 0xfeb96821,
+ 0x90f1c702,
+ 0xf0030180,
+ 0x0f801ff4,
+ 0x0117f002,
+ 0xb6041fbb,
+ 0x07f10112,
+ 0x03f00300,
+ 0x0001d001,
+ 0x07f104bd,
+ 0x03f00400,
+ 0x0001d001,
+ 0x17f104bd,
+ 0xf7f00100,
+ 0x7f21f502,
+ 0x9121f507,
+ 0x10f7f007,
+ 0x07de21f5,
+ 0x98000e98,
+ 0x21f5010f,
+ 0x14950150,
+ 0x0007f108,
+ 0x0103f0c0,
+ 0xbd0004d0,
+ 0x0007f104,
+ 0x0103f0c1,
+ 0xbd0004d0,
+ 0x0030b704,
+ 0x001fbb13,
+ 0xf102f5b6,
+ 0xf0d30007,
+ 0x0fd00103,
+ 0xb604bd00,
+ 0x10b60815,
+ 0x0814b601,
+ 0xf5021fb9,
+ 0xbb02d321,
+ 0x0398001f,
+ 0x0047f102,
+ 0x5043f020,
+/* 0x04f4: init_gpc */
+ 0x08044ea0,
+ 0xf4021fb9,
+ 0x4ea09d21,
+ 0xf4bd010c,
+ 0xa09d21f4,
+ 0xf401044e,
+ 0x4ea09d21,
+ 0xf7f00100,
+ 0x9d21f402,
+ 0x08004ea0,
+/* 0x051c: init_gpc_wait */
+ 0xc86821f4,
+ 0x0bf41fff,
+ 0x044ea0fa,
+ 0x6821f408,
+ 0xb7001fbb,
+ 0xb6800040,
+ 0x1bf40132,
+ 0x00f7f0be,
+ 0x07de21f5,
+ 0xf500f7f0,
+ 0xf1077f21,
  0xf0010007,
  0x01d00203,
  0xbd04bd00,
@@ -519,382 +584,379 @@ uint32_t nve0_grhub_code[] = {
  0x080007f1,
  0xd00203f0,
  0x04bd0001,
-/* 0x0458: main */
+/* 0x0564: main */
  0xf40031f4,
  0xd7f00028,
  0x3921f410,
  0xb1f401f4,
  0xf54001e4,
- 0xbd00de1b,
+ 0xbd00e91b,
  0x0499f094,
  0x0f0007f1,
  0xd00203f0,
  0x04bd0009,
- 0x0b0017f1,
- 0xcf0614b6,
- 0x11cf4012,
- 0x1f13c800,
- 0x00870bf5,
- 0xf41f23c8,
- 0x20f9620b,
- 0xbd0212b9,
- 0x0799f094,
- 0x0f0007f1,
- 0xd00203f0,
- 0x04bd0009,
- 0xf40132f4,
- 0x21f50231,
- 0x94bd0801,
+ 0xc00017f1,
+ 0xcf0213f0,
+ 0x27f10011,
+ 0x23f0c100,
+ 0x0022cf02,
+ 0xf51f13c8,
+ 0xc800890b,
+ 0x0bf41f23,
+ 0xb920f962,
+ 0x94bd0212,
  0xf10799f0,
- 0xf0170007,
+ 0xf00f0007,
  0x09d00203,
- 0xfc04bd00,
- 0xf094bd20,
- 0x07f10699,
- 0x03f00f00,
- 0x0009d002,
- 0x31f404bd,
- 0x0121f501,
- 0xf094bd08,
- 0x07f10699,
+ 0xf404bd00,
+ 0x31f40132,
+ 0xaa21f502,
+ 0xf094bd09,
+ 0x07f10799,
  0x03f01700,
  0x0009d002,
- 0x0ef404bd,
-/* 0x04f9: chsw_prev_no_next */
- 0xb920f931,
- 0x32f40212,
- 0x0232f401,
- 0x080121f5,
- 0x17f120fc,
- 0x14b60b00,
- 0x0012d006,
-/* 0x0517: chsw_no_prev */
- 0xc8130ef4,
- 0x0bf41f23,
- 0x0131f40d,
- 0xf50232f4,
-/* 0x0527: chsw_done */
- 0xf1080121,
- 0xb60b0c17,
- 0x27f00614,
- 0x0012d001,
+ 0x20fc04bd,
  0x99f094bd,
- 0x0007f104,
+ 0x0007f106,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0131f404,
+ 0x09aa21f5,
+ 0x99f094bd,
+ 0x0007f106,
  0x0203f017,
  0xbd0009d0,
- 0x130ef504,
-/* 0x0549: main_not_ctx_switch */
- 0x01e4b0ff,
- 0xb90d1bf4,
- 0x21f502f2,
- 0x0ef40795,
-/* 0x0559: main_not_ctx_chan */
- 0x02e4b046,
- 0xbd321bf4,
- 0x0799f094,
- 0x0f0007f1,
+ 0x330ef404,
+/* 0x060c: chsw_prev_no_next */
+ 0x12b920f9,
+ 0x0132f402,
+ 0xf50232f4,
+ 0xfc09aa21,
+ 0x0007f120,
+ 0x0203f0c0,
+ 0xbd0002d0,
+ 0x130ef404,
+/* 0x062c: chsw_no_prev */
+ 0xf41f23c8,
+ 0x31f40d0b,
+ 0x0232f401,
+ 0x09aa21f5,
+/* 0x063c: chsw_done */
+ 0xf10127f0,
+ 0xf0c30007,
+ 0x02d00203,
+ 0xbd04bd00,
+ 0x0499f094,
+ 0x170007f1,
  0xd00203f0,
  0x04bd0009,
- 0xf40132f4,
- 0x21f50232,
- 0x94bd0801,
+ 0xff080ef5,
+/* 0x0660: main_not_ctx_switch */
+ 0xf401e4b0,
+ 0xf2b90d1b,
+ 0x4221f502,
+ 0x460ef409,
+/* 0x0670: main_not_ctx_chan */
+ 0xf402e4b0,
+ 0x94bd321b,
  0xf10799f0,
- 0xf0170007,
+ 0xf00f0007,
  0x09d00203,
  0xf404bd00,
-/* 0x058e: main_not_ctx_save */
- 0xef94110e,
- 0x01f5f010,
- 0x02fe21f5,
- 0xfec00ef5,
-/* 0x059c: main_done */
- 0x29f024bd,
- 0x0007f11f,
- 0x0203f008,
- 0xbd0002d0,
- 0xab0ef504,
-/* 0x05b1: ih */
- 0xfe80f9fe,
- 0x80f90188,
- 0xa0f990f9,
- 0xd0f9b0f9,
- 0xf0f9e0f9,
- 0x0acf04bd,
- 0x04abc480,
- 0xf11d0bf4,
- 0xf01900b7,
- 0xbecf10d7,
- 0x00bfcf40,
+ 0x32f40132,
+ 0xaa21f502,
+ 0xf094bd09,
+ 0x07f10799,
+ 0x03f01700,
+ 0x0009d002,
+ 0x0ef404bd,
+/* 0x06a5: main_not_ctx_save */
+ 0x10ef9411,
+ 0xf501f5f0,
+ 0xf5037e21,
+/* 0x06b3: main_done */
+ 0xbdfeb50e,
+ 0x1f29f024,
+ 0x080007f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xfea00ef5,
+/* 0x06c8: ih */
+ 0x88fe80f9,
+ 0xf980f901,
+ 0xf9a0f990,
+ 0xf9d0f9b0,
+ 0xbdf0f9e0,
+ 0x00a7f104,
+ 0x00a3f002,
+ 0xc400aacf,
+ 0x0bf404ab,
+ 0x10d7f030,
+ 0x1a00e7f1,
+ 0xcf00e3f0,
+ 0xf7f100ee,
+ 0xf3f01900,
+ 0x00ffcf00,
  0xb70421f4,
  0xf00400b0,
- 0xbed001e7,
-/* 0x05e9: ih_no_fifo */
- 0x00abe400,
- 0x0d0bf401,
- 0xf110d7f0,
- 0xf44001e7,
-/* 0x05fa: ih_no_ctxsw */
- 0xb7f10421,
- 0xb0bd0104,
- 0xf4b4abff,
- 0xa7f10d0b,
- 0xa4b60c1c,
- 0x00abd006,
-/* 0x0610: ih_no_other */
- 0xfc400ad0,
+ 0x07f101e7,
+ 0x03f01d00,
+ 0x000ed000,
+/* 0x071a: ih_no_fifo */
+ 0xabe404bd,
+ 0x0bf40100,
+ 0x10d7f00d,
+ 0x4001e7f1,
+/* 0x072b: ih_no_ctxsw */
+ 0xe40421f4,
+ 0xf40400ab,
+ 0xb7f1140b,
+ 0xbfb90100,
+ 0x44e7f102,
+ 0x40e3f001,
+/* 0x0743: ih_no_fwmthd */
+ 0xf19d21f4,
+ 0xbd0104b7,
+ 0xb4abffb0,
+ 0xf10f0bf4,
+ 0xf0070007,
+ 0x0bd00303,
+/* 0x075b: ih_no_other */
+ 0xf104bd00,
+ 0xf0010007,
+ 0x0ad00003,
+ 0xfc04bd00,
  0xfce0fcf0,
  0xfcb0fcd0,
  0xfc90fca0,
  0x0088fe80,
  0x32f480fc,
-/* 0x062b: ctx_4170s */
- 0xf101f800,
- 0xf04170e7,
- 0xf5f040e3,
- 0x8d21f410,
-/* 0x063a: ctx_4170w */
+/* 0x077f: ctx_4170s */
+ 0xf001f800,
+ 0xffb910f5,
+ 0x70e7f102,
+ 0x40e3f041,
+ 0xf89d21f4,
+/* 0x0791: ctx_4170w */
+ 0x70e7f100,
+ 0x40e3f041,
+ 0xb96821f4,
+ 0xf4f002ff,
+ 0xf01bf410,
+/* 0x07a6: ctx_redswitch */
  0xe7f100f8,
- 0xe3f04170,
- 0x6821f440,
- 0xf410f4f0,
+ 0xe5f00200,
+ 0x20e5f040,
+ 0xf110e5f0,
+ 0xf0850007,
+ 0x0ed00103,
+ 0xf004bd00,
+/* 0x07c2: ctx_redswitch_delay */
+ 0xf2b608f7,
+ 0xfd1bf401,
+ 0x0400e5f1,
+ 0x0100e5f1,
+ 0x850007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+/* 0x07de: ctx_86c */
+ 0x07f100f8,
+ 0x03f01b00,
+ 0x000fd002,
+ 0xffb904bd,
+ 0x14e7f102,
+ 0x40e3f08a,
+ 0xb99d21f4,
+ 0xe7f102ff,
+ 0xe3f0a86c,
+ 0x9d21f441,
+/* 0x0806: ctx_mem */
+ 0x07f100f8,
+ 0x03f08400,
+ 0x000fd002,
+/* 0x0812: ctx_mem_wait */
+ 0xf7f104bd,
+ 0xf3f08400,
+ 0x00ffcf02,
+ 0xf405fffd,
  0x00f8f31b,
-/* 0x064c: ctx_redswitch */
- 0x0614e7f1,
- 0xf106e4b6,
- 0xd00270f7,
- 0xf7f000ef,
-/* 0x065d: ctx_redswitch_delay */
- 0x01f2b608,
- 0xf1fd1bf4,
- 0xd00770f7,
- 0x00f800ef,
-/* 0x066c: ctx_86c */
- 0x086ce7f1,
- 0xd006e4b6,
- 0xe7f100ef,
- 0xe3f08a14,
- 0x8d21f440,
- 0xa86ce7f1,
- 0xf441e3f0,
- 0x00f88d21,
-/* 0x068c: ctx_load */
+/* 0x0824: ctx_load */
  0x99f094bd,
  0x0007f105,
  0x0203f00f,
  0xbd0009d0,
  0x0ca7f004,
- 0xf1c921f4,
- 0xb60a2417,
- 0x10d00614,
- 0x0037f100,
- 0x0634b60b,
- 0xf14032d0,
- 0xb60a0c17,
- 0x47f00614,
- 0x0012d007,
-/* 0x06c7: ctx_chan_wait_0 */
- 0xcf4014d0,
- 0x44f04014,
- 0xfa1bf41f,
- 0xfe0032d0,
- 0x2af0000b,
- 0x0424b61f,
- 0xbd0220b6,
+ 0xbdd021f4,
+ 0x0007f1f4,
+ 0x0203f089,
+ 0xbd000fd0,
+ 0x0007f104,
+ 0x0203f0c1,
+ 0xbd0002d0,
+ 0x0007f104,
+ 0x0203f083,
+ 0xbd0002d0,
+ 0x07f7f004,
+ 0x080621f5,
+ 0xc00007f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xf0000bfe,
+ 0x24b61f2a,
+ 0x0220b604,
+ 0x99f094bd,
+ 0x0007f108,
+ 0x0203f00f,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f081,
+ 0xbd0002d0,
+ 0x0027f104,
+ 0x0023f100,
+ 0x0225f080,
+ 0x880007f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xf11017f0,
+ 0xf0020027,
+ 0x12fa0223,
+ 0xbd03f805,
  0x0899f094,
- 0x0f0007f1,
+ 0x170007f1,
  0xd00203f0,
  0x04bd0009,
- 0x0a0417f1,
- 0xd00614b6,
- 0x17f10012,
- 0x14b60a20,
- 0x0227f006,
- 0x800023f1,
- 0xf00012d0,
- 0x27f11017,
- 0x23f00200,
- 0x0512fa02,
- 0x94bd03f8,
- 0xf10899f0,
- 0xf0170007,
+ 0xb6810198,
+ 0x02981814,
+ 0x0825b680,
+ 0x800512fd,
+ 0x94bd1601,
+ 0xf10999f0,
+ 0xf00f0007,
  0x09d00203,
- 0x9804bd00,
- 0x14b68101,
- 0x80029818,
- 0xfd0825b6,
- 0x01800512,
- 0xf094bd16,
- 0x07f10999,
- 0x03f00f00,
- 0x0009d002,
- 0x27f104bd,
- 0x24b60a04,
- 0x0021d006,
- 0xf10127f0,
- 0xb60a2017,
- 0x12d00614,
- 0x0017f100,
- 0x0613f001,
- 0xf80501fa,
- 0xf094bd03,
- 0x07f10999,
- 0x03f01700,
- 0x0009d002,
- 0x94bd04bd,
- 0xf10599f0,
+ 0xf104bd00,
+ 0xf0810007,
+ 0x01d00203,
+ 0xf004bd00,
+ 0x07f10127,
+ 0x03f08800,
+ 0x0002d002,
+ 0x17f104bd,
+ 0x13f00100,
+ 0x0501fa06,
+ 0x94bd03f8,
+ 0xf10999f0,
  0xf0170007,
  0x09d00203,
- 0xf804bd00,
-/* 0x0795: ctx_chan */
- 0x8c21f500,
- 0x0ca7f006,
- 0xf1c921f4,
- 0xb60a1017,
- 0x27f00614,
- 0x0012d005,
-/* 0x07ac: ctx_chan_wait */
- 0xfd0012cf,
- 0x1bf40522,
-/* 0x07b7: ctx_mmio_exec */
- 0x9800f8fa,
- 0x27f14103,
- 0x24b60a04,
- 0x0023d006,
-/* 0x07c6: ctx_mmio_loop */
+ 0xbd04bd00,
+ 0x0599f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x0942: ctx_chan */
+ 0x21f500f8,
+ 0xa7f00824,
+ 0xd021f40c,
+ 0xf505f7f0,
+ 0xf8080621,
+/* 0x0955: ctx_mmio_exec */
+ 0x41039800,
+ 0x810007f1,
+ 0xd00203f0,
+ 0x04bd0003,
+/* 0x0966: ctx_mmio_loop */
  0x34c434bd,
  0x0f1bf4ff,
  0x020057f1,
  0xfa0653f0,
  0x03f80535,
-/* 0x07d8: ctx_mmio_pull */
+/* 0x0978: ctx_mmio_pull */
  0x98804e98,
  0x21f4814f,
- 0x0830b68d,
+ 0x0830b69d,
  0xf40112b6,
-/* 0x07ea: ctx_mmio_done */
+/* 0x098a: ctx_mmio_done */
  0x0398df1b,
- 0x0023d016,
- 0xf1400080,
- 0xf0010017,
- 0x01fa0613,
- 0xf803f806,
-/* 0x0801: ctx_xfer */
- 0x00f7f100,
- 0x06f4b60c,
- 0xd004e7f0,
-/* 0x080e: ctx_xfer_idle */
- 0xfecf80fe,
- 0x00e4f100,
- 0xf91bf420,
- 0xf40611f4,
-/* 0x081e: ctx_xfer_pre */
- 0xf7f00d02,
- 0x6c21f510,
- 0x1c11f406,
-/* 0x0828: ctx_xfer_pre_load */
- 0xf502f7f0,
- 0xf5062b21,
- 0xf5063a21,
- 0xbd064c21,
- 0x2b21f5f4,
- 0x8c21f506,
-/* 0x0841: ctx_xfer_exec */
- 0x16019806,
- 0x041427f1,
- 0xd00624b6,
- 0xe7f10020,
- 0xe3f0a500,
- 0x021fb941,
- 0xb68d21f4,
- 0xfcf004e0,
- 0x022cf001,
- 0xfd0124b6,
- 0x21f405f2,
- 0xfc17f18d,
- 0x0213f04a,
- 0xd00c27f0,
- 0x21f50012,
- 0x27f10215,
- 0x23f047fc,
- 0x0020d002,
+ 0x0007f116,
+ 0x0203f081,
+ 0xbd0003d0,
+ 0x40008004,
+ 0x010017f1,
+ 0xfa0613f0,
+ 0x03f80601,
+/* 0x09aa: ctx_xfer */
+ 0xe7f000f8,
+ 0x0007f104,
+ 0x0303f002,
+ 0xbd000ed0,
+/* 0x09b9: ctx_xfer_idle */
+ 0x00e7f104,
+ 0x03e3f000,
+ 0xf100eecf,
+ 0xf42000e4,
+ 0x11f4f21b,
+ 0x0d02f406,
+/* 0x09d0: ctx_xfer_pre */
+ 0xf510f7f0,
+ 0xf407de21,
+/* 0x09da: ctx_xfer_pre_load */
+ 0xf7f01c11,
+ 0x7f21f502,
+ 0x9121f507,
+ 0xa621f507,
+ 0xf5f4bd07,
+ 0xf5077f21,
+/* 0x09f3: ctx_xfer_exec */
+ 0x98082421,
+ 0x24bd1601,
+ 0x050007f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0xf1021fb9,
+ 0xf0a500e7,
+ 0x21f441e3,
+ 0x01fcf09d,
+ 0xb6022cf0,
+ 0xf2fd0124,
+ 0x02ffb905,
+ 0xa504e7f1,
+ 0xf441e3f0,
+ 0x21f59d21,
+ 0x24bd026a,
+ 0x47fc07f1,
+ 0xd00203f0,
+ 0x04bd0002,
  0xb6012cf0,
- 0x12d00320,
- 0x01acf000,
- 0xf006a5f0,
- 0x0c9800b7,
- 0x010d9800,
- 0xf500e7f0,
- 0xf0016621,
- 0x21f508a7,
- 0x21f50109,
- 0x01f40215,
- 0x0ca7f022,
- 0xf1c921f4,
- 0xb60a1017,
- 0x27f00614,
- 0x0012d005,
-/* 0x08c8: ctx_xfer_post_save_wait */
- 0xfd0012cf,
- 0x1bf40522,
- 0x2e02f4fa,
-/* 0x08d4: ctx_xfer_post */
- 0xf502f7f0,
- 0xbd062b21,
- 0x6c21f5f4,
- 0x3421f506,
- 0x3a21f502,
- 0xf5f4bd06,
- 0xf4062b21,
- 0x01981011,
- 0x0511fd40,
- 0xf5070bf4,
-/* 0x08ff: ctx_xfer_no_post_mmio */
-/* 0x08ff: ctx_xfer_done */
- 0xf807b721,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
+ 0x07f10320,
+ 0x03f04afc,
+ 0x0002d002,
+ 0xacf004bd,
+ 0x06a5f001,
+ 0x9800b7f0,
+ 0x0d98000c,
+ 0x00e7f001,
+ 0x016f21f5,
+ 0xf508a7f0,
+ 0xf5011021,
+ 0xf4025e21,
+ 0xa7f01301,
+ 0xd021f40c,
+ 0xf505f7f0,
+ 0xf4080621,
+/* 0x0a82: ctx_xfer_post */
+ 0xf7f02e02,
+ 0x7f21f502,
+ 0xf5f4bd07,
+ 0xf507de21,
+ 0xf5027f21,
+ 0xbd079121,
+ 0x7f21f5f4,
+ 0x1011f407,
+ 0xfd400198,
+ 0x0bf40511,
+ 0x5521f507,
+/* 0x0aad: ctx_xfer_no_post_mmio */
+/* 0x0aad: ctx_xfer_done */
+ 0x0000f809,
  0x00000000,
  0x00000000,
  0x00000000,
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvf0.fuc.h b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvf0.fuc.h
index 438506d..229c0ae 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvf0.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/hubnvf0.fuc.h
@@ -206,14 +206,14 @@ uint32_t nvf0_grhub_data[] = {
 };
 
 uint32_t nvf0_grhub_code[] = {
- 0x031b0ef5,
+ 0x039b0ef5,
 /* 0x0004: queue_put */
  0x9800d898,
  0x86f001d9,
  0x0489b808,
  0xf00c1bf4,
  0x21f502f7,
- 0x00f802fe,
+ 0x00f8037e,
 /* 0x001c: queue_put_next */
  0xb60798c4,
  0x8dbb0384,
@@ -237,184 +237,214 @@ uint32_t nvf0_grhub_code[] = {
 /* 0x0066: queue_get_done */
  0x00f80132,
 /* 0x0068: nv_rd32 */
- 0x0728b7f1,
- 0xb906b4b6,
- 0xc9f002ec,
- 0x00bcd01f,
-/* 0x0078: nv_rd32_wait */
- 0xc800bccf,
- 0x1bf41fcc,
- 0x06a7f0fa,
- 0x010921f5,
- 0xf840bfcf,
-/* 0x008d: nv_wr32 */
- 0x28b7f100,
- 0x06b4b607,
- 0xb980bfd0,
- 0xc9f002ec,
- 0x1ec9f01f,
-/* 0x00a3: nv_wr32_wait */
- 0xcf00bcd0,
- 0xccc800bc,
- 0xfa1bf41f,
-/* 0x00ae: watchdog_reset */
- 0x87f100f8,
- 0x84b60430,
- 0x1ff9f006,
- 0xf8008fd0,
-/* 0x00bd: watchdog_clear */
- 0x3087f100,
- 0x0684b604,
- 0xf80080d0,
-/* 0x00c9: wait_donez */
- 0xf094bd00,
- 0x07f10099,
- 0x03f03700,
- 0x0009d002,
- 0x07f104bd,
- 0x03f00600,
- 0x000ad002,
-/* 0x00e6: wait_donez_ne */
- 0x87f104bd,
- 0x83f00000,
- 0x0088cf01,
- 0xf4888aff,
- 0x94bdf31b,
- 0xf10099f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0109: wait_doneo */
- 0xf094bd00,
+ 0xf002ecb9,
+ 0x07f11fc9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x007a: nv_rd32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0xa7f0f31b,
+ 0x1021f506,
+ 0x00f7f101,
+ 0x01f3f0cb,
+ 0xf800ffcf,
+/* 0x009d: nv_wr32 */
+ 0x0007f100,
+ 0x0103f0cc,
+ 0xbd000fd0,
+ 0x02ecb904,
+ 0xf01fc9f0,
+ 0x07f11ec9,
+ 0x03f0ca00,
+ 0x000cd001,
+/* 0x00be: nv_wr32_wait */
+ 0xc7f104bd,
+ 0xc3f0ca00,
+ 0x00cccf01,
+ 0xf41fccc8,
+ 0x00f8f31b,
+/* 0x00d0: wait_donez */
+ 0x99f094bd,
+ 0x0007f100,
+ 0x0203f037,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x00ed: wait_donez_ne */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x1bf4888a,
+ 0xf094bdf3,
  0x07f10099,
- 0x03f03700,
+ 0x03f01700,
  0x0009d002,
- 0x87f104bd,
- 0x84b60818,
- 0x008ad006,
-/* 0x0124: wait_doneo_e */
- 0x040087f1,
- 0xcf0684b6,
- 0x8aff0088,
- 0xf30bf488,
+ 0x00f804bd,
+/* 0x0110: wait_doneo */
  0x99f094bd,
  0x0007f100,
- 0x0203f017,
+ 0x0203f037,
  0xbd0009d0,
-/* 0x0147: mmctx_size */
- 0xbd00f804,
-/* 0x0149: nv_mmctx_size_loop */
- 0x00e89894,
- 0xb61a85b6,
- 0x84b60180,
- 0x0098bb02,
- 0xb804e0b6,
- 0x1bf404ef,
- 0x029fb9eb,
-/* 0x0166: mmctx_xfer */
- 0x94bd00f8,
- 0xf10199f0,
- 0xf0370007,
- 0x09d00203,
- 0xf104bd00,
- 0xb6071087,
- 0x94bd0684,
- 0xf405bbfd,
- 0x8bd0090b,
- 0x0099f000,
-/* 0x018c: mmctx_base_disabled */
- 0xf405eefd,
- 0x8ed00c0b,
- 0xc08fd080,
-/* 0x019b: mmctx_multi_disabled */
- 0xb70199f0,
- 0xc8010080,
+ 0x0007f104,
+ 0x0203f006,
+ 0xbd000ad0,
+/* 0x012d: wait_doneo_e */
+ 0x0087f104,
+ 0x0183f000,
+ 0xff0088cf,
+ 0x0bf4888a,
+ 0xf094bdf3,
+ 0x07f10099,
+ 0x03f01700,
+ 0x0009d002,
+ 0x00f804bd,
+/* 0x0150: mmctx_size */
+/* 0x0152: nv_mmctx_size_loop */
+ 0xe89894bd,
+ 0x1a85b600,
+ 0xb60180b6,
+ 0x98bb0284,
+ 0x04e0b600,
+ 0xf404efb8,
+ 0x9fb9eb1b,
+/* 0x016f: mmctx_xfer */
+ 0xbd00f802,
+ 0x0199f094,
+ 0x370007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0xbbfd94bd,
+ 0x120bf405,
+ 0xc40007f1,
+ 0xd00103f0,
+ 0x04bd000b,
+/* 0x0197: mmctx_base_disabled */
+ 0xfd0099f0,
+ 0x0bf405ee,
+ 0x0007f11e,
+ 0x0103f0c6,
+ 0xbd000ed0,
+ 0x0007f104,
+ 0x0103f0c7,
+ 0xbd000fd0,
+ 0x0199f004,
+/* 0x01b8: mmctx_multi_disabled */
+ 0xb600abc8,
+ 0xb9f010b4,
+ 0x01aec80c,
+ 0xfd11e4b6,
+ 0x07f105be,
+ 0x03f0c500,
+ 0x000bd001,
+/* 0x01d6: mmctx_exec_loop */
+/* 0x01d6: mmctx_wait_free */
+ 0xe7f104bd,
+ 0xe3f0c500,
+ 0x00eecf01,
+ 0xf41fe4f0,
+ 0xce98f30b,
+ 0x05e9fd00,
+ 0xc80007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+ 0xb804c0b6,
+ 0x1bf404cd,
+ 0x02abc8d8,
+/* 0x0207: mmctx_fini_wait */
+ 0xf11f1bf4,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x1fb4f000,
+ 0xf410b4b0,
+ 0xa7f0f01b,
+ 0xd021f402,
+/* 0x0223: mmctx_stop */
+ 0xc82b0ef4,
  0xb4b600ab,
  0x0cb9f010,
- 0xb601aec8,
- 0xbefd11e4,
- 0x008bd005,
-/* 0x01b4: mmctx_exec_loop */
-/* 0x01b4: mmctx_wait_free */
- 0xf0008ecf,
- 0x0bf41fe4,
- 0x00ce98fa,
- 0xd005e9fd,
- 0xc0b6c08e,
- 0x04cdb804,
- 0xc8e81bf4,
- 0x1bf402ab,
-/* 0x01d5: mmctx_fini_wait */
- 0x008bcf18,
- 0xb01fb4f0,
- 0x1bf410b4,
- 0x02a7f0f7,
- 0xf4c921f4,
-/* 0x01ea: mmctx_stop */
- 0xabc81b0e,
- 0x10b4b600,
- 0xf00cb9f0,
- 0x8bd012b9,
-/* 0x01f9: mmctx_stop_wait */
- 0x008bcf00,
- 0xf412bbc8,
-/* 0x0202: mmctx_done */
- 0x94bdfa1b,
- 0xf10199f0,
- 0xf0170007,
- 0x09d00203,
- 0xf804bd00,
-/* 0x0215: strand_wait */
- 0xf0a0f900,
- 0x21f402a7,
- 0xf8a0fcc9,
-/* 0x0221: strand_pre */
- 0xfc87f100,
- 0x0283f04a,
- 0xd00c97f0,
- 0x21f50089,
- 0x00f80215,
-/* 0x0234: strand_post */
- 0x4afc87f1,
- 0xf00283f0,
- 0x89d00d97,
- 0x1521f500,
-/* 0x0247: strand_set */
- 0xf100f802,
- 0xf04ffca7,
- 0xaba202a3,
- 0xc7f00500,
- 0x00acd00f,
- 0xd00bc7f0,
- 0x21f500bc,
- 0xaed00215,
- 0x0ac7f000,
- 0xf500bcd0,
- 0xf8021521,
-/* 0x0271: strand_ctx_init */
- 0xf094bd00,
- 0x07f10399,
- 0x03f03700,
+ 0xf112b9f0,
+ 0xf0c50007,
+ 0x0bd00103,
+/* 0x023b: mmctx_stop_wait */
+ 0xf104bd00,
+ 0xf0c500b7,
+ 0xbbcf01b3,
+ 0x12bbc800,
+/* 0x024b: mmctx_done */
+ 0xbdf31bf4,
+ 0x0199f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x025e: strand_wait */
+ 0xa0f900f8,
+ 0xf402a7f0,
+ 0xa0fcd021,
+/* 0x026a: strand_pre */
+ 0x97f000f8,
+ 0xfc07f10c,
+ 0x0203f04a,
+ 0xbd0009d0,
+ 0x5e21f504,
+/* 0x027f: strand_post */
+ 0xf000f802,
+ 0x07f10d97,
+ 0x03f04afc,
  0x0009d002,
  0x21f504bd,
- 0xe7f00221,
- 0x4721f503,
- 0xfca7f102,
- 0x02a3f046,
- 0x0400aba0,
- 0xf040a0d0,
- 0xbcd001c7,
- 0x1521f500,
- 0x010c9202,
- 0xf000acd0,
- 0xbcd002c7,
- 0x1521f500,
- 0x3421f502,
- 0x8087f102,
- 0x0684b608,
- 0xb70089cf,
- 0x95220080,
-/* 0x02ca: ctx_init_strand_loop */
+ 0x00f8025e,
+/* 0x0294: strand_set */
+ 0xf10fc7f0,
+ 0xf04ffc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f10bc7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x07f104bd,
+ 0x03f04ffc,
+ 0x000ed002,
+ 0xc7f004bd,
+ 0xfc07f10a,
+ 0x0203f04a,
+ 0xbd000cd0,
+ 0x5e21f504,
+/* 0x02d3: strand_ctx_init */
+ 0xbd00f802,
+ 0x0399f094,
+ 0x370007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+ 0x026a21f5,
+ 0xf503e7f0,
+ 0xbd029421,
+ 0xfc07f1c4,
+ 0x0203f047,
+ 0xbd000cd0,
+ 0x01c7f004,
+ 0x4afc07f1,
+ 0xd00203f0,
+ 0x04bd000c,
+ 0x025e21f5,
+ 0xf1010c92,
+ 0xf046fc07,
+ 0x0cd00203,
+ 0xf004bd00,
+ 0x07f102c7,
+ 0x03f04afc,
+ 0x000cd002,
+ 0x21f504bd,
+ 0x21f5025e,
+ 0x87f1027f,
+ 0x83f04200,
+ 0x0097f102,
+ 0x0293f020,
+ 0x950099cf,
+/* 0x034a: ctx_init_strand_loop */
  0x8ed008fe,
  0x408ed000,
  0xb6808acf,
@@ -428,7 +458,7 @@ uint32_t nvf0_grhub_code[] = {
  0x170007f1,
  0xd00203f0,
  0x04bd0009,
-/* 0x02fe: error */
+/* 0x037e: error */
  0x07f100f8,
  0x03f00500,
  0x000fd002,
@@ -436,82 +466,117 @@ uint32_t nvf0_grhub_code[] = {
  0x0007f101,
  0x0303f007,
  0xbd000fd0,
-/* 0x031b: init */
+/* 0x039b: init */
  0xbd00f804,
- 0x0004fe04,
- 0xf10007fe,
- 0xf0120017,
- 0x12d00227,
- 0xb117f100,
- 0x0010fe05,
- 0x040017f1,
- 0xf1c010d0,
- 0xb6040437,
- 0x27f10634,
- 0x32d02003,
- 0x0427f100,
- 0x0132d020,
+ 0x0007fe04,
+ 0x420017f1,
+ 0xcf0013f0,
+ 0x11e70011,
+ 0x14b60109,
+ 0x0014fe08,
+ 0xf10227f0,
+ 0xf0120007,
+ 0x02d00003,
+ 0xf104bd00,
+ 0xfe06c817,
+ 0x24bd0010,
+ 0x070007f1,
+ 0xd00003f0,
+ 0x04bd0002,
+ 0x200327f1,
+ 0x010007f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0x200427f1,
+ 0x010407f1,
+ 0xd00103f0,
+ 0x04bd0002,
  0x200b27f1,
- 0xf10232d0,
- 0xd0200c27,
- 0x27f10732,
- 0x24b60c24,
- 0x0003b906,
- 0xf10023d0,
+ 0x010807f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0x200c27f1,
+ 0x011c07f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0xf1010392,
+ 0xf0090007,
+ 0x03d00303,
+ 0xf104bd00,
  0xf0870427,
- 0x12d00023,
- 0x0012b700,
- 0x0427f001,
- 0xf40012d0,
- 0xe7f11031,
- 0xe3f09604,
- 0x6821f440,
- 0x8090f1c7,
- 0xf4f00301,
- 0x020f801f,
- 0xbb0117f0,
- 0x12b6041f,
- 0x0c27f101,
- 0x0624b604,
- 0xd00021d0,
- 0x17f14021,
- 0x0e980100,
- 0x010f9800,
- 0x014721f5,
- 0x070037f1,
- 0x950634b6,
- 0x34d00814,
- 0x4034d000,
- 0x130030b7,
- 0xb6001fbb,
- 0x3fd002f5,
- 0x0815b600,
- 0xb60110b6,
- 0x1fb90814,
- 0x7121f502,
- 0x001fbb02,
- 0xf1020398,
- 0xf0200047,
-/* 0x03f6: init_gpc */
- 0x4ea05043,
- 0x1fb90804,
- 0x8d21f402,
- 0x010c4ea0,
- 0x21f4f4bd,
- 0x044ea08d,
- 0x8d21f401,
- 0x01004ea0,
- 0xf402f7f0,
- 0x4ea08d21,
-/* 0x041e: init_gpc_wait */
- 0x21f40800,
- 0x1fffc868,
- 0xa0fa0bf4,
- 0xf408044e,
- 0x1fbb6821,
- 0x0040b700,
- 0x0132b680,
- 0xf1be1bf4,
+ 0x07f10023,
+ 0x03f00400,
+ 0x0002d000,
+ 0x27f004bd,
+ 0x0007f104,
+ 0x0003f003,
+ 0xbd0002d0,
+ 0x1031f404,
+ 0x9604e7f1,
+ 0xf440e3f0,
+ 0xfeb96821,
+ 0x90f1c702,
+ 0xf0030180,
+ 0x0f801ff4,
+ 0x0117f002,
+ 0xb6041fbb,
+ 0x07f10112,
+ 0x03f00300,
+ 0x0001d001,
+ 0x07f104bd,
+ 0x03f00400,
+ 0x0001d001,
+ 0x17f104bd,
+ 0xf7f00100,
+ 0x7f21f502,
+ 0x9121f507,
+ 0x10f7f007,
+ 0x07de21f5,
+ 0x98000e98,
+ 0x21f5010f,
+ 0x14950150,
+ 0x0007f108,
+ 0x0103f0c0,
+ 0xbd0004d0,
+ 0x0007f104,
+ 0x0103f0c1,
+ 0xbd0004d0,
+ 0x0030b704,
+ 0x001fbb13,
+ 0xf102f5b6,
+ 0xf0d30007,
+ 0x0fd00103,
+ 0xb604bd00,
+ 0x10b60815,
+ 0x0814b601,
+ 0xf5021fb9,
+ 0xbb02d321,
+ 0x0398001f,
+ 0x0047f102,
+ 0x5043f020,
+/* 0x04f4: init_gpc */
+ 0x08044ea0,
+ 0xf4021fb9,
+ 0x4ea09d21,
+ 0xf4bd010c,
+ 0xa09d21f4,
+ 0xf401044e,
+ 0x4ea09d21,
+ 0xf7f00100,
+ 0x9d21f402,
+ 0x08004ea0,
+/* 0x051c: init_gpc_wait */
+ 0xc86821f4,
+ 0x0bf41fff,
+ 0x044ea0fa,
+ 0x6821f408,
+ 0xb7001fbb,
+ 0xb6800040,
+ 0x1bf40132,
+ 0x00f7f0be,
+ 0x07de21f5,
+ 0xf500f7f0,
+ 0xf1077f21,
  0xf0010007,
  0x01d00203,
  0xbd04bd00,
@@ -519,382 +584,379 @@ uint32_t nvf0_grhub_code[] = {
  0x300007f1,
  0xd00203f0,
  0x04bd0001,
-/* 0x0458: main */
+/* 0x0564: main */
  0xf40031f4,
  0xd7f00028,
  0x3921f410,
  0xb1f401f4,
  0xf54001e4,
- 0xbd00de1b,
+ 0xbd00e91b,
  0x0499f094,
  0x370007f1,
  0xd00203f0,
  0x04bd0009,
- 0x0b0017f1,
- 0xcf0614b6,
- 0x11cf4012,
- 0x1f13c800,
- 0x00870bf5,
- 0xf41f23c8,
- 0x20f9620b,
- 0xbd0212b9,
- 0x0799f094,
- 0x370007f1,
- 0xd00203f0,
- 0x04bd0009,
- 0xf40132f4,
- 0x21f50231,
- 0x94bd0801,
+ 0xc00017f1,
+ 0xcf0213f0,
+ 0x27f10011,
+ 0x23f0c100,
+ 0x0022cf02,
+ 0xf51f13c8,
+ 0xc800890b,
+ 0x0bf41f23,
+ 0xb920f962,
+ 0x94bd0212,
  0xf10799f0,
- 0xf0170007,
+ 0xf0370007,
  0x09d00203,
- 0xfc04bd00,
- 0xf094bd20,
- 0x07f10699,
- 0x03f03700,
- 0x0009d002,
- 0x31f404bd,
- 0x0121f501,
- 0xf094bd08,
- 0x07f10699,
+ 0xf404bd00,
+ 0x31f40132,
+ 0xaa21f502,
+ 0xf094bd09,
+ 0x07f10799,
  0x03f01700,
  0x0009d002,
- 0x0ef404bd,
-/* 0x04f9: chsw_prev_no_next */
- 0xb920f931,
- 0x32f40212,
- 0x0232f401,
- 0x080121f5,
- 0x17f120fc,
- 0x14b60b00,
- 0x0012d006,
-/* 0x0517: chsw_no_prev */
- 0xc8130ef4,
- 0x0bf41f23,
- 0x0131f40d,
- 0xf50232f4,
-/* 0x0527: chsw_done */
- 0xf1080121,
- 0xb60b0c17,
- 0x27f00614,
- 0x0012d001,
+ 0x20fc04bd,
  0x99f094bd,
- 0x0007f104,
+ 0x0007f106,
+ 0x0203f037,
+ 0xbd0009d0,
+ 0x0131f404,
+ 0x09aa21f5,
+ 0x99f094bd,
+ 0x0007f106,
  0x0203f017,
  0xbd0009d0,
- 0x130ef504,
-/* 0x0549: main_not_ctx_switch */
- 0x01e4b0ff,
- 0xb90d1bf4,
- 0x21f502f2,
- 0x0ef40795,
-/* 0x0559: main_not_ctx_chan */
- 0x02e4b046,
- 0xbd321bf4,
- 0x0799f094,
- 0x370007f1,
+ 0x330ef404,
+/* 0x060c: chsw_prev_no_next */
+ 0x12b920f9,
+ 0x0132f402,
+ 0xf50232f4,
+ 0xfc09aa21,
+ 0x0007f120,
+ 0x0203f0c0,
+ 0xbd0002d0,
+ 0x130ef404,
+/* 0x062c: chsw_no_prev */
+ 0xf41f23c8,
+ 0x31f40d0b,
+ 0x0232f401,
+ 0x09aa21f5,
+/* 0x063c: chsw_done */
+ 0xf10127f0,
+ 0xf0c30007,
+ 0x02d00203,
+ 0xbd04bd00,
+ 0x0499f094,
+ 0x170007f1,
  0xd00203f0,
  0x04bd0009,
- 0xf40132f4,
- 0x21f50232,
- 0x94bd0801,
+ 0xff080ef5,
+/* 0x0660: main_not_ctx_switch */
+ 0xf401e4b0,
+ 0xf2b90d1b,
+ 0x4221f502,
+ 0x460ef409,
+/* 0x0670: main_not_ctx_chan */
+ 0xf402e4b0,
+ 0x94bd321b,
  0xf10799f0,
- 0xf0170007,
+ 0xf0370007,
  0x09d00203,
  0xf404bd00,
-/* 0x058e: main_not_ctx_save */
- 0xef94110e,
- 0x01f5f010,
- 0x02fe21f5,
- 0xfec00ef5,
-/* 0x059c: main_done */
- 0x29f024bd,
- 0x0007f11f,
- 0x0203f030,
- 0xbd0002d0,
- 0xab0ef504,
-/* 0x05b1: ih */
- 0xfe80f9fe,
- 0x80f90188,
- 0xa0f990f9,
- 0xd0f9b0f9,
- 0xf0f9e0f9,
- 0x0acf04bd,
- 0x04abc480,
- 0xf11d0bf4,
- 0xf01900b7,
- 0xbecf10d7,
- 0x00bfcf40,
+ 0x32f40132,
+ 0xaa21f502,
+ 0xf094bd09,
+ 0x07f10799,
+ 0x03f01700,
+ 0x0009d002,
+ 0x0ef404bd,
+/* 0x06a5: main_not_ctx_save */
+ 0x10ef9411,
+ 0xf501f5f0,
+ 0xf5037e21,
+/* 0x06b3: main_done */
+ 0xbdfeb50e,
+ 0x1f29f024,
+ 0x300007f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xfea00ef5,
+/* 0x06c8: ih */
+ 0x88fe80f9,
+ 0xf980f901,
+ 0xf9a0f990,
+ 0xf9d0f9b0,
+ 0xbdf0f9e0,
+ 0x00a7f104,
+ 0x00a3f002,
+ 0xc400aacf,
+ 0x0bf404ab,
+ 0x10d7f030,
+ 0x1a00e7f1,
+ 0xcf00e3f0,
+ 0xf7f100ee,
+ 0xf3f01900,
+ 0x00ffcf00,
  0xb70421f4,
  0xf00400b0,
- 0xbed001e7,
-/* 0x05e9: ih_no_fifo */
- 0x00abe400,
- 0x0d0bf401,
- 0xf110d7f0,
- 0xf44001e7,
-/* 0x05fa: ih_no_ctxsw */
- 0xb7f10421,
- 0xb0bd0104,
- 0xf4b4abff,
- 0xa7f10d0b,
- 0xa4b60c1c,
- 0x00abd006,
-/* 0x0610: ih_no_other */
- 0xfc400ad0,
+ 0x07f101e7,
+ 0x03f01d00,
+ 0x000ed000,
+/* 0x071a: ih_no_fifo */
+ 0xabe404bd,
+ 0x0bf40100,
+ 0x10d7f00d,
+ 0x4001e7f1,
+/* 0x072b: ih_no_ctxsw */
+ 0xe40421f4,
+ 0xf40400ab,
+ 0xb7f1140b,
+ 0xbfb90100,
+ 0x44e7f102,
+ 0x40e3f001,
+/* 0x0743: ih_no_fwmthd */
+ 0xf19d21f4,
+ 0xbd0104b7,
+ 0xb4abffb0,
+ 0xf10f0bf4,
+ 0xf0070007,
+ 0x0bd00303,
+/* 0x075b: ih_no_other */
+ 0xf104bd00,
+ 0xf0010007,
+ 0x0ad00003,
+ 0xfc04bd00,
  0xfce0fcf0,
  0xfcb0fcd0,
  0xfc90fca0,
  0x0088fe80,
  0x32f480fc,
-/* 0x062b: ctx_4170s */
- 0xf101f800,
- 0xf04170e7,
- 0xf5f040e3,
- 0x8d21f410,
-/* 0x063a: ctx_4170w */
+/* 0x077f: ctx_4170s */
+ 0xf001f800,
+ 0xffb910f5,
+ 0x70e7f102,
+ 0x40e3f041,
+ 0xf89d21f4,
+/* 0x0791: ctx_4170w */
+ 0x70e7f100,
+ 0x40e3f041,
+ 0xb96821f4,
+ 0xf4f002ff,
+ 0xf01bf410,
+/* 0x07a6: ctx_redswitch */
  0xe7f100f8,
- 0xe3f04170,
- 0x6821f440,
- 0xf410f4f0,
+ 0xe5f00200,
+ 0x20e5f040,
+ 0xf110e5f0,
+ 0xf0850007,
+ 0x0ed00103,
+ 0xf004bd00,
+/* 0x07c2: ctx_redswitch_delay */
+ 0xf2b608f7,
+ 0xfd1bf401,
+ 0x0400e5f1,
+ 0x0100e5f1,
+ 0x850007f1,
+ 0xd00103f0,
+ 0x04bd000e,
+/* 0x07de: ctx_86c */
+ 0x07f100f8,
+ 0x03f02300,
+ 0x000fd002,
+ 0xffb904bd,
+ 0x14e7f102,
+ 0x40e3f08a,
+ 0xb99d21f4,
+ 0xe7f102ff,
+ 0xe3f0a88c,
+ 0x9d21f441,
+/* 0x0806: ctx_mem */
+ 0x07f100f8,
+ 0x03f08400,
+ 0x000fd002,
+/* 0x0812: ctx_mem_wait */
+ 0xf7f104bd,
+ 0xf3f08400,
+ 0x00ffcf02,
+ 0xf405fffd,
  0x00f8f31b,
-/* 0x064c: ctx_redswitch */
- 0x0614e7f1,
- 0xf106e4b6,
- 0xd00270f7,
- 0xf7f000ef,
-/* 0x065d: ctx_redswitch_delay */
- 0x01f2b608,
- 0xf1fd1bf4,
- 0xd00770f7,
- 0x00f800ef,
-/* 0x066c: ctx_86c */
- 0x086ce7f1,
- 0xd006e4b6,
- 0xe7f100ef,
- 0xe3f08a14,
- 0x8d21f440,
- 0xa86ce7f1,
- 0xf441e3f0,
- 0x00f88d21,
-/* 0x068c: ctx_load */
+/* 0x0824: ctx_load */
  0x99f094bd,
  0x0007f105,
  0x0203f037,
  0xbd0009d0,
  0x0ca7f004,
- 0xf1c921f4,
- 0xb60a2417,
- 0x10d00614,
- 0x0037f100,
- 0x0634b60b,
- 0xf14032d0,
- 0xb60a0c17,
- 0x47f00614,
- 0x0012d007,
-/* 0x06c7: ctx_chan_wait_0 */
- 0xcf4014d0,
- 0x44f04014,
- 0xfa1bf41f,
- 0xfe0032d0,
- 0x2af0000b,
- 0x0424b61f,
- 0xbd0220b6,
+ 0xbdd021f4,
+ 0x0007f1f4,
+ 0x0203f089,
+ 0xbd000fd0,
+ 0x0007f104,
+ 0x0203f0c1,
+ 0xbd0002d0,
+ 0x0007f104,
+ 0x0203f083,
+ 0xbd0002d0,
+ 0x07f7f004,
+ 0x080621f5,
+ 0xc00007f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xf0000bfe,
+ 0x24b61f2a,
+ 0x0220b604,
+ 0x99f094bd,
+ 0x0007f108,
+ 0x0203f037,
+ 0xbd0009d0,
+ 0x0007f104,
+ 0x0203f081,
+ 0xbd0002d0,
+ 0x0027f104,
+ 0x0023f100,
+ 0x0225f080,
+ 0x880007f1,
+ 0xd00203f0,
+ 0x04bd0002,
+ 0xf11017f0,
+ 0xf0020027,
+ 0x12fa0223,
+ 0xbd03f805,
  0x0899f094,
- 0x370007f1,
+ 0x170007f1,
  0xd00203f0,
  0x04bd0009,
- 0x0a0417f1,
- 0xd00614b6,
- 0x17f10012,
- 0x14b60a20,
- 0x0227f006,
- 0x800023f1,
- 0xf00012d0,
- 0x27f11017,
- 0x23f00200,
- 0x0512fa02,
- 0x94bd03f8,
- 0xf10899f0,
- 0xf0170007,
+ 0xb6810198,
+ 0x02981814,
+ 0x0825b680,
+ 0x800512fd,
+ 0x94bd1601,
+ 0xf10999f0,
+ 0xf0370007,
  0x09d00203,
- 0x9804bd00,
- 0x14b68101,
- 0x80029818,
- 0xfd0825b6,
- 0x01800512,
- 0xf094bd16,
- 0x07f10999,
- 0x03f03700,
- 0x0009d002,
- 0x27f104bd,
- 0x24b60a04,
- 0x0021d006,
- 0xf10127f0,
- 0xb60a2017,
- 0x12d00614,
- 0x0017f100,
- 0x0613f001,
- 0xf80501fa,
- 0xf094bd03,
- 0x07f10999,
- 0x03f01700,
- 0x0009d002,
- 0x94bd04bd,
- 0xf10599f0,
+ 0xf104bd00,
+ 0xf0810007,
+ 0x01d00203,
+ 0xf004bd00,
+ 0x07f10127,
+ 0x03f08800,
+ 0x0002d002,
+ 0x17f104bd,
+ 0x13f00100,
+ 0x0501fa06,
+ 0x94bd03f8,
+ 0xf10999f0,
  0xf0170007,
  0x09d00203,
- 0xf804bd00,
-/* 0x0795: ctx_chan */
- 0x8c21f500,
- 0x0ca7f006,
- 0xf1c921f4,
- 0xb60a1017,
- 0x27f00614,
- 0x0012d005,
-/* 0x07ac: ctx_chan_wait */
- 0xfd0012cf,
- 0x1bf40522,
-/* 0x07b7: ctx_mmio_exec */
- 0x9800f8fa,
- 0x27f14103,
- 0x24b60a04,
- 0x0023d006,
-/* 0x07c6: ctx_mmio_loop */
+ 0xbd04bd00,
+ 0x0599f094,
+ 0x170007f1,
+ 0xd00203f0,
+ 0x04bd0009,
+/* 0x0942: ctx_chan */
+ 0x21f500f8,
+ 0xa7f00824,
+ 0xd021f40c,
+ 0xf505f7f0,
+ 0xf8080621,
+/* 0x0955: ctx_mmio_exec */
+ 0x41039800,
+ 0x810007f1,
+ 0xd00203f0,
+ 0x04bd0003,
+/* 0x0966: ctx_mmio_loop */
  0x34c434bd,
  0x0f1bf4ff,
  0x020057f1,
  0xfa0653f0,
  0x03f80535,
-/* 0x07d8: ctx_mmio_pull */
+/* 0x0978: ctx_mmio_pull */
  0x98804e98,
  0x21f4814f,
- 0x0830b68d,
+ 0x0830b69d,
  0xf40112b6,
-/* 0x07ea: ctx_mmio_done */
+/* 0x098a: ctx_mmio_done */
  0x0398df1b,
- 0x0023d016,
- 0xf1400080,
- 0xf0010017,
- 0x01fa0613,
- 0xf803f806,
-/* 0x0801: ctx_xfer */
- 0x00f7f100,
- 0x06f4b60c,
- 0xd004e7f0,
-/* 0x080e: ctx_xfer_idle */
- 0xfecf80fe,
- 0x00e4f100,
- 0xf91bf420,
- 0xf40611f4,
-/* 0x081e: ctx_xfer_pre */
- 0xf7f00d02,
- 0x6c21f510,
- 0x1c11f406,
-/* 0x0828: ctx_xfer_pre_load */
- 0xf502f7f0,
- 0xf5062b21,
- 0xf5063a21,
- 0xbd064c21,
- 0x2b21f5f4,
- 0x8c21f506,
-/* 0x0841: ctx_xfer_exec */
- 0x16019806,
- 0x041427f1,
- 0xd00624b6,
- 0xe7f10020,
- 0xe3f0a500,
- 0x021fb941,
- 0xb68d21f4,
- 0xfcf004e0,
- 0x022cf001,
- 0xfd0124b6,
- 0x21f405f2,
- 0xfc17f18d,
- 0x0213f04a,
- 0xd00c27f0,
- 0x21f50012,
- 0x27f10215,
- 0x23f047fc,
- 0x0020d002,
+ 0x0007f116,
+ 0x0203f081,
+ 0xbd0003d0,
+ 0x40008004,
+ 0x010017f1,
+ 0xfa0613f0,
+ 0x03f80601,
+/* 0x09aa: ctx_xfer */
+ 0xe7f000f8,
+ 0x0007f104,
+ 0x0303f002,
+ 0xbd000ed0,
+/* 0x09b9: ctx_xfer_idle */
+ 0x00e7f104,
+ 0x03e3f000,
+ 0xf100eecf,
+ 0xf42000e4,
+ 0x11f4f21b,
+ 0x0d02f406,
+/* 0x09d0: ctx_xfer_pre */
+ 0xf510f7f0,
+ 0xf407de21,
+/* 0x09da: ctx_xfer_pre_load */
+ 0xf7f01c11,
+ 0x7f21f502,
+ 0x9121f507,
+ 0xa621f507,
+ 0xf5f4bd07,
+ 0xf5077f21,
+/* 0x09f3: ctx_xfer_exec */
+ 0x98082421,
+ 0x24bd1601,
+ 0x050007f1,
+ 0xd00103f0,
+ 0x04bd0002,
+ 0xf1021fb9,
+ 0xf0a500e7,
+ 0x21f441e3,
+ 0x01fcf09d,
+ 0xb6022cf0,
+ 0xf2fd0124,
+ 0x02ffb905,
+ 0xa504e7f1,
+ 0xf441e3f0,
+ 0x21f59d21,
+ 0x24bd026a,
+ 0x47fc07f1,
+ 0xd00203f0,
+ 0x04bd0002,
  0xb6012cf0,
- 0x12d00320,
- 0x01acf000,
- 0xf006a5f0,
- 0x0c9800b7,
- 0x010d9800,
- 0xf500e7f0,
- 0xf0016621,
- 0x21f508a7,
- 0x21f50109,
- 0x01f40215,
- 0x0ca7f022,
- 0xf1c921f4,
- 0xb60a1017,
- 0x27f00614,
- 0x0012d005,
-/* 0x08c8: ctx_xfer_post_save_wait */
- 0xfd0012cf,
- 0x1bf40522,
- 0x2e02f4fa,
-/* 0x08d4: ctx_xfer_post */
- 0xf502f7f0,
- 0xbd062b21,
- 0x6c21f5f4,
- 0x3421f506,
- 0x3a21f502,
- 0xf5f4bd06,
- 0xf4062b21,
- 0x01981011,
- 0x0511fd40,
- 0xf5070bf4,
-/* 0x08ff: ctx_xfer_no_post_mmio */
-/* 0x08ff: ctx_xfer_done */
- 0xf807b721,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
+ 0x07f10320,
+ 0x03f04afc,
+ 0x0002d002,
+ 0xacf004bd,
+ 0x06a5f001,
+ 0x9800b7f0,
+ 0x0d98000c,
+ 0x00e7f001,
+ 0x016f21f5,
+ 0xf508a7f0,
+ 0xf5011021,
+ 0xf4025e21,
+ 0xa7f01301,
+ 0xd021f40c,
+ 0xf505f7f0,
+ 0xf4080621,
+/* 0x0a82: ctx_xfer_post */
+ 0xf7f02e02,
+ 0x7f21f502,
+ 0xf5f4bd07,
+ 0xf507de21,
+ 0xf5027f21,
+ 0xbd079121,
+ 0x7f21f5f4,
+ 0x1011f407,
+ 0xfd400198,
+ 0x0bf40511,
+ 0x5521f507,
+/* 0x0aad: ctx_xfer_no_post_mmio */
+/* 0x0aad: ctx_xfer_done */
+ 0x0000f809,
  0x00000000,
  0x00000000,
  0x00000000,
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/macros.fuc b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/macros.fuc
index 33a5a82..6ffe283 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/fuc/macros.fuc
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/fuc/macros.fuc
@@ -28,28 +28,135 @@
 #define GF117 0xd7
 #define GK100 0xe0
 #define GK110 0xf0
+#define GK208 0x108
 
+#define NV_PGRAPH_FECS_INTR_ACK                                        0x409004
+#define NV_PGRAPH_FECS_INTR                                            0x409008
+#define NV_PGRAPH_FECS_INTR_FWMTHD                                   0x00000400
+#define NV_PGRAPH_FECS_INTR_CHSW                                     0x00000100
+#define NV_PGRAPH_FECS_INTR_FIFO                                     0x00000004
+#define NV_PGRAPH_FECS_INTR_MODE                                       0x40900c
+#define NV_PGRAPH_FECS_INTR_MODE_FIFO                                0x00000004
+#define NV_PGRAPH_FECS_INTR_MODE_FIFO_LEVEL                          0x00000004
+#define NV_PGRAPH_FECS_INTR_MODE_FIFO_EDGE                           0x00000000
+#define NV_PGRAPH_FECS_INTR_EN_SET                                     0x409010
+#define NV_PGRAPH_FECS_INTR_EN_SET_FIFO                              0x00000004
+#define NV_PGRAPH_FECS_INTR_ROUTE                                      0x40901c
+#define NV_PGRAPH_FECS_ACCESS                                          0x409048
+#define NV_PGRAPH_FECS_ACCESS_FIFO                                   0x00000002
+#define NV_PGRAPH_FECS_FIFO_DATA                                       0x409064
+#define NV_PGRAPH_FECS_FIFO_CMD                                        0x409068
+#define NV_PGRAPH_FECS_FIFO_ACK                                        0x409074
+#define NV_PGRAPH_FECS_CAPS                                            0x409108
 #define NV_PGRAPH_FECS_SIGNAL                                          0x409400
+#define NV_PGRAPH_FECS_IROUTE                                          0x409404
+#define NV_PGRAPH_FECS_BAR_MASK0                                       0x40940c
+#define NV_PGRAPH_FECS_BAR_MASK1                                       0x409410
+#define NV_PGRAPH_FECS_BAR                                             0x409414
+#define NV_PGRAPH_FECS_BAR_SET                                         0x409418
+#define NV_PGRAPH_FECS_RED_SWITCH                                      0x409614
+#define NV_PGRAPH_FECS_RED_SWITCH_ENABLE_ROP                         0x00000400
+#define NV_PGRAPH_FECS_RED_SWITCH_ENABLE_GPC                         0x00000200
+#define NV_PGRAPH_FECS_RED_SWITCH_ENABLE_MAIN                        0x00000100
+#define NV_PGRAPH_FECS_RED_SWITCH_POWER_ROP                          0x00000040
+#define NV_PGRAPH_FECS_RED_SWITCH_POWER_GPC                          0x00000020
+#define NV_PGRAPH_FECS_RED_SWITCH_POWER_MAIN                         0x00000010
+#define NV_PGRAPH_FECS_RED_SWITCH_PAUSE_GPC                          0x00000002
+#define NV_PGRAPH_FECS_RED_SWITCH_PAUSE_MAIN                         0x00000001
+#define NV_PGRAPH_FECS_MMCTX_SAVE_SWBASE                               0x409700
+#define NV_PGRAPH_FECS_MMCTX_LOAD_SWBASE                               0x409704
+#define NV_PGRAPH_FECS_MMCTX_LOAD_COUNT                                0x40974c
+#define NV_PGRAPH_FECS_MMCTX_SAVE_SWBASE                               0x409700
+#define NV_PGRAPH_FECS_MMCTX_LOAD_SWBASE                               0x409704
+#define NV_PGRAPH_FECS_MMCTX_BASE                                      0x409710
+#define NV_PGRAPH_FECS_MMCTX_CTRL                                      0x409714
+#define NV_PGRAPH_FECS_MMCTX_MULTI_STRIDE                              0x409718
+#define NV_PGRAPH_FECS_MMCTX_MULTI_MASK                                0x40971c
+#define NV_PGRAPH_FECS_MMCTX_QUEUE                                     0x409720
+#define NV_PGRAPH_FECS_MMIO_CTRL                                       0x409728
+#define NV_PGRAPH_FECS_MMIO_RDVAL                                      0x40972c
+#define NV_PGRAPH_FECS_MMIO_WRVAL                                      0x409730
+#define NV_PGRAPH_FECS_MMCTX_LOAD_COUNT                                0x40974c
 #if CHIPSET < GK110
 #define NV_PGRAPH_FECS_CC_SCRATCH_VAL(n)                    ((n) * 4 + 0x409800)
 #define NV_PGRAPH_FECS_CC_SCRATCH_SET(n)                    ((n) * 4 + 0x409820)
 #define NV_PGRAPH_FECS_CC_SCRATCH_CLR(n)                    ((n) * 4 + 0x409840)
+#define NV_PGRAPH_FECS_UNK86C                                          0x40986c
 #else
 #define NV_PGRAPH_FECS_CC_SCRATCH_VAL(n)                    ((n) * 4 + 0x409800)
 #define NV_PGRAPH_FECS_CC_SCRATCH_CLR(n)                    ((n) * 4 + 0x409840)
+#define NV_PGRAPH_FECS_UNK86C                                          0x40988c
 #define NV_PGRAPH_FECS_CC_SCRATCH_SET(n)                    ((n) * 4 + 0x4098c0)
 #endif
+#define NV_PGRAPH_FECS_STRANDS_CNT                                     0x409880
+#define NV_PGRAPH_FECS_STRAND_SAVE_SWBASE                              0x409908
+#define NV_PGRAPH_FECS_STRAND_LOAD_SWBASE                              0x40990c
+#define NV_PGRAPH_FECS_STRAND_WORDS                                    0x409910
+#define NV_PGRAPH_FECS_STRAND_DATA                                     0x409918
+#define NV_PGRAPH_FECS_STRAND_SELECT                                   0x40991c
+#define NV_PGRAPH_FECS_STRAND_CMD                                      0x409928
+#define NV_PGRAPH_FECS_STRAND_CMD_SEEK                               0x00000001
+#define NV_PGRAPH_FECS_STRAND_CMD_GET_INFO                           0x00000002
+#define NV_PGRAPH_FECS_STRAND_CMD_SAVE                               0x00000003
+#define NV_PGRAPH_FECS_STRAND_CMD_LOAD                               0x00000004
+#define NV_PGRAPH_FECS_STRAND_CMD_ACTIVATE_FILTER                    0x0000000a
+#define NV_PGRAPH_FECS_STRAND_CMD_DEACTIVATE_FILTER                  0x0000000b
+#define NV_PGRAPH_FECS_STRAND_CMD_ENABLE                             0x0000000c
+#define NV_PGRAPH_FECS_STRAND_CMD_DISABLE                            0x0000000d
+#define NV_PGRAPH_FECS_STRAND_FILTER                                   0x40993c
+#define NV_PGRAPH_FECS_MEM_BASE                                        0x409a04
+#define NV_PGRAPH_FECS_MEM_CHAN                                        0x409a0c
+#define NV_PGRAPH_FECS_MEM_CMD                                         0x409a10
+#define NV_PGRAPH_FECS_MEM_CMD_LOAD_CHAN                             0x00000007
+#define NV_PGRAPH_FECS_MEM_TARGET                                      0x409a20
+#define NV_PGRAPH_FECS_MEM_TARGET_UNK31                              0x80000000
+#define NV_PGRAPH_FECS_MEM_TARGET_AS                                 0x0000001f
+#define NV_PGRAPH_FECS_MEM_TARGET_AS_VM                              0x00000001
+#define NV_PGRAPH_FECS_MEM_TARGET_AS_VRAM                            0x00000002
+#define NV_PGRAPH_FECS_CHAN_ADDR                                       0x409b00
+#define NV_PGRAPH_FECS_CHAN_NEXT                                       0x409b04
+#define NV_PGRAPH_FECS_CHSW                                            0x409b0c
+#define NV_PGRAPH_FECS_CHSW_ACK                                      0x00000001
 #define NV_PGRAPH_FECS_INTR_UP_SET                                     0x409c1c
+#define NV_PGRAPH_FECS_INTR_UP_EN                                      0x409c24
 
+#define NV_PGRAPH_GPCX_GPCCS_INTR_ACK                                  0x41a004
+#define NV_PGRAPH_GPCX_GPCCS_INTR                                      0x41a008
+#define NV_PGRAPH_GPCX_GPCCS_INTR_FIFO                               0x00000004
+#define NV_PGRAPH_GPCX_GPCCS_INTR_EN_SET                               0x41a010
+#define NV_PGRAPH_GPCX_GPCCS_INTR_EN_SET_FIFO                        0x00000004
+#define NV_PGRAPH_GPCX_GPCCS_INTR_ROUTE                                0x41a01c
+#define NV_PGRAPH_GPCX_GPCCS_ACCESS                                    0x41a048
+#define NV_PGRAPH_GPCX_GPCCS_ACCESS_FIFO                             0x00000002
+#define NV_PGRAPH_GPCX_GPCCS_FIFO_DATA                                 0x41a064
+#define NV_PGRAPH_GPCX_GPCCS_FIFO_CMD                                  0x41a068
+#define NV_PGRAPH_GPCX_GPCCS_FIFO_ACK                                  0x41a074
+#define NV_PGRAPH_GPCX_GPCCS_UNITS                                     0x41a608
+#define NV_PGRAPH_GPCX_GPCCS_RED_SWITCH                                0x41a614
+#define NV_PGRAPH_GPCX_GPCCS_RED_SWITCH_UNK11                        0x00000800
+#define NV_PGRAPH_GPCX_GPCCS_RED_SWITCH_ENABLE                       0x00000200
+#define NV_PGRAPH_GPCX_GPCCS_RED_SWITCH_POWER                        0x00000020
+#define NV_PGRAPH_GPCX_GPCCS_RED_SWITCH_PAUSE                        0x00000002
+#define NV_PGRAPH_GPCX_GPCCS_MYINDEX                                   0x41a618
+#define NV_PGRAPH_GPCX_GPCCS_MMCTX_SAVE_SWBASE                         0x41a700
+#define NV_PGRAPH_GPCX_GPCCS_MMCTX_LOAD_SWBASE                         0x41a704
+#define NV_PGRAPH_GPCX_GPCCS_MMCTX_LOAD_COUNT                          0x41a74c
 #if CHIPSET < GK110
 #define NV_PGRAPH_GPCX_GPCCS_CC_SCRATCH_VAL(n)              ((n) * 4 + 0x41a800)
 #define NV_PGRAPH_GPCX_GPCCS_CC_SCRATCH_SET(n)              ((n) * 4 + 0x41a820)
 #define NV_PGRAPH_GPCX_GPCCS_CC_SCRATCH_CLR(n)              ((n) * 4 + 0x41a840)
+#define NV_PGRAPH_GPCX_GPCCS_UNK86C                                    0x41a86c
 #else
 #define NV_PGRAPH_GPCX_GPCCS_CC_SCRATCH_VAL(n)              ((n) * 4 + 0x41a800)
 #define NV_PGRAPH_GPCX_GPCCS_CC_SCRATCH_CLR(n)              ((n) * 4 + 0x41a840)
+#define NV_PGRAPH_GPCX_GPCCS_UNK86C                                    0x41a88c
 #define NV_PGRAPH_GPCX_GPCCS_CC_SCRATCH_SET(n)              ((n) * 4 + 0x41a8c0)
 #endif
+#define NV_PGRAPH_GPCX_GPCCS_STRAND_SELECT                             0x41a91c
+#define NV_PGRAPH_GPCX_GPCCS_STRAND_CMD                                0x41a928
+#define NV_PGRAPH_GPCX_GPCCS_STRAND_CMD_SAVE                         0x00000003
+#define NV_PGRAPH_GPCX_GPCCS_STRAND_CMD_LOAD                         0x00000004
+#define NV_PGRAPH_GPCX_GPCCS_MEM_BASE                                  0x41aa04
 
 #define mmctx_data(r,c) .b32 (((c - 1) << 26) | r)
 #define queue_init      .skip 72 // (2 * 4) + ((8 * 4) * 2)
@@ -65,24 +172,50 @@
 #define T_LCHAN   8
 #define T_LCTXH   9
 
-#define nv_mkmm(rv,r) /*
-*/ movw rv  ((r) & 0x0000fffc) /*
-*/ sethi rv ((r) & 0x00ff0000)
+#if CHIPSET < GK208
+#define imm32(reg,val) /*
+*/ movw reg  ((val) & 0x0000ffff) /*
+*/ sethi reg ((val) & 0xffff0000)
+#else
+#define imm32(reg,val) /*
+*/ mov reg (val)
+#endif
+
 #define nv_mkio(rv,r,i) /*
-*/ nv_mkmm(rv, (((r) & 0xffc) << 6) | ((i) << 2))
+*/ imm32(rv, (((r) & 0xffc) << 6) | ((i) << 2))
+
+#define hash #
+#define fn(a) a
+#if CHIPSET < GK208
+#define call(a) call fn(hash)a
+#else
+#define call(a) lcall fn(hash)a
+#endif
 
 #define nv_iord(rv,r,i) /*
 */ nv_mkio(rv,r,i) /*
 */ iord rv I[rv]
+
 #define nv_iowr(r,i,rv) /*
 */ nv_mkio($r0,r,i) /*
 */ iowr I[$r0] rv /*
 */ clear b32 $r0
 
+#define nv_rd32(reg,addr) /*
+*/ imm32($r14, addr) /*
+*/ call(nv_rd32) /*
+*/ mov b32 reg $r15
+
+#define nv_wr32(addr,reg) /*
+*/ mov b32 $r15 reg /*
+*/ imm32($r14, addr) /*
+*/ call(nv_wr32)
+
 #define trace_set(bit) /*
 */ clear b32 $r9 /*
 */ bset $r9 bit /*
 */ nv_iowr(NV_PGRAPH_FECS_CC_SCRATCH_SET(7), 0, $r9)
+
 #define trace_clr(bit) /*
 */ clear b32 $r9 /*
 */ bset $r9 bit /*
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/nv108.c b/drivers/gpu/drm/nouveau/core/engine/graph/nv108.c
new file mode 100644
index 0000000..e1af65e
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/nv108.c
@@ -0,0 +1,236 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs <bskeggs@redhat.com>
+ */
+
+#include "nvc0.h"
+
+/*******************************************************************************
+ * Graphics object classes
+ ******************************************************************************/
+
+static struct nouveau_oclass
+nv108_graph_sclass[] = {
+ { 0x902d, &nouveau_object_ofuncs },
+ { 0xa140, &nouveau_object_ofuncs },
+ { 0xa197, &nouveau_object_ofuncs },
+ { 0xa1c0, &nouveau_object_ofuncs },
+ {}
+};
+
+/*******************************************************************************
+ * PGRAPH engine/subdev functions
+ ******************************************************************************/
+
+static struct nvc0_graph_init
+nv108_graph_init_regs[] = {
+ { 0x400080,   1, 0x04, 0x003083c2 },
+ { 0x400088,   1, 0x04, 0x0001bfe7 },
+ { 0x40008c,   1, 0x04, 0x00000000 },
+ { 0x400090,   1, 0x04, 0x00000030 },
+ { 0x40013c,   1, 0x04, 0x003901f7 },
+ { 0x400140,   1, 0x04, 0x00000100 },
+ { 0x400144,   1, 0x04, 0x00000000 },
+ { 0x400148,   1, 0x04, 0x00000110 },
+ { 0x400138,   1, 0x04, 0x00000000 },
+ { 0x400130,   2, 0x04, 0x00000000 },
+ { 0x400124,   1, 0x04, 0x00000002 },
+ {}
+};
+
+struct nvc0_graph_init
+nv108_graph_init_unk58xx[] = {
+ { 0x405844,   1, 0x04, 0x00ffffff },
+ { 0x405850,   1, 0x04, 0x00000000 },
+ { 0x405900,   1, 0x04, 0x00000000 },
+ { 0x405908,   1, 0x04, 0x00000000 },
+ { 0x405928,   1, 0x04, 0x00000000 },
+ { 0x40592c,   1, 0x04, 0x00000000 },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_graph_init_gpc[] = {
+ { 0x418408,   1, 0x04, 0x00000000 },
+ { 0x4184a0,   3, 0x04, 0x00000000 },
+ { 0x418604,   1, 0x04, 0x00000000 },
+ { 0x418680,   1, 0x04, 0x00000000 },
+ { 0x418714,   1, 0x04, 0x00000000 },
+ { 0x418384,   2, 0x04, 0x00000000 },
+ { 0x418814,   3, 0x04, 0x00000000 },
+ { 0x418b04,   1, 0x04, 0x00000000 },
+ { 0x4188c8,   2, 0x04, 0x00000000 },
+ { 0x4188d0,   1, 0x04, 0x00010000 },
+ { 0x4188d4,   1, 0x04, 0x00000201 },
+ { 0x418910,   1, 0x04, 0x00010001 },
+ { 0x418914,   1, 0x04, 0x00000301 },
+ { 0x418918,   1, 0x04, 0x00800000 },
+ { 0x418980,   1, 0x04, 0x77777770 },
+ { 0x418984,   3, 0x04, 0x77777777 },
+ { 0x418c04,   1, 0x04, 0x00000000 },
+ { 0x418c64,   2, 0x04, 0x00000000 },
+ { 0x418c88,   1, 0x04, 0x00000000 },
+ { 0x418cb4,   2, 0x04, 0x00000000 },
+ { 0x418d00,   1, 0x04, 0x00000000 },
+ { 0x418d28,   2, 0x04, 0x00000000 },
+ { 0x418f00,   1, 0x04, 0x00000400 },
+ { 0x418f08,   1, 0x04, 0x00000000 },
+ { 0x418f20,   2, 0x04, 0x00000000 },
+ { 0x418e00,   1, 0x04, 0x00000000 },
+ { 0x418e08,   1, 0x04, 0x00000000 },
+ { 0x418e1c,   2, 0x04, 0x00000000 },
+ { 0x41900c,   1, 0x04, 0x00000000 },
+ { 0x419018,   1, 0x04, 0x00000000 },
+ {}
+};
+
+static struct nvc0_graph_init
+nv108_graph_init_tpc[] = {
+ { 0x419d0c,   1, 0x04, 0x00000000 },
+ { 0x419d10,   1, 0x04, 0x00000014 },
+ { 0x419ab0,   1, 0x04, 0x00000000 },
+ { 0x419ac8,   1, 0x04, 0x00000000 },
+ { 0x419ab8,   1, 0x04, 0x000000e7 },
+ { 0x419abc,   2, 0x04, 0x00000000 },
+ { 0x419ab4,   1, 0x04, 0x00000000 },
+ { 0x419aa8,   2, 0x04, 0x00000000 },
+ { 0x41980c,   1, 0x04, 0x00000010 },
+ { 0x419844,   1, 0x04, 0x00000000 },
+ { 0x419850,   1, 0x04, 0x00000004 },
+ { 0x419854,   2, 0x04, 0x00000000 },
+ { 0x419c98,   1, 0x04, 0x00000000 },
+ { 0x419ca8,   1, 0x04, 0x00000000 },
+ { 0x419cb0,   1, 0x04, 0x01000000 },
+ { 0x419cb4,   1, 0x04, 0x00000000 },
+ { 0x419cb8,   1, 0x04, 0x00b08bea },
+ { 0x419c84,   1, 0x04, 0x00010384 },
+ { 0x419cbc,   1, 0x04, 0x281b3646 },
+ { 0x419cc0,   2, 0x04, 0x00000000 },
+ { 0x419c80,   1, 0x04, 0x00000230 },
+ { 0x419ccc,   2, 0x04, 0x00000000 },
+ { 0x419c0c,   1, 0x04, 0x00000000 },
+ { 0x419e00,   1, 0x04, 0x00000080 },
+ { 0x419ea0,   1, 0x04, 0x00000000 },
+ { 0x419ee4,   1, 0x04, 0x00000000 },
+ { 0x419ea4,   1, 0x04, 0x00000100 },
+ { 0x419ea8,   1, 0x04, 0x00000000 },
+ { 0x419eb4,   1, 0x04, 0x00000000 },
+ { 0x419ebc,   2, 0x04, 0x00000000 },
+ { 0x419edc,   1, 0x04, 0x00000000 },
+ { 0x419f00,   1, 0x04, 0x00000000 },
+ { 0x419ed0,   1, 0x04, 0x00003234 },
+ { 0x419f74,   1, 0x04, 0x00015555 },
+ { 0x419f80,   4, 0x04, 0x00000000 },
+ {}
+};
+
+static int
+nv108_graph_fini(struct nouveau_object *object, bool suspend)
+{
+ struct nvc0_graph_priv *priv = (void *)object;
+ static const struct {
+  u32 addr;
+  u32 data;
+ } magic[] = {
+  { 0x020520, 0xfffffffc },
+  { 0x020524, 0xfffffffe },
+  { 0x020524, 0xfffffffc },
+  { 0x020524, 0xfffffff8 },
+  { 0x020524, 0xffffffe0 },
+  { 0x020530, 0xfffffffe },
+  { 0x02052c, 0xfffffffa },
+  { 0x02052c, 0xfffffff0 },
+  { 0x02052c, 0xffffffc0 },
+  { 0x02052c, 0xffffff00 },
+  { 0x02052c, 0xfffffc00 },
+  { 0x02052c, 0xfffcfc00 },
+  { 0x02052c, 0xfff0fc00 },
+  { 0x02052c, 0xff80fc00 },
+  { 0x020528, 0xfffffffe },
+  { 0x020528, 0xfffffffc },
+ };
+ int i;
+
+ nv_mask(priv, 0x000200, 0x08001000, 0x00000000);
+ nv_mask(priv, 0x0206b4, 0x00000000, 0x00000000);
+ for (i = 0; i < ARRAY_SIZE(magic); i++) {
+  nv_wr32(priv, magic[i].addr, magic[i].data);
+  nv_wait(priv, magic[i].addr, 0x80000000, 0x00000000);
+ }
+
+ return nouveau_graph_fini(&priv->base, suspend);
+}
+
+static struct nvc0_graph_init *
+nv108_graph_init_mmio[] = {
+ nv108_graph_init_regs,
+ nvf0_graph_init_unk40xx,
+ nvc0_graph_init_unk44xx,
+ nvc0_graph_init_unk78xx,
+ nvc0_graph_init_unk60xx,
+ nvd9_graph_init_unk64xx,
+ nv108_graph_init_unk58xx,
+ nvc0_graph_init_unk80xx,
+ nvf0_graph_init_unk70xx,
+ nvf0_graph_init_unk5bxx,
+ nv108_graph_init_gpc,
+ nv108_graph_init_tpc,
+ nve4_graph_init_unk,
+ nve4_graph_init_unk88xx,
+ NULL
+};
+
+#include "fuc/hubnv108.fuc5.h"
+
+static struct nvc0_graph_ucode
+nv108_graph_fecs_ucode = {
+ .code.data = nv108_grhub_code,
+ .code.size = sizeof(nv108_grhub_code),
+ .data.data = nv108_grhub_data,
+ .data.size = sizeof(nv108_grhub_data),
+};
+
+#include "fuc/gpcnv108.fuc5.h"
+
+static struct nvc0_graph_ucode
+nv108_graph_gpccs_ucode = {
+ .code.data = nv108_grgpc_code,
+ .code.size = sizeof(nv108_grgpc_code),
+ .data.data = nv108_grgpc_data,
+ .data.size = sizeof(nv108_grgpc_data),
+};
+
+struct nouveau_oclass *
+nv108_graph_oclass = &(struct nvc0_graph_oclass) {
+ .base.handle = NV_ENGINE(GR, 0x08),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nvc0_graph_ctor,
+  .dtor = nvc0_graph_dtor,
+  .init = nve4_graph_init,
+  .fini = nv108_graph_fini,
+ },
+ .cclass = &nv108_grctx_oclass,
+ .sclass =  nv108_graph_sclass,
+ .mmio = nv108_graph_init_mmio,
+ .fecs.ucode = &nv108_graph_fecs_ucode,
+ .gpccs.ucode = &nv108_graph_gpccs_ucode,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/nv50.c b/drivers/gpu/drm/nouveau/core/engine/graph/nv50.c
index 03de517..7a367c4 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/nv50.c
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/nv50.c
@@ -304,12 +304,28 @@ nv84_graph_tlb_flush(struct nouveau_engine *engine)
  return timeout ? -EBUSY : 0;
 }
 
-static const struct nouveau_enum nv50_mp_exec_error_names[] = {
- { 3, "STACK_UNDERFLOW", NULL },
- { 4, "QUADON_ACTIVE", NULL },
- { 8, "TIMEOUT", NULL },
- { 0x10, "INVALID_OPCODE", NULL },
- { 0x40, "BREAKPOINT", NULL },
+static const struct nouveau_bitfield nv50_mp_exec_errors[] = {
+ { 0x01, "STACK_UNDERFLOW" },
+ { 0x02, "STACK_MISMATCH" },
+ { 0x04, "QUADON_ACTIVE" },
+ { 0x08, "TIMEOUT" },
+ { 0x10, "INVALID_OPCODE" },
+ { 0x20, "PM_OVERFLOW" },
+ { 0x40, "BREAKPOINT" },
+ {}
+};
+
+static const struct nouveau_bitfield nv50_mpc_traps[] = {
+ { 0x0000001, "LOCAL_LIMIT_READ" },
+ { 0x0000010, "LOCAL_LIMIT_WRITE" },
+ { 0x0000040, "STACK_LIMIT" },
+ { 0x0000100, "GLOBAL_LIMIT_READ" },
+ { 0x0001000, "GLOBAL_LIMIT_WRITE" },
+ { 0x0010000, "MP0" },
+ { 0x0020000, "MP1" },
+ { 0x0040000, "GLOBAL_LIMIT_RED" },
+ { 0x0400000, "GLOBAL_LIMIT_ATOM" },
+ { 0x4000000, "MP2" },
  {}
 };
 
@@ -396,6 +412,60 @@ static const struct nouveau_bitfield nv50_graph_intr_name[] = {
  {}
 };
 
+static const struct nouveau_bitfield nv50_graph_trap_prop[] = {
+ { 0x00000004, "SURF_WIDTH_OVERRUN" },
+ { 0x00000008, "SURF_HEIGHT_OVERRUN" },
+ { 0x00000010, "DST2D_FAULT" },
+ { 0x00000020, "ZETA_FAULT" },
+ { 0x00000040, "RT_FAULT" },
+ { 0x00000080, "CUDA_FAULT" },
+ { 0x00000100, "DST2D_STORAGE_TYPE_MISMATCH" },
+ { 0x00000200, "ZETA_STORAGE_TYPE_MISMATCH" },
+ { 0x00000400, "RT_STORAGE_TYPE_MISMATCH" },
+ { 0x00000800, "DST2D_LINEAR_MISMATCH" },
+ { 0x00001000, "RT_LINEAR_MISMATCH" },
+ {}
+};
+
+static void
+nv50_priv_prop_trap(struct nv50_graph_priv *priv,
+      u32 ustatus_addr, u32 ustatus, u32 tp)
+{
+ u32 e0c = nv_rd32(priv, ustatus_addr + 0x04);
+ u32 e10 = nv_rd32(priv, ustatus_addr + 0x08);
+ u32 e14 = nv_rd32(priv, ustatus_addr + 0x0c);
+ u32 e18 = nv_rd32(priv, ustatus_addr + 0x10);
+ u32 e1c = nv_rd32(priv, ustatus_addr + 0x14);
+ u32 e20 = nv_rd32(priv, ustatus_addr + 0x18);
+ u32 e24 = nv_rd32(priv, ustatus_addr + 0x1c);
+
+ /* CUDA memory: l[], g[] or stack. */
+ if (ustatus & 0x00000080) {
+  if (e18 & 0x80000000) {
+   /* g[] read fault? */
+   nv_error(priv, "TRAP_PROP - TP %d - CUDA_FAULT - Global read fault at address %02x%08x\n",
+      tp, e14, e10 | ((e18 >> 24) & 0x1f));
+   e18 &= ~0x1f000000;
+  } else if (e18 & 0xc) {
+   /* g[] write fault? */
+   nv_error(priv, "TRAP_PROP - TP %d - CUDA_FAULT - Global write fault at address %02x%08x\n",
+     tp, e14, e10 | ((e18 >> 7) & 0x1f));
+   e18 &= ~0x00000f80;
+  } else {
+   nv_error(priv, "TRAP_PROP - TP %d - Unknown CUDA fault at address %02x%08x\n",
+     tp, e14, e10);
+  }
+  ustatus &= ~0x00000080;
+ }
+ if (ustatus) {
+  nv_error(priv, "TRAP_PROP - TP %d -", tp);
+  nouveau_bitfield_print(nv50_graph_trap_prop, ustatus);
+  pr_cont(" - Address %02x%08x\n", e14, e10);
+ }
+ nv_error(priv, "TRAP_PROP - TP %d - e0c: %08x, e18: %08x, e1c: %08x, e20: %08x, e24: %08x\n",
+   tp, e0c, e18, e1c, e20, e24);
+}
+
 static void
 nv50_priv_mp_trap(struct nv50_graph_priv *priv, int tpid, int display)
 {
@@ -420,8 +490,8 @@ nv50_priv_mp_trap(struct nv50_graph_priv *priv, int tpid, int display)
    oplow = nv_rd32(priv, addr + 0x70);
    ophigh = nv_rd32(priv, addr + 0x74);
    nv_error(priv, "TRAP_MP_EXEC - "
-     "TP %d MP %d: ", tpid, i);
-   nouveau_enum_print(nv50_mp_exec_error_names, status);
+     "TP %d MP %d:", tpid, i);
+   nouveau_bitfield_print(nv50_mp_exec_errors, status);
    pr_cont(" at %06x warp %d, opcode %08x %08x\n",
      pc&0xffffff, pc >> 24,
      oplow, ophigh);
@@ -468,60 +538,19 @@ nv50_priv_tp_trap(struct nv50_graph_priv *priv, int type, u32 ustatus_old,
     nv50_priv_mp_trap(priv, i, display);
     ustatus &= ~0x04030000;
    }
-   break;
-  case 8: /* TPDMA error */
-   {
-   u32 e0c = nv_rd32(priv, ustatus_addr + 4);
-   u32 e10 = nv_rd32(priv, ustatus_addr + 8);
-   u32 e14 = nv_rd32(priv, ustatus_addr + 0xc);
-   u32 e18 = nv_rd32(priv, ustatus_addr + 0x10);
-   u32 e1c = nv_rd32(priv, ustatus_addr + 0x14);
-   u32 e20 = nv_rd32(priv, ustatus_addr + 0x18);
-   u32 e24 = nv_rd32(priv, ustatus_addr + 0x1c);
-   /* 2d engine destination */
-   if (ustatus & 0x00000010) {
-    if (display) {
-     nv_error(priv, "TRAP_TPDMA_2D - TP %d - Unknown fault at address %02x%08x\n",
-       i, e14, e10);
-     nv_error(priv, "TRAP_TPDMA_2D - TP %d - e0c: %08x, e18: %08x, e1c: %08x, e20: %08x, e24: %08x\n",
-       i, e0c, e18, e1c, e20, e24);
-    }
-    ustatus &= ~0x00000010;
-   }
-   /* Render target */
-   if (ustatus & 0x00000040) {
-    if (display) {
-     nv_error(priv, "TRAP_TPDMA_RT - TP %d - Unknown fault at address %02x%08x\n",
-       i, e14, e10);
-     nv_error(priv, "TRAP_TPDMA_RT - TP %d - e0c: %08x, e18: %08x, e1c: %08x, e20: %08x, e24: %08x\n",
-       i, e0c, e18, e1c, e20, e24);
-    }
-    ustatus &= ~0x00000040;
-   }
-   /* CUDA memory: l[], g[] or stack. */
-   if (ustatus & 0x00000080) {
-    if (display) {
-     if (e18 & 0x80000000) {
-      /* g[] read fault? */
-      nv_error(priv, "TRAP_TPDMA - TP %d - Global read fault at address %02x%08x\n",
-        i, e14, e10 | ((e18 >> 24) & 0x1f));
-      e18 &= ~0x1f000000;
-     } else if (e18 & 0xc) {
-      /* g[] write fault? */
-      nv_error(priv, "TRAP_TPDMA - TP %d - Global write fault at address %02x%08x\n",
-        i, e14, e10 | ((e18 >> 7) & 0x1f));
-      e18 &= ~0x00000f80;
-     } else {
-      nv_error(priv, "TRAP_TPDMA - TP %d - Unknown CUDA fault at address %02x%08x\n",
-        i, e14, e10);
-     }
-     nv_error(priv, "TRAP_TPDMA - TP %d - e0c: %08x, e18: %08x, e1c: %08x, e20: %08x, e24: %08x\n",
-       i, e0c, e18, e1c, e20, e24);
-    }
-    ustatus &= ~0x00000080;
-   }
+   if (ustatus && display) {
+    nv_error(priv, "%s - TP%d:", name, i);
+    nouveau_bitfield_print(nv50_mpc_traps, ustatus);
+    pr_cont("\n");
+    ustatus = 0;
    }
    break;
+  case 8: /* PROP error */
+   if (display)
+    nv50_priv_prop_trap(
+      priv, ustatus_addr, ustatus, i);
+   ustatus = 0;
+   break;
   }
   if (ustatus) {
    if (display)
@@ -727,11 +756,11 @@ nv50_graph_trap_handler(struct nv50_graph_priv *priv, u32 display,
   status &= ~0x080;
  }
 
- /* TPDMA:  Handles TP-initiated uncached memory accesses:
+ /* PROP:  Handles TP-initiated uncached memory accesses:
   * l[], g[], stack, 2d surfaces, render targets. */
  if (status & 0x100) {
   nv50_priv_tp_trap(priv, 8, 0x408e08, 0x408708, display,
-        "TRAP_TPDMA");
+        "TRAP_PROP");
   nv_wr32(priv, 0x400108, 0x100);
   status &= ~0x100;
  }
@@ -760,7 +789,7 @@ nv50_graph_intr(struct nouveau_subdev *subdev)
  u32 mthd = (addr & 0x00001ffc);
  u32 data = nv_rd32(priv, 0x400708);
  u32 class = nv_rd32(priv, 0x400814);
- u32 show = stat;
+ u32 show = stat, show_bitfield = stat;
  int chid;
 
  engctx = nouveau_engctx_get(engine, inst);
@@ -778,21 +807,26 @@ nv50_graph_intr(struct nouveau_subdev *subdev)
   nv_error(priv, "DATA_ERROR ");
   nouveau_enum_print(nv50_data_error_names, ecode);
   pr_cont("\n");
+  show_bitfield &= ~0x00100000;
  }
 
  if (stat & 0x00200000) {
   if (!nv50_graph_trap_handler(priv, show, chid, (u64)inst << 12,
     engctx))
    show &= ~0x00200000;
+  show_bitfield &= ~0x00200000;
  }
 
  nv_wr32(priv, 0x400100, stat);
  nv_wr32(priv, 0x400500, 0x00010001);
 
  if (show) {
-  nv_error(priv, "%s", "");
-  nouveau_bitfield_print(nv50_graph_intr_name, show);
-  pr_cont("\n");
+  show &= show_bitfield;
+  if (show) {
+   nv_error(priv, "%s", "");
+   nouveau_bitfield_print(nv50_graph_intr_name, show);
+   pr_cont("\n");
+  }
   nv_error(priv,
     "ch %d [0x%010llx %s] subc %d class 0x%04x mthd 0x%04x data 0x%08x\n",
     chid, (u64)inst << 12, nouveau_client_name(engctx),
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/nvc0.c b/drivers/gpu/drm/nouveau/core/engine/graph/nvc0.c
index 5c8a63d..a73ab20 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/nvc0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/nvc0.c
@@ -901,6 +901,9 @@ nvc0_graph_init_ctxctl(struct nvc0_graph_priv *priv)
   }
 
   return 0;
+ } else
+ if (!oclass->fecs.ucode) {
+  return -ENOSYS;
  }
 
  /* load HUB microcode */
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/nvc0.h b/drivers/gpu/drm/nouveau/core/engine/graph/nvc0.h
index ea17a80..b0ab6de 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/nvc0.h
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/nvc0.h
@@ -205,6 +205,11 @@ extern struct nvc0_graph_init nve4_graph_init_regs[];
 extern struct nvc0_graph_init nve4_graph_init_unk[];
 extern struct nvc0_graph_init nve4_graph_init_unk88xx[];
 
+extern struct nvc0_graph_init nvf0_graph_init_unk40xx[];
+extern struct nvc0_graph_init nvf0_graph_init_unk70xx[];
+extern struct nvc0_graph_init nvf0_graph_init_unk5bxx[];
+extern struct nvc0_graph_init nvf0_graph_init_tpc[];
+
 int  nvc0_grctx_generate(struct nvc0_graph_priv *);
 void nvc0_grctx_generate_main(struct nvc0_graph_priv *, struct nvc0_grctx *);
 void nvc0_grctx_generate_mods(struct nvc0_graph_priv *, struct nvc0_grctx *);
@@ -266,6 +271,11 @@ extern struct nvc0_graph_init nve4_grctx_init_unk80xx[];
 extern struct nvc0_graph_init nve4_grctx_init_unk90xx[];
 
 extern struct nouveau_oclass *nvf0_grctx_oclass;
+extern struct nvc0_graph_init nvf0_grctx_init_unk44xx[];
+extern struct nvc0_graph_init nvf0_grctx_init_unk5bxx[];
+extern struct nvc0_graph_init nvf0_grctx_init_unk60xx[];
+
+extern struct nouveau_oclass *nv108_grctx_oclass;
 
 #define mmio_data(s,a,p) do {                                                  \
  info->buffer[info->buffer_nr] = round_up(info->addr, (a));             \
diff --git a/drivers/gpu/drm/nouveau/core/engine/graph/nvf0.c b/drivers/gpu/drm/nouveau/core/engine/graph/nvf0.c
index 2f0ac78..b1acb99 100644
--- a/drivers/gpu/drm/nouveau/core/engine/graph/nvf0.c
+++ b/drivers/gpu/drm/nouveau/core/engine/graph/nvf0.c
@@ -41,7 +41,7 @@ nvf0_graph_sclass[] = {
  * PGRAPH engine/subdev functions
  ******************************************************************************/
 
-static struct nvc0_graph_init
+struct nvc0_graph_init
 nvf0_graph_init_unk40xx[] = {
  { 0x40415c,   1, 0x04, 0x00000000 },
  { 0x404170,   1, 0x04, 0x00000000 },
@@ -60,7 +60,7 @@ nvf0_graph_init_unk58xx[] = {
  {}
 };
 
-static struct nvc0_graph_init
+struct nvc0_graph_init
 nvf0_graph_init_unk70xx[] = {
  { 0x407010,   1, 0x04, 0x00000000 },
  { 0x407040,   1, 0x04, 0x80440424 },
@@ -68,7 +68,7 @@ nvf0_graph_init_unk70xx[] = {
  {}
 };
 
-static struct nvc0_graph_init
+struct nvc0_graph_init
 nvf0_graph_init_unk5bxx[] = {
  { 0x405b44,   1, 0x04, 0x00000000 },
  { 0x405b50,   1, 0x04, 0x00000000 },
@@ -114,7 +114,7 @@ nvf0_graph_init_gpc[] = {
  {}
 };
 
-static struct nvc0_graph_init
+struct nvc0_graph_init
 nvf0_graph_init_tpc[] = {
  { 0x419d0c,   1, 0x04, 0x00000000 },
  { 0x419d10,   1, 0x04, 0x00000014 },
@@ -243,6 +243,6 @@ nvf0_graph_oclass = &(struct nvc0_graph_oclass) {
  .cclass = &nvf0_grctx_oclass,
  .sclass =  nvf0_graph_sclass,
  .mmio = nvf0_graph_init_mmio,
- .fecs.ucode = 0 ? &nvf0_graph_fecs_ucode : NULL,
+ .fecs.ucode = &nvf0_graph_fecs_ucode,
  .gpccs.ucode = &nvf0_graph_gpccs_ucode,
 }.base;
diff --git a/drivers/gpu/drm/nouveau/core/include/core/class.h b/drivers/gpu/drm/nouveau/core/include/core/class.h
index 560c359..e71a432 100644
--- a/drivers/gpu/drm/nouveau/core/include/core/class.h
+++ b/drivers/gpu/drm/nouveau/core/include/core/class.h
@@ -230,9 +230,26 @@ struct nve0_channel_ind_class {
 
 #define NV04_DISP_CLASS                                              0x00000046
 
+#define NV04_DISP_MTHD                                               0x00000000
+#define NV04_DISP_MTHD_HEAD                                          0x00000001
+
+#define NV04_DISP_SCANOUTPOS                                         0x00000000
+
 struct nv04_display_class {
 };
 
+struct nv04_display_scanoutpos {
+ s64 time[2];
+ u32 vblanks;
+ u32 vblanke;
+ u32 vtotal;
+ u32 vline;
+ u32 hblanks;
+ u32 hblanke;
+ u32 htotal;
+ u32 hline;
+};
+
 /* 5070: NV50_DISP
  * 8270: NV84_DISP
  * 8370: NVA0_DISP
@@ -252,6 +269,11 @@ struct nv04_display_class {
 #define NVE0_DISP_CLASS                                              0x00009170
 #define NVF0_DISP_CLASS                                              0x00009270
 
+#define NV50_DISP_MTHD                                               0x00000000
+#define NV50_DISP_MTHD_HEAD                                          0x00000003
+
+#define NV50_DISP_SCANOUTPOS                                         0x00000000
+
 #define NV50_DISP_SOR_MTHD                                           0x00010000
 #define NV50_DISP_SOR_MTHD_TYPE                                      0x0000f000
 #define NV50_DISP_SOR_MTHD_HEAD                                      0x00000018
diff --git a/drivers/gpu/drm/nouveau/core/include/core/device.h b/drivers/gpu/drm/nouveau/core/include/core/device.h
index ac2881d..7b8ea22 100644
--- a/drivers/gpu/drm/nouveau/core/include/core/device.h
+++ b/drivers/gpu/drm/nouveau/core/include/core/device.h
@@ -38,7 +38,8 @@ enum nv_subdev_type {
  NVDEV_SUBDEV_THERM,
  NVDEV_SUBDEV_CLOCK,
 
- NVDEV_ENGINE_DMAOBJ,
+ NVDEV_ENGINE_FIRST,
+ NVDEV_ENGINE_DMAOBJ = NVDEV_ENGINE_FIRST,
  NVDEV_ENGINE_FIFO,
  NVDEV_ENGINE_SW,
  NVDEV_ENGINE_GR,
@@ -70,6 +71,7 @@ struct nouveau_device {
  const char *dbgopt;
  const char *name;
  const char *cname;
+ u64 disable_mask;
 
  enum {
   NV_04    = 0x04,
diff --git a/drivers/gpu/drm/nouveau/core/include/engine/fifo.h b/drivers/gpu/drm/nouveau/core/include/engine/fifo.h
index 8c32cf4..26b6b2b 100644
--- a/drivers/gpu/drm/nouveau/core/include/engine/fifo.h
+++ b/drivers/gpu/drm/nouveau/core/include/engine/fifo.h
@@ -109,6 +109,7 @@ extern struct nouveau_oclass *nv50_fifo_oclass;
 extern struct nouveau_oclass *nv84_fifo_oclass;
 extern struct nouveau_oclass *nvc0_fifo_oclass;
 extern struct nouveau_oclass *nve0_fifo_oclass;
+extern struct nouveau_oclass *nv108_fifo_oclass;
 
 void nv04_fifo_intr(struct nouveau_subdev *);
 int  nv04_fifo_context_attach(struct nouveau_object *, struct nouveau_object *);
diff --git a/drivers/gpu/drm/nouveau/core/include/engine/graph.h b/drivers/gpu/drm/nouveau/core/include/engine/graph.h
index 8e1b523..9770561 100644
--- a/drivers/gpu/drm/nouveau/core/include/engine/graph.h
+++ b/drivers/gpu/drm/nouveau/core/include/engine/graph.h
@@ -69,6 +69,7 @@ extern struct nouveau_oclass *nvd7_graph_oclass;
 extern struct nouveau_oclass *nvd9_graph_oclass;
 extern struct nouveau_oclass *nve4_graph_oclass;
 extern struct nouveau_oclass *nvf0_graph_oclass;
+extern struct nouveau_oclass *nv108_graph_oclass;
 
 extern const struct nouveau_bitfield nv04_graph_nsource[];
 extern struct nouveau_ofuncs nv04_graph_ofuncs;
diff --git a/drivers/gpu/drm/nouveau/core/include/subdev/bar.h b/drivers/gpu/drm/nouveau/core/include/subdev/bar.h
index 4f4ff45..9faa98e 100644
--- a/drivers/gpu/drm/nouveau/core/include/subdev/bar.h
+++ b/drivers/gpu/drm/nouveau/core/include/subdev/bar.h
@@ -4,8 +4,7 @@
 #include <core/subdev.h>
 #include <core/device.h>
 
-#include <subdev/fb.h>
-
+struct nouveau_mem;
 struct nouveau_vma;
 
 struct nouveau_bar {
@@ -29,27 +28,7 @@ nouveau_bar(void *obj)
  return (void *)nv_device(obj)->subdev[NVDEV_SUBDEV_BAR];
 }
 
-#define nouveau_bar_create(p,e,o,d)                                            \
- nouveau_bar_create_((p), (e), (o), sizeof(**d), (void **)d)
-#define nouveau_bar_init(p)                                                    \
- nouveau_subdev_init(&(p)->base)
-#define nouveau_bar_fini(p,s)                                                  \
- nouveau_subdev_fini(&(p)->base, (s))
-
-int nouveau_bar_create_(struct nouveau_object *, struct nouveau_object *,
-   struct nouveau_oclass *, int, void **);
-void nouveau_bar_destroy(struct nouveau_bar *);
-
-void _nouveau_bar_dtor(struct nouveau_object *);
-#define _nouveau_bar_init _nouveau_subdev_init
-#define _nouveau_bar_fini _nouveau_subdev_fini
-
 extern struct nouveau_oclass nv50_bar_oclass;
 extern struct nouveau_oclass nvc0_bar_oclass;
 
-int nouveau_bar_alloc(struct nouveau_bar *, struct nouveau_object *,
-        struct nouveau_mem *, struct nouveau_object **);
-
-void nv84_bar_flush(struct nouveau_bar *);
-
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/include/subdev/bios/ramcfg.h b/drivers/gpu/drm/nouveau/core/include/subdev/bios/ramcfg.h
new file mode 100644
index 0000000..c5e6d1e
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/include/subdev/bios/ramcfg.h
@@ -0,0 +1,66 @@
+#ifndef __NVBIOS_RAMCFG_H__
+#define __NVBIOS_RAMCFG_H__
+
+struct nouveau_bios;
+
+struct nvbios_ramcfg {
+ unsigned rammap_11_08_01:1;
+ unsigned rammap_11_08_0c:2;
+ unsigned rammap_11_08_10:1;
+ unsigned rammap_11_11_0c:2;
+
+ unsigned ramcfg_11_01_01:1;
+ unsigned ramcfg_11_01_02:1;
+ unsigned ramcfg_11_01_04:1;
+ unsigned ramcfg_11_01_08:1;
+ unsigned ramcfg_11_01_10:1;
+ unsigned ramcfg_11_01_20:1;
+ unsigned ramcfg_11_01_40:1;
+ unsigned ramcfg_11_01_80:1;
+ unsigned ramcfg_11_02_03:2;
+ unsigned ramcfg_11_02_04:1;
+ unsigned ramcfg_11_02_08:1;
+ unsigned ramcfg_11_02_10:1;
+ unsigned ramcfg_11_02_40:1;
+ unsigned ramcfg_11_02_80:1;
+ unsigned ramcfg_11_03_0f:4;
+ unsigned ramcfg_11_03_30:2;
+ unsigned ramcfg_11_03_c0:2;
+ unsigned ramcfg_11_03_f0:4;
+ unsigned ramcfg_11_04:8;
+ unsigned ramcfg_11_06:8;
+ unsigned ramcfg_11_07_02:1;
+ unsigned ramcfg_11_07_04:1;
+ unsigned ramcfg_11_07_08:1;
+ unsigned ramcfg_11_07_10:1;
+ unsigned ramcfg_11_07_40:1;
+ unsigned ramcfg_11_07_80:1;
+ unsigned ramcfg_11_08_01:1;
+ unsigned ramcfg_11_08_02:1;
+ unsigned ramcfg_11_08_04:1;
+ unsigned ramcfg_11_08_08:1;
+ unsigned ramcfg_11_08_10:1;
+ unsigned ramcfg_11_08_20:1;
+ unsigned ramcfg_11_09:8;
+
+ unsigned timing[11];
+ unsigned timing_20_2e_03:2;
+ unsigned timing_20_2e_30:2;
+ unsigned timing_20_2e_c0:2;
+ unsigned timing_20_2f_03:2;
+ unsigned timing_20_2c_003f:6;
+ unsigned timing_20_2c_1fc0:7;
+ unsigned timing_20_30_f8:5;
+ unsigned timing_20_30_07:3;
+ unsigned timing_20_31_0007:3;
+ unsigned timing_20_31_0078:4;
+ unsigned timing_20_31_0780:4;
+ unsigned timing_20_31_0800:1;
+ unsigned timing_20_31_7000:3;
+ unsigned timing_20_31_8000:1;
+};
+
+u8 nvbios_ramcfg_count(struct nouveau_bios *);
+u8 nvbios_ramcfg_index(struct nouveau_bios *);
+
+#endif
diff --git a/drivers/gpu/drm/nouveau/core/include/subdev/bios/rammap.h b/drivers/gpu/drm/nouveau/core/include/subdev/bios/rammap.h
index bc15e03..5bdf8e4 100644
--- a/drivers/gpu/drm/nouveau/core/include/subdev/bios/rammap.h
+++ b/drivers/gpu/drm/nouveau/core/include/subdev/bios/rammap.h
@@ -1,11 +1,25 @@
 #ifndef __NVBIOS_RAMMAP_H__
 #define __NVBIOS_RAMMAP_H__
 
-u16 nvbios_rammap_table(struct nouveau_bios *, u8 *ver, u8 *hdr,
-   u8 *cnt, u8 *len, u8 *snr, u8 *ssz);
-u16 nvbios_rammap_entry(struct nouveau_bios *, int idx,
-   u8 *ver, u8 *hdr, u8 *cnt, u8 *len);
-u16 nvbios_rammap_match(struct nouveau_bios *, u16 khz,
-   u8 *ver, u8 *hdr, u8 *cnt, u8 *len);
+struct nvbios_ramcfg;
+
+u32 nvbios_rammapTe(struct nouveau_bios *, u8 *ver, u8 *hdr,
+      u8 *cnt, u8 *len, u8 *snr, u8 *ssz);
+
+u32 nvbios_rammapEe(struct nouveau_bios *, int idx,
+      u8 *ver, u8 *hdr, u8 *cnt, u8 *len);
+u32 nvbios_rammapEm(struct nouveau_bios *, u16 mhz,
+      u8 *ver, u8 *hdr, u8 *cnt, u8 *len);
+u32 nvbios_rammapEp(struct nouveau_bios *, u16 mhz,
+      u8 *ver, u8 *hdr, u8 *cnt, u8 *len,
+      struct nvbios_ramcfg *);
+
+u32 nvbios_rammapSe(struct nouveau_bios *, u32 data,
+      u8 ever, u8 ehdr, u8 ecnt, u8 elen, int idx,
+      u8 *ver, u8 *hdr);
+u32 nvbios_rammapSp(struct nouveau_bios *, u32 data,
+      u8 ever, u8 ehdr, u8 ecnt, u8 elen, int idx,
+      u8 *ver, u8 *hdr,
+      struct nvbios_ramcfg *);
 
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/include/subdev/bios/timing.h b/drivers/gpu/drm/nouveau/core/include/subdev/bios/timing.h
index 963694b..76d914b 100644
--- a/drivers/gpu/drm/nouveau/core/include/subdev/bios/timing.h
+++ b/drivers/gpu/drm/nouveau/core/include/subdev/bios/timing.h
@@ -1,8 +1,14 @@
 #ifndef __NVBIOS_TIMING_H__
 #define __NVBIOS_TIMING_H__
 
-u16 nvbios_timing_table(struct nouveau_bios *,
-   u8 *ver, u8 *hdr, u8 *cnt, u8 *len);
-u16 nvbios_timing_entry(struct nouveau_bios *, int idx, u8 *ver, u8 *hdr);
+struct nvbios_ramcfg;
+
+u16 nvbios_timingTe(struct nouveau_bios *,
+      u8 *ver, u8 *hdr, u8 *cnt, u8 *len, u8 *snr, u8 *ssz);
+u16 nvbios_timingEe(struct nouveau_bios *, int idx,
+      u8 *ver, u8 *hdr, u8 *cnt, u8 *len);
+u16 nvbios_timingEp(struct nouveau_bios *, int idx,
+      u8 *ver, u8 *hdr, u8 *cnt, u8 *len,
+      struct nvbios_ramcfg *);
 
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/include/subdev/devinit.h b/drivers/gpu/drm/nouveau/core/include/subdev/devinit.h
index 685c9b1..ed1ac68 100644
--- a/drivers/gpu/drm/nouveau/core/include/subdev/devinit.h
+++ b/drivers/gpu/drm/nouveau/core/include/subdev/devinit.h
@@ -9,7 +9,6 @@ struct nouveau_devinit {
  bool post;
  void (*meminit)(struct nouveau_devinit *);
  int  (*pll_set)(struct nouveau_devinit *, u32 type, u32 freq);
-
 };
 
 static inline struct nouveau_devinit *
@@ -18,32 +17,16 @@ nouveau_devinit(void *obj)
  return (void *)nv_device(obj)->subdev[NVDEV_SUBDEV_DEVINIT];
 }
 
-#define nouveau_devinit_create(p,e,o,d)                                        \
- nouveau_devinit_create_((p), (e), (o), sizeof(**d), (void **)d)
-#define nouveau_devinit_destroy(p)                                             \
- nouveau_subdev_destroy(&(p)->base)
-#define nouveau_devinit_init(p) ({                                             \
- struct nouveau_devinit *d = (p);                                       \
- _nouveau_devinit_init(nv_object(d));                                   \
-})
-#define nouveau_devinit_fini(p,s) ({                                           \
- struct nouveau_devinit *d = (p);                                       \
- _nouveau_devinit_fini(nv_object(d), (s));                              \
-})
-
-int nouveau_devinit_create_(struct nouveau_object *, struct nouveau_object *,
-       struct nouveau_oclass *, int, void **);
-#define _nouveau_devinit_dtor _nouveau_subdev_dtor
-int _nouveau_devinit_init(struct nouveau_object *);
-int _nouveau_devinit_fini(struct nouveau_object *, bool suspend);
-
-extern struct nouveau_oclass nv04_devinit_oclass;
-extern struct nouveau_oclass nv05_devinit_oclass;
-extern struct nouveau_oclass nv10_devinit_oclass;
-extern struct nouveau_oclass nv1a_devinit_oclass;
-extern struct nouveau_oclass nv20_devinit_oclass;
-extern struct nouveau_oclass nv50_devinit_oclass;
-extern struct nouveau_oclass nva3_devinit_oclass;
-extern struct nouveau_oclass nvc0_devinit_oclass;
+extern struct nouveau_oclass *nv04_devinit_oclass;
+extern struct nouveau_oclass *nv05_devinit_oclass;
+extern struct nouveau_oclass *nv10_devinit_oclass;
+extern struct nouveau_oclass *nv1a_devinit_oclass;
+extern struct nouveau_oclass *nv20_devinit_oclass;
+extern struct nouveau_oclass *nv50_devinit_oclass;
+extern struct nouveau_oclass *nv84_devinit_oclass;
+extern struct nouveau_oclass *nv98_devinit_oclass;
+extern struct nouveau_oclass *nva3_devinit_oclass;
+extern struct nouveau_oclass *nvaf_devinit_oclass;
+extern struct nouveau_oclass *nvc0_devinit_oclass;
 
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/include/subdev/fb.h b/drivers/gpu/drm/nouveau/core/include/subdev/fb.h
index d89dbdf..d7ecafb 100644
--- a/drivers/gpu/drm/nouveau/core/include/subdev/fb.h
+++ b/drivers/gpu/drm/nouveau/core/include/subdev/fb.h
@@ -106,6 +106,13 @@ extern struct nouveau_oclass *nvaf_fb_oclass;
 extern struct nouveau_oclass *nvc0_fb_oclass;
 extern struct nouveau_oclass *nve0_fb_oclass;
 
+#include <subdev/bios/ramcfg.h>
+
+struct nouveau_ram_data {
+ struct nvbios_ramcfg bios;
+ u32 freq;
+};
+
 struct nouveau_ram {
  struct nouveau_object base;
  enum {
@@ -142,6 +149,12 @@ struct nouveau_ram {
  } rammap, ramcfg, timing;
  u32 freq;
  u32 mr[16];
+ u32 mr1_nuts;
+
+ struct nouveau_ram_data *next;
+ struct nouveau_ram_data former;
+ struct nouveau_ram_data xition;
+ struct nouveau_ram_data target;
 };
 
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/include/subdev/instmem.h b/drivers/gpu/drm/nouveau/core/include/subdev/instmem.h
index 4aca338..c1df26f 100644
--- a/drivers/gpu/drm/nouveau/core/include/subdev/instmem.h
+++ b/drivers/gpu/drm/nouveau/core/include/subdev/instmem.h
@@ -23,21 +23,6 @@ nv_memobj(void *obj)
  return obj;
 }
 
-#define nouveau_instobj_create(p,e,o,d)                                        \
- nouveau_instobj_create_((p), (e), (o), sizeof(**d), (void **)d)
-#define nouveau_instobj_init(p)                                                \
- nouveau_object_init(&(p)->base)
-#define nouveau_instobj_fini(p,s)                                              \
- nouveau_object_fini(&(p)->base, (s))
-
-int  nouveau_instobj_create_(struct nouveau_object *, struct nouveau_object *,
-        struct nouveau_oclass *, int, void **);
-void nouveau_instobj_destroy(struct nouveau_instobj *);
-
-void _nouveau_instobj_dtor(struct nouveau_object *);
-#define _nouveau_instobj_init nouveau_object_init
-#define _nouveau_instobj_fini nouveau_object_fini
-
 struct nouveau_instmem {
  struct nouveau_subdev base;
  struct list_head list;
@@ -60,21 +45,8 @@ nouveau_instmem(void *obj)
  return (void *)nv_device(obj)->subdev[NVDEV_SUBDEV_INSTMEM];
 }
 
-#define nouveau_instmem_create(p,e,o,d)                                        \
- nouveau_instmem_create_((p), (e), (o), sizeof(**d), (void **)d)
-#define nouveau_instmem_destroy(p)                                             \
- nouveau_subdev_destroy(&(p)->base)
-int nouveau_instmem_create_(struct nouveau_object *, struct nouveau_object *,
-       struct nouveau_oclass *, int, void **);
-int nouveau_instmem_init(struct nouveau_instmem *);
-int nouveau_instmem_fini(struct nouveau_instmem *, bool);
-
-#define _nouveau_instmem_dtor _nouveau_subdev_dtor
-int _nouveau_instmem_init(struct nouveau_object *);
-int _nouveau_instmem_fini(struct nouveau_object *, bool);
-
-extern struct nouveau_oclass nv04_instmem_oclass;
-extern struct nouveau_oclass nv40_instmem_oclass;
-extern struct nouveau_oclass nv50_instmem_oclass;
+extern struct nouveau_oclass *nv04_instmem_oclass;
+extern struct nouveau_oclass *nv40_instmem_oclass;
+extern struct nouveau_oclass *nv50_instmem_oclass;
 
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/include/subdev/mc.h b/drivers/gpu/drm/nouveau/core/include/subdev/mc.h
index adc88b7..3c6738e 100644
--- a/drivers/gpu/drm/nouveau/core/include/subdev/mc.h
+++ b/drivers/gpu/drm/nouveau/core/include/subdev/mc.h
@@ -47,6 +47,7 @@ struct nouveau_mc_oclass {
 extern struct nouveau_oclass *nv04_mc_oclass;
 extern struct nouveau_oclass *nv40_mc_oclass;
 extern struct nouveau_oclass *nv44_mc_oclass;
+extern struct nouveau_oclass *nv4c_mc_oclass;
 extern struct nouveau_oclass *nv50_mc_oclass;
 extern struct nouveau_oclass *nv94_mc_oclass;
 extern struct nouveau_oclass *nv98_mc_oclass;
diff --git a/drivers/gpu/drm/nouveau/core/include/subdev/vm.h b/drivers/gpu/drm/nouveau/core/include/subdev/vm.h
index fcf57fa..c950903 100644
--- a/drivers/gpu/drm/nouveau/core/include/subdev/vm.h
+++ b/drivers/gpu/drm/nouveau/core/include/subdev/vm.h
@@ -131,9 +131,5 @@ void nouveau_vm_map(struct nouveau_vma *, struct nouveau_mem *);
 void nouveau_vm_map_at(struct nouveau_vma *, u64 offset, struct nouveau_mem *);
 void nouveau_vm_unmap(struct nouveau_vma *);
 void nouveau_vm_unmap_at(struct nouveau_vma *, u64 offset, u64 length);
-void nouveau_vm_map_sg(struct nouveau_vma *, u64 offset, u64 length,
-         struct nouveau_mem *);
-void nouveau_vm_map_sg_table(struct nouveau_vma *vma, u64 delta, u64 length,
-       struct nouveau_mem *mem);
 
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/subdev/bar/base.c b/drivers/gpu/drm/nouveau/core/subdev/bar/base.c
index d70ba34..7098ddd 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/bar/base.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/bar/base.c
@@ -23,7 +23,11 @@
  */
 
 #include <core/object.h>
-#include <subdev/bar.h>
+
+#include <subdev/fb.h>
+#include <subdev/vm.h>
+
+#include "priv.h"
 
 struct nouveau_barobj {
  struct nouveau_object base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/bar/nv50.c b/drivers/gpu/drm/nouveau/core/subdev/bar/nv50.c
index 160d27f..090d594 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/bar/nv50.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/bar/nv50.c
@@ -25,10 +25,11 @@
 #include <core/gpuobj.h>
 
 #include <subdev/timer.h>
-#include <subdev/bar.h>
 #include <subdev/fb.h>
 #include <subdev/vm.h>
 
+#include "priv.h"
+
 struct nv50_bar_priv {
  struct nouveau_bar base;
  spinlock_t lock;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/bar/nvc0.c b/drivers/gpu/drm/nouveau/core/subdev/bar/nvc0.c
index b2ec741..bac5e75 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/bar/nvc0.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/bar/nvc0.c
@@ -25,10 +25,11 @@
 #include <core/gpuobj.h>
 
 #include <subdev/timer.h>
-#include <subdev/bar.h>
 #include <subdev/fb.h>
 #include <subdev/vm.h>
 
+#include "priv.h"
+
 struct nvc0_bar_priv {
  struct nouveau_bar base;
  spinlock_t lock;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/bar/priv.h b/drivers/gpu/drm/nouveau/core/subdev/bar/priv.h
new file mode 100644
index 0000000..ffad8f3
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/bar/priv.h
@@ -0,0 +1,26 @@
+#ifndef __NVKM_BAR_PRIV_H__
+#define __NVKM_BAR_PRIV_H__
+
+#include <subdev/bar.h>
+
+#define nouveau_bar_create(p,e,o,d)                                            \
+ nouveau_bar_create_((p), (e), (o), sizeof(**d), (void **)d)
+#define nouveau_bar_init(p)                                                    \
+ nouveau_subdev_init(&(p)->base)
+#define nouveau_bar_fini(p,s)                                                  \
+ nouveau_subdev_fini(&(p)->base, (s))
+
+int nouveau_bar_create_(struct nouveau_object *, struct nouveau_object *,
+   struct nouveau_oclass *, int, void **);
+void nouveau_bar_destroy(struct nouveau_bar *);
+
+void _nouveau_bar_dtor(struct nouveau_object *);
+#define _nouveau_bar_init _nouveau_subdev_init
+#define _nouveau_bar_fini _nouveau_subdev_fini
+
+int  nouveau_bar_alloc(struct nouveau_bar *, struct nouveau_object *,
+         struct nouveau_mem *, struct nouveau_object **);
+
+void nv84_bar_flush(struct nouveau_bar *);
+
+#endif
diff --git a/drivers/gpu/drm/nouveau/core/subdev/bios/base.c b/drivers/gpu/drm/nouveau/core/subdev/bios/base.c
index aa0fbbe..ef0c9c4 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/bios/base.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/bios/base.c
@@ -130,6 +130,10 @@ nouveau_bios_shadow_prom(struct nouveau_bios *bios)
  u16 pcir;
  int i;
 
+ /* there is no prom on nv4x IGP's */
+ if (device->card_type == NV_40 && device->chipset >= 0x4c)
+  return;
+
  /* enable access to rom */
  if (device->card_type >= NV_50)
   pcireg = 0x088050;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/bios/init.c b/drivers/gpu/drm/nouveau/core/subdev/bios/init.c
index df1b1b4..de201ba 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/bios/init.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/bios/init.c
@@ -9,6 +9,7 @@
 #include <subdev/bios/dp.h>
 #include <subdev/bios/gpio.h>
 #include <subdev/bios/init.h>
+#include <subdev/bios/ramcfg.h>
 #include <subdev/devinit.h>
 #include <subdev/i2c.h>
 #include <subdev/vga.h>
@@ -391,43 +392,14 @@ init_unknown_script(struct nouveau_bios *bios)
  return 0x0000;
 }
 
-static u16
-init_ram_restrict_table(struct nvbios_init *init)
-{
- struct nouveau_bios *bios = init->bios;
- struct bit_entry bit_M;
- u16 data = 0x0000;
-
- if (!bit_entry(bios, 'M', &bit_M)) {
-  if (bit_M.version == 1 && bit_M.length >= 5)
-   data = nv_ro16(bios, bit_M.offset + 3);
-  if (bit_M.version == 2 && bit_M.length >= 3)
-   data = nv_ro16(bios, bit_M.offset + 1);
- }
-
- if (data == 0x0000)
-  warn("ram restrict table not found\n");
- return data;
-}
-
 static u8
 init_ram_restrict_group_count(struct nvbios_init *init)
 {
- struct nouveau_bios *bios = init->bios;
- struct bit_entry bit_M;
-
- if (!bit_entry(bios, 'M', &bit_M)) {
-  if (bit_M.version == 1 && bit_M.length >= 5)
-   return nv_ro08(bios, bit_M.offset + 2);
-  if (bit_M.version == 2 && bit_M.length >= 3)
-   return nv_ro08(bios, bit_M.offset + 0);
- }
-
- return 0x00;
+ return nvbios_ramcfg_count(init->bios);
 }
 
 static u8
-init_ram_restrict_strap(struct nvbios_init *init)
+init_ram_restrict(struct nvbios_init *init)
 {
  /* This appears to be the behaviour of the VBIOS parser, and *is*
   * important to cache the NV_PEXTDEV_BOOT0 on later chipsets to
@@ -438,18 +410,8 @@ init_ram_restrict_strap(struct nvbios_init *init)
   * in case *not* re-reading the strap causes similar breakage.
   */
  if (!init->ramcfg || init->bios->version.major < 0x70)
-  init->ramcfg = init_rd32(init, 0x101000);
- return (init->ramcfg & 0x00000003c) >> 2;
-}
-
-static u8
-init_ram_restrict(struct nvbios_init *init)
-{
- u8  strap = init_ram_restrict_strap(init);
- u16 table = init_ram_restrict_table(init);
- if (table)
-  return nv_ro08(init->bios, table + strap);
- return 0x00;
+  init->ramcfg = 0x80000000 | nvbios_ramcfg_index(init->bios);
+ return (init->ramcfg & 0x7fffffff);
 }
 
 static u8
diff --git a/drivers/gpu/drm/nouveau/core/subdev/bios/ramcfg.c b/drivers/gpu/drm/nouveau/core/subdev/bios/ramcfg.c
new file mode 100644
index 0000000..991aedd
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/bios/ramcfg.c
@@ -0,0 +1,67 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs <bskeggs@redhat.com>
+ */
+
+#include <subdev/bios.h>
+#include <subdev/bios/bit.h>
+#include <subdev/bios/ramcfg.h>
+
+static u8
+nvbios_ramcfg_strap(struct nouveau_bios *bios)
+{
+ return (nv_rd32(bios, 0x101000) & 0x0000003c) >> 2;
+}
+
+u8
+nvbios_ramcfg_count(struct nouveau_bios *bios)
+{
+ struct bit_entry bit_M;
+
+ if (!bit_entry(bios, 'M', &bit_M)) {
+  if (bit_M.version == 1 && bit_M.length >= 5)
+   return nv_ro08(bios, bit_M.offset + 2);
+  if (bit_M.version == 2 && bit_M.length >= 3)
+   return nv_ro08(bios, bit_M.offset + 0);
+ }
+
+ return 0x00;
+}
+
+u8
+nvbios_ramcfg_index(struct nouveau_bios *bios)
+{
+ u8 strap = nvbios_ramcfg_strap(bios);
+ u32 xlat = 0x00000000;
+ struct bit_entry bit_M;
+
+ if (!bit_entry(bios, 'M', &bit_M)) {
+  if (bit_M.version == 1 && bit_M.length >= 5)
+   xlat = nv_ro16(bios, bit_M.offset + 3);
+  if (bit_M.version == 2 && bit_M.length >= 3)
+   xlat = nv_ro16(bios, bit_M.offset + 1);
+ }
+
+ if (xlat)
+  strap = nv_ro08(bios, xlat + strap);
+ return strap;
+}
diff --git a/drivers/gpu/drm/nouveau/core/subdev/bios/rammap.c b/drivers/gpu/drm/nouveau/core/subdev/bios/rammap.c
index 916fa9d..1811b2c 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/bios/rammap.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/bios/rammap.c
@@ -24,11 +24,12 @@
 
 #include <subdev/bios.h>
 #include <subdev/bios/bit.h>
+#include <subdev/bios/ramcfg.h>
 #include <subdev/bios/rammap.h>
 
-u16
-nvbios_rammap_table(struct nouveau_bios *bios, u8 *ver, u8 *hdr,
-      u8 *cnt, u8 *len, u8 *snr, u8 *ssz)
+u32
+nvbios_rammapTe(struct nouveau_bios *bios, u8 *ver, u8 *hdr,
+  u8 *cnt, u8 *len, u8 *snr, u8 *ssz)
 {
  struct bit_entry bit_P;
  u16 rammap = 0x0000;
@@ -57,12 +58,12 @@ nvbios_rammap_table(struct nouveau_bios *bios, u8 *ver, u8 *hdr,
  return 0x0000;
 }
 
-u16
-nvbios_rammap_entry(struct nouveau_bios *bios, int idx,
-      u8 *ver, u8 *hdr, u8 *cnt, u8 *len)
+u32
+nvbios_rammapEe(struct nouveau_bios *bios, int idx,
+  u8 *ver, u8 *hdr, u8 *cnt, u8 *len)
 {
  u8  snr, ssz;
- u16 rammap = nvbios_rammap_table(bios, ver, hdr, cnt, len, &snr, &ssz);
+ u16 rammap = nvbios_rammapTe(bios, ver, hdr, cnt, len, &snr, &ssz);
  if (rammap && idx < *cnt) {
   rammap = rammap + *hdr + (idx * (*len + (snr * ssz)));
   *hdr = *len;
@@ -73,16 +74,100 @@ nvbios_rammap_entry(struct nouveau_bios *bios, int idx,
  return 0x0000;
 }
 
-u16
-nvbios_rammap_match(struct nouveau_bios *bios, u16 khz,
-      u8 *ver, u8 *hdr, u8 *cnt, u8 *len)
+u32
+nvbios_rammapEm(struct nouveau_bios *bios, u16 khz,
+  u8 *ver, u8 *hdr, u8 *cnt, u8 *len)
 {
  int idx = 0;
  u32 data;
- while ((data = nvbios_rammap_entry(bios, idx++, ver, hdr, cnt, len))) {
+ while ((data = nvbios_rammapEe(bios, idx++, ver, hdr, cnt, len))) {
   if (khz >= nv_ro16(bios, data + 0x00) &&
       khz <= nv_ro16(bios, data + 0x02))
    break;
  }
  return data;
 }
+
+u32
+nvbios_rammapEp(struct nouveau_bios *bios, u16 khz,
+  u8 *ver, u8 *hdr, u8 *cnt, u8 *len,
+  struct nvbios_ramcfg *p)
+{
+ u32 data = nvbios_rammapEm(bios, khz, ver, hdr, cnt, len);
+ memset(p, 0x00, sizeof(*p));
+ switch (!!data * *ver) {
+ case 0x11:
+  p->rammap_11_08_01 = (nv_ro08(bios, data + 0x08) & 0x01) >> 0;
+  p->rammap_11_08_0c = (nv_ro08(bios, data + 0x08) & 0x0c) >> 2;
+  p->rammap_11_08_10 = (nv_ro08(bios, data + 0x08) & 0x10) >> 4;
+  p->rammap_11_11_0c = (nv_ro08(bios, data + 0x11) & 0x0c) >> 2;
+  break;
+ default:
+  data = 0;
+  break;
+ }
+ return data;
+}
+
+u32
+nvbios_rammapSe(struct nouveau_bios *bios, u32 data,
+  u8 ever, u8 ehdr, u8 ecnt, u8 elen, int idx,
+  u8 *ver, u8 *hdr)
+{
+ if (idx < ecnt) {
+  data = data + ehdr + (idx * elen);
+  *ver = ever;
+  *hdr = elen;
+  return data;
+ }
+ return 0;
+}
+
+u32
+nvbios_rammapSp(struct nouveau_bios *bios, u32 data,
+  u8 ever, u8 ehdr, u8 ecnt, u8 elen, int idx,
+  u8 *ver, u8 *hdr, struct nvbios_ramcfg *p)
+{
+ data = nvbios_rammapSe(bios, data, ever, ehdr, ecnt, elen, idx, ver, hdr);
+ switch (!!data * *ver) {
+ case 0x11:
+  p->ramcfg_11_01_01 = (nv_ro08(bios, data + 0x01) & 0x01) >> 0;
+  p->ramcfg_11_01_02 = (nv_ro08(bios, data + 0x01) & 0x02) >> 1;
+  p->ramcfg_11_01_04 = (nv_ro08(bios, data + 0x01) & 0x04) >> 2;
+  p->ramcfg_11_01_08 = (nv_ro08(bios, data + 0x01) & 0x08) >> 3;
+  p->ramcfg_11_01_10 = (nv_ro08(bios, data + 0x01) & 0x10) >> 4;
+  p->ramcfg_11_01_20 = (nv_ro08(bios, data + 0x01) & 0x20) >> 5;
+  p->ramcfg_11_01_40 = (nv_ro08(bios, data + 0x01) & 0x40) >> 6;
+  p->ramcfg_11_01_80 = (nv_ro08(bios, data + 0x01) & 0x80) >> 7;
+  p->ramcfg_11_02_03 = (nv_ro08(bios, data + 0x02) & 0x03) >> 0;
+  p->ramcfg_11_02_04 = (nv_ro08(bios, data + 0x02) & 0x04) >> 2;
+  p->ramcfg_11_02_08 = (nv_ro08(bios, data + 0x02) & 0x08) >> 3;
+  p->ramcfg_11_02_10 = (nv_ro08(bios, data + 0x02) & 0x10) >> 4;
+  p->ramcfg_11_02_40 = (nv_ro08(bios, data + 0x02) & 0x40) >> 6;
+  p->ramcfg_11_02_80 = (nv_ro08(bios, data + 0x02) & 0x80) >> 7;
+  p->ramcfg_11_03_0f = (nv_ro08(bios, data + 0x03) & 0x0f) >> 0;
+  p->ramcfg_11_03_30 = (nv_ro08(bios, data + 0x03) & 0x30) >> 4;
+  p->ramcfg_11_03_c0 = (nv_ro08(bios, data + 0x03) & 0xc0) >> 6;
+  p->ramcfg_11_03_f0 = (nv_ro08(bios, data + 0x03) & 0xf0) >> 4;
+  p->ramcfg_11_04    = (nv_ro08(bios, data + 0x04) & 0xff) >> 0;
+  p->ramcfg_11_06    = (nv_ro08(bios, data + 0x06) & 0xff) >> 0;
+  p->ramcfg_11_07_02 = (nv_ro08(bios, data + 0x07) & 0x02) >> 1;
+  p->ramcfg_11_07_04 = (nv_ro08(bios, data + 0x07) & 0x04) >> 2;
+  p->ramcfg_11_07_08 = (nv_ro08(bios, data + 0x07) & 0x08) >> 3;
+  p->ramcfg_11_07_10 = (nv_ro08(bios, data + 0x07) & 0x10) >> 4;
+  p->ramcfg_11_07_40 = (nv_ro08(bios, data + 0x07) & 0x40) >> 6;
+  p->ramcfg_11_07_80 = (nv_ro08(bios, data + 0x07) & 0x80) >> 7;
+  p->ramcfg_11_08_01 = (nv_ro08(bios, data + 0x08) & 0x01) >> 0;
+  p->ramcfg_11_08_02 = (nv_ro08(bios, data + 0x08) & 0x02) >> 1;
+  p->ramcfg_11_08_04 = (nv_ro08(bios, data + 0x08) & 0x04) >> 2;
+  p->ramcfg_11_08_08 = (nv_ro08(bios, data + 0x08) & 0x08) >> 3;
+  p->ramcfg_11_08_10 = (nv_ro08(bios, data + 0x08) & 0x10) >> 4;
+  p->ramcfg_11_08_20 = (nv_ro08(bios, data + 0x08) & 0x20) >> 5;
+  p->ramcfg_11_09    = (nv_ro08(bios, data + 0x09) & 0xff) >> 0;
+  break;
+ default:
+  data = 0;
+  break;
+ }
+ return data;
+}
diff --git a/drivers/gpu/drm/nouveau/core/subdev/bios/timing.c b/drivers/gpu/drm/nouveau/core/subdev/bios/timing.c
index 151c2d6..350d44a 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/bios/timing.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/bios/timing.c
@@ -24,11 +24,12 @@
 
 #include <subdev/bios.h>
 #include <subdev/bios/bit.h>
+#include <subdev/bios/ramcfg.h>
 #include <subdev/bios/timing.h>
 
 u16
-nvbios_timing_table(struct nouveau_bios *bios,
-      u8 *ver, u8 *hdr, u8 *cnt, u8 *len)
+nvbios_timingTe(struct nouveau_bios *bios,
+  u8 *ver, u8 *hdr, u8 *cnt, u8 *len, u8 *snr, u8 *ssz)
 {
  struct bit_entry bit_P;
  u16 timing = 0x0000;
@@ -47,11 +48,15 @@ nvbios_timing_table(struct nouveau_bios *bios,
     *hdr = nv_ro08(bios, timing + 1);
     *cnt = nv_ro08(bios, timing + 2);
     *len = nv_ro08(bios, timing + 3);
+    *snr = 0;
+    *ssz = 0;
     return timing;
    case 0x20:
     *hdr = nv_ro08(bios, timing + 1);
-    *cnt = nv_ro08(bios, timing + 3);
+    *cnt = nv_ro08(bios, timing + 5);
     *len = nv_ro08(bios, timing + 2);
+    *snr = nv_ro08(bios, timing + 4);
+    *ssz = nv_ro08(bios, timing + 3);
     return timing;
    default:
     break;
@@ -63,11 +68,60 @@ nvbios_timing_table(struct nouveau_bios *bios,
 }
 
 u16
-nvbios_timing_entry(struct nouveau_bios *bios, int idx, u8 *ver, u8 *len)
+nvbios_timingEe(struct nouveau_bios *bios, int idx,
+  u8 *ver, u8 *hdr, u8 *cnt, u8 *len)
 {
- u8  hdr, cnt;
- u16 timing = nvbios_timing_table(bios, ver, &hdr, &cnt, len);
- if (timing && idx < cnt)
-  return timing + hdr + (idx * *len);
+ u8  snr, ssz;
+ u16 timing = nvbios_timingTe(bios, ver, hdr, cnt, len, &snr, &ssz);
+ if (timing && idx < *cnt) {
+  timing += *hdr + idx * (*len + (snr * ssz));
+  *hdr = *len;
+  *cnt = snr;
+  *len = ssz;
+  return timing;
+ }
  return 0x0000;
 }
+
+u16
+nvbios_timingEp(struct nouveau_bios *bios, int idx,
+  u8 *ver, u8 *hdr, u8 *cnt, u8 *len,
+  struct nvbios_ramcfg *p)
+{
+ u16 data = nvbios_timingEe(bios, idx, ver, hdr, cnt, len), temp;
+ switch (!!data * *ver) {
+ case 0x20:
+  p->timing[0] = nv_ro32(bios, data + 0x00);
+  p->timing[1] = nv_ro32(bios, data + 0x04);
+  p->timing[2] = nv_ro32(bios, data + 0x08);
+  p->timing[3] = nv_ro32(bios, data + 0x0c);
+  p->timing[4] = nv_ro32(bios, data + 0x10);
+  p->timing[5] = nv_ro32(bios, data + 0x14);
+  p->timing[6] = nv_ro32(bios, data + 0x18);
+  p->timing[7] = nv_ro32(bios, data + 0x1c);
+  p->timing[8] = nv_ro32(bios, data + 0x20);
+  p->timing[9] = nv_ro32(bios, data + 0x24);
+  p->timing[10] = nv_ro32(bios, data + 0x28);
+  p->timing_20_2e_03 = (nv_ro08(bios, data + 0x2e) & 0x03) >> 0;
+  p->timing_20_2e_30 = (nv_ro08(bios, data + 0x2e) & 0x30) >> 4;
+  p->timing_20_2e_c0 = (nv_ro08(bios, data + 0x2e) & 0xc0) >> 6;
+  p->timing_20_2f_03 = (nv_ro08(bios, data + 0x2f) & 0x03) >> 0;
+  temp = nv_ro16(bios, data + 0x2c);
+  p->timing_20_2c_003f = (temp & 0x003f) >> 0;
+  p->timing_20_2c_1fc0 = (temp & 0x1fc0) >> 6;
+  p->timing_20_30_07 = (nv_ro08(bios, data + 0x30) & 0x07) >> 0;
+  p->timing_20_30_f8 = (nv_ro08(bios, data + 0x30) & 0xf8) >> 3;
+  temp = nv_ro16(bios, data + 0x31);
+  p->timing_20_31_0007 = (temp & 0x0007) >> 0;
+  p->timing_20_31_0078 = (temp & 0x0078) >> 3;
+  p->timing_20_31_0780 = (temp & 0x0780) >> 7;
+  p->timing_20_31_0800 = (temp & 0x0800) >> 11;
+  p->timing_20_31_7000 = (temp & 0x7000) >> 12;
+  p->timing_20_31_8000 = (temp & 0x8000) >> 15;
+  break;
+ default:
+  data = 0;
+  break;
+ }
+ return data;
+}
diff --git a/drivers/gpu/drm/nouveau/core/subdev/clock/base.c b/drivers/gpu/drm/nouveau/core/subdev/clock/base.c
index e2938a2..dd62bae 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/clock/base.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/clock/base.c
@@ -182,9 +182,12 @@ nouveau_pstate_prog(struct nouveau_clock *clk, int pstatei)
  clk->pstate = pstatei;
 
  if (pfb->ram->calc) {
-  ret = pfb->ram->calc(pfb, pstate->base.domain[nv_clk_src_mem]);
-  if (ret == 0)
-   ret = pfb->ram->prog(pfb);
+  int khz = pstate->base.domain[nv_clk_src_mem];
+  do {
+   ret = pfb->ram->calc(pfb, khz);
+   if (ret == 0)
+    ret = pfb->ram->prog(pfb);
+  } while (ret > 0);
   pfb->ram->tidy(pfb);
  }
 
diff --git a/drivers/gpu/drm/nouveau/core/subdev/clock/nv04.c b/drivers/gpu/drm/nouveau/core/subdev/clock/nv04.c
index 30c1f3a..b74db6c 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/clock/nv04.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/clock/nv04.c
@@ -25,7 +25,7 @@
 #include <subdev/bios.h>
 #include <subdev/bios/pll.h>
 #include <subdev/clock.h>
-#include <subdev/devinit/priv.h>
+#include <subdev/devinit/nv04.h>
 
 #include "pll.h"
 
diff --git a/drivers/gpu/drm/nouveau/core/subdev/clock/nve0.c b/drivers/gpu/drm/nouveau/core/subdev/clock/nve0.c
index 4c62e84..d3c37c9 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/clock/nve0.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/clock/nve0.c
@@ -457,7 +457,7 @@ nve0_domain[] = {
  { nv_clk_src_gpc    , 0x00, NVKM_CLK_DOM_FLAG_CORE, "core", 2000 },
  { nv_clk_src_hubk07 , 0x01, NVKM_CLK_DOM_FLAG_CORE },
  { nv_clk_src_rop    , 0x02, NVKM_CLK_DOM_FLAG_CORE },
- { nv_clk_src_mem    , 0x03, 0, "memory", 1000 },
+ { nv_clk_src_mem    , 0x03, 0, "memory", 500 },
  { nv_clk_src_hubk06 , 0x04, NVKM_CLK_DOM_FLAG_CORE },
  { nv_clk_src_hubk01 , 0x05 },
  { nv_clk_src_vdec   , 0x06 },
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/base.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/base.c
index 79c81d3..8fa34e8 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/base.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/base.c
@@ -24,9 +24,11 @@
 
 #include <core/option.h>
 
-#include <subdev/devinit.h>
 #include <subdev/bios.h>
 #include <subdev/bios/init.h>
+#include <subdev/vga.h>
+
+#include "priv.h"
 
 int
 _nouveau_devinit_fini(struct nouveau_object *object, bool suspend)
@@ -37,18 +39,41 @@ _nouveau_devinit_fini(struct nouveau_object *object, bool suspend)
  if (suspend)
   devinit->post = true;
 
+ /* unlock the extended vga crtc regs */
+ nv_lockvgac(devinit, false);
+
  return nouveau_subdev_fini(&devinit->base, suspend);
 }
 
 int
 _nouveau_devinit_init(struct nouveau_object *object)
 {
+ struct nouveau_devinit_impl *impl = (void *)object->oclass;
  struct nouveau_devinit *devinit = (void *)object;
- int ret = nouveau_subdev_init(&devinit->base);
+ int ret;
+
+ ret = nouveau_subdev_init(&devinit->base);
+ if (ret)
+  return ret;
+
+ ret = nvbios_init(&devinit->base, devinit->post);
  if (ret)
   return ret;
 
- return nvbios_init(&devinit->base, devinit->post);
+ if (impl->disable)
+  nv_device(devinit)->disable_mask |= impl->disable(devinit);
+ return 0;
+}
+
+void
+_nouveau_devinit_dtor(struct nouveau_object *object)
+{
+ struct nouveau_devinit *devinit = (void *)object;
+
+ /* lock crtc regs */
+ nv_lockvgac(devinit, true);
+
+ nouveau_subdev_destroy(&devinit->base);
 }
 
 int
@@ -57,6 +82,7 @@ nouveau_devinit_create_(struct nouveau_object *parent,
    struct nouveau_oclass *oclass,
    int size, void **pobject)
 {
+ struct nouveau_devinit_impl *impl = (void *)oclass;
  struct nouveau_device *device = nv_device(parent);
  struct nouveau_devinit *devinit;
  int ret;
@@ -68,5 +94,7 @@ nouveau_devinit_create_(struct nouveau_object *parent,
   return ret;
 
  devinit->post = nouveau_boolopt(device->cfgopt, "NvForcePost", false);
+ devinit->meminit = impl->meminit;
+ devinit->pll_set = impl->pll_set;
  return 0;
 }
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv04.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv04.c
index 27c8235..7037eae 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv04.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv04.c
@@ -27,12 +27,7 @@
 #include <subdev/vga.h>
 
 #include "fbmem.h"
-#include "priv.h"
-
-struct nv04_devinit_priv {
- struct nouveau_devinit base;
- int owner;
-};
+#include "nv04.h"
 
 static void
 nv04_devinit_meminit(struct nouveau_devinit *devinit)
@@ -393,17 +388,21 @@ int
 nv04_devinit_fini(struct nouveau_object *object, bool suspend)
 {
  struct nv04_devinit_priv *priv = (void *)object;
+ int ret;
 
  /* make i2c busses accessible */
  nv_mask(priv, 0x000200, 0x00000001, 0x00000001);
 
- /* unlock extended vga crtc regs, and unslave crtcs */
- nv_lockvgac(priv, false);
+ ret = nouveau_devinit_fini(&priv->base, suspend);
+ if (ret)
+  return ret;
+
+ /* unslave crtcs */
  if (priv->owner < 0)
   priv->owner = nv_rdvgaowner(priv);
  nv_wrvgaowner(priv, 0);
 
- return nouveau_devinit_fini(&priv->base, suspend);
+ return 0;
 }
 
 int
@@ -431,14 +430,13 @@ nv04_devinit_dtor(struct nouveau_object *object)
 {
  struct nv04_devinit_priv *priv = (void *)object;
 
- /* restore vga owner saved at first init, and lock crtc regs  */
+ /* restore vga owner saved at first init */
  nv_wrvgaowner(priv, priv->owner);
- nv_lockvgac(priv, true);
 
  nouveau_devinit_destroy(&priv->base);
 }
 
-static int
+int
 nv04_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
     struct nouveau_oclass *oclass, void *data, u32 size,
     struct nouveau_object **pobject)
@@ -451,19 +449,19 @@ nv04_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  if (ret)
   return ret;
 
- priv->base.meminit = nv04_devinit_meminit;
- priv->base.pll_set = nv04_devinit_pll_set;
  priv->owner = -1;
  return 0;
 }
 
-struct nouveau_oclass
-nv04_devinit_oclass = {
- .handle = NV_SUBDEV(DEVINIT, 0x04),
- .ofuncs = &(struct nouveau_ofuncs) {
+struct nouveau_oclass *
+nv04_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0x04),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
   .ctor = nv04_devinit_ctor,
   .dtor = nv04_devinit_dtor,
   .init = nv04_devinit_init,
   .fini = nv04_devinit_fini,
  },
-};
+ .meminit = nv04_devinit_meminit,
+ .pll_set = nv04_devinit_pll_set,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv04.h b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv04.h
new file mode 100644
index 0000000..23470a5
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv04.h
@@ -0,0 +1,23 @@
+#ifndef __NVKM_DEVINIT_NV04_H__
+#define __NVKM_DEVINIT_NV04_H__
+
+#include "priv.h"
+
+struct nv04_devinit_priv {
+ struct nouveau_devinit base;
+ u8 owner;
+};
+
+int  nv04_devinit_ctor(struct nouveau_object *, struct nouveau_object *,
+         struct nouveau_oclass *, void *, u32,
+         struct nouveau_object **);
+void nv04_devinit_dtor(struct nouveau_object *);
+int  nv04_devinit_init(struct nouveau_object *);
+int  nv04_devinit_fini(struct nouveau_object *, bool);
+int  nv04_devinit_pll_set(struct nouveau_devinit *, u32, u32);
+
+void setPLL_single(struct nouveau_devinit *, u32, struct nouveau_pll_vals *);
+void setPLL_double_highregs(struct nouveau_devinit *, u32, struct nouveau_pll_vals *);
+void setPLL_double_lowregs(struct nouveau_devinit *, u32, struct nouveau_pll_vals *);
+
+#endif
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv05.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv05.c
index b1912a8..98b7e67 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv05.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv05.c
@@ -29,12 +29,7 @@
 #include <subdev/vga.h>
 
 #include "fbmem.h"
-#include "priv.h"
-
-struct nv05_devinit_priv {
- struct nouveau_devinit base;
- u8 owner;
-};
+#include "nv04.h"
 
 static void
 nv05_devinit_meminit(struct nouveau_devinit *devinit)
@@ -49,7 +44,7 @@ nv05_devinit_meminit(struct nouveau_devinit *devinit)
   { 0x06, 0x00 },
   { 0x00, 0x00 }
  };
- struct nv05_devinit_priv *priv = (void *)devinit;
+ struct nv04_devinit_priv *priv = (void *)devinit;
  struct nouveau_bios *bios = nouveau_bios(priv);
  struct io_mapping *fb;
  u32 patt = 0xdeadbeef;
@@ -130,31 +125,15 @@ out:
  fbmem_fini(fb);
 }
 
-static int
-nv05_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
-    struct nouveau_oclass *oclass, void *data, u32 size,
-    struct nouveau_object **pobject)
-{
- struct nv05_devinit_priv *priv;
- int ret;
-
- ret = nouveau_devinit_create(parent, engine, oclass, &priv);
- *pobject = nv_object(priv);
- if (ret)
-  return ret;
-
- priv->base.meminit = nv05_devinit_meminit;
- priv->base.pll_set = nv04_devinit_pll_set;
- return 0;
-}
-
-struct nouveau_oclass
-nv05_devinit_oclass = {
- .handle = NV_SUBDEV(DEVINIT, 0x05),
- .ofuncs = &(struct nouveau_ofuncs) {
-  .ctor = nv05_devinit_ctor,
+struct nouveau_oclass *
+nv05_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0x05),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nv04_devinit_ctor,
   .dtor = nv04_devinit_dtor,
   .init = nv04_devinit_init,
   .fini = nv04_devinit_fini,
  },
-};
+ .meminit = nv05_devinit_meminit,
+ .pll_set = nv04_devinit_pll_set,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv10.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv10.c
index 8d274db..32b3d21 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv10.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv10.c
@@ -27,17 +27,12 @@
 #include <subdev/vga.h>
 
 #include "fbmem.h"
-#include "priv.h"
-
-struct nv10_devinit_priv {
- struct nouveau_devinit base;
- u8 owner;
-};
+#include "nv04.h"
 
 static void
 nv10_devinit_meminit(struct nouveau_devinit *devinit)
 {
- struct nv10_devinit_priv *priv = (void *)devinit;
+ struct nv04_devinit_priv *priv = (void *)devinit;
  static const int mem_width[] = { 0x10, 0x00, 0x20 };
  int mem_width_count;
  uint32_t patt = 0xdeadbeef;
@@ -101,31 +96,15 @@ amount_found:
  fbmem_fini(fb);
 }
 
-static int
-nv10_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
-    struct nouveau_oclass *oclass, void *data, u32 size,
-    struct nouveau_object **pobject)
-{
- struct nv10_devinit_priv *priv;
- int ret;
-
- ret = nouveau_devinit_create(parent, engine, oclass, &priv);
- *pobject = nv_object(priv);
- if (ret)
-  return ret;
-
- priv->base.meminit = nv10_devinit_meminit;
- priv->base.pll_set = nv04_devinit_pll_set;
- return 0;
-}
-
-struct nouveau_oclass
-nv10_devinit_oclass = {
- .handle = NV_SUBDEV(DEVINIT, 0x10),
- .ofuncs = &(struct nouveau_ofuncs) {
-  .ctor = nv10_devinit_ctor,
+struct nouveau_oclass *
+nv10_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0x10),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nv04_devinit_ctor,
   .dtor = nv04_devinit_dtor,
   .init = nv04_devinit_init,
   .fini = nv04_devinit_fini,
  },
-};
+ .meminit = nv10_devinit_meminit,
+ .pll_set = nv04_devinit_pll_set,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv1a.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv1a.c
index e9743cd..526d0c6 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv1a.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv1a.c
@@ -22,37 +22,16 @@
  * Authors: Ben Skeggs
  */
 
-#include "priv.h"
+#include "nv04.h"
 
-struct nv1a_devinit_priv {
- struct nouveau_devinit base;
- u8 owner;
-};
-
-static int
-nv1a_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
-    struct nouveau_oclass *oclass, void *data, u32 size,
-    struct nouveau_object **pobject)
-{
- struct nv1a_devinit_priv *priv;
- int ret;
-
- ret = nouveau_devinit_create(parent, engine, oclass, &priv);
- *pobject = nv_object(priv);
- if (ret)
-  return ret;
-
- priv->base.pll_set = nv04_devinit_pll_set;
- return 0;
-}
-
-struct nouveau_oclass
-nv1a_devinit_oclass = {
- .handle = NV_SUBDEV(DEVINIT, 0x1a),
- .ofuncs = &(struct nouveau_ofuncs) {
-  .ctor = nv1a_devinit_ctor,
+struct nouveau_oclass *
+nv1a_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0x1a),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nv04_devinit_ctor,
   .dtor = nv04_devinit_dtor,
   .init = nv04_devinit_init,
   .fini = nv04_devinit_fini,
  },
-};
+ .pll_set = nv04_devinit_pll_set,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv20.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv20.c
index 6cc6080..4689ba3 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv20.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv20.c
@@ -24,18 +24,13 @@
  *
  */
 
-#include "priv.h"
+#include "nv04.h"
 #include "fbmem.h"
 
-struct nv20_devinit_priv {
- struct nouveau_devinit base;
- u8 owner;
-};
-
 static void
 nv20_devinit_meminit(struct nouveau_devinit *devinit)
 {
- struct nv20_devinit_priv *priv = (void *)devinit;
+ struct nv04_devinit_priv *priv = (void *)devinit;
  struct nouveau_device *device = nv_device(priv);
  uint32_t mask = (device->chipset >= 0x25 ? 0x300 : 0x900);
  uint32_t amount, off;
@@ -65,31 +60,15 @@ nv20_devinit_meminit(struct nouveau_devinit *devinit)
  fbmem_fini(fb);
 }
 
-static int
-nv20_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
-    struct nouveau_oclass *oclass, void *data, u32 size,
-    struct nouveau_object **pobject)
-{
- struct nv20_devinit_priv *priv;
- int ret;
-
- ret = nouveau_devinit_create(parent, engine, oclass, &priv);
- *pobject = nv_object(priv);
- if (ret)
-  return ret;
-
- priv->base.meminit = nv20_devinit_meminit;
- priv->base.pll_set = nv04_devinit_pll_set;
- return 0;
-}
-
-struct nouveau_oclass
-nv20_devinit_oclass = {
- .handle = NV_SUBDEV(DEVINIT, 0x20),
- .ofuncs = &(struct nouveau_ofuncs) {
-  .ctor = nv20_devinit_ctor,
+struct nouveau_oclass *
+nv20_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0x20),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nv04_devinit_ctor,
   .dtor = nv04_devinit_dtor,
   .init = nv04_devinit_init,
   .fini = nv04_devinit_fini,
  },
-};
+ .meminit = nv20_devinit_meminit,
+ .pll_set = nv04_devinit_pll_set,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv50.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv50.c
index 6df7224..b46c62a 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv50.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv50.c
@@ -28,9 +28,9 @@
 #include <subdev/bios/init.h>
 #include <subdev/vga.h>
 
-#include "priv.h"
+#include "nv50.h"
 
-static int
+int
 nv50_devinit_pll_set(struct nouveau_devinit *devinit, u32 type, u32 freq)
 {
  struct nv50_devinit_priv *priv = (void *)devinit;
@@ -74,6 +74,19 @@ nv50_devinit_pll_set(struct nouveau_devinit *devinit, u32 type, u32 freq)
  return 0;
 }
 
+static u64
+nv50_devinit_disable(struct nouveau_devinit *devinit)
+{
+ struct nv50_devinit_priv *priv = (void *)devinit;
+ u32 r001540 = nv_rd32(priv, 0x001540);
+ u64 disable = 0ULL;
+
+ if (!(r001540 & 0x40000000))
+  disable |= (1ULL << NVDEV_ENGINE_MPEG);
+
+ return disable;
+}
+
 int
 nv50_devinit_init(struct nouveau_object *object)
 {
@@ -120,7 +133,7 @@ nv50_devinit_init(struct nouveau_object *object)
  return 0;
 }
 
-static int
+int
 nv50_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
     struct nouveau_oclass *oclass, void *data, u32 size,
     struct nouveau_object **pobject)
@@ -133,17 +146,18 @@ nv50_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  if (ret)
   return ret;
 
- priv->base.pll_set = nv50_devinit_pll_set;
  return 0;
 }
 
-struct nouveau_oclass
-nv50_devinit_oclass = {
- .handle = NV_SUBDEV(DEVINIT, 0x50),
- .ofuncs = &(struct nouveau_ofuncs) {
+struct nouveau_oclass *
+nv50_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0x50),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
   .ctor = nv50_devinit_ctor,
   .dtor = _nouveau_devinit_dtor,
   .init = nv50_devinit_init,
   .fini = _nouveau_devinit_fini,
  },
-};
+ .pll_set = nv50_devinit_pll_set,
+ .disable = nv50_devinit_disable,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv50.h b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv50.h
new file mode 100644
index 0000000..141c27e
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv50.h
@@ -0,0 +1,18 @@
+#ifndef __NVKM_DEVINIT_NV50_H__
+#define __NVKM_DEVINIT_NV50_H__
+
+#include "priv.h"
+
+struct nv50_devinit_priv {
+ struct nouveau_devinit base;
+};
+
+int  nv50_devinit_ctor(struct nouveau_object *, struct nouveau_object *,
+         struct nouveau_oclass *, void *, u32,
+         struct nouveau_object **);
+int  nv50_devinit_init(struct nouveau_object *);
+int  nv50_devinit_pll_set(struct nouveau_devinit *, u32, u32);
+
+int  nva3_devinit_pll_set(struct nouveau_devinit *, u32, u32);
+
+#endif
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv84.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv84.c
new file mode 100644
index 0000000..7874225
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv84.c
@@ -0,0 +1,63 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+
+#include "nv50.h"
+
+static u64
+nv84_devinit_disable(struct nouveau_devinit *devinit)
+{
+ struct nv50_devinit_priv *priv = (void *)devinit;
+ u32 r001540 = nv_rd32(priv, 0x001540);
+ u32 r00154c = nv_rd32(priv, 0x00154c);
+ u64 disable = 0ULL;
+
+ if (!(r001540 & 0x40000000)) {
+  disable |= (1ULL << NVDEV_ENGINE_MPEG);
+  disable |= (1ULL << NVDEV_ENGINE_VP);
+  disable |= (1ULL << NVDEV_ENGINE_BSP);
+  disable |= (1ULL << NVDEV_ENGINE_CRYPT);
+ }
+
+ if (!(r00154c & 0x00000004))
+  disable |= (1ULL << NVDEV_ENGINE_DISP);
+ if (!(r00154c & 0x00000020))
+  disable |= (1ULL << NVDEV_ENGINE_BSP);
+ if (!(r00154c & 0x00000040))
+  disable |= (1ULL << NVDEV_ENGINE_CRYPT);
+
+ return disable;
+}
+
+struct nouveau_oclass *
+nv84_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0x84),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nv50_devinit_ctor,
+  .dtor = _nouveau_devinit_dtor,
+  .init = nv50_devinit_init,
+  .fini = _nouveau_devinit_fini,
+ },
+ .pll_set = nv50_devinit_pll_set,
+ .disable = nv84_devinit_disable,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nv98.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv98.c
new file mode 100644
index 0000000..2b0e963
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nv98.c
@@ -0,0 +1,62 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+
+#include "nv50.h"
+
+static u64
+nv98_devinit_disable(struct nouveau_devinit *devinit)
+{
+ struct nv50_devinit_priv *priv = (void *)devinit;
+ u32 r001540 = nv_rd32(priv, 0x001540);
+ u32 r00154c = nv_rd32(priv, 0x00154c);
+ u64 disable = 0ULL;
+
+ if (!(r001540 & 0x40000000)) {
+  disable |= (1ULL << NVDEV_ENGINE_VP);
+  disable |= (1ULL << NVDEV_ENGINE_BSP);
+  disable |= (1ULL << NVDEV_ENGINE_PPP);
+ }
+
+ if (!(r00154c & 0x00000004))
+  disable |= (1ULL << NVDEV_ENGINE_DISP);
+ if (!(r00154c & 0x00000020))
+  disable |= (1ULL << NVDEV_ENGINE_BSP);
+ if (!(r00154c & 0x00000040))
+  disable |= (1ULL << NVDEV_ENGINE_CRYPT);
+
+ return disable;
+}
+
+struct nouveau_oclass *
+nv98_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0x98),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nv50_devinit_ctor,
+  .dtor = _nouveau_devinit_dtor,
+  .init = nv50_devinit_init,
+  .fini = _nouveau_devinit_fini,
+ },
+ .pll_set = nv50_devinit_pll_set,
+ .disable = nv98_devinit_disable,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nva3.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nva3.c
index 76a68b2..6dedf1d 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/nva3.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nva3.c
@@ -22,12 +22,12 @@
  * Authors: Ben Skeggs
  */
 
-#include "priv.h"
+#include "nv50.h"
 
-static int
+int
 nva3_devinit_pll_set(struct nouveau_devinit *devinit, u32 type, u32 freq)
 {
- struct nva3_devinit_priv *priv = (void *)devinit;
+ struct nv50_devinit_priv *priv = (void *)devinit;
  struct nouveau_bios *bios = nouveau_bios(priv);
  struct nvbios_pll info;
  int N, fN, M, P;
@@ -58,30 +58,38 @@ nva3_devinit_pll_set(struct nouveau_devinit *devinit, u32 type, u32 freq)
  return ret;
 }
 
-static int
-nva3_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
-    struct nouveau_oclass *oclass, void *data, u32 size,
-    struct nouveau_object **pobject)
+static u64
+nva3_devinit_disable(struct nouveau_devinit *devinit)
 {
- struct nv50_devinit_priv *priv;
- int ret;
+ struct nv50_devinit_priv *priv = (void *)devinit;
+ u32 r001540 = nv_rd32(priv, 0x001540);
+ u32 r00154c = nv_rd32(priv, 0x00154c);
+ u64 disable = 0ULL;
 
- ret = nouveau_devinit_create(parent, engine, oclass, &priv);
- *pobject = nv_object(priv);
- if (ret)
-  return ret;
+ if (!(r001540 & 0x40000000)) {
+  disable |= (1ULL << NVDEV_ENGINE_VP);
+  disable |= (1ULL << NVDEV_ENGINE_PPP);
+ }
+
+ if (!(r00154c & 0x00000004))
+  disable |= (1ULL << NVDEV_ENGINE_DISP);
+ if (!(r00154c & 0x00000020))
+  disable |= (1ULL << NVDEV_ENGINE_BSP);
+ if (!(r00154c & 0x00000200))
+  disable |= (1ULL << NVDEV_ENGINE_COPY0);
 
- priv->base.pll_set = nva3_devinit_pll_set;
- return 0;
+ return disable;
 }
 
-struct nouveau_oclass
-nva3_devinit_oclass = {
- .handle = NV_SUBDEV(DEVINIT, 0xa3),
- .ofuncs = &(struct nouveau_ofuncs) {
-  .ctor = nva3_devinit_ctor,
+struct nouveau_oclass *
+nva3_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0xa3),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nv50_devinit_ctor,
   .dtor = _nouveau_devinit_dtor,
   .init = nv50_devinit_init,
   .fini = _nouveau_devinit_fini,
  },
-};
+ .pll_set = nva3_devinit_pll_set,
+ .disable = nva3_devinit_disable,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nvaf.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nvaf.c
new file mode 100644
index 0000000..4fc68d2
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nvaf.c
@@ -0,0 +1,63 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+
+#include "nv50.h"
+
+static u64
+nvaf_devinit_disable(struct nouveau_devinit *devinit)
+{
+ struct nv50_devinit_priv *priv = (void *)devinit;
+ u32 r001540 = nv_rd32(priv, 0x001540);
+ u32 r00154c = nv_rd32(priv, 0x00154c);
+ u64 disable = 0;
+
+ if (!(r001540 & 0x40000000)) {
+  disable |= (1ULL << NVDEV_ENGINE_VP);
+  disable |= (1ULL << NVDEV_ENGINE_PPP);
+ }
+
+ if (!(r00154c & 0x00000004))
+  disable |= (1ULL << NVDEV_ENGINE_DISP);
+ if (!(r00154c & 0x00000020))
+  disable |= (1ULL << NVDEV_ENGINE_BSP);
+ if (!(r00154c & 0x00000040))
+  disable |= (1ULL << NVDEV_ENGINE_VIC);
+ if (!(r00154c & 0x00000200))
+  disable |= (1ULL << NVDEV_ENGINE_COPY0);
+
+ return disable;
+}
+
+struct nouveau_oclass *
+nvaf_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0xaf),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nv50_devinit_ctor,
+  .dtor = _nouveau_devinit_dtor,
+  .init = nv50_devinit_init,
+  .fini = _nouveau_devinit_fini,
+ },
+ .pll_set = nva3_devinit_pll_set,
+ .disable = nvaf_devinit_disable,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/nvc0.c b/drivers/gpu/drm/nouveau/core/subdev/devinit/nvc0.c
index 19e265b..fa7e637 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/nvc0.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/nvc0.c
@@ -22,12 +22,12 @@
  * Authors: Ben Skeggs
  */
 
-#include "priv.h"
+#include "nv50.h"
 
 static int
 nvc0_devinit_pll_set(struct nouveau_devinit *devinit, u32 type, u32 freq)
 {
- struct nvc0_devinit_priv *priv = (void *)devinit;
+ struct nv50_devinit_priv *priv = (void *)devinit;
  struct nouveau_bios *bios = nouveau_bios(priv);
  struct nvbios_pll info;
  int N, fN, M, P;
@@ -59,6 +59,33 @@ nvc0_devinit_pll_set(struct nouveau_devinit *devinit, u32 type, u32 freq)
  return ret;
 }
 
+static u64
+nvc0_devinit_disable(struct nouveau_devinit *devinit)
+{
+ struct nv50_devinit_priv *priv = (void *)devinit;
+ u32 r022500 = nv_rd32(priv, 0x022500);
+ u64 disable = 0ULL;
+
+ if (r022500 & 0x00000001)
+  disable |= (1ULL << NVDEV_ENGINE_DISP);
+
+ if (r022500 & 0x00000002) {
+  disable |= (1ULL << NVDEV_ENGINE_VP);
+  disable |= (1ULL << NVDEV_ENGINE_PPP);
+ }
+
+ if (r022500 & 0x00000004)
+  disable |= (1ULL << NVDEV_ENGINE_BSP);
+ if (r022500 & 0x00000008)
+  disable |= (1ULL << NVDEV_ENGINE_VENC);
+ if (r022500 & 0x00000100)
+  disable |= (1ULL << NVDEV_ENGINE_COPY0);
+ if (r022500 & 0x00000200)
+  disable |= (1ULL << NVDEV_ENGINE_COPY1);
+
+ return disable;
+}
+
 static int
 nvc0_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
     struct nouveau_oclass *oclass, void *data, u32 size,
@@ -72,19 +99,20 @@ nvc0_devinit_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  if (ret)
   return ret;
 
- priv->base.pll_set = nvc0_devinit_pll_set;
  if (nv_rd32(priv, 0x022500) & 0x00000001)
   priv->base.post = true;
  return 0;
 }
 
-struct nouveau_oclass
-nvc0_devinit_oclass = {
- .handle = NV_SUBDEV(DEVINIT, 0xc0),
- .ofuncs = &(struct nouveau_ofuncs) {
+struct nouveau_oclass *
+nvc0_devinit_oclass = &(struct nouveau_devinit_impl) {
+ .base.handle = NV_SUBDEV(DEVINIT, 0xc0),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
   .ctor = nvc0_devinit_ctor,
   .dtor = _nouveau_devinit_dtor,
   .init = nv50_devinit_init,
   .fini = _nouveau_devinit_fini,
  },
-};
+ .pll_set = nvc0_devinit_pll_set,
+ .disable = nvc0_devinit_disable,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/devinit/priv.h b/drivers/gpu/drm/nouveau/core/subdev/devinit/priv.h
index 7d622e2..822a2fb 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/devinit/priv.h
+++ b/drivers/gpu/drm/nouveau/core/subdev/devinit/priv.h
@@ -6,20 +6,32 @@
 #include <subdev/clock/pll.h>
 #include <subdev/devinit.h>
 
-void nv04_devinit_dtor(struct nouveau_object *);
-int  nv04_devinit_init(struct nouveau_object *);
-int  nv04_devinit_fini(struct nouveau_object *, bool);
-int  nv04_devinit_pll_set(struct nouveau_devinit *, u32, u32);
-
-void setPLL_single(struct nouveau_devinit *, u32, struct nouveau_pll_vals *);
-void setPLL_double_highregs(struct nouveau_devinit *, u32, struct nouveau_pll_vals *);
-void setPLL_double_lowregs(struct nouveau_devinit *, u32, struct nouveau_pll_vals *);
-
-
-struct nv50_devinit_priv {
- struct nouveau_devinit base;
+struct nouveau_devinit_impl {
+ struct nouveau_oclass base;
+ void (*meminit)(struct nouveau_devinit *);
+ int  (*pll_set)(struct nouveau_devinit *, u32 type, u32 freq);
+ u64  (*disable)(struct nouveau_devinit *);
 };
 
-int  nv50_devinit_init(struct nouveau_object *);
+#define nouveau_devinit_create(p,e,o,d)                                        \
+ nouveau_devinit_create_((p), (e), (o), sizeof(**d), (void **)d)
+#define nouveau_devinit_destroy(p) ({                                          \
+ struct nouveau_devinit *d = (p);                                       \
+ _nouveau_devinit_dtor(nv_object(d));                                   \
+})
+#define nouveau_devinit_init(p) ({                                             \
+ struct nouveau_devinit *d = (p);                                       \
+ _nouveau_devinit_init(nv_object(d));                                   \
+})
+#define nouveau_devinit_fini(p,s) ({                                           \
+ struct nouveau_devinit *d = (p);                                       \
+ _nouveau_devinit_fini(nv_object(d), (s));                              \
+})
+
+int nouveau_devinit_create_(struct nouveau_object *, struct nouveau_object *,
+       struct nouveau_oclass *, int, void **);
+void _nouveau_devinit_dtor(struct nouveau_object *);
+int _nouveau_devinit_init(struct nouveau_object *);
+int _nouveau_devinit_fini(struct nouveau_object *, bool suspend);
 
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/subdev/fb/gddr5.c b/drivers/gpu/drm/nouveau/core/subdev/fb/gddr5.c
index 34f9605..66fe959 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/fb/gddr5.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/fb/gddr5.c
@@ -25,35 +25,44 @@
 #include <subdev/bios.h>
 #include "priv.h"
 
+/* binary driver only executes this path if the condition (a) is true
+ * for any configuration (combination of rammap+ramcfg+timing) that
+ * can be reached on a given card.  for now, we will execute the branch
+ * unconditionally in the hope that a "false everywhere" in the bios
+ * tables doesn't actually mean "don't touch this".
+ */
+#define NOTE00(a) 1
+
 int
-nouveau_gddr5_calc(struct nouveau_ram *ram)
+nouveau_gddr5_calc(struct nouveau_ram *ram, bool nuts)
 {
- struct nouveau_bios *bios = nouveau_bios(ram);
- int pd, lf, xd, vh, vr, vo;
- int WL, CL, WR, at, dt, ds;
+ int pd, lf, xd, vh, vr, vo, l3;
+ int WL, CL, WR, at[2], dt, ds;
  int rq = ram->freq < 1000000; /* XXX */
 
- switch (!!ram->ramcfg.data * ram->ramcfg.version) {
+ switch (ram->ramcfg.version) {
  case 0x11:
-  pd =  (nv_ro08(bios, ram->ramcfg.data + 0x01) & 0x80) >> 7;
-  lf =  (nv_ro08(bios, ram->ramcfg.data + 0x01) & 0x40) >> 6;
-  xd = !(nv_ro08(bios, ram->ramcfg.data + 0x01) & 0x20);
-  vh =  (nv_ro08(bios, ram->ramcfg.data + 0x02) & 0x10) >> 4;
-  vr =  (nv_ro08(bios, ram->ramcfg.data + 0x02) & 0x04) >> 2;
-  vo =   nv_ro08(bios, ram->ramcfg.data + 0x06) & 0xff;
+  pd =  ram->next->bios.ramcfg_11_01_80;
+  lf =  ram->next->bios.ramcfg_11_01_40;
+  xd = !ram->next->bios.ramcfg_11_01_20;
+  vh =  ram->next->bios.ramcfg_11_02_10;
+  vr =  ram->next->bios.ramcfg_11_02_04;
+  vo =  ram->next->bios.ramcfg_11_06;
+  l3 = !ram->next->bios.ramcfg_11_07_02;
   break;
  default:
   return -ENOSYS;
  }
 
- switch (!!ram->timing.data * ram->timing.version) {
+ switch (ram->timing.version) {
  case 0x20:
-  WL = (nv_ro16(bios, ram->timing.data + 0x04) & 0x0f80) >> 7;
-  CL =  nv_ro08(bios, ram->timing.data + 0x04) & 0x1f;
-  WR =  nv_ro08(bios, ram->timing.data + 0x0a) & 0x7f;
-  at = (nv_ro08(bios, ram->timing.data + 0x2e) & 0xc0) >> 6;
-  dt =  nv_ro08(bios, ram->timing.data + 0x2e) & 0x03;
-  ds =  nv_ro08(bios, ram->timing.data + 0x2f) & 0x03;
+  WL = (ram->next->bios.timing[1] & 0x00000f80) >> 7;
+  CL = (ram->next->bios.timing[1] & 0x0000001f);
+  WR = (ram->next->bios.timing[2] & 0x007f0000) >> 16;
+  at[0] = ram->next->bios.timing_20_2e_c0;
+  at[1] = ram->next->bios.timing_20_2e_30;
+  dt =  ram->next->bios.timing_20_2e_03;
+  ds =  ram->next->bios.timing_20_2f_03;
   break;
  default:
   return -ENOSYS;
@@ -71,13 +80,25 @@ nouveau_gddr5_calc(struct nouveau_ram *ram)
 
  ram->mr[1] &= ~0x0bf;
  ram->mr[1] |= (xd & 0x01) << 7;
- ram->mr[1] |= (at & 0x03) << 4;
+ ram->mr[1] |= (at[0] & 0x03) << 4;
  ram->mr[1] |= (dt & 0x03) << 2;
  ram->mr[1] |= (ds & 0x03) << 0;
 
+ /* this seems wrong, alternate field used for the broadcast
+  * on nuts vs non-nuts configs..  meh, it matches for now.
+  */
+ ram->mr1_nuts = ram->mr[1];
+ if (nuts) {
+  ram->mr[1] &= ~0x030;
+  ram->mr[1] |= (at[1] & 0x03) << 4;
+ }
+
  ram->mr[3] &= ~0x020;
  ram->mr[3] |= (rq & 0x01) << 5;
 
+ ram->mr[5] &= ~0x004;
+ ram->mr[5] |= (l3 << 2);
+
  if (!vo)
   vo = (ram->mr[6] & 0xff0) >> 4;
  if (ram->mr[6] & 0x001)
@@ -86,11 +107,16 @@ nouveau_gddr5_calc(struct nouveau_ram *ram)
  ram->mr[6] |= (vo & 0xff) << 4;
  ram->mr[6] |= (pd & 0x01) << 0;
 
- if (!(ram->mr[7] & 0x100))
-  vr = 0; /* binary driver does this.. bug? */
- ram->mr[7] &= ~0x188;
- ram->mr[7] |= (vr & 0x01) << 8;
+ if (NOTE00(vr)) {
+  ram->mr[7] &= ~0x300;
+  ram->mr[7] |= (vr & 0x03) << 8;
+ }
+ ram->mr[7] &= ~0x088;
  ram->mr[7] |= (vh & 0x01) << 7;
  ram->mr[7] |= (lf & 0x01) << 3;
+
+ ram->mr[8] &= ~0x003;
+ ram->mr[8] |= (WR & 0x10) >> 3;
+ ram->mr[8] |= (CL & 0x10) >> 4;
  return 0;
 }
diff --git a/drivers/gpu/drm/nouveau/core/subdev/fb/nvc0.c b/drivers/gpu/drm/nouveau/core/subdev/fb/nvc0.c
index e5fc37c..45470e1 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/fb/nvc0.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/fb/nvc0.c
@@ -33,6 +33,21 @@ nvc0_fb_memtype_valid(struct nouveau_fb *pfb, u32 tile_flags)
  return likely((nvc0_pte_storage_type_map[memtype] != 0xff));
 }
 
+static void
+nvc0_fb_intr(struct nouveau_subdev *subdev)
+{
+ struct nvc0_fb_priv *priv = (void *)subdev;
+ u32 intr = nv_rd32(priv, 0x000100);
+ if (intr & 0x08000000) {
+  nv_debug(priv, "PFFB intr\n");
+  intr &= ~0x08000000;
+ }
+ if (intr & 0x00002000) {
+  nv_debug(priv, "PBFB intr\n");
+  intr &= ~0x00002000;
+ }
+}
+
 int
 nvc0_fb_init(struct nouveau_object *object)
 {
@@ -86,6 +101,7 @@ nvc0_fb_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
    return -EFAULT;
  }
 
+ nv_subdev(priv)->intr = nvc0_fb_intr;
  return 0;
 }
 
diff --git a/drivers/gpu/drm/nouveau/core/subdev/fb/priv.h b/drivers/gpu/drm/nouveau/core/subdev/fb/priv.h
index 4931252..edaf95d 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/fb/priv.h
+++ b/drivers/gpu/drm/nouveau/core/subdev/fb/priv.h
@@ -34,7 +34,7 @@ extern struct nouveau_oclass nvc0_ram_oclass;
 extern struct nouveau_oclass nve0_ram_oclass;
 
 int nouveau_sddr3_calc(struct nouveau_ram *ram);
-int nouveau_gddr5_calc(struct nouveau_ram *ram);
+int nouveau_gddr5_calc(struct nouveau_ram *ram, bool nuts);
 
 #define nouveau_fb_create(p,e,c,d)                                             \
  nouveau_fb_create_((p), (e), (c), sizeof(**d), (void **)d)
diff --git a/drivers/gpu/drm/nouveau/core/subdev/fb/ramnv50.c b/drivers/gpu/drm/nouveau/core/subdev/fb/ramnv50.c
index 76762a1..c7fdb3a 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/fb/ramnv50.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/fb/ramnv50.c
@@ -70,13 +70,11 @@ nv50_ram_calc(struct nouveau_fb *pfb, u32 freq)
  struct nv50_ramseq *hwsq = &ram->hwsq;
  struct nvbios_perfE perfE;
  struct nvbios_pll mpll;
- struct bit_entry M;
  struct {
   u32 data;
   u8  size;
  } ramcfg, timing;
- u8  ver, hdr, cnt, strap;
- u32 data;
+ u8  ver, hdr, cnt, len, strap;
  int N1, M1, N2, M2, P;
  int ret, i;
 
@@ -93,16 +91,7 @@ nv50_ram_calc(struct nouveau_fb *pfb, u32 freq)
  } while (perfE.memory < freq);
 
  /* locate specific data set for the attached memory */
- if (bit_entry(bios, 'M', &M) || M.version != 1 || M.length < 5) {
-  nv_error(pfb, "invalid/missing memory table\n");
-  return -EINVAL;
- }
-
- strap = (nv_rd32(pfb, 0x101000) & 0x0000003c) >> 2;
- data = nv_ro16(bios, M.offset + 3);
- if (data)
-  strap = nv_ro08(bios, data + strap);
-
+ strap = nvbios_ramcfg_index(bios);
  if (strap >= cnt) {
   nv_error(pfb, "invalid ramcfg strap\n");
   return -EINVAL;
@@ -113,7 +102,8 @@ nv50_ram_calc(struct nouveau_fb *pfb, u32 freq)
  /* lookup memory timings, if bios says they're present */
  strap = nv_ro08(bios, ramcfg.data + 0x01);
  if (strap != 0xff) {
-  timing.data = nvbios_timing_entry(bios, strap, &ver, &hdr);
+  timing.data = nvbios_timingEe(bios, strap, &ver, &hdr,
+          &cnt, &len);
   if (!timing.data || ver != 0x10 || hdr < 0x12) {
    nv_error(pfb, "invalid/missing timing entry "
      "%02x %04x %02x %02x\n",
diff --git a/drivers/gpu/drm/nouveau/core/subdev/fb/ramnva3.c b/drivers/gpu/drm/nouveau/core/subdev/fb/ramnva3.c
index f6292cd..f4ae8aa 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/fb/ramnva3.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/fb/ramnva3.c
@@ -79,8 +79,7 @@ nva3_ram_calc(struct nouveau_fb *pfb, u32 freq)
  struct nva3_ram *ram = (void *)pfb->ram;
  struct nva3_ramfuc *fuc = &ram->fuc;
  struct nva3_clock_info mclk;
- struct bit_entry M;
- u8  ver, cnt, strap;
+ u8  ver, cnt, len, strap;
  u32 data;
  struct {
   u32 data;
@@ -91,24 +90,15 @@ nva3_ram_calc(struct nouveau_fb *pfb, u32 freq)
  int ret;
 
  /* lookup memory config data relevant to the target frequency */
- rammap.data = nvbios_rammap_match(bios, freq / 1000, &ver, &rammap.size,
-      &cnt, &ramcfg.size);
+ rammap.data = nvbios_rammapEm(bios, freq / 1000, &ver, &rammap.size,
+         &cnt, &ramcfg.size);
  if (!rammap.data || ver != 0x10 || rammap.size < 0x0e) {
   nv_error(pfb, "invalid/missing rammap entry\n");
   return -EINVAL;
  }
 
  /* locate specific data set for the attached memory */
- if (bit_entry(bios, 'M', &M) || M.version != 2 || M.length < 3) {
-  nv_error(pfb, "invalid/missing memory table\n");
-  return -EINVAL;
- }
-
- strap = (nv_rd32(pfb, 0x101000) & 0x0000003c) >> 2;
- data = nv_ro16(bios, M.offset + 1);
- if (data)
-  strap = nv_ro08(bios, data + strap);
-
+ strap = nvbios_ramcfg_index(bios);
  if (strap >= cnt) {
   nv_error(pfb, "invalid ramcfg strap\n");
   return -EINVAL;
@@ -123,8 +113,8 @@ nva3_ram_calc(struct nouveau_fb *pfb, u32 freq)
  /* lookup memory timings, if bios says they're present */
  strap = nv_ro08(bios, ramcfg.data + 0x01);
  if (strap != 0xff) {
-  timing.data = nvbios_timing_entry(bios, strap, &ver,
-       &timing.size);
+  timing.data = nvbios_timingEe(bios, strap, &ver, &timing.size,
+          &cnt, &len);
   if (!timing.data || ver != 0x10 || timing.size < 0x19) {
    nv_error(pfb, "invalid/missing timing entry\n");
    return -EINVAL;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/fb/ramnvc0.c b/drivers/gpu/drm/nouveau/core/subdev/fb/ramnvc0.c
index f464547..0391b82 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/fb/ramnvc0.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/fb/ramnvc0.c
@@ -23,7 +23,6 @@
  */
 
 #include <subdev/bios.h>
-#include <subdev/bios/bit.h>
 #include <subdev/bios/pll.h>
 #include <subdev/bios/rammap.h>
 #include <subdev/bios/timing.h>
@@ -134,9 +133,7 @@ nvc0_ram_calc(struct nouveau_fb *pfb, u32 freq)
  struct nouveau_bios *bios = nouveau_bios(pfb);
  struct nvc0_ram *ram = (void *)pfb->ram;
  struct nvc0_ramfuc *fuc = &ram->fuc;
- struct bit_entry M;
- u8  ver, cnt, strap;
- u32 data;
+ u8  ver, cnt, len, strap;
  struct {
   u32 data;
   u8  size;
@@ -147,24 +144,15 @@ nvc0_ram_calc(struct nouveau_fb *pfb, u32 freq)
  int ret;
 
  /* lookup memory config data relevant to the target frequency */
- rammap.data = nvbios_rammap_match(bios, freq / 1000, &ver, &rammap.size,
-      &cnt, &ramcfg.size);
+ rammap.data = nvbios_rammapEm(bios, freq / 1000, &ver, &rammap.size,
+         &cnt, &ramcfg.size);
  if (!rammap.data || ver != 0x10 || rammap.size < 0x0e) {
   nv_error(pfb, "invalid/missing rammap entry\n");
   return -EINVAL;
  }
 
  /* locate specific data set for the attached memory */
- if (bit_entry(bios, 'M', &M) || M.version != 2 || M.length < 3) {
-  nv_error(pfb, "invalid/missing memory table\n");
-  return -EINVAL;
- }
-
- strap = (nv_rd32(pfb, 0x101000) & 0x0000003c) >> 2;
- data = nv_ro16(bios, M.offset + 1);
- if (data)
-  strap = nv_ro08(bios, data + strap);
-
+ strap = nvbios_ramcfg_index(bios);
  if (strap >= cnt) {
   nv_error(pfb, "invalid ramcfg strap\n");
   return -EINVAL;
@@ -179,8 +167,8 @@ nvc0_ram_calc(struct nouveau_fb *pfb, u32 freq)
  /* lookup memory timings, if bios says they're present */
  strap = nv_ro08(bios, ramcfg.data + 0x01);
  if (strap != 0xff) {
-  timing.data = nvbios_timing_entry(bios, strap, &ver,
-       &timing.size);
+  timing.data = nvbios_timingEe(bios, strap, &ver, &timing.size,
+          &cnt, &len);
   if (!timing.data || ver != 0x10 || timing.size < 0x19) {
    nv_error(pfb, "invalid/missing timing entry\n");
    return -EINVAL;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/fb/ramnve0.c b/drivers/gpu/drm/nouveau/core/subdev/fb/ramnve0.c
index bc86cfd..3257c52 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/fb/ramnve0.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/fb/ramnve0.c
@@ -25,7 +25,6 @@
 #include <subdev/gpio.h>
 
 #include <subdev/bios.h>
-#include <subdev/bios/bit.h>
 #include <subdev/bios/pll.h>
 #include <subdev/bios/init.h>
 #include <subdev/bios/rammap.h>
@@ -42,6 +41,14 @@
 
 #include "ramfuc.h"
 
+/* binary driver only executes this path if the condition (a) is true
+ * for any configuration (combination of rammap+ramcfg+timing) that
+ * can be reached on a given card.  for now, we will execute the branch
+ * unconditionally in the hope that a "false everywhere" in the bios
+ * tables doesn't actually mean "don't touch this".
+ */
+#define NOTE00(a) 1
+
 struct nve0_ramfuc {
  struct ramfuc base;
 
@@ -104,7 +111,9 @@ struct nve0_ramfuc {
  struct ramfuc_reg r_mr[16]; /* MR0 - MR8, MR15 */
 
  struct ramfuc_reg r_0x62c000;
+
  struct ramfuc_reg r_0x10f200;
+
  struct ramfuc_reg r_0x10f210;
  struct ramfuc_reg r_0x10f310;
  struct ramfuc_reg r_0x10f314;
@@ -118,12 +127,17 @@ struct nve0_ramfuc {
  struct ramfuc_reg r_0x10f65c;
  struct ramfuc_reg r_0x10f6bc;
  struct ramfuc_reg r_0x100710;
- struct ramfuc_reg r_0x10f750;
+ struct ramfuc_reg r_0x100750;
 };
 
 struct nve0_ram {
  struct nouveau_ram base;
  struct nve0_ramfuc fuc;
+
+ u32 parts;
+ u32 pmask;
+ u32 pnuts;
+
  int from;
  int mode;
  int N1, fN1, M1, P1;
@@ -134,17 +148,17 @@ struct nve0_ram {
  * GDDR5
  ******************************************************************************/
 static void
-train(struct nve0_ramfuc *fuc, u32 magic)
+nve0_ram_train(struct nve0_ramfuc *fuc, u32 mask, u32 data)
 {
  struct nve0_ram *ram = container_of(fuc, typeof(*ram), fuc);
- struct nouveau_fb *pfb = nouveau_fb(ram);
- const int mc = nv_rd32(pfb, 0x02243c);
- int i;
-
- ram_mask(fuc, 0x10f910, 0xbc0e0000, magic);
- ram_mask(fuc, 0x10f914, 0xbc0e0000, magic);
- for (i = 0; i < mc; i++) {
-  const u32 addr = 0x110974 + (i * 0x1000);
+ u32 addr = 0x110974, i;
+
+ ram_mask(fuc, 0x10f910, mask, data);
+ ram_mask(fuc, 0x10f914, mask, data);
+
+ for (i = 0; (data & 0x80000000) && i < ram->parts; addr += 0x1000, i++) {
+  if (ram->pmask & (1 << i))
+   continue;
   ram_wait(fuc, addr, 0x0000000f, 0x00000000, 500000);
  }
 }
@@ -199,12 +213,12 @@ r1373f4_init(struct nve0_ramfuc *fuc)
 }
 
 static void
-r1373f4_fini(struct nve0_ramfuc *fuc, u32 ramcfg)
+r1373f4_fini(struct nve0_ramfuc *fuc)
 {
  struct nve0_ram *ram = container_of(fuc, typeof(*ram), fuc);
- struct nouveau_bios *bios = nouveau_bios(ram);
- u8 v0 = (nv_ro08(bios, ramcfg + 0x03) & 0xc0) >> 6;
- u8 v1 = (nv_ro08(bios, ramcfg + 0x03) & 0x30) >> 4;
+ struct nouveau_ram_data *next = ram->base.next;
+ u8 v0 = next->bios.ramcfg_11_03_c0;
+ u8 v1 = next->bios.ramcfg_11_03_30;
  u32 tmp;
 
  tmp = ram_rd32(fuc, 0x1373ec) & ~0x00030000;
@@ -220,25 +234,46 @@ r1373f4_fini(struct nve0_ramfuc *fuc, u32 ramcfg)
  ram_mask(fuc, 0x10f800, 0x00000030, (v0 ^ v1) << 4);
 }
 
+static void
+nve0_ram_nuts(struct nve0_ram *ram, struct ramfuc_reg *reg,
+       u32 _mask, u32 _data, u32 _copy)
+{
+ struct nve0_fb_priv *priv = (void *)nouveau_fb(ram);
+ struct ramfuc *fuc = &ram->fuc.base;
+ u32 addr = 0x110000 + (reg->addr[0] & 0xfff);
+ u32 mask = _mask | _copy;
+ u32 data = (_data & _mask) | (reg->data & _copy);
+ u32 i;
+
+ for (i = 0; i < 16; i++, addr += 0x1000) {
+  if (ram->pnuts & (1 << i)) {
+   u32 prev = nv_rd32(priv, addr);
+   u32 next = (prev & ~mask) | data;
+   nouveau_memx_wr32(fuc->memx, addr, next);
+  }
+ }
+}
+#define ram_nuts(s,r,m,d,c)                                                    \
+ nve0_ram_nuts((s), &(s)->fuc.r_##r, (m), (d), (c))
+
 static int
 nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
 {
- struct nouveau_bios *bios = nouveau_bios(pfb);
  struct nve0_ram *ram = (void *)pfb->ram;
  struct nve0_ramfuc *fuc = &ram->fuc;
- const u32 rammap = ram->base.rammap.data;
- const u32 ramcfg = ram->base.ramcfg.data;
- const u32 timing = ram->base.timing.data;
- int vc = !(nv_ro08(bios, ramcfg + 0x02) & 0x08);
- int mv = 1; /*XXX*/
+ struct nouveau_ram_data *next = ram->base.next;
+ int vc = !(next->bios.ramcfg_11_02_08);
+ int mv = !(next->bios.ramcfg_11_02_04);
  u32 mask, data;
 
  ram_mask(fuc, 0x10f808, 0x40000000, 0x40000000);
  ram_wr32(fuc, 0x62c000, 0x0f0f0000);
 
  /* MR1: turn termination on early, for some reason.. */
- if ((ram->base.mr[1] & 0x03c) != 0x030)
+ if ((ram->base.mr[1] & 0x03c) != 0x030) {
   ram_mask(fuc, mr[1], 0x03c, ram->base.mr[1] & 0x03c);
+  ram_nuts(ram, mr[1], 0x03c, ram->base.mr1_nuts & 0x03c, 0x000);
+ }
 
  if (vc == 1 && ram_have(fuc, gpio2E)) {
   u32 temp  = ram_mask(fuc, gpio2E, 0x3000, fuc->r_func2E[1]);
@@ -250,8 +285,7 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
 
  ram_mask(fuc, 0x10f200, 0x00000800, 0x00000000);
 
- ram_mask(fuc, 0x10f914, 0x01020000, 0x000c0000);
- ram_mask(fuc, 0x10f910, 0x01020000, 0x000c0000);
+ nve0_ram_train(fuc, 0x01020000, 0x000c0000);
 
  ram_wr32(fuc, 0x10f210, 0x00000000); /* REFRESH_AUTO = 0 */
  ram_nsec(fuc, 1000);
@@ -280,28 +314,28 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
 
  if (1) {
   data |= 0x800807e0;
-  switch (nv_ro08(bios, ramcfg + 0x03) & 0xc0) {
-  case 0xc0: data &= ~0x00000040; break;
-  case 0x80: data &= ~0x00000100; break;
-  case 0x40: data &= ~0x80000000; break;
-  case 0x00: data &= ~0x00000400; break;
+  switch (next->bios.ramcfg_11_03_c0) {
+  case 3: data &= ~0x00000040; break;
+  case 2: data &= ~0x00000100; break;
+  case 1: data &= ~0x80000000; break;
+  case 0: data &= ~0x00000400; break;
   }
 
-  switch (nv_ro08(bios, ramcfg + 0x03) & 0x30) {
-  case 0x30: data &= ~0x00000020; break;
-  case 0x20: data &= ~0x00000080; break;
-  case 0x10: data &= ~0x00080000; break;
-  case 0x00: data &= ~0x00000200; break;
+  switch (next->bios.ramcfg_11_03_30) {
+  case 3: data &= ~0x00000020; break;
+  case 2: data &= ~0x00000080; break;
+  case 1: data &= ~0x00080000; break;
+  case 0: data &= ~0x00000200; break;
   }
  }
 
- if (nv_ro08(bios, ramcfg + 0x02) & 0x80)
+ if (next->bios.ramcfg_11_02_80)
   mask |= 0x03000000;
- if (nv_ro08(bios, ramcfg + 0x02) & 0x40)
+ if (next->bios.ramcfg_11_02_40)
   mask |= 0x00002000;
- if (nv_ro08(bios, ramcfg + 0x07) & 0x10)
+ if (next->bios.ramcfg_11_07_10)
   mask |= 0x00004000;
- if (nv_ro08(bios, ramcfg + 0x07) & 0x08)
+ if (next->bios.ramcfg_11_07_08)
   mask |= 0x00000003;
  else {
   mask |= 0x34000000;
@@ -314,18 +348,18 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
 
  if (ram->from == 2 && ram->mode != 2) {
   ram_mask(fuc, 0x10f808, 0x00080000, 0x00000000);
-  ram_mask(fuc, 0x10f200, 0x00008000, 0x00008000);
+  ram_mask(fuc, 0x10f200, 0x18008000, 0x00008000);
   ram_mask(fuc, 0x10f800, 0x00000000, 0x00000004);
   ram_mask(fuc, 0x10f830, 0x00008000, 0x01040010);
   ram_mask(fuc, 0x10f830, 0x01000000, 0x00000000);
   r1373f4_init(fuc);
   ram_mask(fuc, 0x1373f0, 0x00000002, 0x00000001);
-  r1373f4_fini(fuc, ramcfg);
+  r1373f4_fini(fuc);
   ram_mask(fuc, 0x10f830, 0x00c00000, 0x00240001);
  } else
  if (ram->from != 2 && ram->mode != 2) {
   r1373f4_init(fuc);
-  r1373f4_fini(fuc, ramcfg);
+  r1373f4_fini(fuc);
  }
 
  if (ram_have(fuc, gpioMV)) {
@@ -336,49 +370,54 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
   }
  }
 
- if ( (nv_ro08(bios, ramcfg + 0x02) & 0x40) ||
-      (nv_ro08(bios, ramcfg + 0x07) & 0x10)) {
+ if ( (next->bios.ramcfg_11_02_40) ||
+      (next->bios.ramcfg_11_07_10)) {
   ram_mask(fuc, 0x132040, 0x00010000, 0x00010000);
   ram_nsec(fuc, 20000);
  }
 
  if (ram->from != 2 && ram->mode == 2) {
+  if (0 /*XXX: Titan */)
+   ram_mask(fuc, 0x10f200, 0x18000000, 0x18000000);
   ram_mask(fuc, 0x10f800, 0x00000004, 0x00000000);
   ram_mask(fuc, 0x1373f0, 0x00000000, 0x00000002);
   ram_mask(fuc, 0x10f830, 0x00800001, 0x00408010);
   r1373f4_init(fuc);
-  r1373f4_fini(fuc, ramcfg);
+  r1373f4_fini(fuc);
   ram_mask(fuc, 0x10f808, 0x00000000, 0x00080000);
   ram_mask(fuc, 0x10f200, 0x00808000, 0x00800000);
  } else
  if (ram->from == 2 && ram->mode == 2) {
   ram_mask(fuc, 0x10f800, 0x00000004, 0x00000000);
   r1373f4_init(fuc);
-  r1373f4_fini(fuc, ramcfg);
+  r1373f4_fini(fuc);
  }
 
  if (ram->mode != 2) /*XXX*/ {
-  if (nv_ro08(bios, ramcfg + 0x07) & 0x40)
+  if (next->bios.ramcfg_11_07_40)
    ram_mask(fuc, 0x10f670, 0x80000000, 0x80000000);
  }
 
- data = (nv_ro08(bios, rammap + 0x11) & 0x0c) >> 2;
- ram_wr32(fuc, 0x10f65c, 0x00000011 * data);
- ram_wr32(fuc, 0x10f6b8, 0x01010101 * nv_ro08(bios, ramcfg + 0x09));
- ram_wr32(fuc, 0x10f6bc, 0x01010101 * nv_ro08(bios, ramcfg + 0x09));
+ ram_wr32(fuc, 0x10f65c, 0x00000011 * next->bios.rammap_11_11_0c);
+ ram_wr32(fuc, 0x10f6b8, 0x01010101 * next->bios.ramcfg_11_09);
+ ram_wr32(fuc, 0x10f6bc, 0x01010101 * next->bios.ramcfg_11_09);
 
- data = nv_ro08(bios, ramcfg + 0x04);
- if (!(nv_ro08(bios, ramcfg + 0x07) & 0x08)) {
-  ram_wr32(fuc, 0x10f698, 0x01010101 * data);
-  ram_wr32(fuc, 0x10f69c, 0x01010101 * data);
+ if (!next->bios.ramcfg_11_07_08 && !next->bios.ramcfg_11_07_04) {
+  ram_wr32(fuc, 0x10f698, 0x01010101 * next->bios.ramcfg_11_04);
+  ram_wr32(fuc, 0x10f69c, 0x01010101 * next->bios.ramcfg_11_04);
+ } else
+ if (!next->bios.ramcfg_11_07_08) {
+  ram_wr32(fuc, 0x10f698, 0x00000000);
+  ram_wr32(fuc, 0x10f69c, 0x00000000);
  }
 
  if (ram->mode != 2) {
-  u32 temp = ram_rd32(fuc, 0x10f694) & ~0xff00ff00;
-  ram_wr32(fuc, 0x10f694, temp | (0x01000100 * data));
+  u32 data = 0x01000100 * next->bios.ramcfg_11_04;
+  ram_nuke(fuc, 0x10f694);
+  ram_mask(fuc, 0x10f694, 0xff00ff00, data);
  }
 
- if (ram->mode == 2 && (nv_ro08(bios, ramcfg + 0x08) & 0x10))
+ if (ram->mode == 2 && (next->bios.ramcfg_11_08_10))
   data = 0x00000080;
  else
   data = 0x00000000;
@@ -386,19 +425,19 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
 
  mask = 0x00070000;
  data = 0x00000000;
- if (!(nv_ro08(bios, ramcfg + 0x02) & 0x80))
+ if (!(next->bios.ramcfg_11_02_80))
   data |= 0x03000000;
- if (!(nv_ro08(bios, ramcfg + 0x02) & 0x40))
+ if (!(next->bios.ramcfg_11_02_40))
   data |= 0x00002000;
- if (!(nv_ro08(bios, ramcfg + 0x07) & 0x10))
+ if (!(next->bios.ramcfg_11_07_10))
   data |= 0x00004000;
- if (!(nv_ro08(bios, ramcfg + 0x07) & 0x08))
+ if (!(next->bios.ramcfg_11_07_08))
   data |= 0x00000003;
  else
   data |= 0x74000000;
  ram_mask(fuc, 0x10f824, mask, data);
 
- if (nv_ro08(bios, ramcfg + 0x01) & 0x08)
+ if (next->bios.ramcfg_11_01_08)
   data = 0x00000000;
  else
   data = 0x00001000;
@@ -409,61 +448,90 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
   ram_mask(fuc, 0x10f670, 0x80000000, 0x00000000);
  }
 
- if (nv_ro08(bios, ramcfg + 0x08) & 0x01)
+ if (next->bios.ramcfg_11_08_01)
   data = 0x00100000;
  else
   data = 0x00000000;
  ram_mask(fuc, 0x10f82c, 0x00100000, data);
 
  data = 0x00000000;
- if (nv_ro08(bios, ramcfg + 0x08) & 0x08)
+ if (next->bios.ramcfg_11_08_08)
   data |= 0x00002000;
- if (nv_ro08(bios, ramcfg + 0x08) & 0x04)
+ if (next->bios.ramcfg_11_08_04)
   data |= 0x00001000;
- if (nv_ro08(bios, ramcfg + 0x08) & 0x02)
+ if (next->bios.ramcfg_11_08_02)
   data |= 0x00004000;
  ram_mask(fuc, 0x10f830, 0x00007000, data);
 
  /* PFB timing */
- ram_mask(fuc, 0x10f248, 0xffffffff, nv_ro32(bios, timing + 0x28));
- ram_mask(fuc, 0x10f290, 0xffffffff, nv_ro32(bios, timing + 0x00));
- ram_mask(fuc, 0x10f294, 0xffffffff, nv_ro32(bios, timing + 0x04));
- ram_mask(fuc, 0x10f298, 0xffffffff, nv_ro32(bios, timing + 0x08));
- ram_mask(fuc, 0x10f29c, 0xffffffff, nv_ro32(bios, timing + 0x0c));
- ram_mask(fuc, 0x10f2a0, 0xffffffff, nv_ro32(bios, timing + 0x10));
- ram_mask(fuc, 0x10f2a4, 0xffffffff, nv_ro32(bios, timing + 0x14));
- ram_mask(fuc, 0x10f2a8, 0xffffffff, nv_ro32(bios, timing + 0x18));
- ram_mask(fuc, 0x10f2ac, 0xffffffff, nv_ro32(bios, timing + 0x1c));
- ram_mask(fuc, 0x10f2cc, 0xffffffff, nv_ro32(bios, timing + 0x20));
- ram_mask(fuc, 0x10f2e8, 0xffffffff, nv_ro32(bios, timing + 0x24));
-
- data = (nv_ro08(bios, ramcfg + 0x02) & 0x03) << 8;
- if (nv_ro08(bios, ramcfg + 0x01) & 0x10)
-  data |= 0x70000000;
- ram_mask(fuc, 0x10f604, 0x70000300, data);
-
- data = (nv_ro08(bios, timing + 0x30) & 0x07) << 28;
- if (nv_ro08(bios, ramcfg + 0x01) & 0x01)
-  data |= 0x00000100;
- ram_mask(fuc, 0x10f614, 0x70000000, data);
-
- data = (nv_ro08(bios, timing + 0x30) & 0x07) << 28;
- if (nv_ro08(bios, ramcfg + 0x01) & 0x02)
-  data |= 0x00000100;
- ram_mask(fuc, 0x10f610, 0x70000000, data);
+ ram_mask(fuc, 0x10f248, 0xffffffff, next->bios.timing[10]);
+ ram_mask(fuc, 0x10f290, 0xffffffff, next->bios.timing[0]);
+ ram_mask(fuc, 0x10f294, 0xffffffff, next->bios.timing[1]);
+ ram_mask(fuc, 0x10f298, 0xffffffff, next->bios.timing[2]);
+ ram_mask(fuc, 0x10f29c, 0xffffffff, next->bios.timing[3]);
+ ram_mask(fuc, 0x10f2a0, 0xffffffff, next->bios.timing[4]);
+ ram_mask(fuc, 0x10f2a4, 0xffffffff, next->bios.timing[5]);
+ ram_mask(fuc, 0x10f2a8, 0xffffffff, next->bios.timing[6]);
+ ram_mask(fuc, 0x10f2ac, 0xffffffff, next->bios.timing[7]);
+ ram_mask(fuc, 0x10f2cc, 0xffffffff, next->bios.timing[8]);
+ ram_mask(fuc, 0x10f2e8, 0xffffffff, next->bios.timing[9]);
+
+ data = mask = 0x00000000;
+ if (NOTE00(ramcfg_08_20)) {
+  if (next->bios.ramcfg_11_08_20)
+   data |= 0x01000000;
+  mask |= 0x01000000;
+ }
+ ram_mask(fuc, 0x10f200, mask, data);
+
+ data = mask = 0x00000000;
+ if (NOTE00(ramcfg_02_03 != 0)) {
+  data |= (next->bios.ramcfg_11_02_03) << 8;
+  mask |= 0x00000300;
+ }
+ if (NOTE00(ramcfg_01_10)) {
+  if (next->bios.ramcfg_11_01_10)
+   data |= 0x70000000;
+  mask |= 0x70000000;
+ }
+ ram_mask(fuc, 0x10f604, mask, data);
+
+ data = mask = 0x00000000;
+ if (NOTE00(timing_30_07 != 0)) {
+  data |= (next->bios.timing_20_30_07) << 28;
+  mask |= 0x70000000;
+ }
+ if (NOTE00(ramcfg_01_01)) {
+  if (next->bios.ramcfg_11_01_01)
+   data |= 0x00000100;
+  mask |= 0x00000100;
+ }
+ ram_mask(fuc, 0x10f614, mask, data);
+
+ data = mask = 0x00000000;
+ if (NOTE00(timing_30_07 != 0)) {
+  data |= (next->bios.timing_20_30_07) << 28;
+  mask |= 0x70000000;
+ }
+ if (NOTE00(ramcfg_01_02)) {
+  if (next->bios.ramcfg_11_01_02)
+   data |= 0x00000100;
+  mask |= 0x00000100;
+ }
+ ram_mask(fuc, 0x10f610, mask, data);
 
  mask = 0x33f00000;
  data = 0x00000000;
- if (!(nv_ro08(bios, ramcfg + 0x01) & 0x04))
+ if (!(next->bios.ramcfg_11_01_04))
   data |= 0x20200000;
- if (!(nv_ro08(bios, ramcfg + 0x07) & 0x80))
+ if (!(next->bios.ramcfg_11_07_80))
   data |= 0x12800000;
  /*XXX: see note above about there probably being some condition
   *     for the 10f824 stuff that uses ramcfg 3...
   */
- if ( (nv_ro08(bios, ramcfg + 0x03) & 0xf0)) {
-  if (nv_ro08(bios, rammap + 0x08) & 0x0c) {
-   if (!(nv_ro08(bios, ramcfg + 0x07) & 0x80))
+ if ( (next->bios.ramcfg_11_03_f0)) {
+  if (next->bios.rammap_11_08_0c) {
+   if (!(next->bios.ramcfg_11_07_80))
     mask |= 0x00000020;
    else
     data |= 0x00000020;
@@ -476,49 +544,53 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
 
  ram_mask(fuc, 0x10f808, mask, data);
 
- data = nv_ro08(bios, ramcfg + 0x03) & 0x0f;
- ram_wr32(fuc, 0x10f870, 0x11111111 * data);
+ ram_wr32(fuc, 0x10f870, 0x11111111 * next->bios.ramcfg_11_03_0f);
 
- data = nv_ro08(bios, ramcfg + 0x02) & 0x03;
- if (nv_ro08(bios, ramcfg + 0x01) & 0x10)
-  data |= 0x00000004;
- if ((nv_rd32(bios, 0x100770) & 0x00000004) != (data & 0x00000004)) {
-  ram_wr32(fuc, 0x10f750, 0x04000009);
+ data = mask = 0x00000000;
+ if (NOTE00(ramcfg_02_03 != 0)) {
+  data |= next->bios.ramcfg_11_02_03;
+  mask |= 0x00000003;
+ }
+ if (NOTE00(ramcfg_01_10)) {
+  if (next->bios.ramcfg_11_01_10)
+   data |= 0x00000004;
+  mask |= 0x00000004;
+ }
+
+ if ((ram_mask(fuc, 0x100770, mask, data) & mask & 4) != (data & 4)) {
+  ram_mask(fuc, 0x100750, 0x00000008, 0x00000008);
   ram_wr32(fuc, 0x100710, 0x00000000);
   ram_wait(fuc, 0x100710, 0x80000000, 0x80000000, 200000);
  }
- ram_mask(fuc, 0x100770, 0x00000007, data);
 
- data = (nv_ro08(bios, timing + 0x30) & 0x07) << 8;
- if (nv_ro08(bios, ramcfg + 0x01) & 0x01)
+ data = (next->bios.timing_20_30_07) << 8;
+ if (next->bios.ramcfg_11_01_01)
   data |= 0x80000000;
  ram_mask(fuc, 0x100778, 0x00000700, data);
 
- data = nv_ro16(bios, timing + 0x2c);
- ram_mask(fuc, 0x10f250, 0x000003f0, (data & 0x003f) <<  4);
- ram_mask(fuc, 0x10f24c, 0x7f000000, (data & 0x1fc0) << 18);
-
- data = nv_ro08(bios, timing + 0x30);
- ram_mask(fuc, 0x10f224, 0x001f0000, (data & 0xf8) << 13);
+ ram_mask(fuc, 0x10f250, 0x000003f0, next->bios.timing_20_2c_003f << 4);
+ data = (next->bios.timing[10] & 0x7f000000) >> 24;
+ if (data < next->bios.timing_20_2c_1fc0)
+  data = next->bios.timing_20_2c_1fc0;
+ ram_mask(fuc, 0x10f24c, 0x7f000000, data << 24);
+ ram_mask(fuc, 0x10f224, 0x001f0000, next->bios.timing_20_30_f8 << 16);
 
- data = nv_ro16(bios, timing + 0x31);
- ram_mask(fuc, 0x10fec4, 0x041e0f07, (data & 0x0800) << 15 |
-         (data & 0x0780) << 10 |
-         (data & 0x0078) <<  5 |
-         (data & 0x0007));
- ram_mask(fuc, 0x10fec8, 0x00000027, (data & 0x8000) >> 10 |
-         (data & 0x7000) >> 12);
+ ram_mask(fuc, 0x10fec4, 0x041e0f07, next->bios.timing_20_31_0800 << 26 |
+         next->bios.timing_20_31_0780 << 17 |
+         next->bios.timing_20_31_0078 << 8 |
+         next->bios.timing_20_31_0007);
+ ram_mask(fuc, 0x10fec8, 0x00000027, next->bios.timing_20_31_8000 << 5 |
+         next->bios.timing_20_31_7000);
 
  ram_wr32(fuc, 0x10f090, 0x4000007e);
- ram_nsec(fuc, 1000);
+ ram_nsec(fuc, 2000);
  ram_wr32(fuc, 0x10f314, 0x00000001); /* PRECHARGE */
  ram_wr32(fuc, 0x10f310, 0x00000001); /* REFRESH */
- ram_nsec(fuc, 2000);
  ram_wr32(fuc, 0x10f210, 0x80000000); /* REFRESH_AUTO = 1 */
 
- if ((nv_ro08(bios, ramcfg + 0x08) & 0x10) && (ram->mode == 2) /*XXX*/) {
+ if ((next->bios.ramcfg_11_08_10) && (ram->mode == 2) /*XXX*/) {
   u32 temp = ram_mask(fuc, 0x10f294, 0xff000000, 0x24000000);
-  train(fuc, 0xa4010000); /*XXX*/
+  nve0_ram_train(fuc, 0xbc0e0000, 0xa4010000); /*XXX*/
   ram_nsec(fuc, 1000);
   ram_wr32(fuc, 0x10f294, temp);
  }
@@ -528,7 +600,7 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
  ram_mask(fuc, mr[8], 0xfff, ram->base.mr[8]);
  ram_nsec(fuc, 1000);
  ram_mask(fuc, mr[1], 0xfff, ram->base.mr[1]);
- ram_mask(fuc, mr[5], 0xfff, ram->base.mr[5]);
+ ram_mask(fuc, mr[5], 0xfff, ram->base.mr[5] & ~0x004); /* LP3 later */
  ram_mask(fuc, mr[6], 0xfff, ram->base.mr[6]);
  ram_mask(fuc, mr[7], 0xfff, ram->base.mr[7]);
 
@@ -544,12 +616,13 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
  ram_wr32(fuc, 0x10f318, 0x00000001); /* NOP? */
  ram_mask(fuc, 0x10f200, 0x80000000, 0x00000000);
  ram_nsec(fuc, 1000);
+ ram_nuts(ram, 0x10f200, 0x18808800, 0x00000000, 0x18808800);
 
  data  = ram_rd32(fuc, 0x10f978);
  data &= ~0x00046144;
  data |=  0x0000000b;
- if (!(nv_ro08(bios, ramcfg + 0x07) & 0x08)) {
-  if (!(nv_ro08(bios, ramcfg + 0x07) & 0x04))
+ if (!(next->bios.ramcfg_11_07_08)) {
+  if (!(next->bios.ramcfg_11_07_04))
    data |= 0x0000200c;
   else
    data |= 0x00000000;
@@ -563,44 +636,43 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
   ram_wr32(fuc, 0x10f830, data);
  }
 
- if (!(nv_ro08(bios, ramcfg + 0x07) & 0x08)) {
+ if (!(next->bios.ramcfg_11_07_08)) {
   data = 0x88020000;
-  if ( (nv_ro08(bios, ramcfg + 0x07) & 0x04))
+  if ( (next->bios.ramcfg_11_07_04))
    data |= 0x10000000;
-  if (!(nv_ro08(bios, rammap + 0x08) & 0x10))
+  if (!(next->bios.rammap_11_08_10))
    data |= 0x00080000;
  } else {
   data = 0xa40e0000;
  }
- train(fuc, data);
- ram_nsec(fuc, 1000);
+ nve0_ram_train(fuc, 0xbc0f0000, data);
+ if (1) /* XXX: not always? */
+  ram_nsec(fuc, 1000);
 
  if (ram->mode == 2) { /*XXX*/
   ram_mask(fuc, 0x10f800, 0x00000004, 0x00000004);
  }
 
- /* MR5: (re)enable LP3 if necessary
-  * XXX: need to find the switch, keeping off for now
-  */
- ram_mask(fuc, mr[5], 0x00000004, 0x00000000);
+ /* LP3 */
+ if (ram_mask(fuc, mr[5], 0x004, ram->base.mr[5]) != ram->base.mr[5])
+  ram_nsec(fuc, 1000);
 
  if (ram->mode != 2) {
   ram_mask(fuc, 0x10f830, 0x01000000, 0x01000000);
   ram_mask(fuc, 0x10f830, 0x01000000, 0x00000000);
  }
 
- if (nv_ro08(bios, ramcfg + 0x07) & 0x02) {
-  ram_mask(fuc, 0x10f910, 0x80020000, 0x01000000);
-  ram_mask(fuc, 0x10f914, 0x80020000, 0x01000000);
- }
+ if (next->bios.ramcfg_11_07_02)
+  nve0_ram_train(fuc, 0x80020000, 0x01000000);
 
  ram_wr32(fuc, 0x62c000, 0x0f0f0f00);
 
- if (nv_ro08(bios, rammap + 0x08) & 0x01)
+ if (next->bios.rammap_11_08_01)
   data = 0x00000800;
  else
   data = 0x00000000;
  ram_mask(fuc, 0x10f200, 0x00000800, data);
+ ram_nuts(ram, 0x10f200, 0x18808800, data, 0x18808800);
  return 0;
 }
 
@@ -611,17 +683,14 @@ nve0_ram_calc_gddr5(struct nouveau_fb *pfb, u32 freq)
 static int
 nve0_ram_calc_sddr3(struct nouveau_fb *pfb, u32 freq)
 {
- struct nouveau_bios *bios = nouveau_bios(pfb);
  struct nve0_ram *ram = (void *)pfb->ram;
  struct nve0_ramfuc *fuc = &ram->fuc;
  const u32 rcoef = ((  ram->P1 << 16) | (ram->N1 << 8) | ram->M1);
  const u32 runk0 = ram->fN1 << 16;
  const u32 runk1 = ram->fN1;
- const u32 rammap = ram->base.rammap.data;
- const u32 ramcfg = ram->base.ramcfg.data;
- const u32 timing = ram->base.timing.data;
- int vc = !(nv_ro08(bios, ramcfg + 0x02) & 0x08);
- int mv = 1; /*XXX*/
+ struct nouveau_ram_data *next = ram->base.next;
+ int vc = !(next->bios.ramcfg_11_02_08);
+ int mv = !(next->bios.ramcfg_11_02_04);
  u32 mask, data;
 
  ram_mask(fuc, 0x10f808, 0x40000000, 0x40000000);
@@ -636,7 +705,7 @@ nve0_ram_calc_sddr3(struct nouveau_fb *pfb, u32 freq)
  }
 
  ram_mask(fuc, 0x10f200, 0x00000800, 0x00000000);
- if ((nv_ro08(bios, ramcfg + 0x03) & 0xf0))
+ if ((next->bios.ramcfg_11_03_f0))
   ram_mask(fuc, 0x10f808, 0x04000000, 0x04000000);
 
  ram_wr32(fuc, 0x10f314, 0x00000001); /* PRECHARGE */
@@ -661,28 +730,28 @@ nve0_ram_calc_sddr3(struct nouveau_fb *pfb, u32 freq)
  if (1) {
   mask |= 0x800807e0;
   data |= 0x800807e0;
-  switch (nv_ro08(bios, ramcfg + 0x03) & 0xc0) {
-  case 0xc0: data &= ~0x00000040; break;
-  case 0x80: data &= ~0x00000100; break;
-  case 0x40: data &= ~0x80000000; break;
-  case 0x00: data &= ~0x00000400; break;
+  switch (next->bios.ramcfg_11_03_c0) {
+  case 3: data &= ~0x00000040; break;
+  case 2: data &= ~0x00000100; break;
+  case 1: data &= ~0x80000000; break;
+  case 0: data &= ~0x00000400; break;
   }
 
-  switch (nv_ro08(bios, ramcfg + 0x03) & 0x30) {
-  case 0x30: data &= ~0x00000020; break;
-  case 0x20: data &= ~0x00000080; break;
-  case 0x10: data &= ~0x00080000; break;
-  case 0x00: data &= ~0x00000200; break;
+  switch (next->bios.ramcfg_11_03_30) {
+  case 3: data &= ~0x00000020; break;
+  case 2: data &= ~0x00000080; break;
+  case 1: data &= ~0x00080000; break;
+  case 0: data &= ~0x00000200; break;
   }
  }
 
- if (nv_ro08(bios, ramcfg + 0x02) & 0x80)
+ if (next->bios.ramcfg_11_02_80)
   mask |= 0x03000000;
- if (nv_ro08(bios, ramcfg + 0x02) & 0x40)
+ if (next->bios.ramcfg_11_02_40)
   mask |= 0x00002000;
- if (nv_ro08(bios, ramcfg + 0x07) & 0x10)
+ if (next->bios.ramcfg_11_07_10)
   mask |= 0x00004000;
- if (nv_ro08(bios, ramcfg + 0x07) & 0x08)
+ if (next->bios.ramcfg_11_07_08)
   mask |= 0x00000003;
  else
   mask |= 0x14000000;
@@ -692,7 +761,7 @@ nve0_ram_calc_sddr3(struct nouveau_fb *pfb, u32 freq)
 
  ram_mask(fuc, 0x1373f4, 0x00000000, 0x00010010);
  data  = ram_rd32(fuc, 0x1373ec) & ~0x00030000;
- data |= (nv_ro08(bios, ramcfg + 0x03) & 0x30) << 12;
+ data |= (next->bios.ramcfg_11_03_30) << 12;
  ram_wr32(fuc, 0x1373ec, data);
  ram_mask(fuc, 0x1373f4, 0x00000003, 0x00000000);
  ram_mask(fuc, 0x1373f4, 0x00000010, 0x00000000);
@@ -724,68 +793,67 @@ nve0_ram_calc_sddr3(struct nouveau_fb *pfb, u32 freq)
   }
  }
 
- if ( (nv_ro08(bios, ramcfg + 0x02) & 0x40) ||
-      (nv_ro08(bios, ramcfg + 0x07) & 0x10)) {
+ if ( (next->bios.ramcfg_11_02_40) ||
+      (next->bios.ramcfg_11_07_10)) {
   ram_mask(fuc, 0x132040, 0x00010000, 0x00010000);
   ram_nsec(fuc, 20000);
  }
 
  if (ram->mode != 2) /*XXX*/ {
-  if (nv_ro08(bios, ramcfg + 0x07) & 0x40)
+  if (next->bios.ramcfg_11_07_40)
    ram_mask(fuc, 0x10f670, 0x80000000, 0x80000000);
  }
 
- data = (nv_ro08(bios, rammap + 0x11) & 0x0c) >> 2;
- ram_wr32(fuc, 0x10f65c, 0x00000011 * data);
- ram_wr32(fuc, 0x10f6b8, 0x01010101 * nv_ro08(bios, ramcfg + 0x09));
- ram_wr32(fuc, 0x10f6bc, 0x01010101 * nv_ro08(bios, ramcfg + 0x09));
+ ram_wr32(fuc, 0x10f65c, 0x00000011 * next->bios.rammap_11_11_0c);
+ ram_wr32(fuc, 0x10f6b8, 0x01010101 * next->bios.ramcfg_11_09);
+ ram_wr32(fuc, 0x10f6bc, 0x01010101 * next->bios.ramcfg_11_09);
 
  mask = 0x00010000;
  data = 0x00000000;
- if (!(nv_ro08(bios, ramcfg + 0x02) & 0x80))
+ if (!(next->bios.ramcfg_11_02_80))
   data |= 0x03000000;
- if (!(nv_ro08(bios, ramcfg + 0x02) & 0x40))
+ if (!(next->bios.ramcfg_11_02_40))
   data |= 0x00002000;
- if (!(nv_ro08(bios, ramcfg + 0x07) & 0x10))
+ if (!(next->bios.ramcfg_11_07_10))
   data |= 0x00004000;
- if (!(nv_ro08(bios, ramcfg + 0x07) & 0x08))
+ if (!(next->bios.ramcfg_11_07_08))
   data |= 0x00000003;
  else
   data |= 0x14000000;
  ram_mask(fuc, 0x10f824, mask, data);
  ram_nsec(fuc, 1000);
 
- if (nv_ro08(bios, ramcfg + 0x08) & 0x01)
+ if (next->bios.ramcfg_11_08_01)
   data = 0x00100000;
  else
   data = 0x00000000;
  ram_mask(fuc, 0x10f82c, 0x00100000, data);
 
  /* PFB timing */
- ram_mask(fuc, 0x10f248, 0xffffffff, nv_ro32(bios, timing + 0x28));
- ram_mask(fuc, 0x10f290, 0xffffffff, nv_ro32(bios, timing + 0x00));
- ram_mask(fuc, 0x10f294, 0xffffffff, nv_ro32(bios, timing + 0x04));
- ram_mask(fuc, 0x10f298, 0xffffffff, nv_ro32(bios, timing + 0x08));
- ram_mask(fuc, 0x10f29c, 0xffffffff, nv_ro32(bios, timing + 0x0c));
- ram_mask(fuc, 0x10f2a0, 0xffffffff, nv_ro32(bios, timing + 0x10));
- ram_mask(fuc, 0x10f2a4, 0xffffffff, nv_ro32(bios, timing + 0x14));
- ram_mask(fuc, 0x10f2a8, 0xffffffff, nv_ro32(bios, timing + 0x18));
- ram_mask(fuc, 0x10f2ac, 0xffffffff, nv_ro32(bios, timing + 0x1c));
- ram_mask(fuc, 0x10f2cc, 0xffffffff, nv_ro32(bios, timing + 0x20));
- ram_mask(fuc, 0x10f2e8, 0xffffffff, nv_ro32(bios, timing + 0x24));
+ ram_mask(fuc, 0x10f248, 0xffffffff, next->bios.timing[10]);
+ ram_mask(fuc, 0x10f290, 0xffffffff, next->bios.timing[0]);
+ ram_mask(fuc, 0x10f294, 0xffffffff, next->bios.timing[1]);
+ ram_mask(fuc, 0x10f298, 0xffffffff, next->bios.timing[2]);
+ ram_mask(fuc, 0x10f29c, 0xffffffff, next->bios.timing[3]);
+ ram_mask(fuc, 0x10f2a0, 0xffffffff, next->bios.timing[4]);
+ ram_mask(fuc, 0x10f2a4, 0xffffffff, next->bios.timing[5]);
+ ram_mask(fuc, 0x10f2a8, 0xffffffff, next->bios.timing[6]);
+ ram_mask(fuc, 0x10f2ac, 0xffffffff, next->bios.timing[7]);
+ ram_mask(fuc, 0x10f2cc, 0xffffffff, next->bios.timing[8]);
+ ram_mask(fuc, 0x10f2e8, 0xffffffff, next->bios.timing[9]);
 
  mask = 0x33f00000;
  data = 0x00000000;
- if (!(nv_ro08(bios, ramcfg + 0x01) & 0x04))
+ if (!(next->bios.ramcfg_11_01_04))
   data |= 0x20200000;
- if (!(nv_ro08(bios, ramcfg + 0x07) & 0x80))
+ if (!(next->bios.ramcfg_11_07_80))
   data |= 0x12800000;
  /*XXX: see note above about there probably being some condition
   *     for the 10f824 stuff that uses ramcfg 3...
   */
- if ( (nv_ro08(bios, ramcfg + 0x03) & 0xf0)) {
-  if (nv_ro08(bios, rammap + 0x08) & 0x0c) {
-   if (!(nv_ro08(bios, ramcfg + 0x07) & 0x80))
+ if ( (next->bios.ramcfg_11_03_f0)) {
+  if (next->bios.rammap_11_08_0c) {
+   if (!(next->bios.ramcfg_11_07_80))
     mask |= 0x00000020;
    else
     data |= 0x00000020;
@@ -799,21 +867,16 @@ nve0_ram_calc_sddr3(struct nouveau_fb *pfb, u32 freq)
 
  ram_mask(fuc, 0x10f808, mask, data);
 
- data = nv_ro08(bios, ramcfg + 0x03) & 0x0f;
- ram_wr32(fuc, 0x10f870, 0x11111111 * data);
+ ram_wr32(fuc, 0x10f870, 0x11111111 * next->bios.ramcfg_11_03_0f);
 
- data = nv_ro16(bios, timing + 0x2c);
- ram_mask(fuc, 0x10f250, 0x000003f0, (data & 0x003f) <<  4);
+ ram_mask(fuc, 0x10f250, 0x000003f0, next->bios.timing_20_2c_003f << 4);
 
- if (((nv_ro32(bios, timing + 0x2c) & 0x00001fc0) >>  6) >
-     ((nv_ro32(bios, timing + 0x28) & 0x7f000000) >> 24))
-  data = (nv_ro32(bios, timing + 0x2c) & 0x00001fc0) >>  6;
- else
-  data = (nv_ro32(bios, timing + 0x28) & 0x1f000000) >> 24;
+ data = (next->bios.timing[10] & 0x7f000000) >> 24;
+ if (data < next->bios.timing_20_2c_1fc0)
+  data = next->bios.timing_20_2c_1fc0;
  ram_mask(fuc, 0x10f24c, 0x7f000000, data << 24);
 
- data = nv_ro08(bios, timing + 0x30);
- ram_mask(fuc, 0x10f224, 0x001f0000, (data & 0xf8) << 13);
+ ram_mask(fuc, 0x10f224, 0x001f0000, next->bios.timing_20_30_f8);
 
  ram_wr32(fuc, 0x10f090, 0x4000007f);
  ram_nsec(fuc, 1000);
@@ -855,7 +918,7 @@ nve0_ram_calc_sddr3(struct nouveau_fb *pfb, u32 freq)
 
  ram_wr32(fuc, 0x62c000, 0x0f0f0f00);
 
- if (nv_ro08(bios, rammap + 0x08) & 0x01)
+ if (next->bios.rammap_11_08_01)
   data = 0x00000800;
  else
   data = 0x00000000;
@@ -868,21 +931,18 @@ nve0_ram_calc_sddr3(struct nouveau_fb *pfb, u32 freq)
  ******************************************************************************/
 
 static int
-nve0_ram_calc(struct nouveau_fb *pfb, u32 freq)
+nve0_ram_calc_data(struct nouveau_fb *pfb, u32 freq,
+     struct nouveau_ram_data *data)
 {
  struct nouveau_bios *bios = nouveau_bios(pfb);
  struct nve0_ram *ram = (void *)pfb->ram;
- struct nve0_ramfuc *fuc = &ram->fuc;
- struct bit_entry M;
- int ret, refclk, strap, i;
- u32 data;
- u8  cnt;
+ u8 strap, cnt, len;
 
  /* lookup memory config data relevant to the target frequency */
- ram->base.rammap.data = nvbios_rammap_match(bios, freq / 1000,
-         &ram->base.rammap.version,
-         &ram->base.rammap.size, &cnt,
-         &ram->base.ramcfg.size);
+ ram->base.rammap.data = nvbios_rammapEp(bios, freq / 1000,
+            &ram->base.rammap.version,
+            &ram->base.rammap.size,
+            &cnt, &len, &data->bios);
  if (!ram->base.rammap.data || ram->base.rammap.version != 0x11 ||
       ram->base.rammap.size < 0x09) {
   nv_error(pfb, "invalid/missing rammap entry\n");
@@ -890,24 +950,13 @@ nve0_ram_calc(struct nouveau_fb *pfb, u32 freq)
  }
 
  /* locate specific data set for the attached memory */
- if (bit_entry(bios, 'M', &M) || M.version != 2 || M.length < 3) {
-  nv_error(pfb, "invalid/missing memory table\n");
-  return -EINVAL;
- }
-
- strap = (nv_rd32(pfb, 0x101000) & 0x0000003c) >> 2;
- data = nv_ro16(bios, M.offset + 1);
- if (data)
-  strap = nv_ro08(bios, data + strap);
-
- if (strap >= cnt) {
-  nv_error(pfb, "invalid ramcfg strap\n");
-  return -EINVAL;
- }
-
- ram->base.ramcfg.version = ram->base.rammap.version;
- ram->base.ramcfg.data = ram->base.rammap.data + ram->base.rammap.size +
-          (ram->base.ramcfg.size * strap);
+ ram->base.ramcfg.data = nvbios_rammapSp(bios, ram->base.rammap.data,
+      ram->base.rammap.version,
+      ram->base.rammap.size, cnt, len,
+      nvbios_ramcfg_index(bios),
+      &ram->base.ramcfg.version,
+      &ram->base.ramcfg.size,
+      &data->bios);
  if (!ram->base.ramcfg.data || ram->base.ramcfg.version != 0x11 ||
       ram->base.ramcfg.size < 0x08) {
   nv_error(pfb, "invalid/missing ramcfg entry\n");
@@ -918,9 +967,9 @@ nve0_ram_calc(struct nouveau_fb *pfb, u32 freq)
  strap = nv_ro08(bios, ram->base.ramcfg.data + 0x00);
  if (strap != 0xff) {
   ram->base.timing.data =
-   nvbios_timing_entry(bios, strap,
-        &ram->base.timing.version,
-        &ram->base.timing.size);
+   nvbios_timingEp(bios, strap, &ram->base.timing.version,
+           &ram->base.timing.size, &cnt, &len,
+           &data->bios);
   if (!ram->base.timing.data ||
        ram->base.timing.version != 0x20 ||
        ram->base.timing.size < 0x33) {
@@ -931,11 +980,23 @@ nve0_ram_calc(struct nouveau_fb *pfb, u32 freq)
   ram->base.timing.data = 0;
  }
 
+ data->freq = freq;
+ return 0;
+}
+
+static int
+nve0_ram_calc_xits(struct nouveau_fb *pfb, struct nouveau_ram_data *next)
+{
+ struct nve0_ram *ram = (void *)pfb->ram;
+ struct nve0_ramfuc *fuc = &ram->fuc;
+ int refclk, i;
+ int ret;
+
  ret = ram_init(fuc, pfb);
  if (ret)
   return ret;
 
- ram->mode = (freq > fuc->refpll.vco1.max_freq) ? 2 : 1;
+ ram->mode = (next->freq > fuc->refpll.vco1.max_freq) ? 2 : 1;
  ram->from = ram_rd32(fuc, 0x1373f4) & 0x0000000f;
 
  /* XXX: this is *not* what nvidia do.  on fermi nvidia generally
@@ -946,7 +1007,7 @@ nve0_ram_calc(struct nouveau_fb *pfb, u32 freq)
   * so far, i've seen very weird values being chosen by nvidia on
   * kepler boards, no idea how/why they're chosen.
   */
- refclk = freq;
+ refclk = next->freq;
  if (ram->mode == 2)
   refclk = fuc->mempll.refclk;
 
@@ -968,7 +1029,7 @@ nve0_ram_calc(struct nouveau_fb *pfb, u32 freq)
   fuc->mempll.min_p = 1;
   fuc->mempll.max_p = 2;
 
-  ret = nva3_pll_calc(nv_subdev(pfb), &fuc->mempll, freq,
+  ret = nva3_pll_calc(nv_subdev(pfb), &fuc->mempll, next->freq,
        &ram->N2, NULL, &ram->M2, &ram->P2);
   if (ret <= 0) {
    nv_error(pfb, "unable to calc mempll\n");
@@ -980,17 +1041,18 @@ nve0_ram_calc(struct nouveau_fb *pfb, u32 freq)
   if (ram_have(fuc, mr[i]))
    ram->base.mr[i] = ram_rd32(fuc, mr[i]);
  }
+ ram->base.freq = next->freq;
 
  switch (ram->base.type) {
  case NV_MEM_TYPE_DDR3:
   ret = nouveau_sddr3_calc(&ram->base);
   if (ret == 0)
-   ret = nve0_ram_calc_sddr3(pfb, freq);
+   ret = nve0_ram_calc_sddr3(pfb, next->freq);
   break;
  case NV_MEM_TYPE_GDDR5:
-  ret = nouveau_gddr5_calc(&ram->base);
+  ret = nouveau_gddr5_calc(&ram->base, ram->pnuts != 0);
   if (ret == 0)
-   ret = nve0_ram_calc_gddr5(pfb, freq);
+   ret = nve0_ram_calc_gddr5(pfb, next->freq);
   break;
  default:
   ret = -ENOSYS;
@@ -1001,13 +1063,55 @@ nve0_ram_calc(struct nouveau_fb *pfb, u32 freq)
 }
 
 static int
+nve0_ram_calc(struct nouveau_fb *pfb, u32 freq)
+{
+ struct nouveau_clock *clk = nouveau_clock(pfb);
+ struct nve0_ram *ram = (void *)pfb->ram;
+ struct nouveau_ram_data *xits = &ram->base.xition;
+ struct nouveau_ram_data *copy;
+ int ret;
+
+ if (ram->base.next == NULL) {
+  ret = nve0_ram_calc_data(pfb, clk->read(clk, nv_clk_src_mem),
+     &ram->base.former);
+  if (ret)
+   return ret;
+
+  ret = nve0_ram_calc_data(pfb, freq, &ram->base.target);
+  if (ret)
+   return ret;
+
+  if (ram->base.target.freq < ram->base.former.freq) {
+   *xits = ram->base.target;
+   copy = &ram->base.former;
+  } else {
+   *xits = ram->base.former;
+   copy = &ram->base.target;
+  }
+
+  xits->bios.ramcfg_11_02_04 = copy->bios.ramcfg_11_02_04;
+  xits->bios.ramcfg_11_02_03 = copy->bios.ramcfg_11_02_03;
+  xits->bios.timing_20_30_07 = copy->bios.timing_20_30_07;
+
+  ram->base.next = &ram->base.target;
+  if (memcmp(xits, &ram->base.former, sizeof(xits->bios)))
+   ram->base.next = &ram->base.xition;
+ } else {
+  BUG_ON(ram->base.next != &ram->base.xition);
+  ram->base.next = &ram->base.target;
+ }
+
+ return nve0_ram_calc_xits(pfb, ram->base.next);
+}
+
+static int
 nve0_ram_prog(struct nouveau_fb *pfb)
 {
  struct nouveau_device *device = nv_device(pfb);
  struct nve0_ram *ram = (void *)pfb->ram;
  struct nve0_ramfuc *fuc = &ram->fuc;
  ram_exec(fuc, nouveau_boolopt(device->cfgopt, "NvMemExec", false));
- return 0;
+ return (ram->base.next == &ram->base.xition);
 }
 
 static void
@@ -1015,6 +1119,7 @@ nve0_ram_tidy(struct nouveau_fb *pfb)
 {
  struct nve0_ram *ram = (void *)pfb->ram;
  struct nve0_ramfuc *fuc = &ram->fuc;
+ ram->base.next = NULL;
  ram_exec(fuc, false);
 }
 
@@ -1055,7 +1160,7 @@ nve0_ram_init(struct nouveau_object *object)
   * binary driver skips the one that's already been setup by
   * the init tables.
   */
- data = nvbios_rammap_table(bios, &ver, &hdr, &cnt, &len, &snr, &ssz);
+ data = nvbios_rammapTe(bios, &ver, &hdr, &cnt, &len, &snr, &ssz);
  if (!data || hdr < 0x15)
   return -EINVAL;
 
@@ -1073,6 +1178,7 @@ nve0_ram_init(struct nouveau_object *object)
   data += 4;
  }
  nv_wr32(pfb, 0x10f65c, save);
+ nv_mask(pfb, 0x10f584, 0x11000000, 0x00000000);
 
  switch (ram->base.type) {
  case NV_MEM_TYPE_GDDR5:
@@ -1117,7 +1223,8 @@ nve0_ram_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  struct nouveau_gpio *gpio = nouveau_gpio(pfb);
  struct dcb_gpio_func func;
  struct nve0_ram *ram;
- int ret;
+ int ret, i;
+ u32 tmp;
 
  ret = nvc0_ram_create(parent, engine, oclass, &ram);
  *pobject = nv_object(ram);
@@ -1136,6 +1243,25 @@ nve0_ram_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
   break;
  }
 
+ /* calculate a mask of differently configured memory partitions,
+  * because, of course reclocking wasn't complicated enough
+  * already without having to treat some of them differently to
+  * the others....
+  */
+ ram->parts = nv_rd32(pfb, 0x022438);
+ ram->pmask = nv_rd32(pfb, 0x022554);
+ ram->pnuts = 0;
+ for (i = 0, tmp = 0; i < ram->parts; i++) {
+  if (!(ram->pmask & (1 << i))) {
+   u32 cfg1 = nv_rd32(pfb, 0x110204 + (i * 0x1000));
+   if (tmp && tmp != cfg1) {
+    ram->pnuts |= (1 << i);
+    continue;
+   }
+   tmp = cfg1;
+  }
+ }
+
  // parse bios data for both pll's
  ret = nvbios_pll_parse(bios, 0x0c, &ram->fuc.refpll);
  if (ret) {
@@ -1248,7 +1374,7 @@ nve0_ram_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  ram->fuc.r_0x10f65c = ramfuc_reg(0x10f65c);
  ram->fuc.r_0x10f6bc = ramfuc_reg(0x10f6bc);
  ram->fuc.r_0x100710 = ramfuc_reg(0x100710);
- ram->fuc.r_0x10f750 = ramfuc_reg(0x10f750);
+ ram->fuc.r_0x100750 = ramfuc_reg(0x100750);
  return 0;
 }
 
diff --git a/drivers/gpu/drm/nouveau/core/subdev/instmem/base.c b/drivers/gpu/drm/nouveau/core/subdev/instmem/base.c
index 6565f3d..14706d9 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/instmem/base.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/instmem/base.c
@@ -22,7 +22,24 @@
  * Authors: Ben Skeggs
  */
 
-#include <subdev/instmem.h>
+#include "priv.h"
+
+/******************************************************************************
+ * instmem object base implementation
+ *****************************************************************************/
+
+void
+_nouveau_instobj_dtor(struct nouveau_object *object)
+{
+ struct nouveau_instmem *imem = (void *)object->engine;
+ struct nouveau_instobj *iobj = (void *)object;
+
+ mutex_lock(&nv_subdev(imem)->mutex);
+ list_del(&iobj->head);
+ mutex_unlock(&nv_subdev(imem)->mutex);
+
+ return nouveau_object_destroy(&iobj->base);
+}
 
 int
 nouveau_instobj_create_(struct nouveau_object *parent,
@@ -46,73 +63,26 @@ nouveau_instobj_create_(struct nouveau_object *parent,
  return 0;
 }
 
-void
-nouveau_instobj_destroy(struct nouveau_instobj *iobj)
-{
- struct nouveau_subdev *subdev = nv_subdev(iobj->base.engine);
+/******************************************************************************
+ * instmem subdev base implementation
+ *****************************************************************************/
 
- mutex_lock(&subdev->mutex);
- list_del(&iobj->head);
- mutex_unlock(&subdev->mutex);
-
- return nouveau_object_destroy(&iobj->base);
-}
-
-void
-_nouveau_instobj_dtor(struct nouveau_object *object)
+static int
+nouveau_instmem_alloc(struct nouveau_instmem *imem,
+        struct nouveau_object *parent, u32 size, u32 align,
+        struct nouveau_object **pobject)
 {
- struct nouveau_instobj *iobj = (void *)object;
- return nouveau_instobj_destroy(iobj);
+ struct nouveau_object *engine = nv_object(imem);
+ struct nouveau_instmem_impl *impl = (void *)engine->oclass;
+ struct nouveau_instobj_args args = { .size = size, .align = align };
+ return nouveau_object_ctor(parent, engine, impl->instobj, &args,
+       sizeof(args), pobject);
 }
 
 int
-nouveau_instmem_create_(struct nouveau_object *parent,
-   struct nouveau_object *engine,
-   struct nouveau_oclass *oclass,
-   int length, void **pobject)
-{
- struct nouveau_instmem *imem;
- int ret;
-
- ret = nouveau_subdev_create_(parent, engine, oclass, 0,
-         "INSTMEM", "instmem", length, pobject);
- imem = *pobject;
- if (ret)
-  return ret;
-
- INIT_LIST_HEAD(&imem->list);
- return 0;
-}
-
-int
-nouveau_instmem_init(struct nouveau_instmem *imem)
-{
- struct nouveau_instobj *iobj;
- int ret, i;
-
- ret = nouveau_subdev_init(&imem->base);
- if (ret)
-  return ret;
-
- mutex_lock(&imem->base.mutex);
-
- list_for_each_entry(iobj, &imem->list, head) {
-  if (iobj->suspend) {
-   for (i = 0; i < iobj->size; i += 4)
-    nv_wo32(iobj, i, iobj->suspend[i / 4]);
-   vfree(iobj->suspend);
-   iobj->suspend = NULL;
-  }
- }
-
- mutex_unlock(&imem->base.mutex);
-
- return 0;
-}
-
-int
-nouveau_instmem_fini(struct nouveau_instmem *imem, bool suspend)
+_nouveau_instmem_fini(struct nouveau_object *object, bool suspend)
 {
+ struct nouveau_instmem *imem = (void *)object;
  struct nouveau_instobj *iobj;
  int i, ret = 0;
 
@@ -143,12 +113,45 @@ int
 _nouveau_instmem_init(struct nouveau_object *object)
 {
  struct nouveau_instmem *imem = (void *)object;
- return nouveau_instmem_init(imem);
+ struct nouveau_instobj *iobj;
+ int ret, i;
+
+ ret = nouveau_subdev_init(&imem->base);
+ if (ret)
+  return ret;
+
+ mutex_lock(&imem->base.mutex);
+
+ list_for_each_entry(iobj, &imem->list, head) {
+  if (iobj->suspend) {
+   for (i = 0; i < iobj->size; i += 4)
+    nv_wo32(iobj, i, iobj->suspend[i / 4]);
+   vfree(iobj->suspend);
+   iobj->suspend = NULL;
+  }
+ }
+
+ mutex_unlock(&imem->base.mutex);
+
+ return 0;
 }
 
 int
-_nouveau_instmem_fini(struct nouveau_object *object, bool suspend)
+nouveau_instmem_create_(struct nouveau_object *parent,
+   struct nouveau_object *engine,
+   struct nouveau_oclass *oclass,
+   int length, void **pobject)
 {
- struct nouveau_instmem *imem = (void *)object;
- return nouveau_instmem_fini(imem, suspend);
+ struct nouveau_instmem *imem;
+ int ret;
+
+ ret = nouveau_subdev_create_(parent, engine, oclass, 0,
+         "INSTMEM", "instmem", length, pobject);
+ imem = *pobject;
+ if (ret)
+  return ret;
+
+ INIT_LIST_HEAD(&imem->list);
+ imem->alloc = nouveau_instmem_alloc;
+ return 0;
 }
diff --git a/drivers/gpu/drm/nouveau/core/subdev/instmem/nv04.c b/drivers/gpu/drm/nouveau/core/subdev/instmem/nv04.c
index 795393d..7b64bef 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/instmem/nv04.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/instmem/nv04.c
@@ -22,10 +22,35 @@
  * Authors: Ben Skeggs
  */
 
-#include <subdev/fb.h>
-
 #include "nv04.h"
 
+/******************************************************************************
+ * instmem object implementation
+ *****************************************************************************/
+
+static u32
+nv04_instobj_rd32(struct nouveau_object *object, u64 addr)
+{
+ struct nv04_instobj_priv *node = (void *)object;
+ return nv_ro32(object->engine, node->mem->offset + addr);
+}
+
+static void
+nv04_instobj_wr32(struct nouveau_object *object, u64 addr, u32 data)
+{
+ struct nv04_instobj_priv *node = (void *)object;
+ nv_wo32(object->engine, node->mem->offset + addr, data);
+}
+
+static void
+nv04_instobj_dtor(struct nouveau_object *object)
+{
+ struct nv04_instmem_priv *priv = (void *)object->engine;
+ struct nv04_instobj_priv *node = (void *)object;
+ nouveau_mm_free(&priv->heap, &node->mem);
+ nouveau_instobj_destroy(&node->base);
+}
+
 static int
 nv04_instobj_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
     struct nouveau_oclass *oclass, void *data, u32 size,
@@ -33,18 +58,19 @@ nv04_instobj_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
 {
  struct nv04_instmem_priv *priv = (void *)engine;
  struct nv04_instobj_priv *node;
- int ret, align;
+ struct nouveau_instobj_args *args = data;
+ int ret;
 
- align = (unsigned long)data;
- if (!align)
-  align = 1;
+ if (!args->align)
+  args->align = 1;
 
  ret = nouveau_instobj_create(parent, engine, oclass, &node);
  *pobject = nv_object(node);
  if (ret)
   return ret;
 
- ret = nouveau_mm_head(&priv->heap, 1, size, size, align, &node->mem);
+ ret = nouveau_mm_head(&priv->heap, 1, args->size, args->size,
+         args->align, &node->mem);
  if (ret)
   return ret;
 
@@ -53,32 +79,9 @@ nv04_instobj_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  return 0;
 }
 
-static void
-nv04_instobj_dtor(struct nouveau_object *object)
-{
- struct nv04_instmem_priv *priv = (void *)object->engine;
- struct nv04_instobj_priv *node = (void *)object;
- nouveau_mm_free(&priv->heap, &node->mem);
- nouveau_instobj_destroy(&node->base);
-}
-
-static u32
-nv04_instobj_rd32(struct nouveau_object *object, u64 addr)
-{
- struct nv04_instobj_priv *node = (void *)object;
- return nv_ro32(object->engine, node->mem->offset + addr);
-}
-
-static void
-nv04_instobj_wr32(struct nouveau_object *object, u64 addr, u32 data)
-{
- struct nv04_instobj_priv *node = (void *)object;
- nv_wo32(object->engine, node->mem->offset + addr, data);
-}
-
-static struct nouveau_oclass
+struct nouveau_instobj_impl
 nv04_instobj_oclass = {
- .ofuncs = &(struct nouveau_ofuncs) {
+ .base.ofuncs = &(struct nouveau_ofuncs) {
   .ctor = nv04_instobj_ctor,
   .dtor = nv04_instobj_dtor,
   .init = _nouveau_instobj_init,
@@ -88,19 +91,34 @@ nv04_instobj_oclass = {
  },
 };
 
-int
-nv04_instmem_alloc(struct nouveau_instmem *imem, struct nouveau_object *parent,
-     u32 size, u32 align, struct nouveau_object **pobject)
+/******************************************************************************
+ * instmem subdev implementation
+ *****************************************************************************/
+
+static u32
+nv04_instmem_rd32(struct nouveau_object *object, u64 addr)
 {
- struct nouveau_object *engine = nv_object(imem);
- int ret;
+ return nv_rd32(object, 0x700000 + addr);
+}
 
- ret = nouveau_object_ctor(parent, engine, &nv04_instobj_oclass,
-      (void *)(unsigned long)align, size, pobject);
- if (ret)
-  return ret;
+static void
+nv04_instmem_wr32(struct nouveau_object *object, u64 addr, u32 data)
+{
+ return nv_wr32(object, 0x700000 + addr, data);
+}
 
- return 0;
+void
+nv04_instmem_dtor(struct nouveau_object *object)
+{
+ struct nv04_instmem_priv *priv = (void *)object;
+ nouveau_gpuobj_ref(NULL, &priv->ramfc);
+ nouveau_gpuobj_ref(NULL, &priv->ramro);
+ nouveau_ramht_ref(NULL, &priv->ramht);
+ nouveau_gpuobj_ref(NULL, &priv->vbios);
+ nouveau_mm_fini(&priv->heap);
+ if (priv->iomem)
+  iounmap(priv->iomem);
+ nouveau_instmem_destroy(&priv->base);
 }
 
 static int
@@ -118,7 +136,6 @@ nv04_instmem_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
 
  /* PRAMIN aperture maps over the end of VRAM, reserve it */
  priv->base.reserved = 512 * 1024;
- priv->base.alloc    = nv04_instmem_alloc;
 
  ret = nouveau_mm_init(&priv->heap, 0, priv->base.reserved, 1);
  if (ret)
@@ -150,36 +167,10 @@ nv04_instmem_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  return 0;
 }
 
-void
-nv04_instmem_dtor(struct nouveau_object *object)
-{
- struct nv04_instmem_priv *priv = (void *)object;
- nouveau_gpuobj_ref(NULL, &priv->ramfc);
- nouveau_gpuobj_ref(NULL, &priv->ramro);
- nouveau_ramht_ref(NULL, &priv->ramht);
- nouveau_gpuobj_ref(NULL, &priv->vbios);
- nouveau_mm_fini(&priv->heap);
- if (priv->iomem)
-  iounmap(priv->iomem);
- nouveau_instmem_destroy(&priv->base);
-}
-
-static u32
-nv04_instmem_rd32(struct nouveau_object *object, u64 addr)
-{
- return nv_rd32(object, 0x700000 + addr);
-}
-
-static void
-nv04_instmem_wr32(struct nouveau_object *object, u64 addr, u32 data)
-{
- return nv_wr32(object, 0x700000 + addr, data);
-}
-
-struct nouveau_oclass
-nv04_instmem_oclass = {
- .handle = NV_SUBDEV(INSTMEM, 0x04),
- .ofuncs = &(struct nouveau_ofuncs) {
+struct nouveau_oclass *
+nv04_instmem_oclass = &(struct nouveau_instmem_impl) {
+ .base.handle = NV_SUBDEV(INSTMEM, 0x04),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
   .ctor = nv04_instmem_ctor,
   .dtor = nv04_instmem_dtor,
   .init = _nouveau_instmem_init,
@@ -187,4 +178,5 @@ nv04_instmem_oclass = {
   .rd32 = nv04_instmem_rd32,
   .wr32 = nv04_instmem_wr32,
  },
-};
+ .instobj = &nv04_instobj_oclass.base,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/instmem/nv04.h b/drivers/gpu/drm/nouveau/core/subdev/instmem/nv04.h
index b15b613..095fbc6 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/instmem/nv04.h
+++ b/drivers/gpu/drm/nouveau/core/subdev/instmem/nv04.h
@@ -5,7 +5,9 @@
 #include <core/ramht.h>
 #include <core/mm.h>
 
-#include <subdev/instmem.h>
+#include "priv.h"
+
+extern struct nouveau_instobj_impl nv04_instobj_oclass;
 
 struct nv04_instmem_priv {
  struct nouveau_instmem base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/instmem/nv40.c b/drivers/gpu/drm/nouveau/core/subdev/instmem/nv40.c
index b10a143..ec0b966 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/instmem/nv40.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/instmem/nv40.c
@@ -26,6 +26,24 @@
 
 #include "nv04.h"
 
+/******************************************************************************
+ * instmem subdev implementation
+ *****************************************************************************/
+
+static u32
+nv40_instmem_rd32(struct nouveau_object *object, u64 addr)
+{
+ struct nv04_instmem_priv *priv = (void *)object;
+ return ioread32_native(priv->iomem + addr);
+}
+
+static void
+nv40_instmem_wr32(struct nouveau_object *object, u64 addr, u32 data)
+{
+ struct nv04_instmem_priv *priv = (void *)object;
+ iowrite32_native(data, priv->iomem + addr);
+}
+
 static int
 nv40_instmem_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
     struct nouveau_oclass *oclass, void *data, u32 size,
@@ -69,7 +87,6 @@ nv40_instmem_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  priv->base.reserved += 512 * 1024; /* object storage */
 
  priv->base.reserved = round_up(priv->base.reserved, 4096);
- priv->base.alloc    = nv04_instmem_alloc;
 
  ret = nouveau_mm_init(&priv->heap, 0, priv->base.reserved, 1);
  if (ret)
@@ -106,24 +123,10 @@ nv40_instmem_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
  return 0;
 }
 
-static u32
-nv40_instmem_rd32(struct nouveau_object *object, u64 addr)
-{
- struct nv04_instmem_priv *priv = (void *)object;
- return ioread32_native(priv->iomem + addr);
-}
-
-static void
-nv40_instmem_wr32(struct nouveau_object *object, u64 addr, u32 data)
-{
- struct nv04_instmem_priv *priv = (void *)object;
- iowrite32_native(data, priv->iomem + addr);
-}
-
-struct nouveau_oclass
-nv40_instmem_oclass = {
- .handle = NV_SUBDEV(INSTMEM, 0x40),
- .ofuncs = &(struct nouveau_ofuncs) {
+struct nouveau_oclass *
+nv40_instmem_oclass = &(struct nouveau_instmem_impl) {
+ .base.handle = NV_SUBDEV(INSTMEM, 0x40),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
   .ctor = nv40_instmem_ctor,
   .dtor = nv04_instmem_dtor,
   .init = _nouveau_instmem_init,
@@ -131,4 +134,5 @@ nv40_instmem_oclass = {
   .rd32 = nv40_instmem_rd32,
   .wr32 = nv40_instmem_wr32,
  },
-};
+ .instobj = &nv04_instobj_oclass.base,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/instmem/nv50.c b/drivers/gpu/drm/nouveau/core/subdev/instmem/nv50.c
index 97bc5df..7cb3b09 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/instmem/nv50.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/instmem/nv50.c
@@ -22,11 +22,11 @@
  * Authors: Ben Skeggs
  */
 
-#include <subdev/instmem.h>
 #include <subdev/fb.h>
-
 #include <core/mm.h>
 
+#include "priv.h"
+
 struct nv50_instmem_priv {
  struct nouveau_instmem base;
  spinlock_t lock;
@@ -38,42 +38,9 @@ struct nv50_instobj_priv {
  struct nouveau_mem *mem;
 };
 
-static int
-nv50_instobj_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
-    struct nouveau_oclass *oclass, void *data, u32 size,
-    struct nouveau_object **pobject)
-{
- struct nouveau_fb *pfb = nouveau_fb(parent);
- struct nv50_instobj_priv *node;
- u32 align = (unsigned long)data;
- int ret;
-
- size  = max((size  + 4095) & ~4095, (u32)4096);
- align = max((align + 4095) & ~4095, (u32)4096);
-
- ret = nouveau_instobj_create(parent, engine, oclass, &node);
- *pobject = nv_object(node);
- if (ret)
-  return ret;
-
- ret = pfb->ram->get(pfb, size, align, 0, 0x800, &node->mem);
- if (ret)
-  return ret;
-
- node->base.addr = node->mem->offset;
- node->base.size = node->mem->size << 12;
- node->mem->page_shift = 12;
- return 0;
-}
-
-static void
-nv50_instobj_dtor(struct nouveau_object *object)
-{
- struct nv50_instobj_priv *node = (void *)object;
- struct nouveau_fb *pfb = nouveau_fb(object);
- pfb->ram->put(pfb, &node->mem);
- nouveau_instobj_destroy(&node->base);
-}
+/******************************************************************************
+ * instmem object implementation
+ *****************************************************************************/
 
 static u32
 nv50_instobj_rd32(struct nouveau_object *object, u64 offset)
@@ -113,9 +80,46 @@ nv50_instobj_wr32(struct nouveau_object *object, u64 offset, u32 data)
  spin_unlock_irqrestore(&priv->lock, flags);
 }
 
-static struct nouveau_oclass
+static void
+nv50_instobj_dtor(struct nouveau_object *object)
+{
+ struct nv50_instobj_priv *node = (void *)object;
+ struct nouveau_fb *pfb = nouveau_fb(object);
+ pfb->ram->put(pfb, &node->mem);
+ nouveau_instobj_destroy(&node->base);
+}
+
+static int
+nv50_instobj_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
+    struct nouveau_oclass *oclass, void *data, u32 size,
+    struct nouveau_object **pobject)
+{
+ struct nouveau_fb *pfb = nouveau_fb(parent);
+ struct nouveau_instobj_args *args = data;
+ struct nv50_instobj_priv *node;
+ int ret;
+
+ args->size  = max((args->size  + 4095) & ~4095, (u32)4096);
+ args->align = max((args->align + 4095) & ~4095, (u32)4096);
+
+ ret = nouveau_instobj_create(parent, engine, oclass, &node);
+ *pobject = nv_object(node);
+ if (ret)
+  return ret;
+
+ ret = pfb->ram->get(pfb, args->size, args->align, 0, 0x800, &node->mem);
+ if (ret)
+  return ret;
+
+ node->base.addr = node->mem->offset;
+ node->base.size = node->mem->size << 12;
+ node->mem->page_shift = 12;
+ return 0;
+}
+
+static struct nouveau_instobj_impl
 nv50_instobj_oclass = {
- .ofuncs = &(struct nouveau_ofuncs) {
+ .base.ofuncs = &(struct nouveau_ofuncs) {
   .ctor = nv50_instobj_ctor,
   .dtor = nv50_instobj_dtor,
   .init = _nouveau_instobj_init,
@@ -125,13 +129,16 @@ nv50_instobj_oclass = {
  },
 };
 
+/******************************************************************************
+ * instmem subdev implementation
+ *****************************************************************************/
+
 static int
-nv50_instmem_alloc(struct nouveau_instmem *imem, struct nouveau_object *parent,
-     u32 size, u32 align, struct nouveau_object **pobject)
+nv50_instmem_fini(struct nouveau_object *object, bool suspend)
 {
- struct nouveau_object *engine = nv_object(imem);
- return nouveau_object_ctor(parent, engine, &nv50_instobj_oclass,
-       (void *)(unsigned long)align, size, pobject);
+ struct nv50_instmem_priv *priv = (void *)object;
+ priv->addr = ~0ULL;
+ return nouveau_instmem_fini(&priv->base, suspend);
 }
 
 static int
@@ -148,25 +155,17 @@ nv50_instmem_ctor(struct nouveau_object *parent, struct nouveau_object *engine,
   return ret;
 
  spin_lock_init(&priv->lock);
- priv->base.alloc = nv50_instmem_alloc;
  return 0;
 }
 
-static int
-nv50_instmem_fini(struct nouveau_object *object, bool suspend)
-{
- struct nv50_instmem_priv *priv = (void *)object;
- priv->addr = ~0ULL;
- return nouveau_instmem_fini(&priv->base, suspend);
-}
-
-struct nouveau_oclass
-nv50_instmem_oclass = {
- .handle = NV_SUBDEV(INSTMEM, 0x50),
- .ofuncs = &(struct nouveau_ofuncs) {
+struct nouveau_oclass *
+nv50_instmem_oclass = &(struct nouveau_instmem_impl) {
+ .base.handle = NV_SUBDEV(INSTMEM, 0x50),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
   .ctor = nv50_instmem_ctor,
   .dtor = _nouveau_instmem_dtor,
   .init = _nouveau_instmem_init,
   .fini = nv50_instmem_fini,
  },
-};
+ .instobj = &nv50_instobj_oclass.base,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/instmem/priv.h b/drivers/gpu/drm/nouveau/core/subdev/instmem/priv.h
new file mode 100644
index 0000000..8d67ded
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/instmem/priv.h
@@ -0,0 +1,56 @@
+#ifndef __NVKM_INSTMEM_PRIV_H__
+#define __NVKM_INSTMEM_PRIV_H__
+
+#include <subdev/instmem.h>
+
+struct nouveau_instobj_impl {
+ struct nouveau_oclass base;
+};
+
+struct nouveau_instobj_args {
+ u32 size;
+ u32 align;
+};
+
+#define nouveau_instobj_create(p,e,o,d)                                        \
+ nouveau_instobj_create_((p), (e), (o), sizeof(**d), (void **)d)
+#define nouveau_instobj_destroy(p) ({                                          \
+ struct nouveau_instobj *iobj = (p);                                    \
+ _nouveau_instobj_dtor(nv_object(iobj));                                \
+})
+#define nouveau_instobj_init(p)                                                \
+ nouveau_object_init(&(p)->base)
+#define nouveau_instobj_fini(p,s)                                              \
+ nouveau_object_fini(&(p)->base, (s))
+
+int  nouveau_instobj_create_(struct nouveau_object *, struct nouveau_object *,
+        struct nouveau_oclass *, int, void **);
+void _nouveau_instobj_dtor(struct nouveau_object *);
+#define _nouveau_instobj_init nouveau_object_init
+#define _nouveau_instobj_fini nouveau_object_fini
+
+struct nouveau_instmem_impl {
+ struct nouveau_oclass base;
+ struct nouveau_oclass *instobj;
+};
+
+#define nouveau_instmem_create(p,e,o,d)                                        \
+ nouveau_instmem_create_((p), (e), (o), sizeof(**d), (void **)d)
+#define nouveau_instmem_destroy(p)                                             \
+ nouveau_subdev_destroy(&(p)->base)
+#define nouveau_instmem_init(p) ({                                             \
+ struct nouveau_instmem *imem = (p);                                    \
+ _nouveau_instmem_init(nv_object(imem));                                \
+})
+#define nouveau_instmem_fini(p,s) ({                                           \
+ struct nouveau_instmem *imem = (p);                                    \
+ _nouveau_instmem_fini(nv_object(imem), (s));                           \
+})
+
+int nouveau_instmem_create_(struct nouveau_object *, struct nouveau_object *,
+       struct nouveau_oclass *, int, void **);
+#define _nouveau_instmem_dtor _nouveau_subdev_dtor
+int _nouveau_instmem_init(struct nouveau_object *);
+int _nouveau_instmem_fini(struct nouveau_object *, bool);
+
+#endif
diff --git a/drivers/gpu/drm/nouveau/core/subdev/mc/nv04.h b/drivers/gpu/drm/nouveau/core/subdev/mc/nv04.h
index b0d5c31..81a408e 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/mc/nv04.h
+++ b/drivers/gpu/drm/nouveau/core/subdev/mc/nv04.h
@@ -14,6 +14,7 @@ int  nv04_mc_ctor(struct nouveau_object *, struct nouveau_object *,
 extern const struct nouveau_mc_intr nv04_mc_intr[];
 int  nv04_mc_init(struct nouveau_object *);
 void nv40_mc_msi_rearm(struct nouveau_mc *);
+int  nv44_mc_init(struct nouveau_object *object);
 int  nv50_mc_init(struct nouveau_object *);
 extern const struct nouveau_mc_intr nv50_mc_intr[];
 extern const struct nouveau_mc_intr nvc0_mc_intr[];
diff --git a/drivers/gpu/drm/nouveau/core/subdev/mc/nv44.c b/drivers/gpu/drm/nouveau/core/subdev/mc/nv44.c
index 3bfee5c..cc4d0d2 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/mc/nv44.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/mc/nv44.c
@@ -24,7 +24,7 @@
 
 #include "nv04.h"
 
-static int
+int
 nv44_mc_init(struct nouveau_object *object)
 {
  struct nv04_mc_priv *priv = (void *)object;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/mc/nv4c.c b/drivers/gpu/drm/nouveau/core/subdev/mc/nv4c.c
new file mode 100644
index 0000000..a75c35c
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/mc/nv4c.c
@@ -0,0 +1,45 @@
+/*
+ * Copyright 2014 Ilia Mirkin
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ilia Mirkin
+ */
+
+#include "nv04.h"
+
+static void
+nv4c_mc_msi_rearm(struct nouveau_mc *pmc)
+{
+ struct nv04_mc_priv *priv = (void *)pmc;
+ nv_wr08(priv, 0x088050, 0xff);
+}
+
+struct nouveau_oclass *
+nv4c_mc_oclass = &(struct nouveau_mc_oclass) {
+ .base.handle = NV_SUBDEV(MC, 0x4c),
+ .base.ofuncs = &(struct nouveau_ofuncs) {
+  .ctor = nv04_mc_ctor,
+  .dtor = _nouveau_mc_dtor,
+  .init = nv44_mc_init,
+  .fini = _nouveau_mc_fini,
+ },
+ .intr = nv04_mc_intr,
+ .msi_rearm = nv4c_mc_msi_rearm,
+}.base;
diff --git a/drivers/gpu/drm/nouveau/core/subdev/mc/nvc0.c b/drivers/gpu/drm/nouveau/core/subdev/mc/nvc0.c
index c02b476..34472d3 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/mc/nvc0.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/mc/nvc0.c
@@ -32,6 +32,7 @@ nvc0_mc_intr[] = {
  { 0x00000080, NVDEV_ENGINE_COPY2 },
  { 0x00000100, NVDEV_ENGINE_FIFO },
  { 0x00001000, NVDEV_ENGINE_GR },
+ { 0x00002000, NVDEV_SUBDEV_FB },
  { 0x00008000, NVDEV_ENGINE_BSP },
  { 0x00040000, NVDEV_SUBDEV_THERM },
  { 0x00020000, NVDEV_ENGINE_VP },
@@ -40,6 +41,7 @@ nvc0_mc_intr[] = {
  { 0x01000000, NVDEV_SUBDEV_PWR },
  { 0x02000000, NVDEV_SUBDEV_LTCG },
  { 0x04000000, NVDEV_ENGINE_DISP },
+ { 0x08000000, NVDEV_SUBDEV_FB },
  { 0x10000000, NVDEV_SUBDEV_BUS },
  { 0x40000000, NVDEV_SUBDEV_IBUS },
  { 0x80000000, NVDEV_ENGINE_SW },
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/i2c_.fuc b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/i2c_.fuc
new file mode 100644
index 0000000..757dda7
--- /dev/null
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/i2c_.fuc
@@ -0,0 +1,393 @@
+/*
+ * Copyright 2013 Red Hat Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors: Ben Skeggs
+ */
+
+#define T_TIMEOUT  2200000
+#define T_RISEFALL 1000
+#define T_HOLD     5000
+
+#ifdef INCLUDE_PROC
+process(PROC_I2C_, #i2c_init, #i2c_recv)
+#endif
+
+/******************************************************************************
+ * I2C_ data segment
+ *****************************************************************************/
+#ifdef INCLUDE_DATA
+i2c_scl_map:
+.b32 NV_PPWR_OUTPUT_I2C_0_SCL
+.b32 NV_PPWR_OUTPUT_I2C_1_SCL
+.b32 NV_PPWR_OUTPUT_I2C_2_SCL
+.b32 NV_PPWR_OUTPUT_I2C_3_SCL
+.b32 NV_PPWR_OUTPUT_I2C_4_SCL
+.b32 NV_PPWR_OUTPUT_I2C_5_SCL
+.b32 NV_PPWR_OUTPUT_I2C_6_SCL
+.b32 NV_PPWR_OUTPUT_I2C_7_SCL
+.b32 NV_PPWR_OUTPUT_I2C_8_SCL
+.b32 NV_PPWR_OUTPUT_I2C_9_SCL
+i2c_sda_map:
+.b32 NV_PPWR_OUTPUT_I2C_0_SDA
+.b32 NV_PPWR_OUTPUT_I2C_1_SDA
+.b32 NV_PPWR_OUTPUT_I2C_2_SDA
+.b32 NV_PPWR_OUTPUT_I2C_3_SDA
+.b32 NV_PPWR_OUTPUT_I2C_4_SDA
+.b32 NV_PPWR_OUTPUT_I2C_5_SDA
+.b32 NV_PPWR_OUTPUT_I2C_6_SDA
+.b32 NV_PPWR_OUTPUT_I2C_7_SDA
+.b32 NV_PPWR_OUTPUT_I2C_8_SDA
+.b32 NV_PPWR_OUTPUT_I2C_9_SDA
+#if NVKM_PPWR_CHIPSET < GF119
+i2c_ctrl:
+.b32 0x00e138
+.b32 0x00e150
+.b32 0x00e168
+.b32 0x00e180
+.b32 0x00e254
+.b32 0x00e274
+.b32 0x00e764
+.b32 0x00e780
+.b32 0x00e79c
+.b32 0x00e7b8
+#endif
+#endif
+
+/******************************************************************************
+ * I2C_ code segment
+ *****************************************************************************/
+#ifdef INCLUDE_CODE
+
+// $r3  - value
+// $r2  - sda line
+// $r1  - scl line
+// $r0  - zero
+i2c_drive_scl:
+ cmp b32 $r3 0
+ bra e #i2c_drive_scl_lo
+ nv_iowr(NV_PPWR_OUTPUT_SET, $r1)
+ ret
+ i2c_drive_scl_lo:
+ nv_iowr(NV_PPWR_OUTPUT_CLR, $r1)
+ ret
+
+i2c_drive_sda:
+ cmp b32 $r3 0
+ bra e #i2c_drive_sda_lo
+ nv_iowr(NV_PPWR_OUTPUT_SET, $r2)
+ ret
+ i2c_drive_sda_lo:
+ nv_iowr(NV_PPWR_OUTPUT_CLR, $r2)
+ ret
+
+i2c_sense_scl:
+ bclr $flags $p1
+ nv_iord($r3, NV_PPWR_INPUT)
+ and $r3 $r1
+ bra z #i2c_sense_scl_done
+  bset $flags $p1
+ i2c_sense_scl_done:
+ ret
+
+i2c_sense_sda:
+ bclr $flags $p1
+ nv_iord($r3, NV_PPWR_INPUT)
+ and $r3 $r2
+ bra z #i2c_sense_sda_done
+  bset $flags $p1
+ i2c_sense_sda_done:
+ ret
+
+#define i2c_drive_scl(v) /*
+*/ mov $r3 (v) /*
+*/ call(i2c_drive_scl)
+#define i2c_drive_sda(v) /*
+*/ mov $r3 (v) /*
+*/ call(i2c_drive_sda)
+#define i2c_sense_scl() /*
+*/ call(i2c_sense_scl)
+#define i2c_sense_sda() /*
+*/ call(i2c_sense_sda)
+#define i2c_delay(v) /*
+*/ mov $r14 (v) /*
+*/ call(nsec)
+
+#define i2c_trace_init() /*
+*/ imm32($r6, 0x10000000) /*
+*/ sub b32 $r7 $r6 1 /*
+*/
+#define i2c_trace_down() /*
+*/ shr b32 $r6 4 /*
+*/ push $r5 /*
+*/ shl b32 $r5 $r6 4 /*
+*/ sub b32 $r5 $r6 /*
+*/ not b32 $r5 /*
+*/ and $r7 $r5 /*
+*/ pop $r5 /*
+*/
+#define i2c_trace_exit() /*
+*/ shl b32 $r6 4 /*
+*/
+#define i2c_trace_next() /*
+*/ add b32 $r7 $r6 /*
+*/
+#define i2c_trace_call(func) /*
+*/ i2c_trace_next() /*
+*/ i2c_trace_down() /*
+*/ call(func) /*
+*/ i2c_trace_exit() /*
+*/
+
+i2c_raise_scl:
+ push $r4
+ mov $r4 (T_TIMEOUT / T_RISEFALL)
+ i2c_drive_scl(1)
+ i2c_raise_scl_wait:
+  i2c_delay(T_RISEFALL)
+  i2c_sense_scl()
+  bra $p1 #i2c_raise_scl_done
+  sub b32 $r4 1
+  bra nz #i2c_raise_scl_wait
+ i2c_raise_scl_done:
+ pop $r4
+ ret
+
+i2c_start:
+ i2c_sense_scl()
+ bra not $p1 #i2c_start_rep
+ i2c_sense_sda()
+ bra not $p1 #i2c_start_rep
+ bra #i2c_start_send
+ i2c_start_rep:
+  i2c_drive_scl(0)
+  i2c_drive_sda(1)
+  i2c_trace_call(i2c_raise_scl)
+  bra not $p1 #i2c_start_out
+ i2c_start_send:
+ i2c_drive_sda(0)
+ i2c_delay(T_HOLD)
+ i2c_drive_scl(0)
+ i2c_delay(T_HOLD)
+ i2c_start_out:
+ ret
+
+i2c_stop:
+ i2c_drive_scl(0)
+ i2c_drive_sda(0)
+ i2c_delay(T_RISEFALL)
+ i2c_drive_scl(1)
+ i2c_delay(T_HOLD)
+ i2c_drive_sda(1)
+ i2c_delay(T_HOLD)
+ ret
+
+// $r3  - value
+// $r2  - sda line
+// $r1  - scl line
+// $r0  - zero
+i2c_bitw:
+ call(i2c_drive_sda)
+ i2c_delay(T_RISEFALL)
+ i2c_trace_call(i2c_raise_scl)
+ bra not $p1 #i2c_bitw_out
+ i2c_delay(T_HOLD)
+ i2c_drive_scl(0)
+ i2c_delay(T_HOLD)
+ i2c_bitw_out:
+ ret
+
+// $r3  - value (out)
+// $r2  - sda line
+// $r1  - scl line
+// $r0  - zero
+i2c_bitr:
+ i2c_drive_sda(1)
+ i2c_delay(T_RISEFALL)
+ i2c_trace_call(i2c_raise_scl)
+ bra not $p1 #i2c_bitr_done
+ i2c_sense_sda()
+ i2c_drive_scl(0)
+ i2c_delay(T_HOLD)
+ xbit $r3 $flags $p1
+ bset $flags $p1
+ i2c_bitr_done:
+ ret
+
+i2c_get_byte:
+ mov $r5 0
+ mov $r4 8
+ i2c_get_byte_next:
+  shl b32 $r5 1
+  i2c_trace_call(i2c_bitr)
+  bra not $p1 #i2c_get_byte_done
+  or $r5 $r3
+  sub b32 $r4 1
+  bra nz #i2c_get_byte_next
+ mov $r3 1
+ i2c_trace_call(i2c_bitw)
+ i2c_get_byte_done:
+ ret
+
+i2c_put_byte:
+ mov $r4 8
+ i2c_put_byte_next:
+  sub b32 $r4 1
+  xbit $r3 $r5 $r4
+  i2c_trace_call(i2c_bitw)
+  bra not $p1 #i2c_put_byte_done
+  cmp b32 $r4 0
+  bra ne #i2c_put_byte_next
+ i2c_trace_call(i2c_bitr)
+ bra not $p1 #i2c_put_byte_done
+ i2c_trace_next()
+ cmp b32 $r3 1
+ bra ne #i2c_put_byte_done
+ bclr $flags $p1 // nack
+ i2c_put_byte_done:
+ ret
+
+i2c_addr:
+ i2c_trace_call(i2c_start)
+ bra not $p1 #i2c_addr_done
+ extr $r3 $r12 I2C__MSG_DATA0_ADDR
+ shl b32 $r3 1
+ or $r5 $r3
+ i2c_trace_call(i2c_put_byte)
+ i2c_addr_done:
+ ret
+
+i2c_acquire_addr:
+ extr $r14 $r12 I2C__MSG_DATA0_PORT
+#if NVKM_PPWR_CHIPSET < GF119
+ shl b32 $r14 2
+ add b32 $r14 #i2c_ctrl
+ ld b32 $r14 D[$r14]
+#else
+ shl b32 $r14 5
+ add b32 $r14 0x00d014
+#endif
+ ret
+
+i2c_acquire:
+ call(i2c_acquire_addr)
+ call(rd32)
+ bset $r13 3
+ call(wr32)
+ ret
+
+i2c_release:
+ call(i2c_acquire_addr)
+ call(rd32)
+ bclr $r13 3
+ call(wr32)
+ ret
+
+// description
+//
+// $r15 - current (i2c)
+// $r14 - sender process name
+// $r13 - message
+// $r12 - data0
+// $r11 - data1
+// $r0  - zero
+i2c_recv:
+ bclr $flags $p1
+ extr $r1 $r12 I2C__MSG_DATA0_PORT
+ shl b32 $r1 2
+ cmp b32 $r1 (#i2c_sda_map - #i2c_scl_map)
+ bra ge #i2c_recv_done
+ add b32 $r3 $r1 #i2c_sda_map
+ ld b32 $r2 D[$r3]
+ add b32 $r3 $r1 #i2c_scl_map
+ ld b32 $r1 D[$r3]
+
+ bset $flags $p2
+ push $r13
+ push $r14
+
+ push $r13
+ i2c_trace_init()
+ i2c_trace_call(i2c_acquire)
+ pop $r13
+
+ cmp b32 $r13 I2C__MSG_RD08
+ bra ne #i2c_recv_not_rd08
+  mov $r5 0
+  i2c_trace_call(i2c_addr)
+  bra not $p1 #i2c_recv_done
+  extr $r5 $r12 I2C__MSG_DATA0_RD08_REG
+  i2c_trace_call(i2c_put_byte)
+  bra not $p1 #i2c_recv_done
+  mov $r5 1
+  i2c_trace_call(i2c_addr)
+  bra not $p1 #i2c_recv_done
+  i2c_trace_call(i2c_get_byte)
+  bra not $p1 #i2c_recv_done
+  ins $r11 $r5 I2C__MSG_DATA1_RD08_VAL
+  i2c_trace_call(i2c_stop)
+  mov b32 $r11 $r5
+  clear b32 $r7
+  bra #i2c_recv_done
+
+ i2c_recv_not_rd08:
+ cmp b32 $r13 I2C__MSG_WR08
+ bra ne #i2c_recv_not_wr08
+  mov $r5 0
+  call(i2c_addr)
+  bra not $p1 #i2c_recv_done
+  extr $r5 $r12 I2C__MSG_DATA0_WR08_REG
+  call(i2c_put_byte)
+  bra not $p1 #i2c_recv_done
+  mov $r5 0
+  call(i2c_addr)
+  bra not $p1 #i2c_recv_done
+  extr $r5 $r11 I2C__MSG_DATA1_WR08_VAL
+  call(i2c_put_byte)
+  bra not $p1 #i2c_recv_done
+  call(i2c_stop)
+  clear b32 $r7
+  extr $r5 $r12 I2C__MSG_DATA0_WR08_SYNC
+  bra nz #i2c_recv_done
+  bclr $flags $p2
+  bra #i2c_recv_done
+
+ i2c_recv_not_wr08:
+
+ i2c_recv_done:
+ extr $r14 $r12 I2C__MSG_DATA0_PORT
+ call(i2c_release)
+
+ pop $r14
+ pop $r13
+ bra not $p2 #i2c_recv_exit
+ mov b32 $r12 $r7
+ call(send)
+
+ i2c_recv_exit:
+ ret
+
+// description
+//
+// $r15 - current (i2c)
+// $r0  - zero
+i2c_init:
+ ret
+#endif
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/kernel.fuc b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/kernel.fuc
index 0a7b05f..8f29bad 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/kernel.fuc
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/kernel.fuc
@@ -51,12 +51,12 @@ time_next: .b32 0
 // $r0  - zero
 rd32:
  nv_iowr(NV_PPWR_MMIO_ADDR, $r14)
- mov $r14 NV_PPWR_MMIO_CTRL_OP_RD
- sethi $r14 NV_PPWR_MMIO_CTRL_TRIGGER
- nv_iowr(NV_PPWR_MMIO_CTRL, $r14)
+ mov $r13 NV_PPWR_MMIO_CTRL_OP_RD
+ sethi $r13 NV_PPWR_MMIO_CTRL_TRIGGER
+ nv_iowr(NV_PPWR_MMIO_CTRL, $r13)
  rd32_wait:
-  nv_iord($r14, NV_PPWR_MMIO_CTRL)
-  and $r14 NV_PPWR_MMIO_CTRL_STATUS
+  nv_iord($r13, NV_PPWR_MMIO_CTRL)
+  and $r13 NV_PPWR_MMIO_CTRL_STATUS
   bra nz #rd32_wait
  nv_iord($r13, NV_PPWR_MMIO_DATA)
  ret
@@ -70,23 +70,25 @@ rd32:
 wr32:
  nv_iowr(NV_PPWR_MMIO_ADDR, $r14)
  nv_iowr(NV_PPWR_MMIO_DATA, $r13)
- mov $r14 NV_PPWR_MMIO_CTRL_OP_WR
- or $r14 NV_PPWR_MMIO_CTRL_MASK_B32_0
- sethi $r14 NV_PPWR_MMIO_CTRL_TRIGGER
+ mov $r13 NV_PPWR_MMIO_CTRL_OP_WR
+ or $r13 NV_PPWR_MMIO_CTRL_MASK_B32_0
+ sethi $r13 NV_PPWR_MMIO_CTRL_TRIGGER
 
 #ifdef NVKM_FALCON_MMIO_TRAP
- mov $r8 NV_PPWR_INTR_TRIGGER_USER1
- nv_iowr(NV_PPWR_INTR_TRIGGER, $r8)
+ push $r13
+ mov $r13 NV_PPWR_INTR_TRIGGER_USER1
+ nv_iowr(NV_PPWR_INTR_TRIGGER, $r13)
  wr32_host:
-  nv_iord($r8, NV_PPWR_INTR)
-  and $r8 NV_PPWR_INTR_USER1
+  nv_iord($r13, NV_PPWR_INTR)
+  and $r13 NV_PPWR_INTR_USER1
   bra nz #wr32_host
+ pop $r13
 #endif
 
- nv_iowr(NV_PPWR_MMIO_CTRL, $r14)
+ nv_iowr(NV_PPWR_MMIO_CTRL, $r13)
  wr32_wait:
-  nv_iord($r14, NV_PPWR_MMIO_CTRL)
-  and $r14 NV_PPWR_MMIO_CTRL_STATUS
+  nv_iord($r13, NV_PPWR_MMIO_CTRL)
+  and $r13 NV_PPWR_MMIO_CTRL_STATUS
   bra nz #wr32_wait
  ret
 
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/macros.fuc b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/macros.fuc
index 2a74ea9..e2a63ac 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/macros.fuc
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/macros.fuc
@@ -83,6 +83,50 @@
 #define NV_PPWR_MMIO_CTRL_OP_WR                                      0x00000002
 #define NV_PPWR_OUTPUT                                                   0x07c0
 #define NV_PPWR_OUTPUT_FB_PAUSE                                      0x00000004
+#if NVKM_PPWR_CHIPSET < GF119
+#define NV_PPWR_OUTPUT_I2C_3_SCL                                     0x00000100
+#define NV_PPWR_OUTPUT_I2C_3_SDA                                     0x00000200
+#define NV_PPWR_OUTPUT_I2C_0_SCL                                     0x00001000
+#define NV_PPWR_OUTPUT_I2C_0_SDA                                     0x00002000
+#define NV_PPWR_OUTPUT_I2C_1_SCL                                     0x00004000
+#define NV_PPWR_OUTPUT_I2C_1_SDA                                     0x00008000
+#define NV_PPWR_OUTPUT_I2C_2_SCL                                     0x00010000
+#define NV_PPWR_OUTPUT_I2C_2_SDA                                     0x00020000
+#define NV_PPWR_OUTPUT_I2C_4_SCL                                     0x00040000
+#define NV_PPWR_OUTPUT_I2C_4_SDA                                     0x00080000
+#define NV_PPWR_OUTPUT_I2C_5_SCL                                     0x00100000
+#define NV_PPWR_OUTPUT_I2C_5_SDA                                     0x00200000
+#define NV_PPWR_OUTPUT_I2C_6_SCL                                     0x00400000
+#define NV_PPWR_OUTPUT_I2C_6_SDA                                     0x00800000
+#define NV_PPWR_OUTPUT_I2C_7_SCL                                     0x01000000
+#define NV_PPWR_OUTPUT_I2C_7_SDA                                     0x02000000
+#define NV_PPWR_OUTPUT_I2C_8_SCL                                     0x04000000
+#define NV_PPWR_OUTPUT_I2C_8_SDA                                     0x08000000
+#define NV_PPWR_OUTPUT_I2C_9_SCL                                     0x10000000
+#define NV_PPWR_OUTPUT_I2C_9_SDA                                     0x20000000
+#else
+#define NV_PPWR_OUTPUT_I2C_0_SCL                                     0x00000400
+#define NV_PPWR_OUTPUT_I2C_1_SCL                                     0x00000800
+#define NV_PPWR_OUTPUT_I2C_2_SCL                                     0x00001000
+#define NV_PPWR_OUTPUT_I2C_3_SCL                                     0x00002000
+#define NV_PPWR_OUTPUT_I2C_4_SCL                                     0x00004000
+#define NV_PPWR_OUTPUT_I2C_5_SCL                                     0x00008000
+#define NV_PPWR_OUTPUT_I2C_6_SCL                                     0x00010000
+#define NV_PPWR_OUTPUT_I2C_7_SCL                                     0x00020000
+#define NV_PPWR_OUTPUT_I2C_8_SCL                                     0x00040000
+#define NV_PPWR_OUTPUT_I2C_9_SCL                                     0x00080000
+#define NV_PPWR_OUTPUT_I2C_0_SDA                                     0x00100000
+#define NV_PPWR_OUTPUT_I2C_1_SDA                                     0x00200000
+#define NV_PPWR_OUTPUT_I2C_2_SDA                                     0x00400000
+#define NV_PPWR_OUTPUT_I2C_3_SDA                                     0x00800000
+#define NV_PPWR_OUTPUT_I2C_4_SDA                                     0x01000000
+#define NV_PPWR_OUTPUT_I2C_5_SDA                                     0x02000000
+#define NV_PPWR_OUTPUT_I2C_6_SDA                                     0x04000000
+#define NV_PPWR_OUTPUT_I2C_7_SDA                                     0x08000000
+#define NV_PPWR_OUTPUT_I2C_8_SDA                                     0x10000000
+#define NV_PPWR_OUTPUT_I2C_9_SDA                                     0x20000000
+#endif
+#define NV_PPWR_INPUT                                                    0x07c4
 #define NV_PPWR_OUTPUT_SET                                               0x07e0
 #define NV_PPWR_OUTPUT_SET_FB_PAUSE                                  0x00000004
 #define NV_PPWR_OUTPUT_CLR                                               0x07e4
@@ -125,6 +169,15 @@
 */ .b32 0 /*
 */ .skip 64
 
+#if NV_PPWR_CHIPSET < GK208
+#define imm32(reg,val) /*
+*/ movw reg  ((val) & 0x0000ffff) /*
+*/ sethi reg ((val) & 0xffff0000)
+#else
+#define imm32(reg,val) /*
+*/ mov reg (val)
+#endif
+
 #ifndef NVKM_FALCON_UNSHIFTED_IO
 #define nv_iord(reg,ior) /*
 */ mov reg ior /*
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nv108.fuc b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nv108.fuc
index 947be53..17a8a38 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nv108.fuc
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nv108.fuc
@@ -37,6 +37,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_PROC
@@ -46,6 +47,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_DATA
@@ -57,6 +59,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_CODE
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nv108.fuc.h b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nv108.fuc.h
index 9342e2d..4bd43a9 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nv108.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nv108.fuc.h
@@ -89,16 +89,9 @@ uint32_t nv108_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
- 0x54534554,
- 0x00000494,
- 0x00000475,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
+ 0x5f433249,
+ 0x00000877,
+ 0x0000071e,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -111,16 +104,6 @@ uint32_t nv108_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
- 0x454c4449,
- 0x0000049f,
- 0x0000049d,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -128,17 +111,16 @@ uint32_t nv108_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+ 0x54534554,
+ 0x00000898,
+ 0x00000879,
  0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0210: proc_list_tail */
-/* 0x0210: time_prev */
  0x00000000,
-/* 0x0214: time_next */
  0x00000000,
-/* 0x0218: fifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -151,6 +133,9 @@ uint32_t nv108_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+ 0x454c4449,
+ 0x000008a3,
+ 0x000008a1,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -170,9 +155,12 @@ uint32_t nv108_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+/* 0x0268: proc_list_tail */
+/* 0x0268: time_prev */
  0x00000000,
-/* 0x0298: rfifo_queue */
+/* 0x026c: time_next */
  0x00000000,
+/* 0x0270: fifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -204,31 +192,8 @@ uint32_t nv108_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0318: memx_func_head */
- 0x00010000,
- 0x00000000,
- 0x000003a9,
-/* 0x0324: memx_func_next */
- 0x00000001,
- 0x00000000,
- 0x000003c7,
- 0x00000002,
- 0x00000002,
- 0x000003df,
- 0x00040003,
- 0x00000000,
- 0x00000407,
- 0x00010004,
- 0x00000000,
- 0x00000421,
-/* 0x0354: memx_func_tail */
-/* 0x0354: memx_data_head */
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
  0x00000000,
+/* 0x02f0: rfifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -261,10 +226,25 @@ uint32_t nv108_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+/* 0x0370: memx_func_head */
+ 0x00010000,
  0x00000000,
+ 0x000003a9,
+/* 0x037c: memx_func_next */
+ 0x00000001,
  0x00000000,
+ 0x000003c7,
+ 0x00000002,
+ 0x00000002,
+ 0x000003df,
+ 0x00040003,
  0x00000000,
+ 0x00000407,
+ 0x00010004,
  0x00000000,
+ 0x00000421,
+/* 0x03ac: memx_func_tail */
+/* 0x03ac: memx_data_head */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -735,7 +715,6 @@ uint32_t nv108_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0b54: memx_data_tail */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -778,6 +757,29 @@ uint32_t nv108_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+/* 0x0bac: memx_data_tail */
+/* 0x0bac: i2c_scl_map */
+ 0x00000400,
+ 0x00000800,
+ 0x00001000,
+ 0x00002000,
+ 0x00004000,
+ 0x00008000,
+ 0x00010000,
+ 0x00020000,
+ 0x00040000,
+ 0x00080000,
+/* 0x0bd4: i2c_sda_map */
+ 0x00100000,
+ 0x00200000,
+ 0x00400000,
+ 0x00800000,
+ 0x01000000,
+ 0x02000000,
+ 0x04000000,
+ 0x08000000,
+ 0x10000000,
+ 0x20000000,
  0x00000000,
 };
 
@@ -786,13 +788,13 @@ uint32_t nv108_pwr_code[] = {
 /* 0x0004: rd32 */
  0xf607a040,
  0x04bd000e,
- 0xe3f0010e,
+ 0xd3f0010d,
  0x07ac4001,
- 0xbd000ef6,
+ 0xbd000df6,
 /* 0x0019: rd32_wait */
- 0x07ac4e04,
- 0xf100eecf,
- 0xf47000e4,
+ 0x07ac4d04,
+ 0xf100ddcf,
+ 0xf47000d4,
  0xa44df61b,
  0x00ddcf07,
 /* 0x002e: wr32 */
@@ -800,14 +802,14 @@ uint32_t nv108_pwr_code[] = {
  0x000ef607,
  0xa44004bd,
  0x000df607,
- 0x020e04bd,
- 0xf0f0e5f0,
- 0xac4001e3,
- 0x000ef607,
+ 0x020d04bd,
+ 0xf0f0d5f0,
+ 0xac4001d3,
+ 0x000df607,
 /* 0x004e: wr32_wait */
- 0xac4e04bd,
- 0x00eecf07,
- 0x7000e4f1,
+ 0xac4d04bd,
+ 0x00ddcf07,
+ 0x7000d4f1,
  0xf8f61bf4,
 /* 0x005d: nsec */
  0xcf2c0800,
@@ -832,20 +834,20 @@ uint32_t nv108_pwr_code[] = {
  0x03e99800,
  0xf40096b0,
  0x0a98280b,
- 0x029abb84,
+ 0x029abb9a,
  0x0d0e1cf4,
  0x01de7e01,
  0xf494bd00,
 /* 0x00b2: intr_watchdog_next_time */
  0x0a98140e,
- 0x00a6b085,
+ 0x00a6b09b,
  0xa6080bf4,
  0x061cf49a,
 /* 0x00c0: intr_watchdog_next_time_set */
 /* 0x00c3: intr_watchdog_next_proc */
- 0xb58509b5,
+ 0xb59b09b5,
  0xe0b603e9,
- 0x10e6b158,
+ 0x68e6b158,
  0xc81bf402,
 /* 0x00d2: intr */
  0x00f900f8,
@@ -862,15 +864,15 @@ uint32_t nv108_pwr_code[] = {
  0x080804bd,
  0xc40088cf,
  0x0bf40289,
- 0x8500b51f,
+ 0x9b00b51f,
  0x957e580e,
  0x09980000,
- 0x0096b085,
+ 0x0096b09b,
  0x000d0bf4,
  0x0009f634,
  0x09b504bd,
 /* 0x0125: intr_skip_watchdog */
- 0x0089e484,
+ 0x0089e49a,
  0x360bf408,
  0xcf068849,
  0x9ac40099,
@@ -918,7 +920,7 @@ uint32_t nv108_pwr_code[] = {
 /* 0x01c6: timer_reset */
  0x3400161e,
  0xbd000ef6,
- 0x840eb504,
+ 0x9a0eb504,
 /* 0x01d0: timer_enable */
  0x38000108,
  0xbd0008f6,
@@ -949,7 +951,7 @@ uint32_t nv108_pwr_code[] = {
  0xa6008a98,
  0x100bf4ae,
  0xb15880b6,
- 0xf4021086,
+ 0xf4026886,
  0x32f4f11b,
 /* 0x0239: find_done */
  0xfc8eb201,
@@ -1009,7 +1011,7 @@ uint32_t nv108_pwr_code[] = {
  0x0bf412a6,
  0x071ec42e,
  0xb704ee94,
- 0x980218e0,
+ 0x980270e0,
  0xec9803eb,
  0x01ed9802,
  0x7e00ee98,
@@ -1031,7 +1033,7 @@ uint32_t nv108_pwr_code[] = {
  0xf412a608,
  0x23c4ef0b,
  0x0434b607,
- 0x029830b7,
+ 0x02f030b7,
  0xb5033bb5,
  0x3db5023c,
  0x003eb501,
@@ -1044,11 +1046,11 @@ uint32_t nv108_pwr_code[] = {
 /* 0x0379: host_init */
  0x00804100,
  0xf11014b6,
- 0x40021815,
+ 0x40027015,
  0x01f604d0,
  0x4104bd00,
  0x14b60080,
- 0x9815f110,
+ 0xf015f110,
  0x04dc4002,
  0xbd0001f6,
  0x40010104,
@@ -1101,13 +1103,13 @@ uint32_t nv108_pwr_code[] = {
  0x001398b2,
  0x950410b6,
  0x30f01034,
- 0xc835980c,
+ 0xde35980c,
  0x12a655f9,
  0xfced1ef4,
  0x7ee0fcd0,
  0xf800023f,
 /* 0x0455: memx_info */
- 0x03544c00,
+ 0x03ac4c00,
  0x7e08004b,
  0xf800023f,
 /* 0x0461: memx_recv */
@@ -1119,7 +1121,301 @@ uint32_t nv108_pwr_code[] = {
 /* 0x0471: perf_recv */
 /* 0x0473: perf_init */
  0xf800f800,
-/* 0x0475: test_recv */
+/* 0x0475: i2c_drive_scl */
+ 0x0036b000,
+ 0x400d0bf4,
+ 0x01f607e0,
+ 0xf804bd00,
+/* 0x0485: i2c_drive_scl_lo */
+ 0x07e44000,
+ 0xbd0001f6,
+/* 0x048f: i2c_drive_sda */
+ 0xb000f804,
+ 0x0bf40036,
+ 0x07e0400d,
+ 0xbd0002f6,
+/* 0x049f: i2c_drive_sda_lo */
+ 0x4000f804,
+ 0x02f607e4,
+ 0xf804bd00,
+/* 0x04a9: i2c_sense_scl */
+ 0x0132f400,
+ 0xcf07c443,
+ 0x31fd0033,
+ 0x060bf404,
+/* 0x04bb: i2c_sense_scl_done */
+ 0xf80131f4,
+/* 0x04bd: i2c_sense_sda */
+ 0x0132f400,
+ 0xcf07c443,
+ 0x32fd0033,
+ 0x060bf404,
+/* 0x04cf: i2c_sense_sda_done */
+ 0xf80131f4,
+/* 0x04d1: i2c_raise_scl */
+ 0x4440f900,
+ 0x01030898,
+ 0x0004757e,
+/* 0x04dc: i2c_raise_scl_wait */
+ 0x7e03e84e,
+ 0x7e00005d,
+ 0xf40004a9,
+ 0x42b60901,
+ 0xef1bf401,
+/* 0x04f0: i2c_raise_scl_done */
+ 0x00f840fc,
+/* 0x04f4: i2c_start */
+ 0x0004a97e,
+ 0x7e0d11f4,
+ 0xf40004bd,
+ 0x0ef40611,
+/* 0x0505: i2c_start_rep */
+ 0x7e00032e,
+ 0x03000475,
+ 0x048f7e01,
+ 0x0076bb00,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0xd17e50fc,
+ 0x64b60004,
+ 0x1d11f404,
+/* 0x0530: i2c_start_send */
+ 0x8f7e0003,
+ 0x884e0004,
+ 0x005d7e13,
+ 0x7e000300,
+ 0x4e000475,
+ 0x5d7e1388,
+/* 0x054a: i2c_start_out */
+ 0x00f80000,
+/* 0x054c: i2c_stop */
+ 0x757e0003,
+ 0x00030004,
+ 0x00048f7e,
+ 0x7e03e84e,
+ 0x0300005d,
+ 0x04757e01,
+ 0x13884e00,
+ 0x00005d7e,
+ 0x8f7e0103,
+ 0x884e0004,
+ 0x005d7e13,
+/* 0x057b: i2c_bitw */
+ 0x7e00f800,
+ 0x4e00048f,
+ 0x5d7e03e8,
+ 0x76bb0000,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0x7e50fc04,
+ 0xb60004d1,
+ 0x11f40464,
+ 0x13884e17,
+ 0x00005d7e,
+ 0x757e0003,
+ 0x884e0004,
+ 0x005d7e13,
+/* 0x05b9: i2c_bitw_out */
+/* 0x05bb: i2c_bitr */
+ 0x0300f800,
+ 0x048f7e01,
+ 0x03e84e00,
+ 0x00005d7e,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x04d17e50,
+ 0x0464b600,
+ 0x7e1a11f4,
+ 0x030004bd,
+ 0x04757e00,
+ 0x13884e00,
+ 0x00005d7e,
+ 0xf4013cf0,
+/* 0x05fe: i2c_bitr_done */
+ 0x00f80131,
+/* 0x0600: i2c_get_byte */
+ 0x08040005,
+/* 0x0604: i2c_get_byte_next */
+ 0xbb0154b6,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x0005bb7e,
+ 0xf40464b6,
+ 0x53fd2a11,
+ 0x0142b605,
+ 0x03d81bf4,
+ 0x0076bb01,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x7b7e50fc,
+ 0x64b60005,
+/* 0x064d: i2c_get_byte_done */
+/* 0x064f: i2c_put_byte */
+ 0x0400f804,
+/* 0x0651: i2c_put_byte_next */
+ 0x0142b608,
+ 0xbb3854ff,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x00057b7e,
+ 0xf40464b6,
+ 0x46b03411,
+ 0xd81bf400,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x05bb7e50,
+ 0x0464b600,
+ 0xbb0f11f4,
+ 0x36b00076,
+ 0x061bf401,
+/* 0x06a7: i2c_put_byte_done */
+ 0xf80132f4,
+/* 0x06a9: i2c_addr */
+ 0x0076bb00,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0xf47e50fc,
+ 0x64b60004,
+ 0x2911f404,
+ 0x012ec3e7,
+ 0xfd0134b6,
+ 0x76bb0553,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0x7e50fc04,
+ 0xb600064f,
+/* 0x06ee: i2c_addr_done */
+ 0x00f80464,
+/* 0x06f0: i2c_acquire_addr */
+ 0xb6f8cec7,
+ 0xe0b705e4,
+ 0x00f8d014,
+/* 0x06fc: i2c_acquire */
+ 0x0006f07e,
+ 0x0000047e,
+ 0x7e03d9f0,
+ 0xf800002e,
+/* 0x070d: i2c_release */
+ 0x06f07e00,
+ 0x00047e00,
+ 0x03daf000,
+ 0x00002e7e,
+/* 0x071e: i2c_recv */
+ 0x32f400f8,
+ 0xf8c1c701,
+ 0xb00214b6,
+ 0x1ff52816,
+ 0x13b80137,
+ 0x98000bd4,
+ 0x13b80032,
+ 0x98000bac,
+ 0x31f40031,
+ 0xf9d0f902,
+ 0xf1d0f9e0,
+ 0xf1000067,
+ 0x92100063,
+ 0x76bb0167,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0x7e50fc04,
+ 0xb60006fc,
+ 0xd0fc0464,
+ 0xf500d6b0,
+ 0x0500b01b,
+ 0x0076bb00,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0xa97e50fc,
+ 0x64b60006,
+ 0xcc11f504,
+ 0xe0c5c700,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x064f7e50,
+ 0x0464b600,
+ 0x00a911f5,
+ 0x76bb0105,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0x7e50fc04,
+ 0xb60006a9,
+ 0x11f50464,
+ 0x76bb0087,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0x7e50fc04,
+ 0xb6000600,
+ 0x11f40464,
+ 0xe05bcb67,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x054c7e50,
+ 0x0464b600,
+ 0x74bd5bb2,
+/* 0x0823: i2c_recv_not_rd08 */
+ 0xb0410ef4,
+ 0x1bf401d6,
+ 0x7e00053b,
+ 0xf40006a9,
+ 0xc5c73211,
+ 0x064f7ee0,
+ 0x2811f400,
+ 0xa97e0005,
+ 0x11f40006,
+ 0xe0b5c71f,
+ 0x00064f7e,
+ 0x7e1511f4,
+ 0xbd00054c,
+ 0x08c5c774,
+ 0xf4091bf4,
+ 0x0ef40232,
+/* 0x0861: i2c_recv_not_wr08 */
+/* 0x0861: i2c_recv_done */
+ 0xf8cec703,
+ 0x00070d7e,
+ 0xd0fce0fc,
+ 0xb20912f4,
+ 0x023f7e7c,
+/* 0x0875: i2c_recv_exit */
+/* 0x0877: i2c_init */
+ 0xf800f800,
+/* 0x0879: test_recv */
  0x04584100,
  0xb60011cf,
  0x58400110,
@@ -1128,26 +1424,26 @@ uint32_t nv108_pwr_code[] = {
  0xe3f1d900,
  0x967e134f,
  0x00f80001,
-/* 0x0494: test_init */
+/* 0x0898: test_init */
  0x7e08004e,
  0xf8000196,
-/* 0x049d: idle_recv */
-/* 0x049f: idle */
+/* 0x08a1: idle_recv */
+/* 0x08a3: idle */
  0xf400f800,
  0x54410031,
  0x0011cf04,
  0x400110b6,
  0x01f60454,
-/* 0x04b3: idle_loop */
+/* 0x08b7: idle_loop */
  0x0104bd00,
  0x0232f458,
-/* 0x04b8: idle_proc */
-/* 0x04b8: idle_proc_exec */
+/* 0x08bc: idle_proc */
+/* 0x08bc: idle_proc_exec */
  0x1eb210f9,
  0x0002487e,
  0x11f410fc,
  0x0231f409,
-/* 0x04cb: idle_proc_next */
+/* 0x08cf: idle_proc_next */
  0xb6f00ef4,
  0x1fa65810,
  0xf4e81bf4,
@@ -1161,5 +1457,4 @@ uint32_t nv108_pwr_code[] = {
  0x00000000,
  0x00000000,
  0x00000000,
- 0x00000000,
 };
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nva3.fuc b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nva3.fuc
index 6fde0b8..6744fcc 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nva3.fuc
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nva3.fuc
@@ -37,6 +37,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_PROC
@@ -46,6 +47,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_DATA
@@ -57,6 +59,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_CODE
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nva3.fuc.h b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nva3.fuc.h
index 0fa4d7d..5a73fa6 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nva3.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nva3.fuc.h
@@ -89,9 +89,31 @@ uint32_t nva3_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+ 0x5f433249,
+ 0x00000982,
+ 0x00000825,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
  0x54534554,
- 0x0000057b,
- 0x00000554,
+ 0x000009ab,
+ 0x00000984,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -112,8 +134,8 @@ uint32_t nva3_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x454c4449,
- 0x00000587,
- 0x00000585,
+ 0x000009b7,
+ 0x000009b5,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -133,12 +155,12 @@ uint32_t nva3_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0210: proc_list_tail */
-/* 0x0210: time_prev */
+/* 0x0268: proc_list_tail */
+/* 0x0268: time_prev */
  0x00000000,
-/* 0x0214: time_next */
+/* 0x026c: time_next */
  0x00000000,
-/* 0x0218: fifo_queue */
+/* 0x0270: fifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -171,7 +193,7 @@ uint32_t nva3_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0298: rfifo_queue */
+/* 0x02f0: rfifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -204,11 +226,11 @@ uint32_t nva3_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0318: memx_func_head */
+/* 0x0370: memx_func_head */
  0x00010000,
  0x00000000,
  0x0000046f,
-/* 0x0324: memx_func_next */
+/* 0x037c: memx_func_next */
  0x00000001,
  0x00000000,
  0x00000496,
@@ -221,8 +243,18 @@ uint32_t nva3_pwr_data[] = {
  0x00010004,
  0x00000000,
  0x000004fc,
-/* 0x0354: memx_func_tail */
-/* 0x0354: memx_data_head */
+/* 0x03ac: memx_func_tail */
+/* 0x03ac: memx_data_head */
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -725,6 +757,42 @@ uint32_t nva3_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+/* 0x0bac: memx_data_tail */
+/* 0x0bac: i2c_scl_map */
+ 0x00001000,
+ 0x00004000,
+ 0x00010000,
+ 0x00000100,
+ 0x00040000,
+ 0x00100000,
+ 0x00400000,
+ 0x01000000,
+ 0x04000000,
+ 0x10000000,
+/* 0x0bd4: i2c_sda_map */
+ 0x00002000,
+ 0x00008000,
+ 0x00020000,
+ 0x00000200,
+ 0x00080000,
+ 0x00200000,
+ 0x00800000,
+ 0x02000000,
+ 0x08000000,
+ 0x20000000,
+/* 0x0bfc: i2c_ctrl */
+ 0x0000e138,
+ 0x0000e150,
+ 0x0000e168,
+ 0x0000e180,
+ 0x0000e254,
+ 0x0000e274,
+ 0x0000e764,
+ 0x0000e780,
+ 0x0000e79c,
+ 0x0000e7b8,
+ 0x00000000,
+ 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -735,7 +803,6 @@ uint32_t nva3_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0b54: memx_data_tail */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -787,15 +854,15 @@ uint32_t nva3_pwr_code[] = {
  0x07a007f1,
  0xd00604b6,
  0x04bd000e,
- 0xf001e7f0,
- 0x07f101e3,
+ 0xf001d7f0,
+ 0x07f101d3,
  0x04b607ac,
- 0x000ed006,
+ 0x000dd006,
 /* 0x0022: rd32_wait */
- 0xe7f104bd,
- 0xe4b607ac,
- 0x00eecf06,
- 0x7000e4f1,
+ 0xd7f104bd,
+ 0xd4b607ac,
+ 0x00ddcf06,
+ 0x7000d4f1,
  0xf1f21bf4,
  0xb607a4d7,
  0xddcf06d4,
@@ -807,15 +874,15 @@ uint32_t nva3_pwr_code[] = {
  0xb607a407,
  0x0dd00604,
  0xf004bd00,
- 0xe5f002e7,
- 0x01e3f0f0,
+ 0xd5f002d7,
+ 0x01d3f0f0,
  0x07ac07f1,
  0xd00604b6,
- 0x04bd000e,
+ 0x04bd000d,
 /* 0x006c: wr32_wait */
- 0x07ace7f1,
- 0xcf06e4b6,
- 0xe4f100ee,
+ 0x07acd7f1,
+ 0xcf06d4b6,
+ 0xd4f100dd,
  0x1bf47000,
 /* 0x007f: nsec */
  0xf000f8f2,
@@ -845,21 +912,21 @@ uint32_t nva3_pwr_code[] = {
  0x9800f8df,
  0x96b003e9,
  0x2a0bf400,
- 0xbb840a98,
+ 0xbb9a0a98,
  0x1cf4029a,
  0x01d7f00f,
  0x025421f5,
  0x0ef494bd,
 /* 0x00e9: intr_watchdog_next_time */
- 0x850a9815,
+ 0x9b0a9815,
  0xf400a6b0,
  0x9ab8090b,
  0x061cf406,
 /* 0x00f8: intr_watchdog_next_time_set */
 /* 0x00fb: intr_watchdog_next_proc */
- 0x80850980,
+ 0x809b0980,
  0xe0b603e9,
- 0x10e6b158,
+ 0x68e6b158,
  0xc61bf402,
 /* 0x010a: intr */
  0x00f900f8,
@@ -880,15 +947,15 @@ uint32_t nva3_pwr_code[] = {
  0x0088cf06,
  0xf40289c4,
  0x0080230b,
- 0x58e7f085,
+ 0x58e7f09b,
  0x98cb21f4,
- 0x96b08509,
+ 0x96b09b09,
  0x110bf400,
  0xb63407f0,
  0x09d00604,
  0x8004bd00,
 /* 0x016e: intr_skip_watchdog */
- 0x89e48409,
+ 0x89e49a09,
  0x0bf40800,
  0x8897f148,
  0x0694b606,
@@ -948,7 +1015,7 @@ uint32_t nva3_pwr_code[] = {
  0x000ed006,
  0x0e8004bd,
 /* 0x0241: timer_enable */
- 0x0187f084,
+ 0x0187f09a,
  0xb63807f0,
  0x08d00604,
 /* 0x024f: timer_done */
@@ -979,7 +1046,7 @@ uint32_t nva3_pwr_code[] = {
  0xb8008a98,
  0x0bf406ae,
  0x5880b610,
- 0x021086b1,
+ 0x026886b1,
  0xf4f01bf4,
 /* 0x02b2: find_done */
  0x8eb90132,
@@ -1049,7 +1116,7 @@ uint32_t nva3_pwr_code[] = {
  0x320bf406,
  0x94071ec4,
  0xe0b704ee,
- 0xeb980218,
+ 0xeb980270,
  0x02ec9803,
  0x9801ed98,
  0x21f500ee,
@@ -1075,7 +1142,7 @@ uint32_t nva3_pwr_code[] = {
  0xe60bf406,
  0xb60723c4,
  0x30b70434,
- 0x3b800298,
+ 0x3b8002f0,
  0x023c8003,
  0x80013d80,
  0x20b6003e,
@@ -1090,13 +1157,13 @@ uint32_t nva3_pwr_code[] = {
 /* 0x0430: host_init */
  0x008017f1,
  0xf11014b6,
- 0xf1021815,
+ 0xf1027015,
  0xb604d007,
  0x01d00604,
  0xf104bd00,
  0xb6008017,
  0x15f11014,
- 0x07f10298,
+ 0x07f102f0,
  0x04b604dc,
  0x0001d006,
  0x17f004bd,
@@ -1156,14 +1223,14 @@ uint32_t nva3_pwr_code[] = {
  0x00139802,
  0x950410b6,
  0x30f01034,
- 0xc835980c,
+ 0xde35980c,
  0x12b855f9,
  0xec1ef406,
  0xe0fcd0fc,
  0x02b921f5,
 /* 0x0532: memx_info */
  0xc7f100f8,
- 0xb7f10354,
+ 0xb7f103ac,
  0x21f50800,
  0x00f802b9,
 /* 0x0540: memx_recv */
@@ -1175,7 +1242,312 @@ uint32_t nva3_pwr_code[] = {
 /* 0x0550: perf_recv */
 /* 0x0552: perf_init */
  0x00f800f8,
-/* 0x0554: test_recv */
+/* 0x0554: i2c_drive_scl */
+ 0xf40036b0,
+ 0x07f1110b,
+ 0x04b607e0,
+ 0x0001d006,
+ 0x00f804bd,
+/* 0x0568: i2c_drive_scl_lo */
+ 0x07e407f1,
+ 0xd00604b6,
+ 0x04bd0001,
+/* 0x0576: i2c_drive_sda */
+ 0x36b000f8,
+ 0x110bf400,
+ 0x07e007f1,
+ 0xd00604b6,
+ 0x04bd0002,
+/* 0x058a: i2c_drive_sda_lo */
+ 0x07f100f8,
+ 0x04b607e4,
+ 0x0002d006,
+ 0x00f804bd,
+/* 0x0598: i2c_sense_scl */
+ 0xf10132f4,
+ 0xb607c437,
+ 0x33cf0634,
+ 0x0431fd00,
+ 0xf4060bf4,
+/* 0x05ae: i2c_sense_scl_done */
+ 0x00f80131,
+/* 0x05b0: i2c_sense_sda */
+ 0xf10132f4,
+ 0xb607c437,
+ 0x33cf0634,
+ 0x0432fd00,
+ 0xf4060bf4,
+/* 0x05c6: i2c_sense_sda_done */
+ 0x00f80131,
+/* 0x05c8: i2c_raise_scl */
+ 0x47f140f9,
+ 0x37f00898,
+ 0x5421f501,
+/* 0x05d5: i2c_raise_scl_wait */
+ 0xe8e7f105,
+ 0x7f21f403,
+ 0x059821f5,
+ 0xb60901f4,
+ 0x1bf40142,
+/* 0x05e9: i2c_raise_scl_done */
+ 0xf840fcef,
+/* 0x05ed: i2c_start */
+ 0x9821f500,
+ 0x0d11f405,
+ 0x05b021f5,
+ 0xf40611f4,
+/* 0x05fe: i2c_start_rep */
+ 0x37f0300e,
+ 0x5421f500,
+ 0x0137f005,
+ 0x057621f5,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0xc821f550,
+ 0x0464b605,
+/* 0x062b: i2c_start_send */
+ 0xf01f11f4,
+ 0x21f50037,
+ 0xe7f10576,
+ 0x21f41388,
+ 0x0037f07f,
+ 0x055421f5,
+ 0x1388e7f1,
+/* 0x0647: i2c_start_out */
+ 0xf87f21f4,
+/* 0x0649: i2c_stop */
+ 0x0037f000,
+ 0x055421f5,
+ 0xf50037f0,
+ 0xf1057621,
+ 0xf403e8e7,
+ 0x37f07f21,
+ 0x5421f501,
+ 0x88e7f105,
+ 0x7f21f413,
+ 0xf50137f0,
+ 0xf1057621,
+ 0xf41388e7,
+ 0x00f87f21,
+/* 0x067c: i2c_bitw */
+ 0x057621f5,
+ 0x03e8e7f1,
+ 0xbb7f21f4,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x05c821f5,
+ 0xf40464b6,
+ 0xe7f11811,
+ 0x21f41388,
+ 0x0037f07f,
+ 0x055421f5,
+ 0x1388e7f1,
+/* 0x06bb: i2c_bitw_out */
+ 0xf87f21f4,
+/* 0x06bd: i2c_bitr */
+ 0x0137f000,
+ 0x057621f5,
+ 0x03e8e7f1,
+ 0xbb7f21f4,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x05c821f5,
+ 0xf40464b6,
+ 0x21f51b11,
+ 0x37f005b0,
+ 0x5421f500,
+ 0x88e7f105,
+ 0x7f21f413,
+ 0xf4013cf0,
+/* 0x0702: i2c_bitr_done */
+ 0x00f80131,
+/* 0x0704: i2c_get_byte */
+ 0xf00057f0,
+/* 0x070a: i2c_get_byte_next */
+ 0x54b60847,
+ 0x0076bb01,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b606bd,
+ 0x2b11f404,
+ 0xb60553fd,
+ 0x1bf40142,
+ 0x0137f0d8,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x7c21f550,
+ 0x0464b606,
+/* 0x0754: i2c_get_byte_done */
+/* 0x0756: i2c_put_byte */
+ 0x47f000f8,
+/* 0x0759: i2c_put_byte_next */
+ 0x0142b608,
+ 0xbb3854ff,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x067c21f5,
+ 0xf40464b6,
+ 0x46b03411,
+ 0xd81bf400,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0xbd21f550,
+ 0x0464b606,
+ 0xbb0f11f4,
+ 0x36b00076,
+ 0x061bf401,
+/* 0x07af: i2c_put_byte_done */
+ 0xf80132f4,
+/* 0x07b1: i2c_addr */
+ 0x0076bb00,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b605ed,
+ 0x2911f404,
+ 0x012ec3e7,
+ 0xfd0134b6,
+ 0x76bb0553,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0xf550fc04,
+ 0xb6075621,
+/* 0x07f6: i2c_addr_done */
+ 0x00f80464,
+/* 0x07f8: i2c_acquire_addr */
+ 0xb6f8cec7,
+ 0xe0b702e4,
+ 0xee980bfc,
+/* 0x0807: i2c_acquire */
+ 0xf500f800,
+ 0xf407f821,
+ 0xd9f00421,
+ 0x3f21f403,
+/* 0x0816: i2c_release */
+ 0x21f500f8,
+ 0x21f407f8,
+ 0x03daf004,
+ 0xf83f21f4,
+/* 0x0825: i2c_recv */
+ 0x0132f400,
+ 0xb6f8c1c7,
+ 0x16b00214,
+ 0x3a1ff528,
+ 0xd413a001,
+ 0x0032980b,
+ 0x0bac13a0,
+ 0xf4003198,
+ 0xd0f90231,
+ 0xd0f9e0f9,
+ 0x000067f1,
+ 0x100063f1,
+ 0xbb016792,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x080721f5,
+ 0xfc0464b6,
+ 0x00d6b0d0,
+ 0x00b31bf5,
+ 0xbb0057f0,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x07b121f5,
+ 0xf50464b6,
+ 0xc700d011,
+ 0x76bbe0c5,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0xf550fc04,
+ 0xb6075621,
+ 0x11f50464,
+ 0x57f000ad,
+ 0x0076bb01,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b607b1,
+ 0x8a11f504,
+ 0x0076bb00,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b60704,
+ 0x6a11f404,
+ 0xbbe05bcb,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x064921f5,
+ 0xb90464b6,
+ 0x74bd025b,
+/* 0x092b: i2c_recv_not_rd08 */
+ 0xb0430ef4,
+ 0x1bf401d6,
+ 0x0057f03d,
+ 0x07b121f5,
+ 0xc73311f4,
+ 0x21f5e0c5,
+ 0x11f40756,
+ 0x0057f029,
+ 0x07b121f5,
+ 0xc71f11f4,
+ 0x21f5e0b5,
+ 0x11f40756,
+ 0x4921f515,
+ 0xc774bd06,
+ 0x1bf408c5,
+ 0x0232f409,
+/* 0x096b: i2c_recv_not_wr08 */
+/* 0x096b: i2c_recv_done */
+ 0xc7030ef4,
+ 0x21f5f8ce,
+ 0xe0fc0816,
+ 0x12f4d0fc,
+ 0x027cb90a,
+ 0x02b921f5,
+/* 0x0980: i2c_recv_exit */
+/* 0x0982: i2c_init */
+ 0x00f800f8,
+/* 0x0984: test_recv */
  0x05d817f1,
  0xcf0614b6,
  0x10b60011,
@@ -1185,12 +1557,12 @@ uint32_t nva3_pwr_code[] = {
  0x00e7f104,
  0x4fe3f1d9,
  0xf521f513,
-/* 0x057b: test_init */
+/* 0x09ab: test_init */
  0xf100f801,
  0xf50800e7,
  0xf801f521,
-/* 0x0585: idle_recv */
-/* 0x0587: idle */
+/* 0x09b5: idle_recv */
+/* 0x09b7: idle */
  0xf400f800,
  0x17f10031,
  0x14b605d4,
@@ -1198,32 +1570,20 @@ uint32_t nva3_pwr_code[] = {
  0xf10110b6,
  0xb605d407,
  0x01d00604,
-/* 0x05a3: idle_loop */
+/* 0x09d3: idle_loop */
  0xf004bd00,
  0x32f45817,
-/* 0x05a9: idle_proc */
-/* 0x05a9: idle_proc_exec */
+/* 0x09d9: idle_proc */
+/* 0x09d9: idle_proc_exec */
  0xb910f902,
  0x21f5021e,
  0x10fc02c2,
  0xf40911f4,
  0x0ef40231,
-/* 0x05bd: idle_proc_next */
+/* 0x09ed: idle_proc_next */
  0x5810b6ef,
  0xf4061fb8,
  0x02f4e61b,
  0x0028f4dd,
  0x00bb0ef4,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
 };
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvc0.fuc b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvc0.fuc
index eaa64da..48f7943 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvc0.fuc
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvc0.fuc
@@ -37,6 +37,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_PROC
@@ -46,6 +47,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_DATA
@@ -57,6 +59,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_CODE
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvc0.fuc.h b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvc0.fuc.h
index 82c8e8b..4dba00d 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvc0.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvc0.fuc.h
@@ -89,9 +89,31 @@ uint32_t nvc0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+ 0x5f433249,
+ 0x00000982,
+ 0x00000825,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
  0x54534554,
- 0x0000057b,
- 0x00000554,
+ 0x000009ab,
+ 0x00000984,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -112,8 +134,8 @@ uint32_t nvc0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x454c4449,
- 0x00000587,
- 0x00000585,
+ 0x000009b7,
+ 0x000009b5,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -133,12 +155,12 @@ uint32_t nvc0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0210: proc_list_tail */
-/* 0x0210: time_prev */
+/* 0x0268: proc_list_tail */
+/* 0x0268: time_prev */
  0x00000000,
-/* 0x0214: time_next */
+/* 0x026c: time_next */
  0x00000000,
-/* 0x0218: fifo_queue */
+/* 0x0270: fifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -171,7 +193,7 @@ uint32_t nvc0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0298: rfifo_queue */
+/* 0x02f0: rfifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -204,11 +226,11 @@ uint32_t nvc0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0318: memx_func_head */
+/* 0x0370: memx_func_head */
  0x00010000,
  0x00000000,
  0x0000046f,
-/* 0x0324: memx_func_next */
+/* 0x037c: memx_func_next */
  0x00000001,
  0x00000000,
  0x00000496,
@@ -221,8 +243,18 @@ uint32_t nvc0_pwr_data[] = {
  0x00010004,
  0x00000000,
  0x000004fc,
-/* 0x0354: memx_func_tail */
-/* 0x0354: memx_data_head */
+/* 0x03ac: memx_func_tail */
+/* 0x03ac: memx_data_head */
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
+ 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -725,6 +757,42 @@ uint32_t nvc0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+/* 0x0bac: memx_data_tail */
+/* 0x0bac: i2c_scl_map */
+ 0x00001000,
+ 0x00004000,
+ 0x00010000,
+ 0x00000100,
+ 0x00040000,
+ 0x00100000,
+ 0x00400000,
+ 0x01000000,
+ 0x04000000,
+ 0x10000000,
+/* 0x0bd4: i2c_sda_map */
+ 0x00002000,
+ 0x00008000,
+ 0x00020000,
+ 0x00000200,
+ 0x00080000,
+ 0x00200000,
+ 0x00800000,
+ 0x02000000,
+ 0x08000000,
+ 0x20000000,
+/* 0x0bfc: i2c_ctrl */
+ 0x0000e138,
+ 0x0000e150,
+ 0x0000e168,
+ 0x0000e180,
+ 0x0000e254,
+ 0x0000e274,
+ 0x0000e764,
+ 0x0000e780,
+ 0x0000e79c,
+ 0x0000e7b8,
+ 0x00000000,
+ 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -735,7 +803,6 @@ uint32_t nvc0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0b54: memx_data_tail */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -787,15 +854,15 @@ uint32_t nvc0_pwr_code[] = {
  0x07a007f1,
  0xd00604b6,
  0x04bd000e,
- 0xf001e7f0,
- 0x07f101e3,
+ 0xf001d7f0,
+ 0x07f101d3,
  0x04b607ac,
- 0x000ed006,
+ 0x000dd006,
 /* 0x0022: rd32_wait */
- 0xe7f104bd,
- 0xe4b607ac,
- 0x00eecf06,
- 0x7000e4f1,
+ 0xd7f104bd,
+ 0xd4b607ac,
+ 0x00ddcf06,
+ 0x7000d4f1,
  0xf1f21bf4,
  0xb607a4d7,
  0xddcf06d4,
@@ -807,15 +874,15 @@ uint32_t nvc0_pwr_code[] = {
  0xb607a407,
  0x0dd00604,
  0xf004bd00,
- 0xe5f002e7,
- 0x01e3f0f0,
+ 0xd5f002d7,
+ 0x01d3f0f0,
  0x07ac07f1,
  0xd00604b6,
- 0x04bd000e,
+ 0x04bd000d,
 /* 0x006c: wr32_wait */
- 0x07ace7f1,
- 0xcf06e4b6,
- 0xe4f100ee,
+ 0x07acd7f1,
+ 0xcf06d4b6,
+ 0xd4f100dd,
  0x1bf47000,
 /* 0x007f: nsec */
  0xf000f8f2,
@@ -845,21 +912,21 @@ uint32_t nvc0_pwr_code[] = {
  0x9800f8df,
  0x96b003e9,
  0x2a0bf400,
- 0xbb840a98,
+ 0xbb9a0a98,
  0x1cf4029a,
  0x01d7f00f,
  0x025421f5,
  0x0ef494bd,
 /* 0x00e9: intr_watchdog_next_time */
- 0x850a9815,
+ 0x9b0a9815,
  0xf400a6b0,
  0x9ab8090b,
  0x061cf406,
 /* 0x00f8: intr_watchdog_next_time_set */
 /* 0x00fb: intr_watchdog_next_proc */
- 0x80850980,
+ 0x809b0980,
  0xe0b603e9,
- 0x10e6b158,
+ 0x68e6b158,
  0xc61bf402,
 /* 0x010a: intr */
  0x00f900f8,
@@ -880,15 +947,15 @@ uint32_t nvc0_pwr_code[] = {
  0x0088cf06,
  0xf40289c4,
  0x0080230b,
- 0x58e7f085,
+ 0x58e7f09b,
  0x98cb21f4,
- 0x96b08509,
+ 0x96b09b09,
  0x110bf400,
  0xb63407f0,
  0x09d00604,
  0x8004bd00,
 /* 0x016e: intr_skip_watchdog */
- 0x89e48409,
+ 0x89e49a09,
  0x0bf40800,
  0x8897f148,
  0x0694b606,
@@ -948,7 +1015,7 @@ uint32_t nvc0_pwr_code[] = {
  0x000ed006,
  0x0e8004bd,
 /* 0x0241: timer_enable */
- 0x0187f084,
+ 0x0187f09a,
  0xb63807f0,
  0x08d00604,
 /* 0x024f: timer_done */
@@ -979,7 +1046,7 @@ uint32_t nvc0_pwr_code[] = {
  0xb8008a98,
  0x0bf406ae,
  0x5880b610,
- 0x021086b1,
+ 0x026886b1,
  0xf4f01bf4,
 /* 0x02b2: find_done */
  0x8eb90132,
@@ -1049,7 +1116,7 @@ uint32_t nvc0_pwr_code[] = {
  0x320bf406,
  0x94071ec4,
  0xe0b704ee,
- 0xeb980218,
+ 0xeb980270,
  0x02ec9803,
  0x9801ed98,
  0x21f500ee,
@@ -1075,7 +1142,7 @@ uint32_t nvc0_pwr_code[] = {
  0xe60bf406,
  0xb60723c4,
  0x30b70434,
- 0x3b800298,
+ 0x3b8002f0,
  0x023c8003,
  0x80013d80,
  0x20b6003e,
@@ -1090,13 +1157,13 @@ uint32_t nvc0_pwr_code[] = {
 /* 0x0430: host_init */
  0x008017f1,
  0xf11014b6,
- 0xf1021815,
+ 0xf1027015,
  0xb604d007,
  0x01d00604,
  0xf104bd00,
  0xb6008017,
  0x15f11014,
- 0x07f10298,
+ 0x07f102f0,
  0x04b604dc,
  0x0001d006,
  0x17f004bd,
@@ -1156,14 +1223,14 @@ uint32_t nvc0_pwr_code[] = {
  0x00139802,
  0x950410b6,
  0x30f01034,
- 0xc835980c,
+ 0xde35980c,
  0x12b855f9,
  0xec1ef406,
  0xe0fcd0fc,
  0x02b921f5,
 /* 0x0532: memx_info */
  0xc7f100f8,
- 0xb7f10354,
+ 0xb7f103ac,
  0x21f50800,
  0x00f802b9,
 /* 0x0540: memx_recv */
@@ -1175,7 +1242,312 @@ uint32_t nvc0_pwr_code[] = {
 /* 0x0550: perf_recv */
 /* 0x0552: perf_init */
  0x00f800f8,
-/* 0x0554: test_recv */
+/* 0x0554: i2c_drive_scl */
+ 0xf40036b0,
+ 0x07f1110b,
+ 0x04b607e0,
+ 0x0001d006,
+ 0x00f804bd,
+/* 0x0568: i2c_drive_scl_lo */
+ 0x07e407f1,
+ 0xd00604b6,
+ 0x04bd0001,
+/* 0x0576: i2c_drive_sda */
+ 0x36b000f8,
+ 0x110bf400,
+ 0x07e007f1,
+ 0xd00604b6,
+ 0x04bd0002,
+/* 0x058a: i2c_drive_sda_lo */
+ 0x07f100f8,
+ 0x04b607e4,
+ 0x0002d006,
+ 0x00f804bd,
+/* 0x0598: i2c_sense_scl */
+ 0xf10132f4,
+ 0xb607c437,
+ 0x33cf0634,
+ 0x0431fd00,
+ 0xf4060bf4,
+/* 0x05ae: i2c_sense_scl_done */
+ 0x00f80131,
+/* 0x05b0: i2c_sense_sda */
+ 0xf10132f4,
+ 0xb607c437,
+ 0x33cf0634,
+ 0x0432fd00,
+ 0xf4060bf4,
+/* 0x05c6: i2c_sense_sda_done */
+ 0x00f80131,
+/* 0x05c8: i2c_raise_scl */
+ 0x47f140f9,
+ 0x37f00898,
+ 0x5421f501,
+/* 0x05d5: i2c_raise_scl_wait */
+ 0xe8e7f105,
+ 0x7f21f403,
+ 0x059821f5,
+ 0xb60901f4,
+ 0x1bf40142,
+/* 0x05e9: i2c_raise_scl_done */
+ 0xf840fcef,
+/* 0x05ed: i2c_start */
+ 0x9821f500,
+ 0x0d11f405,
+ 0x05b021f5,
+ 0xf40611f4,
+/* 0x05fe: i2c_start_rep */
+ 0x37f0300e,
+ 0x5421f500,
+ 0x0137f005,
+ 0x057621f5,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0xc821f550,
+ 0x0464b605,
+/* 0x062b: i2c_start_send */
+ 0xf01f11f4,
+ 0x21f50037,
+ 0xe7f10576,
+ 0x21f41388,
+ 0x0037f07f,
+ 0x055421f5,
+ 0x1388e7f1,
+/* 0x0647: i2c_start_out */
+ 0xf87f21f4,
+/* 0x0649: i2c_stop */
+ 0x0037f000,
+ 0x055421f5,
+ 0xf50037f0,
+ 0xf1057621,
+ 0xf403e8e7,
+ 0x37f07f21,
+ 0x5421f501,
+ 0x88e7f105,
+ 0x7f21f413,
+ 0xf50137f0,
+ 0xf1057621,
+ 0xf41388e7,
+ 0x00f87f21,
+/* 0x067c: i2c_bitw */
+ 0x057621f5,
+ 0x03e8e7f1,
+ 0xbb7f21f4,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x05c821f5,
+ 0xf40464b6,
+ 0xe7f11811,
+ 0x21f41388,
+ 0x0037f07f,
+ 0x055421f5,
+ 0x1388e7f1,
+/* 0x06bb: i2c_bitw_out */
+ 0xf87f21f4,
+/* 0x06bd: i2c_bitr */
+ 0x0137f000,
+ 0x057621f5,
+ 0x03e8e7f1,
+ 0xbb7f21f4,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x05c821f5,
+ 0xf40464b6,
+ 0x21f51b11,
+ 0x37f005b0,
+ 0x5421f500,
+ 0x88e7f105,
+ 0x7f21f413,
+ 0xf4013cf0,
+/* 0x0702: i2c_bitr_done */
+ 0x00f80131,
+/* 0x0704: i2c_get_byte */
+ 0xf00057f0,
+/* 0x070a: i2c_get_byte_next */
+ 0x54b60847,
+ 0x0076bb01,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b606bd,
+ 0x2b11f404,
+ 0xb60553fd,
+ 0x1bf40142,
+ 0x0137f0d8,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x7c21f550,
+ 0x0464b606,
+/* 0x0754: i2c_get_byte_done */
+/* 0x0756: i2c_put_byte */
+ 0x47f000f8,
+/* 0x0759: i2c_put_byte_next */
+ 0x0142b608,
+ 0xbb3854ff,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x067c21f5,
+ 0xf40464b6,
+ 0x46b03411,
+ 0xd81bf400,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0xbd21f550,
+ 0x0464b606,
+ 0xbb0f11f4,
+ 0x36b00076,
+ 0x061bf401,
+/* 0x07af: i2c_put_byte_done */
+ 0xf80132f4,
+/* 0x07b1: i2c_addr */
+ 0x0076bb00,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b605ed,
+ 0x2911f404,
+ 0x012ec3e7,
+ 0xfd0134b6,
+ 0x76bb0553,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0xf550fc04,
+ 0xb6075621,
+/* 0x07f6: i2c_addr_done */
+ 0x00f80464,
+/* 0x07f8: i2c_acquire_addr */
+ 0xb6f8cec7,
+ 0xe0b702e4,
+ 0xee980bfc,
+/* 0x0807: i2c_acquire */
+ 0xf500f800,
+ 0xf407f821,
+ 0xd9f00421,
+ 0x3f21f403,
+/* 0x0816: i2c_release */
+ 0x21f500f8,
+ 0x21f407f8,
+ 0x03daf004,
+ 0xf83f21f4,
+/* 0x0825: i2c_recv */
+ 0x0132f400,
+ 0xb6f8c1c7,
+ 0x16b00214,
+ 0x3a1ff528,
+ 0xd413a001,
+ 0x0032980b,
+ 0x0bac13a0,
+ 0xf4003198,
+ 0xd0f90231,
+ 0xd0f9e0f9,
+ 0x000067f1,
+ 0x100063f1,
+ 0xbb016792,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x080721f5,
+ 0xfc0464b6,
+ 0x00d6b0d0,
+ 0x00b31bf5,
+ 0xbb0057f0,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x07b121f5,
+ 0xf50464b6,
+ 0xc700d011,
+ 0x76bbe0c5,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0xf550fc04,
+ 0xb6075621,
+ 0x11f50464,
+ 0x57f000ad,
+ 0x0076bb01,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b607b1,
+ 0x8a11f504,
+ 0x0076bb00,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b60704,
+ 0x6a11f404,
+ 0xbbe05bcb,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x064921f5,
+ 0xb90464b6,
+ 0x74bd025b,
+/* 0x092b: i2c_recv_not_rd08 */
+ 0xb0430ef4,
+ 0x1bf401d6,
+ 0x0057f03d,
+ 0x07b121f5,
+ 0xc73311f4,
+ 0x21f5e0c5,
+ 0x11f40756,
+ 0x0057f029,
+ 0x07b121f5,
+ 0xc71f11f4,
+ 0x21f5e0b5,
+ 0x11f40756,
+ 0x4921f515,
+ 0xc774bd06,
+ 0x1bf408c5,
+ 0x0232f409,
+/* 0x096b: i2c_recv_not_wr08 */
+/* 0x096b: i2c_recv_done */
+ 0xc7030ef4,
+ 0x21f5f8ce,
+ 0xe0fc0816,
+ 0x12f4d0fc,
+ 0x027cb90a,
+ 0x02b921f5,
+/* 0x0980: i2c_recv_exit */
+/* 0x0982: i2c_init */
+ 0x00f800f8,
+/* 0x0984: test_recv */
  0x05d817f1,
  0xcf0614b6,
  0x10b60011,
@@ -1185,12 +1557,12 @@ uint32_t nvc0_pwr_code[] = {
  0x00e7f104,
  0x4fe3f1d9,
  0xf521f513,
-/* 0x057b: test_init */
+/* 0x09ab: test_init */
  0xf100f801,
  0xf50800e7,
  0xf801f521,
-/* 0x0585: idle_recv */
-/* 0x0587: idle */
+/* 0x09b5: idle_recv */
+/* 0x09b7: idle */
  0xf400f800,
  0x17f10031,
  0x14b605d4,
@@ -1198,32 +1570,20 @@ uint32_t nvc0_pwr_code[] = {
  0xf10110b6,
  0xb605d407,
  0x01d00604,
-/* 0x05a3: idle_loop */
+/* 0x09d3: idle_loop */
  0xf004bd00,
  0x32f45817,
-/* 0x05a9: idle_proc */
-/* 0x05a9: idle_proc_exec */
+/* 0x09d9: idle_proc */
+/* 0x09d9: idle_proc_exec */
  0xb910f902,
  0x21f5021e,
  0x10fc02c2,
  0xf40911f4,
  0x0ef40231,
-/* 0x05bd: idle_proc_next */
+/* 0x09ed: idle_proc_next */
  0x5810b6ef,
  0xf4061fb8,
  0x02f4e61b,
  0x0028f4dd,
  0x00bb0ef4,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
 };
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvd0.fuc b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvd0.fuc
index 32d65ea..8a89dfe 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvd0.fuc
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvd0.fuc
@@ -37,6 +37,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_PROC
@@ -46,6 +47,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_DATA
@@ -57,6 +59,7 @@
 #include "host.fuc"
 #include "memx.fuc"
 #include "perf.fuc"
+#include "i2c_.fuc"
 #include "test.fuc"
 #include "idle.fuc"
 #undef INCLUDE_CODE
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvd0.fuc.h b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvd0.fuc.h
index ce65e2a..5e24c6b 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvd0.fuc.h
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/nvd0.fuc.h
@@ -89,33 +89,13 @@ uint32_t nvd0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
- 0x54534554,
- 0x000004eb,
- 0x000004ca,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
+ 0x5f433249,
+ 0x000008e3,
+ 0x00000786,
  0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
- 0x454c4449,
- 0x000004f7,
- 0x000004f5,
- 0x00000000,
- 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -131,14 +111,13 @@ uint32_t nvd0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+ 0x54534554,
+ 0x00000906,
+ 0x000008e5,
  0x00000000,
  0x00000000,
-/* 0x0210: proc_list_tail */
-/* 0x0210: time_prev */
  0x00000000,
-/* 0x0214: time_next */
  0x00000000,
-/* 0x0218: fifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -154,6 +133,9 @@ uint32_t nvd0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+ 0x454c4449,
+ 0x00000912,
+ 0x00000910,
  0x00000000,
  0x00000000,
  0x00000000,
@@ -171,11 +153,14 @@ uint32_t nvd0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0298: rfifo_queue */
  0x00000000,
  0x00000000,
+/* 0x0268: proc_list_tail */
+/* 0x0268: time_prev */
  0x00000000,
+/* 0x026c: time_next */
  0x00000000,
+/* 0x0270: fifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -204,31 +189,11 @@ uint32_t nvd0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0318: memx_func_head */
- 0x00010000,
- 0x00000000,
- 0x000003f4,
-/* 0x0324: memx_func_next */
- 0x00000001,
- 0x00000000,
- 0x00000415,
- 0x00000002,
- 0x00000002,
- 0x00000430,
- 0x00040003,
- 0x00000000,
- 0x00000458,
- 0x00010004,
- 0x00000000,
- 0x00000472,
-/* 0x0354: memx_func_tail */
-/* 0x0354: memx_data_head */
- 0x00000000,
- 0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
  0x00000000,
+/* 0x02f0: rfifo_queue */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -261,10 +226,25 @@ uint32_t nvd0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+/* 0x0370: memx_func_head */
+ 0x00010000,
  0x00000000,
+ 0x000003f4,
+/* 0x037c: memx_func_next */
+ 0x00000001,
  0x00000000,
+ 0x00000415,
+ 0x00000002,
+ 0x00000002,
+ 0x00000430,
+ 0x00040003,
  0x00000000,
+ 0x00000458,
+ 0x00010004,
  0x00000000,
+ 0x00000472,
+/* 0x03ac: memx_func_tail */
+/* 0x03ac: memx_data_head */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -735,7 +715,6 @@ uint32_t nvd0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
-/* 0x0b54: memx_data_tail */
  0x00000000,
  0x00000000,
  0x00000000,
@@ -778,6 +757,29 @@ uint32_t nvd0_pwr_data[] = {
  0x00000000,
  0x00000000,
  0x00000000,
+/* 0x0bac: memx_data_tail */
+/* 0x0bac: i2c_scl_map */
+ 0x00000400,
+ 0x00000800,
+ 0x00001000,
+ 0x00002000,
+ 0x00004000,
+ 0x00008000,
+ 0x00010000,
+ 0x00020000,
+ 0x00040000,
+ 0x00080000,
+/* 0x0bd4: i2c_sda_map */
+ 0x00100000,
+ 0x00200000,
+ 0x00400000,
+ 0x00800000,
+ 0x01000000,
+ 0x02000000,
+ 0x04000000,
+ 0x08000000,
+ 0x10000000,
+ 0x20000000,
  0x00000000,
 };
 
@@ -786,14 +788,14 @@ uint32_t nvd0_pwr_code[] = {
 /* 0x0004: rd32 */
  0x07a007f1,
  0xbd000ed0,
- 0x01e7f004,
- 0xf101e3f0,
+ 0x01d7f004,
+ 0xf101d3f0,
  0xd007ac07,
- 0x04bd000e,
+ 0x04bd000d,
 /* 0x001c: rd32_wait */
- 0x07ace7f1,
- 0xf100eecf,
- 0xf47000e4,
+ 0x07acd7f1,
+ 0xf100ddcf,
+ 0xf47000d4,
  0xd7f1f51b,
  0xddcf07a4,
 /* 0x0033: wr32 */
@@ -802,14 +804,14 @@ uint32_t nvd0_pwr_code[] = {
  0x04bd000e,
  0x07a407f1,
  0xbd000dd0,
- 0x02e7f004,
- 0xf0f0e5f0,
- 0x07f101e3,
- 0x0ed007ac,
+ 0x02d7f004,
+ 0xf0f0d5f0,
+ 0x07f101d3,
+ 0x0dd007ac,
 /* 0x0057: wr32_wait */
  0xf104bd00,
- 0xcf07ace7,
- 0xe4f100ee,
+ 0xcf07acd7,
+ 0xd4f100dd,
  0x1bf47000,
 /* 0x0067: nsec */
  0xf000f8f5,
@@ -836,21 +838,21 @@ uint32_t nvd0_pwr_code[] = {
  0x9800f8e2,
  0x96b003e9,
  0x2a0bf400,
- 0xbb840a98,
+ 0xbb9a0a98,
  0x1cf4029a,
  0x01d7f00f,
  0x020621f5,
  0x0ef494bd,
 /* 0x00c5: intr_watchdog_next_time */
- 0x850a9815,
+ 0x9b0a9815,
  0xf400a6b0,
  0x9ab8090b,
  0x061cf406,
 /* 0x00d4: intr_watchdog_next_time_set */
 /* 0x00d7: intr_watchdog_next_proc */
- 0x80850980,
+ 0x809b0980,
  0xe0b603e9,
- 0x10e6b158,
+ 0x68e6b158,
  0xc61bf402,
 /* 0x00e6: intr */
  0x00f900f8,
@@ -868,15 +870,15 @@ uint32_t nvd0_pwr_code[] = {
  0x0887f004,
  0xc40088cf,
  0x0bf40289,
- 0x85008020,
+ 0x9b008020,
  0xf458e7f0,
  0x0998a721,
- 0x0096b085,
+ 0x0096b09b,
  0xf00e0bf4,
  0x09d03407,
  0x8004bd00,
 /* 0x013e: intr_skip_watchdog */
- 0x89e48409,
+ 0x89e49a09,
  0x0bf40800,
  0x8897f13c,
  0x0099cf06,
@@ -929,7 +931,7 @@ uint32_t nvd0_pwr_code[] = {
  0x0ed03407,
  0x8004bd00,
 /* 0x01f6: timer_enable */
- 0x87f0840e,
+ 0x87f09a0e,
  0x3807f001,
  0xbd0008d0,
 /* 0x0201: timer_done */
@@ -960,7 +962,7 @@ uint32_t nvd0_pwr_code[] = {
  0x06aeb800,
  0xb6100bf4,
  0x86b15880,
- 0x1bf40210,
+ 0x1bf40268,
  0x0132f4f0,
 /* 0x0264: find_done */
  0xfc028eb9,
@@ -1024,7 +1026,7 @@ uint32_t nvd0_pwr_code[] = {
  0x0bf40612,
  0x071ec42f,
  0xb704ee94,
- 0x980218e0,
+ 0x980270e0,
  0xec9803eb,
  0x01ed9802,
  0xf500ee98,
@@ -1048,7 +1050,7 @@ uint32_t nvd0_pwr_code[] = {
  0xec0bf406,
  0xb60723c4,
  0x30b70434,
- 0x3b800298,
+ 0x3b8002f0,
  0x023c8003,
  0x80013d80,
  0x20b6003e,
@@ -1061,12 +1063,12 @@ uint32_t nvd0_pwr_code[] = {
 /* 0x03be: host_init */
  0x17f100f8,
  0x14b60080,
- 0x1815f110,
+ 0x7015f110,
  0xd007f102,
  0x0001d004,
  0x17f104bd,
  0x14b60080,
- 0x9815f110,
+ 0xf015f110,
  0xdc07f102,
  0x0001d004,
  0x17f004bd,
@@ -1122,13 +1124,13 @@ uint32_t nvd0_pwr_code[] = {
  0x10b60013,
  0x10349504,
  0x980c30f0,
- 0x55f9c835,
+ 0x55f9de35,
  0xf40612b8,
  0xd0fcec1e,
  0x21f5e0fc,
  0x00f8026b,
 /* 0x04a8: memx_info */
- 0x0354c7f1,
+ 0x03acc7f1,
  0x0800b7f1,
  0x026b21f5,
 /* 0x04b6: memx_recv */
@@ -1140,49 +1142,342 @@ uint32_t nvd0_pwr_code[] = {
 /* 0x04c6: perf_recv */
  0x00f800f8,
 /* 0x04c8: perf_init */
-/* 0x04ca: test_recv */
- 0x17f100f8,
- 0x11cf05d8,
- 0x0110b600,
- 0x05d807f1,
+/* 0x04ca: i2c_drive_scl */
+ 0x36b000f8,
+ 0x0e0bf400,
+ 0x07e007f1,
  0xbd0001d0,
- 0x00e7f104,
- 0x4fe3f1d9,
- 0xb621f513,
-/* 0x04eb: test_init */
- 0xf100f801,
- 0xf50800e7,
- 0xf801b621,
-/* 0x04f5: idle_recv */
-/* 0x04f7: idle */
- 0xf400f800,
- 0x17f10031,
- 0x11cf05d4,
- 0x0110b600,
- 0x05d407f1,
- 0xbd0001d0,
-/* 0x050d: idle_loop */
- 0x5817f004,
-/* 0x0513: idle_proc */
-/* 0x0513: idle_proc_exec */
- 0xf90232f4,
- 0x021eb910,
- 0x027421f5,
- 0x11f410fc,
- 0x0231f409,
-/* 0x0527: idle_proc_next */
- 0xb6ef0ef4,
- 0x1fb85810,
- 0xe61bf406,
- 0xf4dd02f4,
- 0x0ef40028,
- 0x000000c1,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
- 0x00000000,
+/* 0x04db: i2c_drive_scl_lo */
+ 0xf100f804,
+ 0xd007e407,
+ 0x04bd0001,
+/* 0x04e6: i2c_drive_sda */
+ 0x36b000f8,
+ 0x0e0bf400,
+ 0x07e007f1,
+ 0xbd0002d0,
+/* 0x04f7: i2c_drive_sda_lo */
+ 0xf100f804,
+ 0xd007e407,
+ 0x04bd0002,
+/* 0x0502: i2c_sense_scl */
+ 0x32f400f8,
+ 0xc437f101,
+ 0x0033cf07,
+ 0xf40431fd,
+ 0x31f4060b,
+/* 0x0515: i2c_sense_scl_done */
+/* 0x0517: i2c_sense_sda */
+ 0xf400f801,
+ 0x37f10132,
+ 0x33cf07c4,
+ 0x0432fd00,
+ 0xf4060bf4,
+/* 0x052a: i2c_sense_sda_done */
+ 0x00f80131,
+/* 0x052c: i2c_raise_scl */
+ 0x47f140f9,
+ 0x37f00898,
+ 0xca21f501,
+/* 0x0539: i2c_raise_scl_wait */
+ 0xe8e7f104,
+ 0x6721f403,
+ 0x050221f5,
+ 0xb60901f4,
+ 0x1bf40142,
+/* 0x054d: i2c_raise_scl_done */
+ 0xf840fcef,
+/* 0x0551: i2c_start */
+ 0x0221f500,
+ 0x0d11f405,
+ 0x051721f5,
+ 0xf40611f4,
+/* 0x0562: i2c_start_rep */
+ 0x37f0300e,
+ 0xca21f500,
+ 0x0137f004,
+ 0x04e621f5,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x2c21f550,
+ 0x0464b605,
+/* 0x058f: i2c_start_send */
+ 0xf01f11f4,
+ 0x21f50037,
+ 0xe7f104e6,
+ 0x21f41388,
+ 0x0037f067,
+ 0x04ca21f5,
+ 0x1388e7f1,
+/* 0x05ab: i2c_start_out */
+ 0xf86721f4,
+/* 0x05ad: i2c_stop */
+ 0x0037f000,
+ 0x04ca21f5,
+ 0xf50037f0,
+ 0xf104e621,
+ 0xf403e8e7,
+ 0x37f06721,
+ 0xca21f501,
+ 0x88e7f104,
+ 0x6721f413,
+ 0xf50137f0,
+ 0xf104e621,
+ 0xf41388e7,
+ 0x00f86721,
+/* 0x05e0: i2c_bitw */
+ 0x04e621f5,
+ 0x03e8e7f1,
+ 0xbb6721f4,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x052c21f5,
+ 0xf40464b6,
+ 0xe7f11811,
+ 0x21f41388,
+ 0x0037f067,
+ 0x04ca21f5,
+ 0x1388e7f1,
+/* 0x061f: i2c_bitw_out */
+ 0xf86721f4,
+/* 0x0621: i2c_bitr */
+ 0x0137f000,
+ 0x04e621f5,
+ 0x03e8e7f1,
+ 0xbb6721f4,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x052c21f5,
+ 0xf40464b6,
+ 0x21f51b11,
+ 0x37f00517,
+ 0xca21f500,
+ 0x88e7f104,
+ 0x6721f413,
+ 0xf4013cf0,
+/* 0x0666: i2c_bitr_done */
+ 0x00f80131,
+/* 0x0668: i2c_get_byte */
+ 0xf00057f0,
+/* 0x066e: i2c_get_byte_next */
+ 0x54b60847,
+ 0x0076bb01,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b60621,
+ 0x2b11f404,
+ 0xb60553fd,
+ 0x1bf40142,
+ 0x0137f0d8,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0xe021f550,
+ 0x0464b605,
+/* 0x06b8: i2c_get_byte_done */
+/* 0x06ba: i2c_put_byte */
+ 0x47f000f8,
+/* 0x06bd: i2c_put_byte_next */
+ 0x0142b608,
+ 0xbb3854ff,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x05e021f5,
+ 0xf40464b6,
+ 0x46b03411,
+ 0xd81bf400,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x2121f550,
+ 0x0464b606,
+ 0xbb0f11f4,
+ 0x36b00076,
+ 0x061bf401,
+/* 0x0713: i2c_put_byte_done */
+ 0xf80132f4,
+/* 0x0715: i2c_addr */
+ 0x0076bb00,
+ 0xf90465b6,
+ 0x04659450,
+ 0xbd0256bb,
+ 0x0475fd50,
+ 0x21f550fc,
+ 0x64b60551,
+ 0x2911f404,
+ 0x012ec3e7,
+ 0xfd0134b6,
+ 0x76bb0553,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0xf550fc04,
+ 0xb606ba21,
+/* 0x075a: i2c_addr_done */
+ 0x00f80464,
+/* 0x075c: i2c_acquire_addr */
+ 0xb6f8cec7,
+ 0xe0b705e4,
+ 0x00f8d014,
+/* 0x0768: i2c_acquire */
+ 0x075c21f5,
+ 0xf00421f4,
+ 0x21f403d9,
+/* 0x0777: i2c_release */
+ 0xf500f833,
+ 0xf4075c21,
+ 0xdaf00421,
+ 0x3321f403,
+/* 0x0786: i2c_recv */
+ 0x32f400f8,
+ 0xf8c1c701,
+ 0xb00214b6,
+ 0x1ff52816,
+ 0x13a0013a,
+ 0x32980bd4,
+ 0xac13a000,
+ 0x0031980b,
+ 0xf90231f4,
+ 0xf9e0f9d0,
+ 0x0067f1d0,
+ 0x0063f100,
+ 0x01679210,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x6821f550,
+ 0x0464b607,
+ 0xd6b0d0fc,
+ 0xb31bf500,
+ 0x0057f000,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0x1521f550,
+ 0x0464b607,
+ 0x00d011f5,
+ 0xbbe0c5c7,
+ 0x65b60076,
+ 0x9450f904,
+ 0x56bb0465,
+ 0xfd50bd02,
+ 0x50fc0475,
+ 0x06ba21f5,
+ 0xf50464b6,
+ 0xf000ad11,
+ 0x76bb0157,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0xf550fc04,
+ 0xb6071521,
+ 0x11f50464,
+ 0x76bb008a,
+ 0x0465b600,
+ 0x659450f9,
+ 0x0256bb04,
+ 0x75fd50bd,
+ 0xf550fc04,
+ 0xb6066821,
+ 0x11f40464,
+ 0xe05bcb6a,
+ 0xb60076bb,
+ 0x50f90465,
+ 0xbb046594,
+ 0x50bd0256,
+ 0xfc0475fd,
+ 0xad21f550,
+ 0x0464b605,
+ 0xbd025bb9,
+ 0x430ef474,
+/* 0x088c: i2c_recv_not_rd08 */
+ 0xf401d6b0,
+ 0x57f03d1b,
+ 0x1521f500,
+ 0x3311f407,
+ 0xf5e0c5c7,
+ 0xf406ba21,
+ 0x57f02911,
+ 0x1521f500,
+ 0x1f11f407,
+ 0xf5e0b5c7,
+ 0xf406ba21,
+ 0x21f51511,
+ 0x74bd05ad,
+ 0xf408c5c7,
+ 0x32f4091b,
+ 0x030ef402,
+/* 0x08cc: i2c_recv_not_wr08 */
+/* 0x08cc: i2c_recv_done */
+ 0xf5f8cec7,
+ 0xfc077721,
+ 0xf4d0fce0,
+ 0x7cb90a12,
+ 0x6b21f502,
+/* 0x08e1: i2c_recv_exit */
+/* 0x08e3: i2c_init */
+ 0xf800f802,
+/* 0x08e5: test_recv */
+ 0xd817f100,
+ 0x0011cf05,
+ 0xf10110b6,
+ 0xd005d807,
+ 0x04bd0001,
+ 0xd900e7f1,
+ 0x134fe3f1,
+ 0x01b621f5,
+/* 0x0906: test_init */
+ 0xe7f100f8,
+ 0x21f50800,
+ 0x00f801b6,
+/* 0x0910: idle_recv */
+/* 0x0912: idle */
+ 0x31f400f8,
+ 0xd417f100,
+ 0x0011cf05,
+ 0xf10110b6,
+ 0xd005d407,
+ 0x04bd0001,
+/* 0x0928: idle_loop */
+ 0xf45817f0,
+/* 0x092e: idle_proc */
+/* 0x092e: idle_proc_exec */
+ 0x10f90232,
+ 0xf5021eb9,
+ 0xfc027421,
+ 0x0911f410,
+ 0xf40231f4,
+/* 0x0942: idle_proc_next */
+ 0x10b6ef0e,
+ 0x061fb858,
+ 0xf4e61bf4,
+ 0x28f4dd02,
+ 0xc10ef400,
  0x00000000,
  0x00000000,
  0x00000000,
diff --git a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/os.h b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/os.h
index 5fb0ccc..574acfa 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/os.h
+++ b/drivers/gpu/drm/nouveau/core/subdev/pwr/fuc/os.h
@@ -7,6 +7,7 @@
 #define PROC_HOST 0x54534f48
 #define PROC_MEMX 0x584d454d
 #define PROC_PERF 0x46524550
+#define PROC_I2C_ 0x5f433249
 #define PROC_TEST 0x54534554
 
 /* KERN: message identifiers */
@@ -24,4 +25,22 @@
 #define MEMX_WAIT   3
 #define MEMX_DELAY  4
 
+/* I2C_: message identifiers */
+#define I2C__MSG_RD08 0
+#define I2C__MSG_WR08 1
+
+#define I2C__MSG_DATA0_PORT 24:31
+#define I2C__MSG_DATA0_ADDR 14:23
+
+#define I2C__MSG_DATA0_RD08_PORT I2C__MSG_DATA0_PORT
+#define I2C__MSG_DATA0_RD08_ADDR I2C__MSG_DATA0_ADDR
+#define I2C__MSG_DATA0_RD08_REG 0:7
+#define I2C__MSG_DATA1_RD08_VAL 0:7
+
+#define I2C__MSG_DATA0_WR08_PORT I2C__MSG_DATA0_PORT
+#define I2C__MSG_DATA0_WR08_ADDR I2C__MSG_DATA0_ADDR
+#define I2C__MSG_DATA0_WR08_SYNC 8:8
+#define I2C__MSG_DATA0_WR08_REG 0:7
+#define I2C__MSG_DATA1_WR08_VAL 0:7
+
 #endif
diff --git a/drivers/gpu/drm/nouveau/core/subdev/vm/base.c b/drivers/gpu/drm/nouveau/core/subdev/vm/base.c
index ef3133e..7dd680f 100644
--- a/drivers/gpu/drm/nouveau/core/subdev/vm/base.c
+++ b/drivers/gpu/drm/nouveau/core/subdev/vm/base.c
@@ -72,13 +72,7 @@ nouveau_vm_map_at(struct nouveau_vma *vma, u64 delta, struct nouveau_mem *node)
  vmm->flush(vm);
 }
 
-void
-nouveau_vm_map(struct nouveau_vma *vma, struct nouveau_mem *node)
-{
- nouveau_vm_map_at(vma, 0, node);
-}
-
-void
+static void
 nouveau_vm_map_sg_table(struct nouveau_vma *vma, u64 delta, u64 length,
    struct nouveau_mem *mem)
 {
@@ -136,7 +130,7 @@ finish:
  vmm->flush(vm);
 }
 
-void
+static void
 nouveau_vm_map_sg(struct nouveau_vma *vma, u64 delta, u64 length,
     struct nouveau_mem *mem)
 {
@@ -175,6 +169,18 @@ nouveau_vm_map_sg(struct nouveau_vma *vma, u64 delta, u64 length,
 }
 
 void
+nouveau_vm_map(struct nouveau_vma *vma, struct nouveau_mem *node)
+{
+ if (node->sg)
+  nouveau_vm_map_sg_table(vma, 0, node->size << 12, node);
+ else
+ if (node->pages)
+  nouveau_vm_map_sg(vma, 0, node->size << 12, node);
+ else
+  nouveau_vm_map_at(vma, 0, node);
+}
+
+void
 nouveau_vm_unmap_at(struct nouveau_vma *vma, u64 delta, u64 length)
 {
  struct nouveau_vm *vm = vma->vm;
diff --git a/drivers/gpu/drm/nouveau/dispnv04/disp.c b/drivers/gpu/drm/nouveau/dispnv04/disp.c
index b13ff0f..2f1ed61 100644
--- a/drivers/gpu/drm/nouveau/dispnv04/disp.c
+++ b/drivers/gpu/drm/nouveau/dispnv04/disp.c
@@ -77,11 +77,6 @@ nv04_display_create(struct drm_device *dev)
 
  nouveau_hw_save_vga_fonts(dev, 1);
 
- ret = nouveau_object_new(nv_object(drm), NVDRM_DEVICE, 0xd1500000,
-     NV04_DISP_CLASS, NULL, 0, &disp->core);
- if (ret)
-  return ret;
-
  nv04_crtc_create(dev, 0);
  if (nv_two_heads(dev))
   nv04_crtc_create(dev, 1);
diff --git a/drivers/gpu/drm/nouveau/dispnv04/disp.h b/drivers/gpu/drm/nouveau/dispnv04/disp.h
index 56a28db..4245fc3 100644
--- a/drivers/gpu/drm/nouveau/dispnv04/disp.h
+++ b/drivers/gpu/drm/nouveau/dispnv04/disp.h
@@ -80,7 +80,6 @@ struct nv04_display {
  struct nv04_mode_state saved_reg;
  uint32_t saved_vga_font[4][16384];
  uint32_t dac_users[4];
- struct nouveau_object *core;
  struct nouveau_bo *image[2];
 };
 
diff --git a/drivers/gpu/drm/nouveau/dispnv04/overlay.c b/drivers/gpu/drm/nouveau/dispnv04/overlay.c
index 32e7064..ab03f77 100644
--- a/drivers/gpu/drm/nouveau/dispnv04/overlay.c
+++ b/drivers/gpu/drm/nouveau/dispnv04/overlay.c
@@ -55,9 +55,12 @@ struct nouveau_plane {
  int hue;
  int saturation;
  int iturbt_709;
+
+ void (*set_params)(struct nouveau_plane *);
 };
 
 static uint32_t formats[] = {
+ DRM_FORMAT_YUYV,
  DRM_FORMAT_UYVY,
  DRM_FORMAT_NV12,
 };
@@ -140,10 +143,10 @@ nv10_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
  nv_wr32(dev, NV_PVIDEO_POINT_OUT(flip), crtc_y << 16 | crtc_x);
  nv_wr32(dev, NV_PVIDEO_SIZE_OUT(flip), crtc_h << 16 | crtc_w);
 
- if (fb->pixel_format == DRM_FORMAT_NV12) {
+ if (fb->pixel_format != DRM_FORMAT_UYVY)
   format |= NV_PVIDEO_FORMAT_COLOR_LE_CR8YB8CB8YA8;
+ if (fb->pixel_format == DRM_FORMAT_NV12)
   format |= NV_PVIDEO_FORMAT_PLANAR;
- }
  if (nv_plane->iturbt_709)
   format |= NV_PVIDEO_FORMAT_MATRIX_ITURBT709;
  if (nv_plane->colorkey & (1 << 24))
@@ -182,9 +185,9 @@ nv10_disable_plane(struct drm_plane *plane)
 }
 
 static void
-nv10_destroy_plane(struct drm_plane *plane)
+nv_destroy_plane(struct drm_plane *plane)
 {
- nv10_disable_plane(plane);
+ plane->funcs->disable_plane(plane);
  drm_plane_cleanup(plane);
  kfree(plane);
 }
@@ -217,9 +220,9 @@ nv10_set_params(struct nouveau_plane *plane)
 }
 
 static int
-nv10_set_property(struct drm_plane *plane,
-    struct drm_property *property,
-    uint64_t value)
+nv_set_property(struct drm_plane *plane,
+  struct drm_property *property,
+  uint64_t value)
 {
  struct nouveau_plane *nv_plane = (struct nouveau_plane *)plane;
 
@@ -238,15 +241,16 @@ nv10_set_property(struct drm_plane *plane,
  else
   return -EINVAL;
 
- nv10_set_params(nv_plane);
+ if (nv_plane->set_params)
+  nv_plane->set_params(nv_plane);
  return 0;
 }
 
 static const struct drm_plane_funcs nv10_plane_funcs = {
  .update_plane = nv10_update_plane,
  .disable_plane = nv10_disable_plane,
- .set_property = nv10_set_property,
- .destroy = nv10_destroy_plane,
+ .set_property = nv_set_property,
+ .destroy = nv_destroy_plane,
 };
 
 static void
@@ -266,7 +270,7 @@ nv10_overlay_init(struct drm_device *device)
  case 0x15:
  case 0x1a:
  case 0x20:
-  num_formats = 1;
+  num_formats = 2;
   break;
  }
 
@@ -321,8 +325,159 @@ nv10_overlay_init(struct drm_device *device)
  drm_object_attach_property(&plane->base.base,
        plane->props.iturbt_709, plane->iturbt_709);
 
+ plane->set_params = nv10_set_params;
  nv10_set_params(plane);
- nv_wr32(dev, NV_PVIDEO_STOP, 1);
+ nv10_disable_plane(&plane->base);
+ return;
+cleanup:
+ drm_plane_cleanup(&plane->base);
+err:
+ kfree(plane);
+ nv_error(dev, "Failed to create plane\n");
+}
+
+static int
+nv04_update_plane(struct drm_plane *plane, struct drm_crtc *crtc,
+    struct drm_framebuffer *fb, int crtc_x, int crtc_y,
+    unsigned int crtc_w, unsigned int crtc_h,
+    uint32_t src_x, uint32_t src_y,
+    uint32_t src_w, uint32_t src_h)
+{
+ struct nouveau_device *dev = nouveau_dev(plane->dev);
+ struct nouveau_plane *nv_plane = (struct nouveau_plane *)plane;
+ struct nouveau_framebuffer *nv_fb = nouveau_framebuffer(fb);
+ struct nouveau_bo *cur = nv_plane->cur;
+ uint32_t overlay = 1;
+ int brightness = (nv_plane->brightness - 512) * 62 / 512;
+ int pitch, ret, i;
+
+ /* Source parameters given in 16.16 fixed point, ignore fractional. */
+ src_x >>= 16;
+ src_y >>= 16;
+ src_w >>= 16;
+ src_h >>= 16;
+
+ pitch = ALIGN(src_w * 4, 0x100);
+
+ if (pitch > 0xffff)
+  return -ERANGE;
+
+ /* TODO: Compute an offset? Not sure how to do this for YUYV. */
+ if (src_x != 0 || src_y != 0)
+  return -ERANGE;
+
+ if (crtc_w < src_w || crtc_h < src_h)
+  return -ERANGE;
+
+ ret = nouveau_bo_pin(nv_fb->nvbo, TTM_PL_FLAG_VRAM);
+ if (ret)
+  return ret;
+
+ nv_plane->cur = nv_fb->nvbo;
+
+ nv_wr32(dev, NV_PVIDEO_OE_STATE, 0);
+ nv_wr32(dev, NV_PVIDEO_SU_STATE, 0);
+ nv_wr32(dev, NV_PVIDEO_RM_STATE, 0);
+
+ for (i = 0; i < 2; i++) {
+  nv_wr32(dev, NV_PVIDEO_BUFF0_START_ADDRESS + 4 * i,
+   nv_fb->nvbo->bo.offset);
+  nv_wr32(dev, NV_PVIDEO_BUFF0_PITCH_LENGTH + 4 * i, pitch);
+  nv_wr32(dev, NV_PVIDEO_BUFF0_OFFSET + 4 * i, 0);
+ }
+ nv_wr32(dev, NV_PVIDEO_WINDOW_START, crtc_y << 16 | crtc_x);
+ nv_wr32(dev, NV_PVIDEO_WINDOW_SIZE, crtc_h << 16 | crtc_w);
+ nv_wr32(dev, NV_PVIDEO_STEP_SIZE,
+  (uint32_t)(((src_h - 1) << 11) / (crtc_h - 1)) << 16 | (uint32_t)(((src_w - 1) << 11) / (crtc_w - 1)));
+
+ /* It should be possible to convert hue/contrast to this */
+ nv_wr32(dev, NV_PVIDEO_RED_CSC_OFFSET, 0x69 - brightness);
+ nv_wr32(dev, NV_PVIDEO_GREEN_CSC_OFFSET, 0x3e + brightness);
+ nv_wr32(dev, NV_PVIDEO_BLUE_CSC_OFFSET, 0x89 - brightness);
+ nv_wr32(dev, NV_PVIDEO_CSC_ADJUST, 0);
+
+ nv_wr32(dev, NV_PVIDEO_CONTROL_Y, 0x001); /* (BLUR_ON, LINE_HALF) */
+ nv_wr32(dev, NV_PVIDEO_CONTROL_X, 0x111); /* (WEIGHT_HEAVY, SHARPENING_ON, SMOOTHING_ON) */
+
+ nv_wr32(dev, NV_PVIDEO_FIFO_BURST_LENGTH, 0x03);
+ nv_wr32(dev, NV_PVIDEO_FIFO_THRES_SIZE, 0x38);
+
+ nv_wr32(dev, NV_PVIDEO_KEY, nv_plane->colorkey);
+
+ if (nv_plane->colorkey & (1 << 24))
+  overlay |= 0x10;
+ if (fb->pixel_format == DRM_FORMAT_YUYV)
+  overlay |= 0x100;
+
+ nv_wr32(dev, NV_PVIDEO_OVERLAY, overlay);
+
+ nv_wr32(dev, NV_PVIDEO_SU_STATE, nv_rd32(dev, NV_PVIDEO_SU_STATE) ^ (1 << 16));
+
+ if (cur)
+  nouveau_bo_unpin(cur);
+
+ return 0;
+}
+
+static int
+nv04_disable_plane(struct drm_plane *plane)
+{
+ struct nouveau_device *dev = nouveau_dev(plane->dev);
+ struct nouveau_plane *nv_plane = (struct nouveau_plane *)plane;
+
+ nv_mask(dev, NV_PVIDEO_OVERLAY, 1, 0);
+ nv_wr32(dev, NV_PVIDEO_OE_STATE, 0);
+ nv_wr32(dev, NV_PVIDEO_SU_STATE, 0);
+ nv_wr32(dev, NV_PVIDEO_RM_STATE, 0);
+ if (nv_plane->cur) {
+  nouveau_bo_unpin(nv_plane->cur);
+  nv_plane->cur = NULL;
+ }
+
+ return 0;
+}
+
+static const struct drm_plane_funcs nv04_plane_funcs = {
+ .update_plane = nv04_update_plane,
+ .disable_plane = nv04_disable_plane,
+ .set_property = nv_set_property,
+ .destroy = nv_destroy_plane,
+};
+
+static void
+nv04_overlay_init(struct drm_device *device)
+{
+ struct nouveau_device *dev = nouveau_dev(device);
+ struct nouveau_plane *plane = kzalloc(sizeof(struct nouveau_plane), GFP_KERNEL);
+ int ret;
+
+ if (!plane)
+  return;
+
+ ret = drm_plane_init(device, &plane->base, 1 /* single crtc */,
+        &nv04_plane_funcs,
+        formats, 2, false);
+ if (ret)
+  goto err;
+
+ /* Set up the plane properties */
+ plane->props.colorkey = drm_property_create_range(
+   device, 0, "colorkey", 0, 0x01ffffff);
+ plane->props.brightness = drm_property_create_range(
+   device, 0, "brightness", 0, 1024);
+ if (!plane->props.colorkey ||
+     !plane->props.brightness)
+  goto cleanup;
+
+ plane->colorkey = 0;
+ drm_object_attach_property(&plane->base.base,
+       plane->props.colorkey, plane->colorkey);
+
+ plane->brightness = 512;
+ drm_object_attach_property(&plane->base.base,
+       plane->props.brightness, plane->brightness);
+
+ nv04_disable_plane(&plane->base);
  return;
 cleanup:
  drm_plane_cleanup(&plane->base);
@@ -335,6 +490,8 @@ void
 nouveau_overlay_init(struct drm_device *device)
 {
  struct nouveau_device *dev = nouveau_dev(device);
- if (dev->chipset >= 0x10 && dev->chipset <= 0x40)
+ if (dev->chipset < 0x10)
+  nv04_overlay_init(device);
+ else if (dev->chipset <= 0x40)
   nv10_overlay_init(device);
 }
diff --git a/drivers/gpu/drm/nouveau/nouveau_bo.c b/drivers/gpu/drm/nouveau/nouveau_bo.c
index a790371..4aed171 100644
--- a/drivers/gpu/drm/nouveau/nouveau_bo.c
+++ b/drivers/gpu/drm/nouveau/nouveau_bo.c
@@ -560,28 +560,6 @@ nouveau_bo_evict_flags(struct ttm_buffer_object *bo, struct ttm_placement *pl)
 }
 
 
-/* GPU-assisted copy using NV_MEMORY_TO_MEMORY_FORMAT, can access
- * TTM_PL_{VRAM,TT} directly.
- */
-
-static int
-nouveau_bo_move_accel_cleanup(struct nouveau_channel *chan,
-         struct nouveau_bo *nvbo, bool evict,
-         bool no_wait_gpu, struct ttm_mem_reg *new_mem)
-{
- struct nouveau_fence *fence = NULL;
- int ret;
-
- ret = nouveau_fence_new(chan, false, &fence);
- if (ret)
-  return ret;
-
- ret = ttm_bo_move_accel_cleanup(&nvbo->bo, fence, evict,
-     no_wait_gpu, new_mem);
- nouveau_fence_unref(&fence);
- return ret;
-}
-
 static int
 nve0_bo_move_init(struct nouveau_channel *chan, u32 handle)
 {
@@ -936,23 +914,28 @@ nv04_bo_move_m2mf(struct nouveau_channel *chan, struct ttm_buffer_object *bo,
 }
 
 static int
-nouveau_vma_getmap(struct nouveau_channel *chan, struct nouveau_bo *nvbo,
-     struct ttm_mem_reg *mem, struct nouveau_vma *vma)
+nouveau_bo_move_prep(struct nouveau_drm *drm, struct ttm_buffer_object *bo,
+       struct ttm_mem_reg *mem)
 {
- struct nouveau_mem *node = mem->mm_node;
+ struct nouveau_mem *old_node = bo->mem.mm_node;
+ struct nouveau_mem *new_node = mem->mm_node;
+ u64 size = (u64)mem->num_pages << PAGE_SHIFT;
  int ret;
 
- ret = nouveau_vm_get(nv_client(chan->cli)->vm, mem->num_pages <<
-        PAGE_SHIFT, node->page_shift,
-        NV_MEM_ACCESS_RW, vma);
+ ret = nouveau_vm_get(nv_client(drm)->vm, size, old_node->page_shift,
+        NV_MEM_ACCESS_RW, &old_node->vma[0]);
  if (ret)
   return ret;
 
- if (mem->mem_type == TTM_PL_VRAM)
-  nouveau_vm_map(vma, node);
- else
-  nouveau_vm_map_sg(vma, 0, mem->num_pages << PAGE_SHIFT, node);
+ ret = nouveau_vm_get(nv_client(drm)->vm, size, new_node->page_shift,
+        NV_MEM_ACCESS_RW, &old_node->vma[1]);
+ if (ret) {
+  nouveau_vm_put(&old_node->vma[0]);
+  return ret;
+ }
 
+ nouveau_vm_map(&old_node->vma[0], old_node);
+ nouveau_vm_map(&old_node->vma[1], new_node);
  return 0;
 }
 
@@ -962,35 +945,34 @@ nouveau_bo_move_m2mf(struct ttm_buffer_object *bo, int evict, bool intr,
 {
  struct nouveau_drm *drm = nouveau_bdev(bo->bdev);
  struct nouveau_channel *chan = drm->ttm.chan;
- struct nouveau_bo *nvbo = nouveau_bo(bo);
- struct ttm_mem_reg *old_mem = &bo->mem;
+ struct nouveau_fence *fence;
  int ret;
 
- mutex_lock_nested(&chan->cli->mutex, SINGLE_DEPTH_NESTING);
-
  /* create temporary vmas for the transfer and attach them to the
   * old nouveau_mem node, these will get cleaned up after ttm has
   * destroyed the ttm_mem_reg
   */
  if (nv_device(drm->device)->card_type >= NV_50) {
-  struct nouveau_mem *node = old_mem->mm_node;
-
-  ret = nouveau_vma_getmap(chan, nvbo, old_mem, &node->vma[0]);
+  ret = nouveau_bo_move_prep(drm, bo, new_mem);
   if (ret)
-   goto out;
-
-  ret = nouveau_vma_getmap(chan, nvbo, new_mem, &node->vma[1]);
-  if (ret)
-   goto out;
+   return ret;
  }
 
- ret = drm->ttm.move(chan, bo, &bo->mem, new_mem);
+ mutex_lock_nested(&chan->cli->mutex, SINGLE_DEPTH_NESTING);
+ ret = nouveau_fence_sync(bo->sync_obj, chan);
  if (ret == 0) {
-  ret = nouveau_bo_move_accel_cleanup(chan, nvbo, evict,
-          no_wait_gpu, new_mem);
+  ret = drm->ttm.move(chan, bo, &bo->mem, new_mem);
+  if (ret == 0) {
+   ret = nouveau_fence_new(chan, false, &fence);
+   if (ret == 0) {
+    ret = ttm_bo_move_accel_cleanup(bo, fence,
+        evict,
+        no_wait_gpu,
+        new_mem);
+    nouveau_fence_unref(&fence);
+   }
+  }
  }
-
-out:
  mutex_unlock(&chan->cli->mutex);
  return ret;
 }
@@ -1130,19 +1112,10 @@ nouveau_bo_move_ntfy(struct ttm_buffer_object *bo, struct ttm_mem_reg *new_mem)
   return;
 
  list_for_each_entry(vma, &nvbo->vma_list, head) {
-  if (new_mem && new_mem->mem_type == TTM_PL_VRAM) {
+  if (new_mem && new_mem->mem_type != TTM_PL_SYSTEM &&
+         (new_mem->mem_type == TTM_PL_VRAM ||
+          nvbo->page_shift != vma->vm->vmm->lpg_shift)) {
    nouveau_vm_map(vma, new_mem->mm_node);
-  } else
-  if (new_mem && new_mem->mem_type == TTM_PL_TT &&
-      nvbo->page_shift == vma->vm->vmm->spg_shift) {
-   if (((struct nouveau_mem *)new_mem->mm_node)->sg)
-    nouveau_vm_map_sg_table(vma, 0, new_mem->
-        num_pages << PAGE_SHIFT,
-        new_mem->mm_node);
-   else
-    nouveau_vm_map_sg(vma, 0, new_mem->
-        num_pages << PAGE_SHIFT,
-        new_mem->mm_node);
   } else {
    nouveau_vm_unmap(vma);
   }
@@ -1207,28 +1180,27 @@ nouveau_bo_move(struct ttm_buffer_object *bo, bool evict, bool intr,
   goto out;
  }
 
- /* CPU copy if we have no accelerated method available */
- if (!drm->ttm.move) {
-  ret = ttm_bo_move_memcpy(bo, evict, no_wait_gpu, new_mem);
-  goto out;
- }
-
  /* Hardware assisted copy. */
- if (new_mem->mem_type == TTM_PL_SYSTEM)
-  ret = nouveau_bo_move_flipd(bo, evict, intr,
-         no_wait_gpu, new_mem);
- else if (old_mem->mem_type == TTM_PL_SYSTEM)
-  ret = nouveau_bo_move_flips(bo, evict, intr,
-         no_wait_gpu, new_mem);
- else
-  ret = nouveau_bo_move_m2mf(bo, evict, intr,
-        no_wait_gpu, new_mem);
-
- if (!ret)
-  goto out;
+ if (drm->ttm.move) {
+  if (new_mem->mem_type == TTM_PL_SYSTEM)
+   ret = nouveau_bo_move_flipd(bo, evict, intr,
+          no_wait_gpu, new_mem);
+  else if (old_mem->mem_type == TTM_PL_SYSTEM)
+   ret = nouveau_bo_move_flips(bo, evict, intr,
+          no_wait_gpu, new_mem);
+  else
+   ret = nouveau_bo_move_m2mf(bo, evict, intr,
+         no_wait_gpu, new_mem);
+  if (!ret)
+   goto out;
+ }
 
  /* Fallback to software copy. */
- ret = ttm_bo_move_memcpy(bo, evict, no_wait_gpu, new_mem);
+ spin_lock(&bo->bdev->fence_lock);
+ ret = ttm_bo_wait(bo, true, intr, no_wait_gpu);
+ spin_unlock(&bo->bdev->fence_lock);
+ if (ret == 0)
+  ret = ttm_bo_move_memcpy(bo, evict, no_wait_gpu, new_mem);
 
 out:
  if (nv_device(drm->device)->card_type < NV_50) {
@@ -1254,6 +1226,7 @@ nouveau_ttm_io_mem_reserve(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem)
 {
  struct ttm_mem_type_manager *man = &bdev->man[mem->mem_type];
  struct nouveau_drm *drm = nouveau_bdev(bdev);
+ struct nouveau_mem *node = mem->mm_node;
  struct drm_device *dev = drm->dev;
  int ret;
 
@@ -1276,14 +1249,16 @@ nouveau_ttm_io_mem_reserve(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem)
    mem->bus.is_iomem = !dev->agp->cant_use_aperture;
   }
 #endif
-  break;
+  if (nv_device(drm->device)->card_type < NV_50 || !node->memtype)
+   /* untiled */
+   break;
+  /* fallthrough, tiled memory */
  case TTM_PL_VRAM:
   mem->bus.offset = mem->start << PAGE_SHIFT;
   mem->bus.base = pci_resource_start(dev->pdev, 1);
   mem->bus.is_iomem = true;
   if (nv_device(drm->device)->card_type >= NV_50) {
    struct nouveau_bar *bar = nouveau_bar(drm->device);
-   struct nouveau_mem *node = mem->mm_node;
 
    ret = bar->umap(bar, node, NV_MEM_ACCESS_RW,
      &node->bar_vma);
@@ -1319,6 +1294,7 @@ nouveau_ttm_fault_reserve_notify(struct ttm_buffer_object *bo)
  struct nouveau_bo *nvbo = nouveau_bo(bo);
  struct nouveau_device *device = nv_device(drm->device);
  u32 mappable = pci_resource_len(device->pdev, 1) >> PAGE_SHIFT;
+ int ret;
 
  /* as long as the bo isn't in vram, and isn't tiled, we've got
   * nothing to do here.
@@ -1327,10 +1303,20 @@ nouveau_ttm_fault_reserve_notify(struct ttm_buffer_object *bo)
   if (nv_device(drm->device)->card_type < NV_50 ||
       !nouveau_bo_tile_layout(nvbo))
    return 0;
+
+  if (bo->mem.mem_type == TTM_PL_SYSTEM) {
+   nouveau_bo_placement_set(nvbo, TTM_PL_TT, 0);
+
+   ret = nouveau_bo_validate(nvbo, false, false);
+   if (ret)
+    return ret;
+  }
+  return 0;
  }
 
  /* make sure bo is in mappable vram */
- if (bo->mem.start + bo->mem.num_pages < mappable)
+ if (nv_device(drm->device)->card_type >= NV_50 ||
+     bo->mem.start + bo->mem.num_pages < mappable)
   return 0;
 
 
@@ -1518,7 +1504,6 @@ nouveau_bo_vma_add(struct nouveau_bo *nvbo, struct nouveau_vm *vm,
      struct nouveau_vma *vma)
 {
  const u32 size = nvbo->bo.mem.num_pages << PAGE_SHIFT;
- struct nouveau_mem *node = nvbo->bo.mem.mm_node;
  int ret;
 
  ret = nouveau_vm_get(vm, size, nvbo->page_shift,
@@ -1526,15 +1511,10 @@ nouveau_bo_vma_add(struct nouveau_bo *nvbo, struct nouveau_vm *vm,
  if (ret)
   return ret;
 
- if (nvbo->bo.mem.mem_type == TTM_PL_VRAM)
+ if ( nvbo->bo.mem.mem_type != TTM_PL_SYSTEM &&
+     (nvbo->bo.mem.mem_type == TTM_PL_VRAM ||
+      nvbo->page_shift != vma->vm->vmm->lpg_shift))
   nouveau_vm_map(vma, nvbo->bo.mem.mm_node);
- else if (nvbo->bo.mem.mem_type == TTM_PL_TT &&
-   nvbo->page_shift == vma->vm->vmm->spg_shift) {
-  if (node->sg)
-   nouveau_vm_map_sg_table(vma, 0, size, node);
-  else
-   nouveau_vm_map_sg(vma, 0, size, node);
- }
 
  list_add_tail(&vma->head, &nvbo->vma_list);
  vma->refcount = 1;
diff --git a/drivers/gpu/drm/nouveau/nouveau_display.c b/drivers/gpu/drm/nouveau/nouveau_display.c
index 91c826c..2401159 100644
--- a/drivers/gpu/drm/nouveau/nouveau_display.c
+++ b/drivers/gpu/drm/nouveau/nouveau_display.c
@@ -68,20 +68,100 @@ nouveau_display_vblank_disable(struct drm_device *dev, int head)
   nouveau_event_put(disp->vblank[head]);
 }
 
+static inline int
+calc(int blanks, int blanke, int total, int line)
+{
+ if (blanke >= blanks) {
+  if (line >= blanks)
+   line -= total;
+ } else {
+  if (line >= blanks)
+   line -= total;
+  line -= blanke + 1;
+ }
+ return line;
+}
+
+int
+nouveau_display_scanoutpos_head(struct drm_crtc *crtc, int *vpos, int *hpos,
+    ktime_t *stime, ktime_t *etime)
+{
+ const u32 mthd = NV04_DISP_SCANOUTPOS + nouveau_crtc(crtc)->index;
+ struct nouveau_display *disp = nouveau_display(crtc->dev);
+ struct nv04_display_scanoutpos args;
+ int ret, retry = 1;
+
+ do {
+  ret = nv_exec(disp->core, mthd, &args, sizeof(args));
+  if (ret != 0)
+   return 0;
+
+  if (args.vline) {
+   ret |= DRM_SCANOUTPOS_ACCURATE;
+   ret |= DRM_SCANOUTPOS_VALID;
+   break;
+  }
+
+  if (retry) ndelay(crtc->linedur_ns);
+ } while (retry--);
+
+ *hpos = calc(args.hblanks, args.hblanke, args.htotal, args.hline);
+ *vpos = calc(args.vblanks, args.vblanke, args.vtotal, args.vline);
+ if (stime) *stime = ns_to_ktime(args.time[0]);
+ if (etime) *etime = ns_to_ktime(args.time[1]);
+
+ if (*vpos < 0)
+  ret |= DRM_SCANOUTPOS_INVBL;
+ return ret;
+}
+
+int
+nouveau_display_scanoutpos(struct drm_device *dev, int head, unsigned int flags,
+      int *vpos, int *hpos, ktime_t *stime, ktime_t *etime)
+{
+ struct drm_crtc *crtc;
+
+ list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+  if (nouveau_crtc(crtc)->index == head) {
+   return nouveau_display_scanoutpos_head(crtc, vpos, hpos,
+              stime, etime);
+  }
+ }
+
+ return 0;
+}
+
+int
+nouveau_display_vblstamp(struct drm_device *dev, int head, int *max_error,
+    struct timeval *time, unsigned flags)
+{
+ struct drm_crtc *crtc;
+
+ list_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {
+  if (nouveau_crtc(crtc)->index == head) {
+   return drm_calc_vbltimestamp_from_scanoutpos(dev,
+     head, max_error, time, flags, crtc,
+     &crtc->hwmode);
+  }
+ }
+
+ return -EINVAL;
+}
+
 static void
 nouveau_display_vblank_fini(struct drm_device *dev)
 {
  struct nouveau_display *disp = nouveau_display(dev);
  int i;
 
+ drm_vblank_cleanup(dev);
+
  if (disp->vblank) {
   for (i = 0; i < dev->mode_config.num_crtc; i++)
    nouveau_event_ref(NULL, &disp->vblank[i]);
   kfree(disp->vblank);
   disp->vblank = NULL;
  }
-
- drm_vblank_cleanup(dev);
 }
 
 static int
@@ -407,10 +487,31 @@ nouveau_display_create(struct drm_device *dev)
  drm_kms_helper_poll_disable(dev);
 
  if (drm->vbios.dcb.entries) {
-  if (nv_device(drm->device)->card_type < NV_50)
-   ret = nv04_display_create(dev);
-  else
-   ret = nv50_display_create(dev);
+  static const u16 oclass[] = {
+   NVF0_DISP_CLASS,
+   NVE0_DISP_CLASS,
+   NVD0_DISP_CLASS,
+   NVA3_DISP_CLASS,
+   NV94_DISP_CLASS,
+   NVA0_DISP_CLASS,
+   NV84_DISP_CLASS,
+   NV50_DISP_CLASS,
+   NV04_DISP_CLASS,
+  };
+  int i;
+
+  for (i = 0, ret = -ENODEV; ret && i < ARRAY_SIZE(oclass); i++) {
+   ret = nouveau_object_new(nv_object(drm), NVDRM_DEVICE,
+       NVDRM_DISPLAY, oclass[i],
+       NULL, 0, &disp->core);
+  }
+
+  if (ret == 0) {
+   if (nv_mclass(disp->core) < NV50_DISP_CLASS)
+    ret = nv04_display_create(dev);
+   else
+    ret = nv50_display_create(dev);
+  }
  } else {
   ret = 0;
  }
@@ -439,6 +540,7 @@ void
 nouveau_display_destroy(struct drm_device *dev)
 {
  struct nouveau_display *disp = nouveau_display(dev);
+ struct nouveau_drm *drm = nouveau_drm(dev);
 
  nouveau_backlight_exit(dev);
  nouveau_display_vblank_fini(dev);
@@ -449,6 +551,8 @@ nouveau_display_destroy(struct drm_device *dev)
  if (disp->dtor)
   disp->dtor(dev);
 
+ nouveau_object_del(nv_object(drm), NVDRM_DEVICE, NVDRM_DISPLAY);
+
  nouveau_drm(dev)->display = NULL;
  kfree(disp);
 }
diff --git a/drivers/gpu/drm/nouveau/nouveau_display.h b/drivers/gpu/drm/nouveau/nouveau_display.h
index 8bc8bab..a71cf77 100644
--- a/drivers/gpu/drm/nouveau/nouveau_display.h
+++ b/drivers/gpu/drm/nouveau/nouveau_display.h
@@ -36,6 +36,7 @@ struct nouveau_display {
  int  (*init)(struct drm_device *);
  void (*fini)(struct drm_device *);
 
+ struct nouveau_object *core;
  struct nouveau_eventh **vblank;
 
  struct drm_property *dithering_mode;
@@ -63,6 +64,10 @@ void nouveau_display_repin(struct drm_device *dev);
 void nouveau_display_resume(struct drm_device *dev);
 int  nouveau_display_vblank_enable(struct drm_device *, int);
 void nouveau_display_vblank_disable(struct drm_device *, int);
+int  nouveau_display_scanoutpos(struct drm_device *, int, unsigned int,
+    int *, int *, ktime_t *, ktime_t *);
+int  nouveau_display_vblstamp(struct drm_device *, int, int *,
+         struct timeval *, unsigned);
 
 int  nouveau_crtc_page_flip(struct drm_crtc *crtc, struct drm_framebuffer *fb,
        struct drm_pending_vblank_event *event,
diff --git a/drivers/gpu/drm/nouveau/nouveau_dma.c b/drivers/gpu/drm/nouveau/nouveau_dma.c
index 40f91e1..c177272 100644
--- a/drivers/gpu/drm/nouveau/nouveau_dma.c
+++ b/drivers/gpu/drm/nouveau/nouveau_dma.c
@@ -100,7 +100,7 @@ nv50_dma_push(struct nouveau_channel *chan, struct nouveau_bo *bo,
 
  chan->dma.ib_put = (chan->dma.ib_put + 1) & chan->dma.ib_max;
 
- DRM_MEMORYBARRIER();
+ mb();
  /* Flush writes. */
  nouveau_bo_rd32(pb, 0);
 
diff --git a/drivers/gpu/drm/nouveau/nouveau_dma.h b/drivers/gpu/drm/nouveau/nouveau_dma.h
index 984004d..dc0e0c5 100644
--- a/drivers/gpu/drm/nouveau/nouveau_dma.h
+++ b/drivers/gpu/drm/nouveau/nouveau_dma.h
@@ -155,7 +155,7 @@ BEGIN_IMC0(struct nouveau_channel *chan, int subc, int mthd, u16 data)
 }
 
 #define WRITE_PUT(val) do {                                                    \
- DRM_MEMORYBARRIER();                                                   \
+ mb();                                                   \
  nouveau_bo_rd32(chan->push.buffer, 0);                                 \
  nv_wo32(chan->object, chan->user_put, ((val) << 2) + chan->push.vma.offset);  \
 } while (0)
diff --git a/drivers/gpu/drm/nouveau/nouveau_drm.c b/drivers/gpu/drm/nouveau/nouveau_drm.c
index 7431033..4ee702a 100644
--- a/drivers/gpu/drm/nouveau/nouveau_drm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_drm.c
@@ -506,19 +506,21 @@ nouveau_do_suspend(struct drm_device *dev)
  if (drm->cechan) {
   ret = nouveau_channel_idle(drm->cechan);
   if (ret)
-   return ret;
+   goto fail_display;
  }
 
  if (drm->channel) {
   ret = nouveau_channel_idle(drm->channel);
   if (ret)
-   return ret;
+   goto fail_display;
  }
 
  NV_INFO(drm, "suspending client object trees...\n");
  if (drm->fence && nouveau_fence(drm)->suspend) {
-  if (!nouveau_fence(drm)->suspend(drm))
-   return -ENOMEM;
+  if (!nouveau_fence(drm)->suspend(drm)) {
+   ret = -ENOMEM;
+   goto fail_display;
+  }
  }
 
  list_for_each_entry(cli, &drm->clients, head) {
@@ -540,6 +542,10 @@ fail_client:
   nouveau_client_init(&cli->base);
  }
 
+ if (drm->fence && nouveau_fence(drm)->resume)
+  nouveau_fence(drm)->resume(drm);
+
+fail_display:
  if (dev->mode_config.num_crtc) {
   NV_INFO(drm, "resuming display...\n");
   nouveau_display_resume(dev);
@@ -801,6 +807,8 @@ driver = {
  .get_vblank_counter = drm_vblank_count,
  .enable_vblank = nouveau_display_vblank_enable,
  .disable_vblank = nouveau_display_vblank_disable,
+ .get_scanout_position = nouveau_display_scanoutpos,
+ .get_vblank_timestamp = nouveau_display_vblstamp,
 
  .ioctls = nouveau_ioctls,
  .num_ioctls = ARRAY_SIZE(nouveau_ioctls),
@@ -858,13 +866,16 @@ static int nouveau_pmops_runtime_suspend(struct device *dev)
  struct drm_device *drm_dev = pci_get_drvdata(pdev);
  int ret;
 
- if (nouveau_runtime_pm == 0)
-  return -EINVAL;
+ if (nouveau_runtime_pm == 0) {
+  pm_runtime_forbid(dev);
+  return -EBUSY;
+ }
 
  /* are we optimus enabled? */
  if (nouveau_runtime_pm == -1 && !nouveau_is_optimus() && !nouveau_is_v1_dsm()) {
   DRM_DEBUG_DRIVER("failing to power off - not optimus\n");
-  return -EINVAL;
+  pm_runtime_forbid(dev);
+  return -EBUSY;
  }
 
  nv_debug_level(SILENT);
@@ -915,12 +926,15 @@ static int nouveau_pmops_runtime_idle(struct device *dev)
  struct nouveau_drm *drm = nouveau_drm(drm_dev);
  struct drm_crtc *crtc;
 
- if (nouveau_runtime_pm == 0)
+ if (nouveau_runtime_pm == 0) {
+  pm_runtime_forbid(dev);
   return -EBUSY;
+ }
 
  /* are we optimus enabled? */
  if (nouveau_runtime_pm == -1 && !nouveau_is_optimus() && !nouveau_is_v1_dsm()) {
   DRM_DEBUG_DRIVER("failing to power off - not optimus\n");
+  pm_runtime_forbid(dev);
   return -EBUSY;
  }
 
diff --git a/drivers/gpu/drm/nouveau/nouveau_drm.h b/drivers/gpu/drm/nouveau/nouveau_drm.h
index 4b0fb6c..23ca7a5 100644
--- a/drivers/gpu/drm/nouveau/nouveau_drm.h
+++ b/drivers/gpu/drm/nouveau/nouveau_drm.h
@@ -54,6 +54,7 @@ enum nouveau_drm_handle {
  NVDRM_CLIENT  = 0xffffffff,
  NVDRM_DEVICE  = 0xdddddddd,
  NVDRM_CONTROL = 0xdddddddc,
+ NVDRM_DISPLAY = 0xd1500000,
  NVDRM_PUSH    = 0xbbbb0000, /* |= client chid */
  NVDRM_CHAN    = 0xcccc0000, /* |= client chid */
  NVDRM_NVSW    = 0x55550000,
diff --git a/drivers/gpu/drm/nouveau/nouveau_fence.c b/drivers/gpu/drm/nouveau/nouveau_fence.c
index 40cf52e..90074d6 100644
--- a/drivers/gpu/drm/nouveau/nouveau_fence.c
+++ b/drivers/gpu/drm/nouveau/nouveau_fence.c
@@ -143,7 +143,7 @@ nouveau_fence_emit(struct nouveau_fence *fence, struct nouveau_channel *chan)
  int ret;
 
  fence->channel  = chan;
- fence->timeout  = jiffies + (15 * DRM_HZ);
+ fence->timeout  = jiffies + (15 * HZ);
  fence->sequence = ++fctx->sequence;
 
  ret = fctx->emit(fence);
diff --git a/drivers/gpu/drm/nouveau/nouveau_gem.c b/drivers/gpu/drm/nouveau/nouveau_gem.c
index 78a27f8..27c3fd8 100644
--- a/drivers/gpu/drm/nouveau/nouveau_gem.c
+++ b/drivers/gpu/drm/nouveau/nouveau_gem.c
@@ -463,12 +463,6 @@ validate_list(struct nouveau_channel *chan, struct nouveau_cli *cli,
  list_for_each_entry(nvbo, list, entry) {
   struct drm_nouveau_gem_pushbuf_bo *b = &pbbo[nvbo->pbbo_index];
 
-  ret = validate_sync(chan, nvbo);
-  if (unlikely(ret)) {
-   NV_ERROR(cli, "fail pre-validate sync\n");
-   return ret;
-  }
-
   ret = nouveau_gem_set_domain(&nvbo->gem, b->read_domains,
           b->write_domains,
           b->valid_domains);
@@ -506,7 +500,7 @@ validate_list(struct nouveau_channel *chan, struct nouveau_cli *cli,
    b->presumed.valid = 0;
    relocs++;
 
-   if (DRM_COPY_TO_USER(&upbbo[nvbo->pbbo_index].presumed,
+   if (copy_to_user(&upbbo[nvbo->pbbo_index].presumed,
           &b->presumed, sizeof(b->presumed)))
     return -EFAULT;
   }
@@ -593,7 +587,7 @@ u_memcpya(uint64_t user, unsigned nmemb, unsigned size)
  if (!mem)
   return ERR_PTR(-ENOMEM);
 
- if (DRM_COPY_FROM_USER(mem, userptr, size)) {
+ if (copy_from_user(mem, userptr, size)) {
   u_free(mem);
   return ERR_PTR(-EFAULT);
  }
diff --git a/drivers/gpu/drm/nouveau/nouveau_sgdma.c b/drivers/gpu/drm/nouveau/nouveau_sgdma.c
index 0843ebc..a4d22e5 100644
--- a/drivers/gpu/drm/nouveau/nouveau_sgdma.c
+++ b/drivers/gpu/drm/nouveau/nouveau_sgdma.c
@@ -31,16 +31,17 @@ nv04_sgdma_bind(struct ttm_tt *ttm, struct ttm_mem_reg *mem)
 {
  struct nouveau_sgdma_be *nvbe = (struct nouveau_sgdma_be *)ttm;
  struct nouveau_mem *node = mem->mm_node;
- u64 size = mem->num_pages << 12;
 
  if (ttm->sg) {
-  node->sg = ttm->sg;
-  nouveau_vm_map_sg_table(&node->vma[0], 0, size, node);
+  node->sg    = ttm->sg;
+  node->pages = NULL;
  } else {
+  node->sg    = NULL;
   node->pages = nvbe->ttm.dma_address;
-  nouveau_vm_map_sg(&node->vma[0], 0, size, node);
  }
+ node->size = (mem->num_pages << PAGE_SHIFT) >> 12;
 
+ nouveau_vm_map(&node->vma[0], node);
  nvbe->node = node;
  return 0;
 }
@@ -67,9 +68,13 @@ nv50_sgdma_bind(struct ttm_tt *ttm, struct ttm_mem_reg *mem)
 
  /* noop: bound in move_notify() */
  if (ttm->sg) {
-  node->sg = ttm->sg;
- } else
+  node->sg    = ttm->sg;
+  node->pages = NULL;
+ } else {
+  node->sg    = NULL;
   node->pages = nvbe->ttm.dma_address;
+ }
+ node->size = (mem->num_pages << PAGE_SHIFT) >> 12;
  return 0;
 }
 
diff --git a/drivers/gpu/drm/nouveau/nouveau_ttm.c b/drivers/gpu/drm/nouveau/nouveau_ttm.c
index 19e3757..d45d50d 100644
--- a/drivers/gpu/drm/nouveau/nouveau_ttm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_ttm.c
@@ -171,6 +171,7 @@ nouveau_gart_manager_new(struct ttm_mem_type_manager *man,
  node = kzalloc(sizeof(*node), GFP_KERNEL);
  if (!node)
   return -ENOMEM;
+
  node->page_shift = 12;
 
  switch (nv_device(drm->device)->card_type) {
diff --git a/drivers/gpu/drm/nouveau/nouveau_vga.c b/drivers/gpu/drm/nouveau/nouveau_vga.c
index 81638d7..471347e 100644
--- a/drivers/gpu/drm/nouveau/nouveau_vga.c
+++ b/drivers/gpu/drm/nouveau/nouveau_vga.c
@@ -14,7 +14,9 @@ nouveau_vga_set_decode(void *priv, bool state)
 {
  struct nouveau_device *device = nouveau_dev(priv);
 
- if (device->chipset >= 0x40)
+ if (device->card_type == NV_40 && device->chipset >= 0x4c)
+  nv_wr32(device, 0x088060, state);
+ else if (device->chipset >= 0x40)
   nv_wr32(device, 0x088054, state);
  else
   nv_wr32(device, 0x001854, state);
diff --git a/drivers/gpu/drm/nouveau/nv50_display.c b/drivers/gpu/drm/nouveau/nv50_display.c
index 4e384a2..2dccafc 100644
--- a/drivers/gpu/drm/nouveau/nv50_display.c
+++ b/drivers/gpu/drm/nouveau/nv50_display.c
@@ -1035,6 +1035,7 @@ static bool
 nv50_crtc_mode_fixup(struct drm_crtc *crtc, const struct drm_display_mode *mode,
        struct drm_display_mode *adjusted_mode)
 {
+ drm_mode_set_crtcinfo(adjusted_mode, CRTC_INTERLACE_HALVE_V);
  return true;
 }
 
@@ -2199,16 +2200,6 @@ nv50_display_destroy(struct drm_device *dev)
 int
 nv50_display_create(struct drm_device *dev)
 {
- static const u16 oclass[] = {
-  NVF0_DISP_CLASS,
-  NVE0_DISP_CLASS,
-  NVD0_DISP_CLASS,
-  NVA3_DISP_CLASS,
-  NV94_DISP_CLASS,
-  NVA0_DISP_CLASS,
-  NV84_DISP_CLASS,
-  NV50_DISP_CLASS,
- };
  struct nouveau_device *device = nouveau_dev(dev);
  struct nouveau_drm *drm = nouveau_drm(dev);
  struct dcb_table *dcb = &drm->vbios.dcb;
@@ -2225,6 +2216,7 @@ nv50_display_create(struct drm_device *dev)
  nouveau_display(dev)->dtor = nv50_display_destroy;
  nouveau_display(dev)->init = nv50_display_init;
  nouveau_display(dev)->fini = nv50_display_fini;
+ disp->core = nouveau_display(dev)->core;
 
  /* small shared memory area we use for notifiers and semaphores */
  ret = nouveau_bo_new(dev, 4096, 0x1000, TTM_PL_FLAG_VRAM,
@@ -2243,17 +2235,6 @@ nv50_display_create(struct drm_device *dev)
  if (ret)
   goto out;
 
- /* attempt to allocate a supported evo display class */
- ret = -ENODEV;
- for (i = 0; ret && i < ARRAY_SIZE(oclass); i++) {
-  ret = nouveau_object_new(nv_object(drm), NVDRM_DEVICE,
-      0xd1500000, oclass[i], NULL, 0,
-      &disp->core);
- }
-
- if (ret)
-  goto out;
-
  /* allocate master evo channel */
  ret = nv50_dmac_create(disp->core, NV50_DISP_MAST_CLASS, 0,
          &(struct nv50_display_mast_class) {
diff --git a/drivers/gpu/drm/qxl/Kconfig b/drivers/gpu/drm/qxl/Kconfig
index 66ac0ff..38c2bb7 100644
--- a/drivers/gpu/drm/qxl/Kconfig
+++ b/drivers/gpu/drm/qxl/Kconfig
@@ -5,9 +5,11 @@ config DRM_QXL
  select FB_SYS_COPYAREA
  select FB_SYS_IMAGEBLIT
  select FB_DEFERRED_IO
-        select DRM_KMS_HELPER
+ select DRM_KMS_HELPER
  select DRM_KMS_FB_HELPER
-        select DRM_TTM
+ select DRM_TTM
  select CRC32
  help
-  QXL virtual GPU for Spice virtualization desktop integration. Do not enable this driver unless your distro ships a corresponding X.org QXL driver that can handle kernel modesetting.
+   QXL virtual GPU for Spice virtualization desktop integration.
+   Do not enable this driver unless your distro ships a corresponding
+   X.org QXL driver that can handle kernel modesetting.
diff --git a/drivers/gpu/drm/qxl/qxl_display.c b/drivers/gpu/drm/qxl/qxl_display.c
index d70aafb..798bde2 100644
--- a/drivers/gpu/drm/qxl/qxl_display.c
+++ b/drivers/gpu/drm/qxl/qxl_display.c
@@ -399,10 +399,14 @@ static int qxl_framebuffer_surface_dirty(struct drm_framebuffer *fb,
  struct qxl_bo *qobj;
  int inc = 1;
 
+ drm_modeset_lock_all(fb->dev);
+
  qobj = gem_to_qxl_bo(qxl_fb->obj);
  /* if we aren't primary surface ignore this */
- if (!qobj->is_primary)
+ if (!qobj->is_primary) {
+  drm_modeset_unlock_all(fb->dev);
   return 0;
+ }
 
  if (!num_clips) {
   num_clips = 1;
@@ -417,6 +421,9 @@ static int qxl_framebuffer_surface_dirty(struct drm_framebuffer *fb,
 
  qxl_draw_dirty_fb(qdev, qxl_fb, qobj, flags, color,
      clips, num_clips, inc);
+
+ drm_modeset_unlock_all(fb->dev);
+
  return 0;
 }
 
diff --git a/drivers/gpu/drm/qxl/qxl_drv.h b/drivers/gpu/drm/qxl/qxl_drv.h
index 7bda32f..36ed40b 100644
--- a/drivers/gpu/drm/qxl/qxl_drv.h
+++ b/drivers/gpu/drm/qxl/qxl_drv.h
@@ -534,7 +534,7 @@ void qxl_debugfs_takedown(struct drm_minor *minor);
 
 /* qxl_irq.c */
 int qxl_irq_init(struct qxl_device *qdev);
-irqreturn_t qxl_irq_handler(DRM_IRQ_ARGS);
+irqreturn_t qxl_irq_handler(int irq, void *arg);
 
 /* qxl_fb.c */
 int qxl_fb_init(struct qxl_device *qdev);
diff --git a/drivers/gpu/drm/qxl/qxl_ioctl.c b/drivers/gpu/drm/qxl/qxl_ioctl.c
index 7b95c75..0bb86e6 100644
--- a/drivers/gpu/drm/qxl/qxl_ioctl.c
+++ b/drivers/gpu/drm/qxl/qxl_ioctl.c
@@ -200,7 +200,7 @@ static int qxl_process_single_command(struct qxl_device *qdev,
  for (i = 0; i < cmd->relocs_num; ++i) {
   struct drm_qxl_reloc reloc;
 
-  if (DRM_COPY_FROM_USER(&reloc,
+  if (copy_from_user(&reloc,
            &((struct drm_qxl_reloc *)(uintptr_t)cmd->relocs)[i],
            sizeof(reloc))) {
    ret = -EFAULT;
@@ -297,7 +297,7 @@ static int qxl_execbuffer_ioctl(struct drm_device *dev, void *data,
   struct drm_qxl_command *commands =
    (struct drm_qxl_command *)(uintptr_t)execbuffer->commands;
 
-  if (DRM_COPY_FROM_USER(&user_cmd, &commands[cmd_num],
+  if (copy_from_user(&user_cmd, &commands[cmd_num],
            sizeof(user_cmd)))
    return -EFAULT;
 
diff --git a/drivers/gpu/drm/qxl/qxl_irq.c b/drivers/gpu/drm/qxl/qxl_irq.c
index f4b6b89..3485bdc 100644
--- a/drivers/gpu/drm/qxl/qxl_irq.c
+++ b/drivers/gpu/drm/qxl/qxl_irq.c
@@ -25,7 +25,7 @@
 
 #include "qxl_drv.h"
 
-irqreturn_t qxl_irq_handler(DRM_IRQ_ARGS)
+irqreturn_t qxl_irq_handler(int irq, void *arg)
 {
  struct drm_device *dev = (struct drm_device *) arg;
  struct qxl_device *qdev = (struct qxl_device *)dev->dev_private;
diff --git a/drivers/gpu/drm/qxl/qxl_kms.c b/drivers/gpu/drm/qxl/qxl_kms.c
index e5ca498..fd88eb4 100644
--- a/drivers/gpu/drm/qxl/qxl_kms.c
+++ b/drivers/gpu/drm/qxl/qxl_kms.c
@@ -115,7 +115,7 @@ static void qxl_gc_work(struct work_struct *work)
  qxl_garbage_collect(qdev);
 }
 
-int qxl_device_init(struct qxl_device *qdev,
+static int qxl_device_init(struct qxl_device *qdev,
       struct drm_device *ddev,
       struct pci_dev *pdev,
       unsigned long flags)
diff --git a/drivers/gpu/drm/r128/r128_cce.c b/drivers/gpu/drm/r128/r128_cce.c
index c451257..59459fe 100644
--- a/drivers/gpu/drm/r128/r128_cce.c
+++ b/drivers/gpu/drm/r128/r128_cce.c
@@ -892,10 +892,10 @@ static int r128_cce_get_buffers(struct drm_device *dev,
 
   buf->file_priv = file_priv;
 
-  if (DRM_COPY_TO_USER(&d->request_indices[i], &buf->idx,
+  if (copy_to_user(&d->request_indices[i], &buf->idx,
          sizeof(buf->idx)))
    return -EFAULT;
-  if (DRM_COPY_TO_USER(&d->request_sizes[i], &buf->total,
+  if (copy_to_user(&d->request_sizes[i], &buf->total,
          sizeof(buf->total)))
    return -EFAULT;
 
diff --git a/drivers/gpu/drm/r128/r128_drv.h b/drivers/gpu/drm/r128/r128_drv.h
index 56eb5e3..5bf3f5f 100644
--- a/drivers/gpu/drm/r128/r128_drv.h
+++ b/drivers/gpu/drm/r128/r128_drv.h
@@ -154,7 +154,7 @@ extern int r128_do_cleanup_cce(struct drm_device *dev);
 extern int r128_enable_vblank(struct drm_device *dev, int crtc);
 extern void r128_disable_vblank(struct drm_device *dev, int crtc);
 extern u32 r128_get_vblank_counter(struct drm_device *dev, int crtc);
-extern irqreturn_t r128_driver_irq_handler(DRM_IRQ_ARGS);
+extern irqreturn_t r128_driver_irq_handler(int irq, void *arg);
 extern void r128_driver_irq_preinstall(struct drm_device *dev);
 extern int r128_driver_irq_postinstall(struct drm_device *dev);
 extern void r128_driver_irq_uninstall(struct drm_device *dev);
@@ -514,7 +514,7 @@ do {         \
  if (R128_VERBOSE)      \
   DRM_INFO("COMMIT_RING() tail=0x%06x\n",   \
     dev_priv->ring.tail);    \
- DRM_MEMORYBARRIER();      \
+ mb();      \
  R128_WRITE(R128_PM4_BUFFER_DL_WPTR, dev_priv->ring.tail); \
  R128_READ(R128_PM4_BUFFER_DL_WPTR);    \
 } while (0)
diff --git a/drivers/gpu/drm/r128/r128_ioc32.c b/drivers/gpu/drm/r128/r128_ioc32.c
index a954c54..b0d0fd3 100644
--- a/drivers/gpu/drm/r128/r128_ioc32.c
+++ b/drivers/gpu/drm/r128/r128_ioc32.c
@@ -33,6 +33,7 @@
 
 #include <drm/drmP.h>
 #include <drm/r128_drm.h>
+#include "r128_drv.h"
 
 typedef struct drm_r128_init32 {
  int func;
diff --git a/drivers/gpu/drm/r128/r128_irq.c b/drivers/gpu/drm/r128/r128_irq.c
index 2ea4f09..c2ae496 100644
--- a/drivers/gpu/drm/r128/r128_irq.c
+++ b/drivers/gpu/drm/r128/r128_irq.c
@@ -44,7 +44,7 @@ u32 r128_get_vblank_counter(struct drm_device *dev, int crtc)
  return atomic_read(&dev_priv->vbl_received);
 }
 
-irqreturn_t r128_driver_irq_handler(DRM_IRQ_ARGS)
+irqreturn_t r128_driver_irq_handler(int irq, void *arg)
 {
  struct drm_device *dev = (struct drm_device *) arg;
  drm_r128_private_t *dev_priv = (drm_r128_private_t *) dev->dev_private;
diff --git a/drivers/gpu/drm/r128/r128_state.c b/drivers/gpu/drm/r128/r128_state.c
index 01dd9ae..e806dac 100644
--- a/drivers/gpu/drm/r128/r128_state.c
+++ b/drivers/gpu/drm/r128/r128_state.c
@@ -895,31 +895,22 @@ static int r128_cce_dispatch_write_span(struct drm_device *dev,
  if (count > 4096 || count <= 0)
   return -EMSGSIZE;
 
- if (DRM_COPY_FROM_USER(&x, depth->x, sizeof(x)))
+ if (copy_from_user(&x, depth->x, sizeof(x)))
   return -EFAULT;
- if (DRM_COPY_FROM_USER(&y, depth->y, sizeof(y)))
+ if (copy_from_user(&y, depth->y, sizeof(y)))
   return -EFAULT;
 
  buffer_size = depth->n * sizeof(u32);
- buffer = kmalloc(buffer_size, GFP_KERNEL);
- if (buffer == NULL)
-  return -ENOMEM;
- if (DRM_COPY_FROM_USER(buffer, depth->buffer, buffer_size)) {
-  kfree(buffer);
-  return -EFAULT;
- }
+ buffer = memdup_user(depth->buffer, buffer_size);
+ if (IS_ERR(buffer))
+  return PTR_ERR(buffer);
 
  mask_size = depth->n * sizeof(u8);
  if (depth->mask) {
-  mask = kmalloc(mask_size, GFP_KERNEL);
-  if (mask == NULL) {
+  mask = memdup_user(depth->mask, mask_size);
+  if (IS_ERR(mask)) {
    kfree(buffer);
-   return -ENOMEM;
-  }
-  if (DRM_COPY_FROM_USER(mask, depth->mask, mask_size)) {
-   kfree(buffer);
-   kfree(mask);
-   return -EFAULT;
+   return PTR_ERR(mask);
   }
 
   for (i = 0; i < count; i++, x++) {
@@ -999,46 +990,33 @@ static int r128_cce_dispatch_write_pixels(struct drm_device *dev,
   kfree(x);
   return -ENOMEM;
  }
- if (DRM_COPY_FROM_USER(x, depth->x, xbuf_size)) {
+ if (copy_from_user(x, depth->x, xbuf_size)) {
   kfree(x);
   kfree(y);
   return -EFAULT;
  }
- if (DRM_COPY_FROM_USER(y, depth->y, xbuf_size)) {
+ if (copy_from_user(y, depth->y, xbuf_size)) {
   kfree(x);
   kfree(y);
   return -EFAULT;
  }
 
  buffer_size = depth->n * sizeof(u32);
- buffer = kmalloc(buffer_size, GFP_KERNEL);
- if (buffer == NULL) {
-  kfree(x);
-  kfree(y);
-  return -ENOMEM;
- }
- if (DRM_COPY_FROM_USER(buffer, depth->buffer, buffer_size)) {
+ buffer = memdup_user(depth->buffer, buffer_size);
+ if (IS_ERR(buffer)) {
   kfree(x);
   kfree(y);
-  kfree(buffer);
-  return -EFAULT;
+  return PTR_ERR(buffer);
  }
 
  if (depth->mask) {
   mask_size = depth->n * sizeof(u8);
-  mask = kmalloc(mask_size, GFP_KERNEL);
-  if (mask == NULL) {
-   kfree(x);
-   kfree(y);
-   kfree(buffer);
-   return -ENOMEM;
-  }
-  if (DRM_COPY_FROM_USER(mask, depth->mask, mask_size)) {
+  mask = memdup_user(depth->mask, mask_size);
+  if (IS_ERR(mask)) {
    kfree(x);
    kfree(y);
    kfree(buffer);
-   kfree(mask);
-   return -EFAULT;
+   return PTR_ERR(mask);
   }
 
   for (i = 0; i < count; i++) {
@@ -1107,9 +1085,9 @@ static int r128_cce_dispatch_read_span(struct drm_device *dev,
  if (count > 4096 || count <= 0)
   return -EMSGSIZE;
 
- if (DRM_COPY_FROM_USER(&x, depth->x, sizeof(x)))
+ if (copy_from_user(&x, depth->x, sizeof(x)))
   return -EFAULT;
- if (DRM_COPY_FROM_USER(&y, depth->y, sizeof(y)))
+ if (copy_from_user(&y, depth->y, sizeof(y)))
   return -EFAULT;
 
  BEGIN_RING(7);
@@ -1162,12 +1140,12 @@ static int r128_cce_dispatch_read_pixels(struct drm_device *dev,
   kfree(x);
   return -ENOMEM;
  }
- if (DRM_COPY_FROM_USER(x, depth->x, xbuf_size)) {
+ if (copy_from_user(x, depth->x, xbuf_size)) {
   kfree(x);
   kfree(y);
   return -EFAULT;
  }
- if (DRM_COPY_FROM_USER(y, depth->y, ybuf_size)) {
+ if (copy_from_user(y, depth->y, ybuf_size)) {
   kfree(x);
   kfree(y);
   return -EFAULT;
@@ -1524,7 +1502,7 @@ static int r128_cce_stipple(struct drm_device *dev, void *data, struct drm_file
 
  DEV_INIT_TEST_WITH_RETURN(dev_priv);
 
- if (DRM_COPY_FROM_USER(&mask, stipple->mask, 32 * sizeof(u32)))
+ if (copy_from_user(&mask, stipple->mask, 32 * sizeof(u32)))
   return -EFAULT;
 
  RING_SPACE_TEST_WITH_RETURN(dev_priv);
@@ -1622,7 +1600,7 @@ static int r128_getparam(struct drm_device *dev, void *data, struct drm_file *fi
   return -EINVAL;
  }
 
- if (DRM_COPY_TO_USER(param->value, &value, sizeof(int))) {
+ if (copy_to_user(param->value, &value, sizeof(int))) {
   DRM_ERROR("copy_to_user\n");
   return -EFAULT;
  }
diff --git a/drivers/gpu/drm/radeon/atombios_crtc.c b/drivers/gpu/drm/radeon/atombios_crtc.c
index 153aa49..daa4dd3 100644
--- a/drivers/gpu/drm/radeon/atombios_crtc.c
+++ b/drivers/gpu/drm/radeon/atombios_crtc.c
@@ -443,7 +443,17 @@ static void atombios_crtc_program_ss(struct radeon_device *rdev,
  int index = GetIndexIntoMasterTable(COMMAND, EnableSpreadSpectrumOnPPLL);
  union atom_enable_ss args;
 
- if (!enable) {
+ if (enable) {
+  /* Don't mess with SS if percentage is 0 or external ss.
+   * SS is already disabled previously, and disabling it
+   * again can cause display problems if the pll is already
+   * programmed.
+   */
+  if (ss->percentage == 0)
+   return;
+  if (ss->type & ATOM_EXTERNAL_SS_MASK)
+   return;
+ } else {
   for (i = 0; i < rdev->num_crtc; i++) {
    if (rdev->mode_info.crtcs[i] &&
        rdev->mode_info.crtcs[i]->enabled &&
@@ -479,8 +489,6 @@ static void atombios_crtc_program_ss(struct radeon_device *rdev,
   args.v3.usSpreadSpectrumAmount = cpu_to_le16(ss->amount);
   args.v3.usSpreadSpectrumStep = cpu_to_le16(ss->step);
   args.v3.ucEnable = enable;
-  if ((ss->percentage == 0) || (ss->type & ATOM_EXTERNAL_SS_MASK) || ASIC_IS_DCE61(rdev))
-   args.v3.ucEnable = ATOM_DISABLE;
  } else if (ASIC_IS_DCE4(rdev)) {
   args.v2.usSpreadSpectrumPercentage = cpu_to_le16(ss->percentage);
   args.v2.ucSpreadSpectrumType = ss->type & ATOM_SS_CENTRE_SPREAD_MODE_MASK;
@@ -500,8 +508,6 @@ static void atombios_crtc_program_ss(struct radeon_device *rdev,
   args.v2.usSpreadSpectrumAmount = cpu_to_le16(ss->amount);
   args.v2.usSpreadSpectrumStep = cpu_to_le16(ss->step);
   args.v2.ucEnable = enable;
-  if ((ss->percentage == 0) || (ss->type & ATOM_EXTERNAL_SS_MASK) || ASIC_IS_DCE41(rdev))
-   args.v2.ucEnable = ATOM_DISABLE;
  } else if (ASIC_IS_DCE3(rdev)) {
   args.v1.usSpreadSpectrumPercentage = cpu_to_le16(ss->percentage);
   args.v1.ucSpreadSpectrumType = ss->type & ATOM_SS_CENTRE_SPREAD_MODE_MASK;
@@ -523,8 +529,7 @@ static void atombios_crtc_program_ss(struct radeon_device *rdev,
   args.lvds_ss_2.ucSpreadSpectrumRange = ss->range;
   args.lvds_ss_2.ucEnable = enable;
  } else {
-  if ((enable == ATOM_DISABLE) || (ss->percentage == 0) ||
-      (ss->type & ATOM_EXTERNAL_SS_MASK)) {
+  if (enable == ATOM_DISABLE) {
    atombios_disable_ss(rdev, pll_id);
    return;
   }
@@ -554,7 +559,7 @@ static u32 atombios_adjust_pll(struct drm_crtc *crtc,
  u32 adjusted_clock = mode->clock;
  int encoder_mode = atombios_get_encoder_mode(encoder);
  u32 dp_clock = mode->clock;
- int bpc = radeon_get_monitor_bpc(connector);
+ int bpc = radeon_crtc->bpc;
  bool is_duallink = radeon_dig_monitor_is_duallink(encoder, mode->clock);
 
  /* reset the pll flags */
@@ -1062,15 +1067,17 @@ static void atombios_crtc_set_pll(struct drm_crtc *crtc, struct drm_display_mode
   /* calculate ss amount and step size */
   if (ASIC_IS_DCE4(rdev)) {
    u32 step_size;
-   u32 amount = (((fb_div * 10) + frac_fb_div) * radeon_crtc->ss.percentage) / 10000;
+   u32 amount = (((fb_div * 10) + frac_fb_div) *
+          (u32)radeon_crtc->ss.percentage) /
+    (100 * (u32)radeon_crtc->ss.percentage_divider);
    radeon_crtc->ss.amount = (amount / 10) & ATOM_PPLL_SS_AMOUNT_V2_FBDIV_MASK;
    radeon_crtc->ss.amount |= ((amount - (amount / 10)) << ATOM_PPLL_SS_AMOUNT_V2_NFRAC_SHIFT) &
     ATOM_PPLL_SS_AMOUNT_V2_NFRAC_MASK;
    if (radeon_crtc->ss.type & ATOM_PPLL_SS_TYPE_V2_CENTRE_SPREAD)
-    step_size = (4 * amount * ref_div * (radeon_crtc->ss.rate * 2048)) /
+    step_size = (4 * amount * ref_div * ((u32)radeon_crtc->ss.rate * 2048)) /
      (125 * 25 * pll->reference_freq / 100);
    else
-    step_size = (2 * amount * ref_div * (radeon_crtc->ss.rate * 2048)) /
+    step_size = (2 * amount * ref_div * ((u32)radeon_crtc->ss.rate * 2048)) /
      (125 * 25 * pll->reference_freq / 100);
    radeon_crtc->ss.step = step_size;
   }
diff --git a/drivers/gpu/drm/radeon/atombios_dp.c b/drivers/gpu/drm/radeon/atombios_dp.c
index fb3ae07..4ad7643 100644
--- a/drivers/gpu/drm/radeon/atombios_dp.c
+++ b/drivers/gpu/drm/radeon/atombios_dp.c
@@ -157,21 +157,22 @@ static int radeon_dp_aux_native_write(struct radeon_connector *radeon_connector,
 
  msg[0] = address;
  msg[1] = address >> 8;
- msg[2] = AUX_NATIVE_WRITE << 4;
+ msg[2] = DP_AUX_NATIVE_WRITE << 4;
  msg[3] = (msg_bytes << 4) | (send_bytes - 1);
  memcpy(&msg[4], send, send_bytes);
 
- for (retry = 0; retry < 4; retry++) {
+ for (retry = 0; retry < 7; retry++) {
   ret = radeon_process_aux_ch(dig_connector->dp_i2c_bus,
          msg, msg_bytes, NULL, 0, delay, &ack);
   if (ret == -EBUSY)
    continue;
   else if (ret < 0)
    return ret;
-  if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_ACK)
+  ack >>= 4;
+  if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_ACK)
    return send_bytes;
-  else if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_DEFER)
-   udelay(400);
+  else if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_DEFER)
+   usleep_range(400, 500);
   else
    return -EIO;
  }
@@ -191,20 +192,21 @@ static int radeon_dp_aux_native_read(struct radeon_connector *radeon_connector,
 
  msg[0] = address;
  msg[1] = address >> 8;
- msg[2] = AUX_NATIVE_READ << 4;
+ msg[2] = DP_AUX_NATIVE_READ << 4;
  msg[3] = (msg_bytes << 4) | (recv_bytes - 1);
 
- for (retry = 0; retry < 4; retry++) {
+ for (retry = 0; retry < 7; retry++) {
   ret = radeon_process_aux_ch(dig_connector->dp_i2c_bus,
          msg, msg_bytes, recv, recv_bytes, delay, &ack);
   if (ret == -EBUSY)
    continue;
   else if (ret < 0)
    return ret;
-  if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_ACK)
+  ack >>= 4;
+  if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_ACK)
    return ret;
-  else if ((ack & AUX_NATIVE_REPLY_MASK) == AUX_NATIVE_REPLY_DEFER)
-   udelay(400);
+  else if ((ack & DP_AUX_NATIVE_REPLY_MASK) == DP_AUX_NATIVE_REPLY_DEFER)
+   usleep_range(400, 500);
   else if (ret == 0)
    return -EPROTO;
   else
@@ -246,12 +248,12 @@ int radeon_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
 
  /* Set up the command byte */
  if (mode & MODE_I2C_READ)
-  msg[2] = AUX_I2C_READ << 4;
+  msg[2] = DP_AUX_I2C_READ << 4;
  else
-  msg[2] = AUX_I2C_WRITE << 4;
+  msg[2] = DP_AUX_I2C_WRITE << 4;
 
  if (!(mode & MODE_I2C_STOP))
-  msg[2] |= AUX_I2C_MOT << 4;
+  msg[2] |= DP_AUX_I2C_MOT << 4;
 
  msg[0] = address;
  msg[1] = address >> 8;
@@ -272,7 +274,7 @@ int radeon_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
   break;
  }
 
- for (retry = 0; retry < 4; retry++) {
+ for (retry = 0; retry < 7; retry++) {
   ret = radeon_process_aux_ch(auxch,
          msg, msg_bytes, reply, reply_bytes, 0, &ack);
   if (ret == -EBUSY)
@@ -282,35 +284,35 @@ int radeon_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
    return ret;
   }
 
-  switch (ack & AUX_NATIVE_REPLY_MASK) {
-  case AUX_NATIVE_REPLY_ACK:
+  switch ((ack >> 4) & DP_AUX_NATIVE_REPLY_MASK) {
+  case DP_AUX_NATIVE_REPLY_ACK:
    /* I2C-over-AUX Reply field is only valid
     * when paired with AUX ACK.
     */
    break;
-  case AUX_NATIVE_REPLY_NACK:
+  case DP_AUX_NATIVE_REPLY_NACK:
    DRM_DEBUG_KMS("aux_ch native nack\n");
    return -EREMOTEIO;
-  case AUX_NATIVE_REPLY_DEFER:
+  case DP_AUX_NATIVE_REPLY_DEFER:
    DRM_DEBUG_KMS("aux_ch native defer\n");
-   udelay(400);
+   usleep_range(500, 600);
    continue;
   default:
    DRM_ERROR("aux_ch invalid native reply 0x%02x\n", ack);
    return -EREMOTEIO;
   }
 
-  switch (ack & AUX_I2C_REPLY_MASK) {
-  case AUX_I2C_REPLY_ACK:
+  switch ((ack >> 4) & DP_AUX_I2C_REPLY_MASK) {
+  case DP_AUX_I2C_REPLY_ACK:
    if (mode == MODE_I2C_READ)
     *read_byte = reply[0];
    return ret;
-  case AUX_I2C_REPLY_NACK:
+  case DP_AUX_I2C_REPLY_NACK:
    DRM_DEBUG_KMS("aux_i2c nack\n");
    return -EREMOTEIO;
-  case AUX_I2C_REPLY_DEFER:
+  case DP_AUX_I2C_REPLY_DEFER:
    DRM_DEBUG_KMS("aux_i2c defer\n");
-   udelay(400);
+   usleep_range(400, 500);
    break;
   default:
    DRM_ERROR("aux_i2c invalid reply 0x%02x\n", ack);
@@ -671,9 +673,11 @@ static int radeon_dp_link_train_init(struct radeon_dp_link_train_info *dp_info)
  u8 tmp;
 
  /* power up the sink */
- if (dp_info->dpcd[0] >= 0x11)
+ if (dp_info->dpcd[0] >= 0x11) {
   radeon_write_dpcd_reg(dp_info->radeon_connector,
           DP_SET_POWER, DP_SET_POWER_D0);
+  usleep_range(1000, 2000);
+ }
 
  /* possibly enable downspread on the sink */
  if (dp_info->dpcd[3] & 0x1)
diff --git a/drivers/gpu/drm/radeon/atombios_encoders.c b/drivers/gpu/drm/radeon/atombios_encoders.c
index cf90161..607dc14 100644
--- a/drivers/gpu/drm/radeon/atombios_encoders.c
+++ b/drivers/gpu/drm/radeon/atombios_encoders.c
@@ -464,11 +464,12 @@ atombios_tv_setup(struct drm_encoder *encoder, int action)
 
 static u8 radeon_atom_get_bpc(struct drm_encoder *encoder)
 {
- struct drm_connector *connector = radeon_get_connector_for_encoder(encoder);
  int bpc = 8;
 
- if (connector)
-  bpc = radeon_get_monitor_bpc(connector);
+ if (encoder->crtc) {
+  struct radeon_crtc *radeon_crtc = to_radeon_crtc(encoder->crtc);
+  bpc = radeon_crtc->bpc;
+ }
 
  switch (bpc) {
  case 0:
diff --git a/drivers/gpu/drm/radeon/atombios_i2c.c b/drivers/gpu/drm/radeon/atombios_i2c.c
index f685035..b5162c3 100644
--- a/drivers/gpu/drm/radeon/atombios_i2c.c
+++ b/drivers/gpu/drm/radeon/atombios_i2c.c
@@ -27,8 +27,6 @@
 #include "radeon.h"
 #include "atom.h"
 
-extern void radeon_atom_copy_swap(u8 *dst, u8 *src, u8 num_bytes, bool to_le);
-
 #define TARGET_HW_I2C_CLOCK 50
 
 /* these are a limitation of ProcessI2cChannelTransaction not the hw */
diff --git a/drivers/gpu/drm/radeon/btc_dpm.c b/drivers/gpu/drm/radeon/btc_dpm.c
index 9b6950d..ea103cc 100644
--- a/drivers/gpu/drm/radeon/btc_dpm.c
+++ b/drivers/gpu/drm/radeon/btc_dpm.c
@@ -29,6 +29,7 @@
 #include "cypress_dpm.h"
 #include "btc_dpm.h"
 #include "atom.h"
+#include <linux/seq_file.h>
 
 #define MC_CG_ARB_FREQ_F0           0x0a
 #define MC_CG_ARB_FREQ_F1           0x0b
@@ -49,6 +50,7 @@ struct rv7xx_ps *rv770_get_ps(struct radeon_ps *rps);
 struct rv7xx_power_info *rv770_get_pi(struct radeon_device *rdev);
 struct evergreen_power_info *evergreen_get_pi(struct radeon_device *rdev);
 
+extern int ni_mc_load_microcode(struct radeon_device *rdev);
 
 //********* BARTS **************//
 static const u32 barts_cgcg_cgls_default[] =
@@ -2510,21 +2512,6 @@ int btc_dpm_enable(struct radeon_device *rdev)
  if (eg_pi->ls_clock_gating)
   btc_ls_clock_gating_enable(rdev, true);
 
- if (rdev->irq.installed &&
-     r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
-  PPSMC_Result result;
-
-  ret = rv770_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);
-  if (ret)
-   return ret;
-  rdev->irq.dpm_thermal = true;
-  radeon_irq_set(rdev);
-  result = rv770_send_msg_to_smc(rdev, PPSMC_MSG_EnableThermalInterrupt);
-
-  if (result != PPSMC_Result_OK)
-   DRM_DEBUG_KMS("Could not enable thermal interrupts.\n");
- }
-
  rv770_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
 
  btc_init_stutter_mode(rdev);
@@ -2576,7 +2563,11 @@ void btc_dpm_disable(struct radeon_device *rdev)
 void btc_dpm_setup_asic(struct radeon_device *rdev)
 {
  struct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);
+ int r;
 
+ r = ni_mc_load_microcode(rdev);
+ if (r)
+  DRM_ERROR("Failed to load MC firmware!\n");
  rv770_get_memory_type(rdev);
  rv740_read_clock_registers(rdev);
  btc_read_arb_registers(rdev);
@@ -2766,6 +2757,37 @@ void btc_dpm_fini(struct radeon_device *rdev)
  r600_free_extended_power_table(rdev);
 }
 
+void btc_dpm_debugfs_print_current_performance_level(struct radeon_device *rdev,
+           struct seq_file *m)
+{
+ struct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);
+ struct radeon_ps *rps = &eg_pi->current_rps;
+ struct rv7xx_ps *ps = rv770_get_ps(rps);
+ struct rv7xx_pl *pl;
+ u32 current_index =
+  (RREG32(TARGET_AND_CURRENT_PROFILE_INDEX) & CURRENT_PROFILE_INDEX_MASK) >>
+  CURRENT_PROFILE_INDEX_SHIFT;
+
+ if (current_index > 2) {
+  seq_printf(m, "invalid dpm profile %d\n", current_index);
+ } else {
+  if (current_index == 0)
+   pl = &ps->low;
+  else if (current_index == 1)
+   pl = &ps->medium;
+  else /* current_index == 2 */
+   pl = &ps->high;
+  seq_printf(m, "uvd    vclk: %d dclk: %d\n", rps->vclk, rps->dclk);
+  if (rdev->family >= CHIP_CEDAR) {
+   seq_printf(m, "power level %d    sclk: %u mclk: %u vddc: %u vddci: %u\n",
+       current_index, pl->sclk, pl->mclk, pl->vddc, pl->vddci);
+  } else {
+   seq_printf(m, "power level %d    sclk: %u mclk: %u vddc: %u\n",
+       current_index, pl->sclk, pl->mclk, pl->vddc);
+  }
+ }
+}
+
 u32 btc_dpm_get_sclk(struct radeon_device *rdev, bool low)
 {
  struct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);
diff --git a/drivers/gpu/drm/radeon/btcd.h b/drivers/gpu/drm/radeon/btcd.h
index 29e32de..9c65be2 100644
--- a/drivers/gpu/drm/radeon/btcd.h
+++ b/drivers/gpu/drm/radeon/btcd.h
@@ -44,6 +44,10 @@
 #       define DYN_SPREAD_SPECTRUM_EN                   (1 << 23)
 #       define AC_DC_SW                                 (1 << 24)
 
+#define TARGET_AND_CURRENT_PROFILE_INDEX                  0x66c
+#       define CURRENT_PROFILE_INDEX_MASK                 (0xf << 4)
+#       define CURRENT_PROFILE_INDEX_SHIFT                4
+
 #define CG_BIF_REQ_AND_RSP    0x7f4
 #define  CG_CLIENT_REQ(x)   ((x) << 0)
 #define  CG_CLIENT_REQ_MASK   (0xff << 0)
diff --git a/drivers/gpu/drm/radeon/ci_dpm.c b/drivers/gpu/drm/radeon/ci_dpm.c
index 1ed4799..8d49104 100644
--- a/drivers/gpu/drm/radeon/ci_dpm.c
+++ b/drivers/gpu/drm/radeon/ci_dpm.c
@@ -171,8 +171,7 @@ extern void si_trim_voltage_table_to_fit_state_table(struct radeon_device *rdev,
            struct atom_voltage_table *voltage_table);
 extern void cik_enter_rlc_safe_mode(struct radeon_device *rdev);
 extern void cik_exit_rlc_safe_mode(struct radeon_device *rdev);
-extern void cik_update_cg(struct radeon_device *rdev,
-     u32 block, bool enable);
+extern int ci_mc_load_microcode(struct radeon_device *rdev);
 
 static int ci_get_std_voltage_value_sidd(struct radeon_device *rdev,
       struct atom_voltage_table_entry *voltage_table,
@@ -4503,8 +4502,8 @@ static void ci_get_memory_type(struct radeon_device *rdev)
 
 }
 
-void ci_update_current_ps(struct radeon_device *rdev,
-     struct radeon_ps *rps)
+static void ci_update_current_ps(struct radeon_device *rdev,
+     struct radeon_ps *rps)
 {
  struct ci_ps *new_ps = ci_get_ps(rps);
  struct ci_power_info *pi = ci_get_pi(rdev);
@@ -4514,8 +4513,8 @@ void ci_update_current_ps(struct radeon_device *rdev,
  pi->current_rps.ps_priv = &pi->current_ps;
 }
 
-void ci_update_requested_ps(struct radeon_device *rdev,
-       struct radeon_ps *rps)
+static void ci_update_requested_ps(struct radeon_device *rdev,
+       struct radeon_ps *rps)
 {
  struct ci_ps *new_ps = ci_get_ps(rps);
  struct ci_power_info *pi = ci_get_pi(rdev);
@@ -4549,6 +4548,11 @@ void ci_dpm_post_set_power_state(struct radeon_device *rdev)
 
 void ci_dpm_setup_asic(struct radeon_device *rdev)
 {
+ int r;
+
+ r = ci_mc_load_microcode(rdev);
+ if (r)
+  DRM_ERROR("Failed to load MC firmware!\n");
  ci_read_clock_registers(rdev);
  ci_get_memory_type(rdev);
  ci_enable_acpi_power_management(rdev);
@@ -4561,13 +4565,6 @@ int ci_dpm_enable(struct radeon_device *rdev)
  struct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;
  int ret;
 
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_MC |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_BIF |
-        RADEON_CG_BLOCK_UVD |
-        RADEON_CG_BLOCK_HDP), false);
-
  if (ci_is_smc_running(rdev))
   return -EINVAL;
  if (pi->voltage_control != CISLANDS_VOLTAGE_CONTROL_NONE) {
@@ -4665,6 +4662,18 @@ int ci_dpm_enable(struct radeon_device *rdev)
   DRM_ERROR("ci_enable_power_containment failed\n");
   return ret;
  }
+
+ ci_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
+
+ ci_update_current_ps(rdev, boot_ps);
+
+ return 0;
+}
+
+int ci_dpm_late_enable(struct radeon_device *rdev)
+{
+ int ret;
+
  if (rdev->irq.installed &&
      r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
 #if 0
@@ -4685,19 +4694,8 @@ int ci_dpm_enable(struct radeon_device *rdev)
 #endif
  }
 
- ci_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
-
  ci_dpm_powergate_uvd(rdev, true);
 
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_MC |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_BIF |
-        RADEON_CG_BLOCK_UVD |
-        RADEON_CG_BLOCK_HDP), true);
-
- ci_update_current_ps(rdev, boot_ps);
-
  return 0;
 }
 
@@ -4706,12 +4704,6 @@ void ci_dpm_disable(struct radeon_device *rdev)
  struct ci_power_info *pi = ci_get_pi(rdev);
  struct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;
 
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_MC |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_UVD |
-        RADEON_CG_BLOCK_HDP), false);
-
  ci_dpm_powergate_uvd(rdev, false);
 
  if (!ci_is_smc_running(rdev))
@@ -4742,13 +4734,6 @@ int ci_dpm_set_power_state(struct radeon_device *rdev)
  struct radeon_ps *old_ps = &pi->current_rps;
  int ret;
 
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_MC |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_BIF |
-        RADEON_CG_BLOCK_UVD |
-        RADEON_CG_BLOCK_HDP), false);
-
  ci_find_dpm_states_clocks_in_dpm_table(rdev, new_ps);
  if (pi->pcie_performance_request)
   ci_request_link_speed_change_before_state_change(rdev, new_ps, old_ps);
@@ -4804,13 +4789,6 @@ int ci_dpm_set_power_state(struct radeon_device *rdev)
  if (pi->pcie_performance_request)
   ci_notify_link_speed_change_after_state_change(rdev, new_ps, old_ps);
 
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_MC |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_BIF |
-        RADEON_CG_BLOCK_UVD |
-        RADEON_CG_BLOCK_HDP), true);
-
  return 0;
 }
 
@@ -5023,8 +5001,8 @@ static int ci_parse_power_table(struct radeon_device *rdev)
  return 0;
 }
 
-int ci_get_vbios_boot_values(struct radeon_device *rdev,
-        struct ci_vbios_boot_state *boot_state)
+static int ci_get_vbios_boot_values(struct radeon_device *rdev,
+        struct ci_vbios_boot_state *boot_state)
 {
  struct radeon_mode_info *mode_info = &rdev->mode_info;
  int index = GetIndexIntoMasterTable(DATA, FirmwareInfo);
diff --git a/drivers/gpu/drm/radeon/ci_smc.c b/drivers/gpu/drm/radeon/ci_smc.c
index 9c745dd..8debc9d 100644
--- a/drivers/gpu/drm/radeon/ci_smc.c
+++ b/drivers/gpu/drm/radeon/ci_smc.c
@@ -28,6 +28,7 @@
 #include "cikd.h"
 #include "ppsmc.h"
 #include "radeon_ucode.h"
+#include "ci_dpm.h"
 
 static int ci_set_smc_sram_address(struct radeon_device *rdev,
        u32 smc_address, u32 limit)
diff --git a/drivers/gpu/drm/radeon/cik.c b/drivers/gpu/drm/radeon/cik.c
index 272392d..bbb1784 100644
--- a/drivers/gpu/drm/radeon/cik.c
+++ b/drivers/gpu/drm/radeon/cik.c
@@ -1697,7 +1697,7 @@ static void cik_srbm_select(struct radeon_device *rdev,
  * Load the GDDR MC ucode into the hw (CIK).
  * Returns 0 on success, error on failure.
  */
-static int ci_mc_load_microcode(struct radeon_device *rdev)
+int ci_mc_load_microcode(struct radeon_device *rdev)
 {
  const __be32 *fw_data;
  u32 running, blackout = 0;
@@ -3046,7 +3046,7 @@ static u32 cik_create_bitmask(u32 bit_width)
 }
 
 /**
- * cik_select_se_sh - select which SE, SH to address
+ * cik_get_rb_disabled - computes the mask of disabled RBs
  *
  * @rdev: radeon_device pointer
  * @max_rb_num: max RBs (render backends) for the asic
@@ -3487,6 +3487,51 @@ int cik_ring_test(struct radeon_device *rdev, struct radeon_ring *ring)
 }
 
 /**
+ * cik_hdp_flush_cp_ring_emit - emit an hdp flush on the cp
+ *
+ * @rdev: radeon_device pointer
+ * @ridx: radeon ring index
+ *
+ * Emits an hdp flush on the cp.
+ */
+static void cik_hdp_flush_cp_ring_emit(struct radeon_device *rdev,
+           int ridx)
+{
+ struct radeon_ring *ring = &rdev->ring[ridx];
+ u32 ref_and_mask;
+
+ switch (ring->idx) {
+ case CAYMAN_RING_TYPE_CP1_INDEX:
+ case CAYMAN_RING_TYPE_CP2_INDEX:
+ default:
+  switch (ring->me) {
+  case 0:
+   ref_and_mask = CP2 << ring->pipe;
+   break;
+  case 1:
+   ref_and_mask = CP6 << ring->pipe;
+   break;
+  default:
+   return;
+  }
+  break;
+ case RADEON_RING_TYPE_GFX_INDEX:
+  ref_and_mask = CP0;
+  break;
+ }
+
+ radeon_ring_write(ring, PACKET3(PACKET3_WAIT_REG_MEM, 5));
+ radeon_ring_write(ring, (WAIT_REG_MEM_OPERATION(1) | /* write, wait, write */
+     WAIT_REG_MEM_FUNCTION(3) |  /* == */
+     WAIT_REG_MEM_ENGINE(1)));   /* pfp */
+ radeon_ring_write(ring, GPU_HDP_FLUSH_REQ >> 2);
+ radeon_ring_write(ring, GPU_HDP_FLUSH_DONE >> 2);
+ radeon_ring_write(ring, ref_and_mask);
+ radeon_ring_write(ring, ref_and_mask);
+ radeon_ring_write(ring, 0x20); /* poll interval */
+}
+
+/**
  * cik_fence_gfx_ring_emit - emit a fence on the gfx ring
  *
  * @rdev: radeon_device pointer
@@ -3512,15 +3557,7 @@ void cik_fence_gfx_ring_emit(struct radeon_device *rdev,
  radeon_ring_write(ring, fence->seq);
  radeon_ring_write(ring, 0);
  /* HDP flush */
- /* We should be using the new WAIT_REG_MEM special op packet here
-  * but it causes the CP to hang
-  */
- radeon_ring_write(ring, PACKET3(PACKET3_WRITE_DATA, 3));
- radeon_ring_write(ring, (WRITE_DATA_ENGINE_SEL(0) |
-     WRITE_DATA_DST_SEL(0)));
- radeon_ring_write(ring, HDP_MEM_COHERENCY_FLUSH_CNTL >> 2);
- radeon_ring_write(ring, 0);
- radeon_ring_write(ring, 0);
+ cik_hdp_flush_cp_ring_emit(rdev, fence->ring);
 }
 
 /**
@@ -3550,15 +3587,7 @@ void cik_fence_compute_ring_emit(struct radeon_device *rdev,
  radeon_ring_write(ring, fence->seq);
  radeon_ring_write(ring, 0);
  /* HDP flush */
- /* We should be using the new WAIT_REG_MEM special op packet here
-  * but it causes the CP to hang
-  */
- radeon_ring_write(ring, PACKET3(PACKET3_WRITE_DATA, 3));
- radeon_ring_write(ring, (WRITE_DATA_ENGINE_SEL(0) |
-     WRITE_DATA_DST_SEL(0)));
- radeon_ring_write(ring, HDP_MEM_COHERENCY_FLUSH_CNTL >> 2);
- radeon_ring_write(ring, 0);
- radeon_ring_write(ring, 0);
+ cik_hdp_flush_cp_ring_emit(rdev, fence->ring);
 }
 
 bool cik_semaphore_ring_emit(struct radeon_device *rdev,
@@ -3811,6 +3840,8 @@ static void cik_cp_gfx_enable(struct radeon_device *rdev, bool enable)
  if (enable)
   WREG32(CP_ME_CNTL, 0);
  else {
+  if (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)
+   radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
   WREG32(CP_ME_CNTL, (CP_ME_HALT | CP_PFP_HALT | CP_CE_HALT));
   rdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;
  }
@@ -4009,18 +4040,50 @@ static int cik_cp_gfx_resume(struct radeon_device *rdev)
   rdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;
   return r;
  }
+
+ if (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
+
  return 0;
 }
 
-u32 cik_compute_ring_get_rptr(struct radeon_device *rdev,
-         struct radeon_ring *ring)
+u32 cik_gfx_get_rptr(struct radeon_device *rdev,
+       struct radeon_ring *ring)
 {
  u32 rptr;
 
+ if (rdev->wb.enabled)
+  rptr = rdev->wb.wb[ring->rptr_offs/4];
+ else
+  rptr = RREG32(CP_RB0_RPTR);
+
+ return rptr;
+}
+
+u32 cik_gfx_get_wptr(struct radeon_device *rdev,
+       struct radeon_ring *ring)
+{
+ u32 wptr;
+
+ wptr = RREG32(CP_RB0_WPTR);
+
+ return wptr;
+}
+
+void cik_gfx_set_wptr(struct radeon_device *rdev,
+        struct radeon_ring *ring)
+{
+ WREG32(CP_RB0_WPTR, ring->wptr);
+ (void)RREG32(CP_RB0_WPTR);
+}
 
+u32 cik_compute_get_rptr(struct radeon_device *rdev,
+    struct radeon_ring *ring)
+{
+ u32 rptr;
 
  if (rdev->wb.enabled) {
-  rptr = le32_to_cpu(rdev->wb.wb[ring->rptr_offs/4]);
+  rptr = rdev->wb.wb[ring->rptr_offs/4];
  } else {
   mutex_lock(&rdev->srbm_mutex);
   cik_srbm_select(rdev, ring->me, ring->pipe, ring->queue, 0);
@@ -4032,13 +4095,14 @@ u32 cik_compute_ring_get_rptr(struct radeon_device *rdev,
  return rptr;
 }
 
-u32 cik_compute_ring_get_wptr(struct radeon_device *rdev,
-         struct radeon_ring *ring)
+u32 cik_compute_get_wptr(struct radeon_device *rdev,
+    struct radeon_ring *ring)
 {
  u32 wptr;
 
  if (rdev->wb.enabled) {
-  wptr = le32_to_cpu(rdev->wb.wb[ring->wptr_offs/4]);
+  /* XXX check if swapping is necessary on BE */
+  wptr = rdev->wb.wb[ring->wptr_offs/4];
  } else {
   mutex_lock(&rdev->srbm_mutex);
   cik_srbm_select(rdev, ring->me, ring->pipe, ring->queue, 0);
@@ -4050,10 +4114,11 @@ u32 cik_compute_ring_get_wptr(struct radeon_device *rdev,
  return wptr;
 }
 
-void cik_compute_ring_set_wptr(struct radeon_device *rdev,
-          struct radeon_ring *ring)
+void cik_compute_set_wptr(struct radeon_device *rdev,
+     struct radeon_ring *ring)
 {
- rdev->wb.wb[ring->wptr_offs/4] = cpu_to_le32(ring->wptr);
+ /* XXX check if swapping is necessary on BE */
+ rdev->wb.wb[ring->wptr_offs/4] = ring->wptr;
  WDOORBELL32(ring->doorbell_index, ring->wptr);
 }
 
@@ -4850,6 +4915,160 @@ static void cik_gpu_soft_reset(struct radeon_device *rdev, u32 reset_mask)
  cik_print_gpu_status_regs(rdev);
 }
 
+struct kv_reset_save_regs {
+ u32 gmcon_reng_execute;
+ u32 gmcon_misc;
+ u32 gmcon_misc3;
+};
+
+static void kv_save_regs_for_reset(struct radeon_device *rdev,
+       struct kv_reset_save_regs *save)
+{
+ save->gmcon_reng_execute = RREG32(GMCON_RENG_EXECUTE);
+ save->gmcon_misc = RREG32(GMCON_MISC);
+ save->gmcon_misc3 = RREG32(GMCON_MISC3);
+
+ WREG32(GMCON_RENG_EXECUTE, save->gmcon_reng_execute & ~RENG_EXECUTE_ON_PWR_UP);
+ WREG32(GMCON_MISC, save->gmcon_misc & ~(RENG_EXECUTE_ON_REG_UPDATE |
+      STCTRL_STUTTER_EN));
+}
+
+static void kv_restore_regs_for_reset(struct radeon_device *rdev,
+          struct kv_reset_save_regs *save)
+{
+ int i;
+
+ WREG32(GMCON_PGFSM_WRITE, 0);
+ WREG32(GMCON_PGFSM_CONFIG, 0x200010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0);
+ WREG32(GMCON_PGFSM_CONFIG, 0x300010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0x210000);
+ WREG32(GMCON_PGFSM_CONFIG, 0xa00010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0x21003);
+ WREG32(GMCON_PGFSM_CONFIG, 0xb00010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0x2b00);
+ WREG32(GMCON_PGFSM_CONFIG, 0xc00010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0);
+ WREG32(GMCON_PGFSM_CONFIG, 0xd00010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0x420000);
+ WREG32(GMCON_PGFSM_CONFIG, 0x100010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0x120202);
+ WREG32(GMCON_PGFSM_CONFIG, 0x500010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0x3e3e36);
+ WREG32(GMCON_PGFSM_CONFIG, 0x600010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0x373f3e);
+ WREG32(GMCON_PGFSM_CONFIG, 0x700010ff);
+
+ for (i = 0; i < 5; i++)
+  WREG32(GMCON_PGFSM_WRITE, 0);
+
+ WREG32(GMCON_PGFSM_WRITE, 0x3e1332);
+ WREG32(GMCON_PGFSM_CONFIG, 0xe00010ff);
+
+ WREG32(GMCON_MISC3, save->gmcon_misc3);
+ WREG32(GMCON_MISC, save->gmcon_misc);
+ WREG32(GMCON_RENG_EXECUTE, save->gmcon_reng_execute);
+}
+
+static void cik_gpu_pci_config_reset(struct radeon_device *rdev)
+{
+ struct evergreen_mc_save save;
+ struct kv_reset_save_regs kv_save = { 0 };
+ u32 tmp, i;
+
+ dev_info(rdev->dev, "GPU pci config reset\n");
+
+ /* disable dpm? */
+
+ /* disable cg/pg */
+ cik_fini_pg(rdev);
+ cik_fini_cg(rdev);
+
+ /* Disable GFX parsing/prefetching */
+ WREG32(CP_ME_CNTL, CP_ME_HALT | CP_PFP_HALT | CP_CE_HALT);
+
+ /* Disable MEC parsing/prefetching */
+ WREG32(CP_MEC_CNTL, MEC_ME1_HALT | MEC_ME2_HALT);
+
+ /* sdma0 */
+ tmp = RREG32(SDMA0_ME_CNTL + SDMA0_REGISTER_OFFSET);
+ tmp |= SDMA_HALT;
+ WREG32(SDMA0_ME_CNTL + SDMA0_REGISTER_OFFSET, tmp);
+ /* sdma1 */
+ tmp = RREG32(SDMA0_ME_CNTL + SDMA1_REGISTER_OFFSET);
+ tmp |= SDMA_HALT;
+ WREG32(SDMA0_ME_CNTL + SDMA1_REGISTER_OFFSET, tmp);
+ /* XXX other engines? */
+
+ /* halt the rlc, disable cp internal ints */
+ cik_rlc_stop(rdev);
+
+ udelay(50);
+
+ /* disable mem access */
+ evergreen_mc_stop(rdev, &save);
+ if (evergreen_mc_wait_for_idle(rdev)) {
+  dev_warn(rdev->dev, "Wait for MC idle timed out !\n");
+ }
+
+ if (rdev->flags & RADEON_IS_IGP)
+  kv_save_regs_for_reset(rdev, &kv_save);
+
+ /* disable BM */
+ pci_clear_master(rdev->pdev);
+ /* reset */
+ radeon_pci_config_reset(rdev);
+
+ udelay(100);
+
+ /* wait for asic to come out of reset */
+ for (i = 0; i < rdev->usec_timeout; i++) {
+  if (RREG32(CONFIG_MEMSIZE) != 0xffffffff)
+   break;
+  udelay(1);
+ }
+
+ /* does asic init need to be run first??? */
+ if (rdev->flags & RADEON_IS_IGP)
+  kv_restore_regs_for_reset(rdev, &kv_save);
+}
+
 /**
  * cik_asic_reset - soft reset GPU
  *
@@ -4868,10 +5087,17 @@ int cik_asic_reset(struct radeon_device *rdev)
  if (reset_mask)
   r600_set_bios_scratch_engine_hung(rdev, true);
 
+ /* try soft reset */
  cik_gpu_soft_reset(rdev, reset_mask);
 
  reset_mask = cik_gpu_check_soft_reset(rdev);
 
+ /* try pci config reset */
+ if (reset_mask && radeon_hard_reset)
+  cik_gpu_pci_config_reset(rdev);
+
+ reset_mask = cik_gpu_check_soft_reset(rdev);
+
  if (!reset_mask)
   r600_set_bios_scratch_engine_hung(rdev, false);
 
@@ -5136,20 +5362,6 @@ static int cik_pcie_gart_enable(struct radeon_device *rdev)
     WRITE_PROTECTION_FAULT_ENABLE_INTERRUPT |
     WRITE_PROTECTION_FAULT_ENABLE_DEFAULT);
 
- /* TC cache setup ??? */
- WREG32(TC_CFG_L1_LOAD_POLICY0, 0);
- WREG32(TC_CFG_L1_LOAD_POLICY1, 0);
- WREG32(TC_CFG_L1_STORE_POLICY, 0);
-
- WREG32(TC_CFG_L2_LOAD_POLICY0, 0);
- WREG32(TC_CFG_L2_LOAD_POLICY1, 0);
- WREG32(TC_CFG_L2_STORE_POLICY0, 0);
- WREG32(TC_CFG_L2_STORE_POLICY1, 0);
- WREG32(TC_CFG_L2_ATOMIC_POLICY, 0);
-
- WREG32(TC_CFG_L1_VOLATILE, 0);
- WREG32(TC_CFG_L2_VOLATILE, 0);
-
  if (rdev->family == CHIP_KAVERI) {
   u32 tmp = RREG32(CHUB_CONTROL);
   tmp &= ~BYPASS_VM;
@@ -5365,16 +5577,7 @@ void cik_vm_flush(struct radeon_device *rdev, int ridx, struct radeon_vm *vm)
  radeon_ring_write(ring, VMID(0));
 
  /* HDP flush */
- /* We should be using the WAIT_REG_MEM packet here like in
-  * cik_fence_ring_emit(), but it causes the CP to hang in this
-  * context...
-  */
- radeon_ring_write(ring, PACKET3(PACKET3_WRITE_DATA, 3));
- radeon_ring_write(ring, (WRITE_DATA_ENGINE_SEL(0) |
-     WRITE_DATA_DST_SEL(0)));
- radeon_ring_write(ring, HDP_MEM_COHERENCY_FLUSH_CNTL >> 2);
- radeon_ring_write(ring, 0);
- radeon_ring_write(ring, 0);
+ cik_hdp_flush_cp_ring_emit(rdev, ridx);
 
  /* bits 0-15 are the VM contexts0-15 */
  radeon_ring_write(ring, PACKET3(PACKET3_WRITE_DATA, 3));
@@ -7501,7 +7704,7 @@ static int cik_startup(struct radeon_device *rdev)
 
  cik_mc_program(rdev);
 
- if (!(rdev->flags & RADEON_IS_IGP)) {
+ if (!(rdev->flags & RADEON_IS_IGP) && !rdev->pm.dpm_enabled) {
   r = ci_mc_load_microcode(rdev);
   if (r) {
    DRM_ERROR("Failed to load MC firmware!\n");
@@ -7606,7 +7809,6 @@ static int cik_startup(struct radeon_device *rdev)
 
  ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP_RPTR_OFFSET,
-        CP_RB0_RPTR, CP_RB0_WPTR,
         PACKET3(PACKET3_NOP, 0x3FFF));
  if (r)
   return r;
@@ -7615,7 +7817,6 @@ static int cik_startup(struct radeon_device *rdev)
  /* type-2 packets are deprecated on MEC, use type-3 instead */
  ring = &rdev->ring[CAYMAN_RING_TYPE_CP1_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP1_RPTR_OFFSET,
-        CP_HQD_PQ_RPTR, CP_HQD_PQ_WPTR,
         PACKET3(PACKET3_NOP, 0x3FFF));
  if (r)
   return r;
@@ -7627,7 +7828,6 @@ static int cik_startup(struct radeon_device *rdev)
  /* type-2 packets are deprecated on MEC, use type-3 instead */
  ring = &rdev->ring[CAYMAN_RING_TYPE_CP2_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP2_RPTR_OFFSET,
-        CP_HQD_PQ_RPTR, CP_HQD_PQ_WPTR,
         PACKET3(PACKET3_NOP, 0x3FFF));
  if (r)
   return r;
@@ -7639,16 +7839,12 @@ static int cik_startup(struct radeon_device *rdev)
 
  ring = &rdev->ring[R600_RING_TYPE_DMA_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, R600_WB_DMA_RPTR_OFFSET,
-        SDMA0_GFX_RB_RPTR + SDMA0_REGISTER_OFFSET,
-        SDMA0_GFX_RB_WPTR + SDMA0_REGISTER_OFFSET,
         SDMA_PACKET(SDMA_OPCODE_NOP, 0, 0));
  if (r)
   return r;
 
  ring = &rdev->ring[CAYMAN_RING_TYPE_DMA1_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, CAYMAN_WB_DMA1_RPTR_OFFSET,
-        SDMA0_GFX_RB_RPTR + SDMA1_REGISTER_OFFSET,
-        SDMA0_GFX_RB_WPTR + SDMA1_REGISTER_OFFSET,
         SDMA_PACKET(SDMA_OPCODE_NOP, 0, 0));
  if (r)
   return r;
@@ -7664,7 +7860,6 @@ static int cik_startup(struct radeon_device *rdev)
  ring = &rdev->ring[R600_RING_TYPE_UVD_INDEX];
  if (ring->ring_size) {
   r = radeon_ring_init(rdev, ring, ring->ring_size, 0,
-         UVD_RBC_RB_RPTR, UVD_RBC_RB_WPTR,
          RADEON_CP_PACKET2);
   if (!r)
    r = uvd_v1_0_init(rdev);
@@ -7710,6 +7905,9 @@ int cik_resume(struct radeon_device *rdev)
  /* init golden registers */
  cik_init_golden_registers(rdev);
 
+ if (rdev->pm.pm_method == PM_METHOD_DPM)
+  radeon_pm_resume(rdev);
+
  rdev->accel_working = true;
  r = cik_startup(rdev);
  if (r) {
@@ -7733,6 +7931,7 @@ int cik_resume(struct radeon_device *rdev)
  */
 int cik_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  dce6_audio_fini(rdev);
  radeon_vm_manager_fini(rdev);
  cik_cp_enable(rdev, false);
@@ -7835,6 +8034,9 @@ int cik_init(struct radeon_device *rdev)
   }
  }
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];
  ring->ring_obj = NULL;
  r600_ring_init(rdev, ring, 1024 * 1024);
@@ -7915,6 +8117,7 @@ int cik_init(struct radeon_device *rdev)
  */
 void cik_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  cik_cp_fini(rdev);
  cik_sdma_fini(rdev);
  cik_fini_pg(rdev);
diff --git a/drivers/gpu/drm/radeon/cik_sdma.c b/drivers/gpu/drm/radeon/cik_sdma.c
index 2e0c7a8..94626ea 100644
--- a/drivers/gpu/drm/radeon/cik_sdma.c
+++ b/drivers/gpu/drm/radeon/cik_sdma.c
@@ -52,6 +52,75 @@ u32 cik_gpu_check_soft_reset(struct radeon_device *rdev);
  */
 
 /**
+ * cik_sdma_get_rptr - get the current read pointer
+ *
+ * @rdev: radeon_device pointer
+ * @ring: radeon ring pointer
+ *
+ * Get the current rptr from the hardware (CIK+).
+ */
+uint32_t cik_sdma_get_rptr(struct radeon_device *rdev,
+      struct radeon_ring *ring)
+{
+ u32 rptr, reg;
+
+ if (rdev->wb.enabled) {
+  rptr = rdev->wb.wb[ring->rptr_offs/4];
+ } else {
+  if (ring->idx == R600_RING_TYPE_DMA_INDEX)
+   reg = SDMA0_GFX_RB_RPTR + SDMA0_REGISTER_OFFSET;
+  else
+   reg = SDMA0_GFX_RB_RPTR + SDMA1_REGISTER_OFFSET;
+
+  rptr = RREG32(reg);
+ }
+
+ return (rptr & 0x3fffc) >> 2;
+}
+
+/**
+ * cik_sdma_get_wptr - get the current write pointer
+ *
+ * @rdev: radeon_device pointer
+ * @ring: radeon ring pointer
+ *
+ * Get the current wptr from the hardware (CIK+).
+ */
+uint32_t cik_sdma_get_wptr(struct radeon_device *rdev,
+      struct radeon_ring *ring)
+{
+ u32 reg;
+
+ if (ring->idx == R600_RING_TYPE_DMA_INDEX)
+  reg = SDMA0_GFX_RB_WPTR + SDMA0_REGISTER_OFFSET;
+ else
+  reg = SDMA0_GFX_RB_WPTR + SDMA1_REGISTER_OFFSET;
+
+ return (RREG32(reg) & 0x3fffc) >> 2;
+}
+
+/**
+ * cik_sdma_set_wptr - commit the write pointer
+ *
+ * @rdev: radeon_device pointer
+ * @ring: radeon ring pointer
+ *
+ * Write the wptr back to the hardware (CIK+).
+ */
+void cik_sdma_set_wptr(struct radeon_device *rdev,
+         struct radeon_ring *ring)
+{
+ u32 reg;
+
+ if (ring->idx == R600_RING_TYPE_DMA_INDEX)
+  reg = SDMA0_GFX_RB_WPTR + SDMA0_REGISTER_OFFSET;
+ else
+  reg = SDMA0_GFX_RB_WPTR + SDMA1_REGISTER_OFFSET;
+
+ WREG32(reg, (ring->wptr << 2) & 0x3fffc);
+}
+
+/**
  * cik_sdma_ring_ib_execute - Schedule an IB on the DMA engine
  *
  * @rdev: radeon_device pointer
@@ -181,7 +250,9 @@ static void cik_sdma_gfx_stop(struct radeon_device *rdev)
  u32 rb_cntl, reg_offset;
  int i;
 
- radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
+ if ((rdev->asic->copy.copy_ring_index == R600_RING_TYPE_DMA_INDEX) ||
+     (rdev->asic->copy.copy_ring_index == CAYMAN_RING_TYPE_DMA1_INDEX))
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
 
  for (i = 0; i < 2; i++) {
   if (i == 0)
@@ -319,7 +390,9 @@ static int cik_sdma_gfx_resume(struct radeon_device *rdev)
   }
  }
 
- radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
+ if ((rdev->asic->copy.copy_ring_index == R600_RING_TYPE_DMA_INDEX) ||
+     (rdev->asic->copy.copy_ring_index == CAYMAN_RING_TYPE_DMA1_INDEX))
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
 
  return 0;
 }
diff --git a/drivers/gpu/drm/radeon/cikd.h b/drivers/gpu/drm/radeon/cikd.h
index 5964af5..98bae9d 100644
--- a/drivers/gpu/drm/radeon/cikd.h
+++ b/drivers/gpu/drm/radeon/cikd.h
@@ -724,6 +724,17 @@
 
 #define ATC_MISC_CG               0x3350
 
+#define GMCON_RENG_EXECUTE    0x3508
+#define  RENG_EXECUTE_ON_PWR_UP   (1 << 0)
+#define GMCON_MISC     0x350c
+#define  RENG_EXECUTE_ON_REG_UPDATE  (1 << 11)
+#define  STCTRL_STUTTER_EN   (1 << 16)
+
+#define GMCON_PGFSM_CONFIG    0x3538
+#define GMCON_PGFSM_WRITE    0x353c
+#define GMCON_PGFSM_READ    0x3540
+#define GMCON_MISC3     0x3544
+
 #define MC_SEQ_CNTL_3                                     0x3600
 #       define CAC_EN                                     (1 << 31)
 #define MC_SEQ_G5PDX_CTRL                                 0x3604
diff --git a/drivers/gpu/drm/radeon/cypress_dpm.c b/drivers/gpu/drm/radeon/cypress_dpm.c
index 920e1e4..cf783fc 100644
--- a/drivers/gpu/drm/radeon/cypress_dpm.c
+++ b/drivers/gpu/drm/radeon/cypress_dpm.c
@@ -1905,21 +1905,6 @@ int cypress_dpm_enable(struct radeon_device *rdev)
  if (pi->mg_clock_gating)
   cypress_mg_clock_gating_enable(rdev, true);
 
- if (rdev->irq.installed &&
-     r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
-  PPSMC_Result result;
-
-  ret = rv770_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);
-  if (ret)
-   return ret;
-  rdev->irq.dpm_thermal = true;
-  radeon_irq_set(rdev);
-  result = rv770_send_msg_to_smc(rdev, PPSMC_MSG_EnableThermalInterrupt);
-
-  if (result != PPSMC_Result_OK)
-   DRM_DEBUG_KMS("Could not enable thermal interrupts.\n");
- }
-
  rv770_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
 
  return 0;
diff --git a/drivers/gpu/drm/radeon/dce6_afmt.c b/drivers/gpu/drm/radeon/dce6_afmt.c
index 36e8f10..94e8587 100644
--- a/drivers/gpu/drm/radeon/dce6_afmt.c
+++ b/drivers/gpu/drm/radeon/dce6_afmt.c
@@ -278,13 +278,15 @@ static int dce6_audio_chipset_supported(struct radeon_device *rdev)
  return !ASIC_IS_NODCE(rdev);
 }
 
-static void dce6_audio_enable(struct radeon_device *rdev,
-         struct r600_audio_pin *pin,
-         bool enable)
+void dce6_audio_enable(struct radeon_device *rdev,
+         struct r600_audio_pin *pin,
+         bool enable)
 {
+ if (!pin)
+  return;
+
  WREG32_ENDPOINT(pin->offset, AZ_F0_CODEC_PIN_CONTROL_HOTPLUG_CONTROL,
    enable ? AUDIO_ENABLED : 0);
- DRM_INFO("%s audio %d support\n", enable ? "Enabling" : "Disabling", pin->id);
 }
 
 static const u32 pin_offsets[7] =
@@ -323,7 +325,8 @@ int dce6_audio_init(struct radeon_device *rdev)
   rdev->audio.pin[i].connected = false;
   rdev->audio.pin[i].offset = pin_offsets[i];
   rdev->audio.pin[i].id = i;
-  dce6_audio_enable(rdev, &rdev->audio.pin[i], true);
+  /* disable audio.  it will be set up later */
+  dce6_audio_enable(rdev, &rdev->audio.pin[i], false);
  }
 
  return 0;
diff --git a/drivers/gpu/drm/radeon/evergreen.c b/drivers/gpu/drm/radeon/evergreen.c
index 6d27faf..27b0ff1 100644
--- a/drivers/gpu/drm/radeon/evergreen.c
+++ b/drivers/gpu/drm/radeon/evergreen.c
@@ -146,6 +146,7 @@ extern u32 si_get_csb_size(struct radeon_device *rdev);
 extern void si_get_csb_buffer(struct radeon_device *rdev, volatile u32 *buffer);
 extern u32 cik_get_csb_size(struct radeon_device *rdev);
 extern void cik_get_csb_buffer(struct radeon_device *rdev, volatile u32 *buffer);
+extern void rv770_set_clk_bypass_mode(struct radeon_device *rdev);
 
 static const u32 evergreen_golden_registers[] =
 {
@@ -1679,7 +1680,7 @@ bool evergreen_hpd_sense(struct radeon_device *rdev, enum radeon_hpd_id hpd)
  case RADEON_HPD_6:
   if (RREG32(DC_HPD6_INT_STATUS) & DC_HPDx_SENSE)
    connected = true;
-   break;
+  break;
  default:
   break;
  }
@@ -3867,6 +3868,48 @@ static void evergreen_gpu_soft_reset(struct radeon_device *rdev, u32 reset_mask)
  evergreen_print_gpu_status_regs(rdev);
 }
 
+void evergreen_gpu_pci_config_reset(struct radeon_device *rdev)
+{
+ struct evergreen_mc_save save;
+ u32 tmp, i;
+
+ dev_info(rdev->dev, "GPU pci config reset\n");
+
+ /* disable dpm? */
+
+ /* Disable CP parsing/prefetching */
+ WREG32(CP_ME_CNTL, CP_ME_HALT | CP_PFP_HALT);
+ udelay(50);
+ /* Disable DMA */
+ tmp = RREG32(DMA_RB_CNTL);
+ tmp &= ~DMA_RB_ENABLE;
+ WREG32(DMA_RB_CNTL, tmp);
+ /* XXX other engines? */
+
+ /* halt the rlc */
+ r600_rlc_stop(rdev);
+
+ udelay(50);
+
+ /* set mclk/sclk to bypass */
+ rv770_set_clk_bypass_mode(rdev);
+ /* disable BM */
+ pci_clear_master(rdev->pdev);
+ /* disable mem access */
+ evergreen_mc_stop(rdev, &save);
+ if (evergreen_mc_wait_for_idle(rdev)) {
+  dev_warn(rdev->dev, "Wait for MC idle timed out !\n");
+ }
+ /* reset */
+ radeon_pci_config_reset(rdev);
+ /* wait for asic to come out of reset */
+ for (i = 0; i < rdev->usec_timeout; i++) {
+  if (RREG32(CONFIG_MEMSIZE) != 0xffffffff)
+   break;
+  udelay(1);
+ }
+}
+
 int evergreen_asic_reset(struct radeon_device *rdev)
 {
  u32 reset_mask;
@@ -3876,10 +3919,17 @@ int evergreen_asic_reset(struct radeon_device *rdev)
  if (reset_mask)
   r600_set_bios_scratch_engine_hung(rdev, true);
 
+ /* try soft reset */
  evergreen_gpu_soft_reset(rdev, reset_mask);
 
  reset_mask = evergreen_gpu_check_soft_reset(rdev);
 
+ /* try pci config reset */
+ if (reset_mask && radeon_hard_reset)
+  evergreen_gpu_pci_config_reset(rdev);
+
+ reset_mask = evergreen_gpu_check_soft_reset(rdev);
+
  if (!reset_mask)
   r600_set_bios_scratch_engine_hung(rdev, false);
 
@@ -5109,7 +5159,7 @@ static int evergreen_startup(struct radeon_device *rdev)
 
  evergreen_mc_program(rdev);
 
- if (ASIC_IS_DCE5(rdev)) {
+ if (ASIC_IS_DCE5(rdev) && !rdev->pm.dpm_enabled) {
   r = ni_mc_load_microcode(rdev);
   if (r) {
    DRM_ERROR("Failed to load MC firmware!\n");
@@ -5184,14 +5234,12 @@ static int evergreen_startup(struct radeon_device *rdev)
 
  ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP_RPTR_OFFSET,
-        R600_CP_RB_RPTR, R600_CP_RB_WPTR,
         RADEON_CP_PACKET2);
  if (r)
   return r;
 
  ring = &rdev->ring[R600_RING_TYPE_DMA_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, R600_WB_DMA_RPTR_OFFSET,
-        DMA_RB_RPTR, DMA_RB_WPTR,
         DMA_PACKET(DMA_PACKET_NOP, 0, 0));
  if (r)
   return r;
@@ -5209,7 +5257,6 @@ static int evergreen_startup(struct radeon_device *rdev)
  ring = &rdev->ring[R600_RING_TYPE_UVD_INDEX];
  if (ring->ring_size) {
   r = radeon_ring_init(rdev, ring, ring->ring_size, 0,
-         UVD_RBC_RB_RPTR, UVD_RBC_RB_WPTR,
          RADEON_CP_PACKET2);
   if (!r)
    r = uvd_v1_0_init(rdev);
@@ -5252,6 +5299,9 @@ int evergreen_resume(struct radeon_device *rdev)
  /* init golden registers */
  evergreen_init_golden_registers(rdev);
 
+ if (rdev->pm.pm_method == PM_METHOD_DPM)
+  radeon_pm_resume(rdev);
+
  rdev->accel_working = true;
  r = evergreen_startup(rdev);
  if (r) {
@@ -5266,6 +5316,7 @@ int evergreen_resume(struct radeon_device *rdev)
 
 int evergreen_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r600_audio_fini(rdev);
  uvd_v1_0_fini(rdev);
  radeon_uvd_suspend(rdev);
@@ -5360,6 +5411,9 @@ int evergreen_init(struct radeon_device *rdev)
   }
  }
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->ring[RADEON_RING_TYPE_GFX_INDEX].ring_obj = NULL;
  r600_ring_init(rdev, &rdev->ring[RADEON_RING_TYPE_GFX_INDEX], 1024 * 1024);
 
@@ -5412,6 +5466,7 @@ int evergreen_init(struct radeon_device *rdev)
 
 void evergreen_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r600_audio_fini(rdev);
  r700_cp_fini(rdev);
  r600_dma_fini(rdev);
diff --git a/drivers/gpu/drm/radeon/evergreen_hdmi.c b/drivers/gpu/drm/radeon/evergreen_hdmi.c
index 0c6d5ce..05b0c95 100644
--- a/drivers/gpu/drm/radeon/evergreen_hdmi.c
+++ b/drivers/gpu/drm/radeon/evergreen_hdmi.c
@@ -306,6 +306,15 @@ void evergreen_hdmi_setmode(struct drm_encoder *encoder, struct drm_display_mode
   return;
  offset = dig->afmt->offset;
 
+ /* disable audio prior to setting up hw */
+ if (ASIC_IS_DCE6(rdev)) {
+  dig->afmt->pin = dce6_audio_get_pin(rdev);
+  dce6_audio_enable(rdev, dig->afmt->pin, false);
+ } else {
+  dig->afmt->pin = r600_audio_get_pin(rdev);
+  r600_audio_enable(rdev, dig->afmt->pin, false);
+ }
+
  evergreen_audio_set_dto(encoder, mode->clock);
 
  WREG32(HDMI_VBI_PACKET_CONTROL + offset,
@@ -409,12 +418,16 @@ void evergreen_hdmi_setmode(struct drm_encoder *encoder, struct drm_display_mode
  WREG32(AFMT_RAMP_CONTROL1 + offset, 0x007FFFFF);
  WREG32(AFMT_RAMP_CONTROL2 + offset, 0x00000001);
  WREG32(AFMT_RAMP_CONTROL3 + offset, 0x00000001);
+
+ /* enable audio after to setting up hw */
+ if (ASIC_IS_DCE6(rdev))
+  dce6_audio_enable(rdev, dig->afmt->pin, true);
+ else
+  r600_audio_enable(rdev, dig->afmt->pin, true);
 }
 
 void evergreen_hdmi_enable(struct drm_encoder *encoder, bool enable)
 {
- struct drm_device *dev = encoder->dev;
- struct radeon_device *rdev = dev->dev_private;
  struct radeon_encoder *radeon_encoder = to_radeon_encoder(encoder);
  struct radeon_encoder_atom_dig *dig = radeon_encoder->enc_priv;
 
@@ -427,15 +440,6 @@ void evergreen_hdmi_enable(struct drm_encoder *encoder, bool enable)
  if (!enable && !dig->afmt->enabled)
   return;
 
- if (enable) {
-  if (ASIC_IS_DCE6(rdev))
-   dig->afmt->pin = dce6_audio_get_pin(rdev);
-  else
-   dig->afmt->pin = r600_audio_get_pin(rdev);
- } else {
-  dig->afmt->pin = NULL;
- }
-
  dig->afmt->enabled = enable;
 
  DRM_DEBUG("%sabling HDMI interface @ 0x%04X for encoder 0x%x\n",
diff --git a/drivers/gpu/drm/radeon/evergreen_reg.h b/drivers/gpu/drm/radeon/evergreen_reg.h
index 8a4e641..a0f63ff 100644
--- a/drivers/gpu/drm/radeon/evergreen_reg.h
+++ b/drivers/gpu/drm/radeon/evergreen_reg.h
@@ -33,6 +33,7 @@
 #define EVERGREEN_PIF_PHY0_DATA                         0xc
 #define EVERGREEN_PIF_PHY1_INDEX                        0x10
 #define EVERGREEN_PIF_PHY1_DATA                         0x14
+#define EVERGREEN_MM_INDEX_HI                           0x18
 
 #define EVERGREEN_VGA_MEMORY_BASE_ADDRESS               0x310
 #define EVERGREEN_VGA_MEMORY_BASE_ADDRESS_HIGH          0x324
diff --git a/drivers/gpu/drm/radeon/evergreend.h b/drivers/gpu/drm/radeon/evergreend.h
index 17f9907..f9c7963 100644
--- a/drivers/gpu/drm/radeon/evergreend.h
+++ b/drivers/gpu/drm/radeon/evergreend.h
@@ -82,12 +82,16 @@
 #define CG_SPLL_FUNC_CNTL_2    0x604
 #define  SCLK_MUX_SEL(x)    ((x) << 0)
 #define  SCLK_MUX_SEL_MASK   (0x1ff << 0)
+#define  SCLK_MUX_UPDATE    (1 << 26)
 #define CG_SPLL_FUNC_CNTL_3    0x608
 #define  SPLL_FB_DIV(x)    ((x) << 0)
 #define  SPLL_FB_DIV_MASK   (0x3ffffff << 0)
 #define  SPLL_DITHEN    (1 << 28)
+#define CG_SPLL_STATUS     0x60c
+#define  SPLL_CHG_STATUS    (1 << 1)
 
 #define MPLL_CNTL_MODE                                  0x61c
+#       define MPLL_MCLK_SEL                            (1 << 11)
 #       define SS_SSEN                                  (1 << 24)
 #       define SS_DSMODE_EN                             (1 << 25)
 
diff --git a/drivers/gpu/drm/radeon/kv_dpm.c b/drivers/gpu/drm/radeon/kv_dpm.c
index b419055..351db36 100644
--- a/drivers/gpu/drm/radeon/kv_dpm.c
+++ b/drivers/gpu/drm/radeon/kv_dpm.c
@@ -1126,11 +1126,6 @@ int kv_dpm_enable(struct radeon_device *rdev)
  struct kv_power_info *pi = kv_get_pi(rdev);
  int ret;
 
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_BIF |
-        RADEON_CG_BLOCK_HDP), false);
-
  ret = kv_process_firmware_header(rdev);
  if (ret) {
   DRM_ERROR("kv_process_firmware_header failed\n");
@@ -1215,6 +1210,21 @@ int kv_dpm_enable(struct radeon_device *rdev)
 
  kv_reset_acp_boot_level(rdev);
 
+ ret = kv_smc_bapm_enable(rdev, false);
+ if (ret) {
+  DRM_ERROR("kv_smc_bapm_enable failed\n");
+  return ret;
+ }
+
+ kv_update_current_ps(rdev, rdev->pm.dpm.boot_ps);
+
+ return ret;
+}
+
+int kv_dpm_late_enable(struct radeon_device *rdev)
+{
+ int ret = 0;
+
  if (rdev->irq.installed &&
      r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
   ret = kv_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);
@@ -1226,35 +1236,17 @@ int kv_dpm_enable(struct radeon_device *rdev)
   radeon_irq_set(rdev);
  }
 
- ret = kv_smc_bapm_enable(rdev, false);
- if (ret) {
-  DRM_ERROR("kv_smc_bapm_enable failed\n");
-  return ret;
- }
-
  /* powerdown unused blocks for now */
  kv_dpm_powergate_acp(rdev, true);
  kv_dpm_powergate_samu(rdev, true);
  kv_dpm_powergate_vce(rdev, true);
  kv_dpm_powergate_uvd(rdev, true);
 
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_BIF |
-        RADEON_CG_BLOCK_HDP), true);
-
- kv_update_current_ps(rdev, rdev->pm.dpm.boot_ps);
-
  return ret;
 }
 
 void kv_dpm_disable(struct radeon_device *rdev)
 {
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_BIF |
-        RADEON_CG_BLOCK_HDP), false);
-
  kv_smc_bapm_enable(rdev, false);
 
  /* powerup blocks */
@@ -1779,11 +1771,6 @@ int kv_dpm_set_power_state(struct radeon_device *rdev)
  /*struct radeon_ps *old_ps = &pi->current_rps;*/
  int ret;
 
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_BIF |
-        RADEON_CG_BLOCK_HDP), false);
-
  if (pi->bapm_enable) {
   ret = kv_smc_bapm_enable(rdev, rdev->pm.dpm.ac_power);
   if (ret) {
@@ -1849,11 +1836,6 @@ int kv_dpm_set_power_state(struct radeon_device *rdev)
   }
  }
 
- cik_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-        RADEON_CG_BLOCK_SDMA |
-        RADEON_CG_BLOCK_BIF |
-        RADEON_CG_BLOCK_HDP), true);
-
  return 0;
 }
 
diff --git a/drivers/gpu/drm/radeon/mkregtable.c b/drivers/gpu/drm/radeon/mkregtable.c
index af85299..4a85bb6 100644
--- a/drivers/gpu/drm/radeon/mkregtable.c
+++ b/drivers/gpu/drm/radeon/mkregtable.c
@@ -655,7 +655,7 @@ static int parser_auth(struct table *t, const char *filename)
 
  /* first line will contain the last register
   * and gpu name */
- sscanf(buf, "%s %s", gpu_name, last_reg_s);
+ sscanf(buf, "%9s %9s", gpu_name, last_reg_s);
  t->gpu_prefix = gpu_name;
  last_reg = strtol(last_reg_s, NULL, 16);
 
diff --git a/drivers/gpu/drm/radeon/ni.c b/drivers/gpu/drm/radeon/ni.c
index 2443d11..bf6300c 100644
--- a/drivers/gpu/drm/radeon/ni.c
+++ b/drivers/gpu/drm/radeon/ni.c
@@ -174,6 +174,7 @@ extern void evergreen_pcie_gen2_enable(struct radeon_device *rdev);
 extern void evergreen_program_aspm(struct radeon_device *rdev);
 extern void sumo_rlc_fini(struct radeon_device *rdev);
 extern int sumo_rlc_init(struct radeon_device *rdev);
+extern void evergreen_gpu_pci_config_reset(struct radeon_device *rdev);
 
 /* Firmware Names */
 MODULE_FIRMWARE("radeon/BARTS_pfp.bin");
@@ -1389,13 +1390,63 @@ static void cayman_cp_enable(struct radeon_device *rdev, bool enable)
  if (enable)
   WREG32(CP_ME_CNTL, 0);
  else {
-  radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
+  if (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)
+   radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
   WREG32(CP_ME_CNTL, (CP_ME_HALT | CP_PFP_HALT));
   WREG32(SCRATCH_UMSK, 0);
   rdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;
  }
 }
 
+u32 cayman_gfx_get_rptr(struct radeon_device *rdev,
+   struct radeon_ring *ring)
+{
+ u32 rptr;
+
+ if (rdev->wb.enabled)
+  rptr = rdev->wb.wb[ring->rptr_offs/4];
+ else {
+  if (ring->idx == RADEON_RING_TYPE_GFX_INDEX)
+   rptr = RREG32(CP_RB0_RPTR);
+  else if (ring->idx == CAYMAN_RING_TYPE_CP1_INDEX)
+   rptr = RREG32(CP_RB1_RPTR);
+  else
+   rptr = RREG32(CP_RB2_RPTR);
+ }
+
+ return rptr;
+}
+
+u32 cayman_gfx_get_wptr(struct radeon_device *rdev,
+   struct radeon_ring *ring)
+{
+ u32 wptr;
+
+ if (ring->idx == RADEON_RING_TYPE_GFX_INDEX)
+  wptr = RREG32(CP_RB0_WPTR);
+ else if (ring->idx == CAYMAN_RING_TYPE_CP1_INDEX)
+  wptr = RREG32(CP_RB1_WPTR);
+ else
+  wptr = RREG32(CP_RB2_WPTR);
+
+ return wptr;
+}
+
+void cayman_gfx_set_wptr(struct radeon_device *rdev,
+    struct radeon_ring *ring)
+{
+ if (ring->idx == RADEON_RING_TYPE_GFX_INDEX) {
+  WREG32(CP_RB0_WPTR, ring->wptr);
+  (void)RREG32(CP_RB0_WPTR);
+ } else if (ring->idx == CAYMAN_RING_TYPE_CP1_INDEX) {
+  WREG32(CP_RB1_WPTR, ring->wptr);
+  (void)RREG32(CP_RB1_WPTR);
+ } else {
+  WREG32(CP_RB2_WPTR, ring->wptr);
+  (void)RREG32(CP_RB2_WPTR);
+ }
+}
+
 static int cayman_cp_load_microcode(struct radeon_device *rdev)
 {
  const __be32 *fw_data;
@@ -1524,6 +1575,16 @@ static int cayman_cp_resume(struct radeon_device *rdev)
   CP_RB1_BASE,
   CP_RB2_BASE
  };
+ static const unsigned cp_rb_rptr[] = {
+  CP_RB0_RPTR,
+  CP_RB1_RPTR,
+  CP_RB2_RPTR
+ };
+ static const unsigned cp_rb_wptr[] = {
+  CP_RB0_WPTR,
+  CP_RB1_WPTR,
+  CP_RB2_WPTR
+ };
  struct radeon_ring *ring;
  int i, r;
 
@@ -1582,8 +1643,8 @@ static int cayman_cp_resume(struct radeon_device *rdev)
   WREG32_P(cp_rb_cntl[i], RB_RPTR_WR_ENA, ~RB_RPTR_WR_ENA);
 
   ring->rptr = ring->wptr = 0;
-  WREG32(ring->rptr_reg, ring->rptr);
-  WREG32(ring->wptr_reg, ring->wptr);
+  WREG32(cp_rb_rptr[i], ring->rptr);
+  WREG32(cp_rb_wptr[i], ring->wptr);
 
   mdelay(1);
   WREG32_P(cp_rb_cntl[i], 0, ~RB_RPTR_WR_ENA);
@@ -1603,6 +1664,9 @@ static int cayman_cp_resume(struct radeon_device *rdev)
   return r;
  }
 
+ if (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
+
  return 0;
 }
 
@@ -1829,8 +1893,10 @@ int cayman_asic_reset(struct radeon_device *rdev)
 
  reset_mask = cayman_gpu_check_soft_reset(rdev);
 
- if (!reset_mask)
-  r600_set_bios_scratch_engine_hung(rdev, false);
+ if (reset_mask)
+  evergreen_gpu_pci_config_reset(rdev);
+
+ r600_set_bios_scratch_engine_hung(rdev, false);
 
  return 0;
 }
@@ -1876,7 +1942,7 @@ static int cayman_startup(struct radeon_device *rdev)
 
  evergreen_mc_program(rdev);
 
- if (!(rdev->flags & RADEON_IS_IGP)) {
+ if (!(rdev->flags & RADEON_IS_IGP) && !rdev->pm.dpm_enabled) {
   r = ni_mc_load_microcode(rdev);
   if (r) {
    DRM_ERROR("Failed to load MC firmware!\n");
@@ -1963,23 +2029,18 @@ static int cayman_startup(struct radeon_device *rdev)
  evergreen_irq_set(rdev);
 
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP_RPTR_OFFSET,
-        CP_RB0_RPTR, CP_RB0_WPTR,
         RADEON_CP_PACKET2);
  if (r)
   return r;
 
  ring = &rdev->ring[R600_RING_TYPE_DMA_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, R600_WB_DMA_RPTR_OFFSET,
-        DMA_RB_RPTR + DMA0_REGISTER_OFFSET,
-        DMA_RB_WPTR + DMA0_REGISTER_OFFSET,
         DMA_PACKET(DMA_PACKET_NOP, 0, 0, 0));
  if (r)
   return r;
 
  ring = &rdev->ring[CAYMAN_RING_TYPE_DMA1_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, CAYMAN_WB_DMA1_RPTR_OFFSET,
-        DMA_RB_RPTR + DMA1_REGISTER_OFFSET,
-        DMA_RB_WPTR + DMA1_REGISTER_OFFSET,
         DMA_PACKET(DMA_PACKET_NOP, 0, 0, 0));
  if (r)
   return r;
@@ -1998,7 +2059,6 @@ static int cayman_startup(struct radeon_device *rdev)
  ring = &rdev->ring[R600_RING_TYPE_UVD_INDEX];
  if (ring->ring_size) {
   r = radeon_ring_init(rdev, ring, ring->ring_size, 0,
-         UVD_RBC_RB_RPTR, UVD_RBC_RB_WPTR,
          RADEON_CP_PACKET2);
   if (!r)
    r = uvd_v1_0_init(rdev);
@@ -2045,6 +2105,9 @@ int cayman_resume(struct radeon_device *rdev)
  /* init golden registers */
  ni_init_golden_registers(rdev);
 
+ if (rdev->pm.pm_method == PM_METHOD_DPM)
+  radeon_pm_resume(rdev);
+
  rdev->accel_working = true;
  r = cayman_startup(rdev);
  if (r) {
@@ -2057,6 +2120,7 @@ int cayman_resume(struct radeon_device *rdev)
 
 int cayman_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  if (ASIC_IS_DCE6(rdev))
   dce6_audio_fini(rdev);
  else
@@ -2145,6 +2209,9 @@ int cayman_init(struct radeon_device *rdev)
   }
  }
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  ring->ring_obj = NULL;
  r600_ring_init(rdev, ring, 1024 * 1024);
 
@@ -2204,6 +2271,7 @@ int cayman_init(struct radeon_device *rdev)
 
 void cayman_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  cayman_cp_fini(rdev);
  cayman_dma_fini(rdev);
  r600_irq_fini(rdev);
diff --git a/drivers/gpu/drm/radeon/ni_dma.c b/drivers/gpu/drm/radeon/ni_dma.c
index bdeb65e..7cf96b1 100644
--- a/drivers/gpu/drm/radeon/ni_dma.c
+++ b/drivers/gpu/drm/radeon/ni_dma.c
@@ -43,6 +43,75 @@ u32 cayman_gpu_check_soft_reset(struct radeon_device *rdev);
  */
 
 /**
+ * cayman_dma_get_rptr - get the current read pointer
+ *
+ * @rdev: radeon_device pointer
+ * @ring: radeon ring pointer
+ *
+ * Get the current rptr from the hardware (cayman+).
+ */
+uint32_t cayman_dma_get_rptr(struct radeon_device *rdev,
+        struct radeon_ring *ring)
+{
+ u32 rptr, reg;
+
+ if (rdev->wb.enabled) {
+  rptr = rdev->wb.wb[ring->rptr_offs/4];
+ } else {
+  if (ring->idx == R600_RING_TYPE_DMA_INDEX)
+   reg = DMA_RB_RPTR + DMA0_REGISTER_OFFSET;
+  else
+   reg = DMA_RB_RPTR + DMA1_REGISTER_OFFSET;
+
+  rptr = RREG32(reg);
+ }
+
+ return (rptr & 0x3fffc) >> 2;
+}
+
+/**
+ * cayman_dma_get_wptr - get the current write pointer
+ *
+ * @rdev: radeon_device pointer
+ * @ring: radeon ring pointer
+ *
+ * Get the current wptr from the hardware (cayman+).
+ */
+uint32_t cayman_dma_get_wptr(struct radeon_device *rdev,
+      struct radeon_ring *ring)
+{
+ u32 reg;
+
+ if (ring->idx == R600_RING_TYPE_DMA_INDEX)
+  reg = DMA_RB_WPTR + DMA0_REGISTER_OFFSET;
+ else
+  reg = DMA_RB_WPTR + DMA1_REGISTER_OFFSET;
+
+ return (RREG32(reg) & 0x3fffc) >> 2;
+}
+
+/**
+ * cayman_dma_set_wptr - commit the write pointer
+ *
+ * @rdev: radeon_device pointer
+ * @ring: radeon ring pointer
+ *
+ * Write the wptr back to the hardware (cayman+).
+ */
+void cayman_dma_set_wptr(struct radeon_device *rdev,
+    struct radeon_ring *ring)
+{
+ u32 reg;
+
+ if (ring->idx == R600_RING_TYPE_DMA_INDEX)
+  reg = DMA_RB_WPTR + DMA0_REGISTER_OFFSET;
+ else
+  reg = DMA_RB_WPTR + DMA1_REGISTER_OFFSET;
+
+ WREG32(reg, (ring->wptr << 2) & 0x3fffc);
+}
+
+/**
  * cayman_dma_ring_ib_execute - Schedule an IB on the DMA engine
  *
  * @rdev: radeon_device pointer
@@ -88,7 +157,9 @@ void cayman_dma_stop(struct radeon_device *rdev)
 {
  u32 rb_cntl;
 
- radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
+ if ((rdev->asic->copy.copy_ring_index == R600_RING_TYPE_DMA_INDEX) ||
+     (rdev->asic->copy.copy_ring_index == CAYMAN_RING_TYPE_DMA1_INDEX))
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
 
  /* dma0 */
  rb_cntl = RREG32(DMA_RB_CNTL + DMA0_REGISTER_OFFSET);
@@ -190,7 +261,9 @@ int cayman_dma_resume(struct radeon_device *rdev)
   }
  }
 
- radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
+ if ((rdev->asic->copy.copy_ring_index == R600_RING_TYPE_DMA_INDEX) ||
+     (rdev->asic->copy.copy_ring_index == CAYMAN_RING_TYPE_DMA1_INDEX))
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
 
  return 0;
 }
diff --git a/drivers/gpu/drm/radeon/ni_dpm.c b/drivers/gpu/drm/radeon/ni_dpm.c
index 1ee58a3..ca81427 100644
--- a/drivers/gpu/drm/radeon/ni_dpm.c
+++ b/drivers/gpu/drm/radeon/ni_dpm.c
@@ -720,6 +720,8 @@ static const u32 cayman_sysls_enable[] =
 struct rv7xx_power_info *rv770_get_pi(struct radeon_device *rdev);
 struct evergreen_power_info *evergreen_get_pi(struct radeon_device *rdev);
 
+extern int ni_mc_load_microcode(struct radeon_device *rdev);
+
 struct ni_power_info *ni_get_pi(struct radeon_device *rdev)
 {
         struct ni_power_info *pi = rdev->pm.dpm.priv;
@@ -3565,7 +3567,11 @@ void ni_set_uvd_clock_after_set_eng_clock(struct radeon_device *rdev,
 void ni_dpm_setup_asic(struct radeon_device *rdev)
 {
  struct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);
+ int r;
 
+ r = ni_mc_load_microcode(rdev);
+ if (r)
+  DRM_ERROR("Failed to load MC firmware!\n");
  ni_read_clock_registers(rdev);
  btc_read_arb_registers(rdev);
  rv770_get_memory_type(rdev);
@@ -3710,21 +3716,6 @@ int ni_dpm_enable(struct radeon_device *rdev)
  if (eg_pi->ls_clock_gating)
   ni_ls_clockgating_enable(rdev, true);
 
- if (rdev->irq.installed &&
-     r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
-  PPSMC_Result result;
-
-  ret = rv770_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, 0xff * 1000);
-  if (ret)
-   return ret;
-  rdev->irq.dpm_thermal = true;
-  radeon_irq_set(rdev);
-  result = rv770_send_msg_to_smc(rdev, PPSMC_MSG_EnableThermalInterrupt);
-
-  if (result != PPSMC_Result_OK)
-   DRM_DEBUG_KMS("Could not enable thermal interrupts.\n");
- }
-
  rv770_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
 
  ni_update_current_ps(rdev, boot_ps);
@@ -3954,7 +3945,6 @@ static void ni_parse_pplib_clock_info(struct radeon_device *rdev,
  struct rv7xx_power_info *pi = rv770_get_pi(rdev);
  struct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);
  struct ni_ps *ps = ni_get_ps(rps);
- u16 vddc;
  struct rv7xx_pl *pl = &ps->performance_levels[index];
 
  ps->performance_level_count = index + 1;
@@ -3970,8 +3960,8 @@ static void ni_parse_pplib_clock_info(struct radeon_device *rdev,
 
  /* patch up vddc if necessary */
  if (pl->vddc == 0xff01) {
-  if (radeon_atom_get_max_vddc(rdev, 0, 0, &vddc) == 0)
-   pl->vddc = vddc;
+  if (pi->max_vddc)
+   pl->vddc = pi->max_vddc;
  }
 
  if (rps->class & ATOM_PPLIB_CLASSIFICATION_ACPI) {
@@ -4331,7 +4321,8 @@ void ni_dpm_print_power_state(struct radeon_device *rdev,
 void ni_dpm_debugfs_print_current_performance_level(struct radeon_device *rdev,
           struct seq_file *m)
 {
- struct radeon_ps *rps = rdev->pm.dpm.current_ps;
+ struct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);
+ struct radeon_ps *rps = &eg_pi->current_rps;
  struct ni_ps *ps = ni_get_ps(rps);
  struct rv7xx_pl *pl;
  u32 current_index =
diff --git a/drivers/gpu/drm/radeon/pptable.h b/drivers/gpu/drm/radeon/pptable.h
index da43ab3..2d53299 100644
--- a/drivers/gpu/drm/radeon/pptable.h
+++ b/drivers/gpu/drm/radeon/pptable.h
@@ -23,7 +23,7 @@
 #ifndef _PPTABLE_H
 #define _PPTABLE_H
 
-#pragma pack(push, 1)
+#pragma pack(1)
 
 typedef struct _ATOM_PPLIB_THERMALCONTROLLER
 
@@ -677,6 +677,6 @@ typedef struct _ATOM_PPLIB_PPM_Table
       ULONG  ulTjmax;
 } ATOM_PPLIB_PPM_Table;
 
-#pragma pack(pop)
+#pragma pack()
 
 #endif
diff --git a/drivers/gpu/drm/radeon/r100.c b/drivers/gpu/drm/radeon/r100.c
index 10abc4d..3cc78bb 100644
--- a/drivers/gpu/drm/radeon/r100.c
+++ b/drivers/gpu/drm/radeon/r100.c
@@ -1050,6 +1050,36 @@ static int r100_cp_init_microcode(struct radeon_device *rdev)
  return err;
 }
 
+u32 r100_gfx_get_rptr(struct radeon_device *rdev,
+        struct radeon_ring *ring)
+{
+ u32 rptr;
+
+ if (rdev->wb.enabled)
+  rptr = le32_to_cpu(rdev->wb.wb[ring->rptr_offs/4]);
+ else
+  rptr = RREG32(RADEON_CP_RB_RPTR);
+
+ return rptr;
+}
+
+u32 r100_gfx_get_wptr(struct radeon_device *rdev,
+        struct radeon_ring *ring)
+{
+ u32 wptr;
+
+ wptr = RREG32(RADEON_CP_RB_WPTR);
+
+ return wptr;
+}
+
+void r100_gfx_set_wptr(struct radeon_device *rdev,
+         struct radeon_ring *ring)
+{
+ WREG32(RADEON_CP_RB_WPTR, ring->wptr);
+ (void)RREG32(RADEON_CP_RB_WPTR);
+}
+
 static void r100_cp_load_microcode(struct radeon_device *rdev)
 {
  const __be32 *fw_data;
@@ -1102,7 +1132,6 @@ int r100_cp_init(struct radeon_device *rdev, unsigned ring_size)
  ring_size = (1 << (rb_bufsz + 1)) * 4;
  r100_cp_load_microcode(rdev);
  r = radeon_ring_init(rdev, ring, ring_size, RADEON_WB_CP_RPTR_OFFSET,
-        RADEON_CP_RB_RPTR, RADEON_CP_RB_WPTR,
         RADEON_CP_PACKET2);
  if (r) {
   return r;
@@ -3923,6 +3952,7 @@ int r100_resume(struct radeon_device *rdev)
 
 int r100_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r100_cp_disable(rdev);
  radeon_wb_disable(rdev);
  r100_irq_disable(rdev);
@@ -3933,6 +3963,7 @@ int r100_suspend(struct radeon_device *rdev)
 
 void r100_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r100_cp_fini(rdev);
  radeon_wb_fini(rdev);
  radeon_ib_pool_fini(rdev);
@@ -4039,6 +4070,9 @@ int r100_init(struct radeon_device *rdev)
  }
  r100_set_safe_registers(rdev);
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->accel_working = true;
  r = r100_startup(rdev);
  if (r) {
diff --git a/drivers/gpu/drm/radeon/r300.c b/drivers/gpu/drm/radeon/r300.c
index d8dd269..0b658b3 100644
--- a/drivers/gpu/drm/radeon/r300.c
+++ b/drivers/gpu/drm/radeon/r300.c
@@ -1440,6 +1440,7 @@ int r300_resume(struct radeon_device *rdev)
 
 int r300_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r100_cp_disable(rdev);
  radeon_wb_disable(rdev);
  r100_irq_disable(rdev);
@@ -1452,6 +1453,7 @@ int r300_suspend(struct radeon_device *rdev)
 
 void r300_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r100_cp_fini(rdev);
  radeon_wb_fini(rdev);
  radeon_ib_pool_fini(rdev);
@@ -1538,6 +1540,9 @@ int r300_init(struct radeon_device *rdev)
  }
  r300_set_reg_safe(rdev);
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->accel_working = true;
  r = r300_startup(rdev);
  if (r) {
diff --git a/drivers/gpu/drm/radeon/r300_cmdbuf.c b/drivers/gpu/drm/radeon/r300_cmdbuf.c
index 60170ea..84b1d53 100644
--- a/drivers/gpu/drm/radeon/r300_cmdbuf.c
+++ b/drivers/gpu/drm/radeon/r300_cmdbuf.c
@@ -75,7 +75,7 @@ static int r300_emit_cliprects(drm_radeon_private_t *dev_priv,
   OUT_RING(CP_PACKET0(R300_RE_CLIPRECT_TL_0, nr * 2 - 1));
 
   for (i = 0; i < nr; ++i) {
-   if (DRM_COPY_FROM_USER
+   if (copy_from_user
        (&box, &cmdbuf->boxes[n + i], sizeof(box))) {
     DRM_ERROR("copy cliprect faulted\n");
     return -EFAULT;
@@ -928,12 +928,12 @@ static int r300_scratch(drm_radeon_private_t *dev_priv,
   buf_idx = drm_buffer_pointer_to_dword(cmdbuf->buffer, 0);
   *buf_idx *= 2; /* 8 bytes per buf */
 
-  if (DRM_COPY_TO_USER(ref_age_base + *buf_idx,
+  if (copy_to_user(ref_age_base + *buf_idx,
     &dev_priv->scratch_ages[header.scratch.reg],
     sizeof(u32)))
    return -EINVAL;
 
-  if (DRM_COPY_FROM_USER(&h_pending,
+  if (copy_from_user(&h_pending,
     ref_age_base + *buf_idx + 1,
     sizeof(u32)))
    return -EINVAL;
@@ -943,7 +943,7 @@ static int r300_scratch(drm_radeon_private_t *dev_priv,
 
   h_pending--;
 
-  if (DRM_COPY_TO_USER(ref_age_base + *buf_idx + 1,
+  if (copy_to_user(ref_age_base + *buf_idx + 1,
      &h_pending,
      sizeof(u32)))
    return -EINVAL;
diff --git a/drivers/gpu/drm/radeon/r420.c b/drivers/gpu/drm/radeon/r420.c
index 6edf2b3..802b192 100644
--- a/drivers/gpu/drm/radeon/r420.c
+++ b/drivers/gpu/drm/radeon/r420.c
@@ -335,6 +335,7 @@ int r420_resume(struct radeon_device *rdev)
 
 int r420_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r420_cp_errata_fini(rdev);
  r100_cp_disable(rdev);
  radeon_wb_disable(rdev);
@@ -348,6 +349,7 @@ int r420_suspend(struct radeon_device *rdev)
 
 void r420_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r100_cp_fini(rdev);
  radeon_wb_fini(rdev);
  radeon_ib_pool_fini(rdev);
@@ -444,6 +446,9 @@ int r420_init(struct radeon_device *rdev)
  }
  r420_set_reg_safe(rdev);
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->accel_working = true;
  r = r420_startup(rdev);
  if (r) {
diff --git a/drivers/gpu/drm/radeon/r520.c b/drivers/gpu/drm/radeon/r520.c
index e1aece7..98d6053 100644
--- a/drivers/gpu/drm/radeon/r520.c
+++ b/drivers/gpu/drm/radeon/r520.c
@@ -312,6 +312,9 @@ int r520_init(struct radeon_device *rdev)
   return r;
  rv515_set_safe_registers(rdev);
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->accel_working = true;
  r = r520_startup(rdev);
  if (r) {
diff --git a/drivers/gpu/drm/radeon/r600.c b/drivers/gpu/drm/radeon/r600.c
index 2d75542..647ef40 100644
--- a/drivers/gpu/drm/radeon/r600.c
+++ b/drivers/gpu/drm/radeon/r600.c
@@ -105,6 +105,7 @@ void r600_fini(struct radeon_device *rdev);
 void r600_irq_disable(struct radeon_device *rdev);
 static void r600_pcie_gen2_enable(struct radeon_device *rdev);
 extern int evergreen_rlc_resume(struct radeon_device *rdev);
+extern void rv770_set_clk_bypass_mode(struct radeon_device *rdev);
 
 /**
  * r600_get_xclk - get the xclk
@@ -1644,6 +1645,67 @@ static void r600_gpu_soft_reset(struct radeon_device *rdev, u32 reset_mask)
  r600_print_gpu_status_regs(rdev);
 }
 
+static void r600_gpu_pci_config_reset(struct radeon_device *rdev)
+{
+ struct rv515_mc_save save;
+ u32 tmp, i;
+
+ dev_info(rdev->dev, "GPU pci config reset\n");
+
+ /* disable dpm? */
+
+ /* Disable CP parsing/prefetching */
+ if (rdev->family >= CHIP_RV770)
+  WREG32(R_0086D8_CP_ME_CNTL, S_0086D8_CP_ME_HALT(1) | S_0086D8_CP_PFP_HALT(1));
+ else
+  WREG32(R_0086D8_CP_ME_CNTL, S_0086D8_CP_ME_HALT(1));
+
+ /* disable the RLC */
+ WREG32(RLC_CNTL, 0);
+
+ /* Disable DMA */
+ tmp = RREG32(DMA_RB_CNTL);
+ tmp &= ~DMA_RB_ENABLE;
+ WREG32(DMA_RB_CNTL, tmp);
+
+ mdelay(50);
+
+ /* set mclk/sclk to bypass */
+ if (rdev->family >= CHIP_RV770)
+  rv770_set_clk_bypass_mode(rdev);
+ /* disable BM */
+ pci_clear_master(rdev->pdev);
+ /* disable mem access */
+ rv515_mc_stop(rdev, &save);
+ if (r600_mc_wait_for_idle(rdev)) {
+  dev_warn(rdev->dev, "Wait for MC idle timedout !\n");
+ }
+
+ /* BIF reset workaround.  Not sure if this is needed on 6xx */
+ tmp = RREG32(BUS_CNTL);
+ tmp |= VGA_COHE_SPEC_TIMER_DIS;
+ WREG32(BUS_CNTL, tmp);
+
+ tmp = RREG32(BIF_SCRATCH0);
+
+ /* reset */
+ radeon_pci_config_reset(rdev);
+ mdelay(1);
+
+ /* BIF reset workaround.  Not sure if this is needed on 6xx */
+ tmp = SOFT_RESET_BIF;
+ WREG32(SRBM_SOFT_RESET, tmp);
+ mdelay(1);
+ WREG32(SRBM_SOFT_RESET, 0);
+
+ /* wait for asic to come out of reset */
+ for (i = 0; i < rdev->usec_timeout; i++) {
+  if (RREG32(CONFIG_MEMSIZE) != 0xffffffff)
+   break;
+  udelay(1);
+ }
+}
+
 int r600_asic_reset(struct radeon_device *rdev)
 {
  u32 reset_mask;
@@ -1653,10 +1715,17 @@ int r600_asic_reset(struct radeon_device *rdev)
  if (reset_mask)
   r600_set_bios_scratch_engine_hung(rdev, true);
 
+ /* try soft reset */
  r600_gpu_soft_reset(rdev, reset_mask);
 
  reset_mask = r600_gpu_check_soft_reset(rdev);
 
+ /* try pci config reset */
+ if (reset_mask && radeon_hard_reset)
+  r600_gpu_pci_config_reset(rdev);
+
+ reset_mask = r600_gpu_check_soft_reset(rdev);
+
  if (!reset_mask)
   r600_set_bios_scratch_engine_hung(rdev, false);
 
@@ -2185,7 +2254,8 @@ void r600_pciep_wreg(struct radeon_device *rdev, u32 reg, u32 v)
  */
 void r600_cp_stop(struct radeon_device *rdev)
 {
- radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
+ if (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
  WREG32(R_0086D8_CP_ME_CNTL, S_0086D8_CP_ME_HALT(1));
  WREG32(SCRATCH_UMSK, 0);
  rdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;
@@ -2382,6 +2452,36 @@ out:
  return err;
 }
 
+u32 r600_gfx_get_rptr(struct radeon_device *rdev,
+        struct radeon_ring *ring)
+{
+ u32 rptr;
+
+ if (rdev->wb.enabled)
+  rptr = rdev->wb.wb[ring->rptr_offs/4];
+ else
+  rptr = RREG32(R600_CP_RB_RPTR);
+
+ return rptr;
+}
+
+u32 r600_gfx_get_wptr(struct radeon_device *rdev,
+        struct radeon_ring *ring)
+{
+ u32 wptr;
+
+ wptr = RREG32(R600_CP_RB_WPTR);
+
+ return wptr;
+}
+
+void r600_gfx_set_wptr(struct radeon_device *rdev,
+         struct radeon_ring *ring)
+{
+ WREG32(R600_CP_RB_WPTR, ring->wptr);
+ (void)RREG32(R600_CP_RB_WPTR);
+}
+
 static int r600_cp_load_microcode(struct radeon_device *rdev)
 {
  const __be32 *fw_data;
@@ -2513,6 +2613,10 @@ int r600_cp_resume(struct radeon_device *rdev)
   ring->ready = false;
   return r;
  }
+
+ if (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
+
  return 0;
 }
 
@@ -2796,12 +2900,6 @@ static int r600_startup(struct radeon_device *rdev)
   return r;
  }
 
- r = radeon_fence_driver_start_ring(rdev, R600_RING_TYPE_DMA_INDEX);
- if (r) {
-  dev_err(rdev->dev, "failed initializing DMA fences (%d).\n", r);
-  return r;
- }
-
  /* Enable IRQ */
  if (!rdev->irq.installed) {
   r = radeon_irq_kms_init(rdev);
@@ -2819,18 +2917,10 @@ static int r600_startup(struct radeon_device *rdev)
 
  ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP_RPTR_OFFSET,
-        R600_CP_RB_RPTR, R600_CP_RB_WPTR,
         RADEON_CP_PACKET2);
  if (r)
   return r;
 
- ring = &rdev->ring[R600_RING_TYPE_DMA_INDEX];
- r = radeon_ring_init(rdev, ring, ring->ring_size, R600_WB_DMA_RPTR_OFFSET,
-        DMA_RB_RPTR, DMA_RB_WPTR,
-        DMA_PACKET(DMA_PACKET_NOP, 0, 0, 0));
- if (r)
-  return r;
-
  r = r600_cp_load_microcode(rdev);
  if (r)
   return r;
@@ -2838,10 +2928,6 @@ static int r600_startup(struct radeon_device *rdev)
  if (r)
   return r;
 
- r = r600_dma_resume(rdev);
- if (r)
-  return r;
-
  r = radeon_ib_pool_init(rdev);
  if (r) {
   dev_err(rdev->dev, "IB initialization failed (%d).\n", r);
@@ -2882,6 +2968,9 @@ int r600_resume(struct radeon_device *rdev)
  /* post card */
  atom_asic_init(rdev->mode_info.atom_context);
 
+ if (rdev->pm.pm_method == PM_METHOD_DPM)
+  radeon_pm_resume(rdev);
+
  rdev->accel_working = true;
  r = r600_startup(rdev);
  if (r) {
@@ -2895,9 +2984,9 @@ int r600_resume(struct radeon_device *rdev)
 
 int r600_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r600_audio_fini(rdev);
  r600_cp_stop(rdev);
- r600_dma_stop(rdev);
  r600_irq_suspend(rdev);
  radeon_wb_disable(rdev);
  r600_pcie_gart_disable(rdev);
@@ -2971,12 +3060,12 @@ int r600_init(struct radeon_device *rdev)
   }
  }
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->ring[RADEON_RING_TYPE_GFX_INDEX].ring_obj = NULL;
  r600_ring_init(rdev, &rdev->ring[RADEON_RING_TYPE_GFX_INDEX], 1024 * 1024);
 
- rdev->ring[R600_RING_TYPE_DMA_INDEX].ring_obj = NULL;
- r600_ring_init(rdev, &rdev->ring[R600_RING_TYPE_DMA_INDEX], 64 * 1024);
-
  rdev->ih.ring_obj = NULL;
  r600_ih_ring_init(rdev, 64 * 1024);
 
@@ -2989,7 +3078,6 @@ int r600_init(struct radeon_device *rdev)
  if (r) {
   dev_err(rdev->dev, "disabling GPU acceleration\n");
   r600_cp_fini(rdev);
-  r600_dma_fini(rdev);
   r600_irq_fini(rdev);
   radeon_wb_fini(rdev);
   radeon_ib_pool_fini(rdev);
@@ -3003,9 +3091,9 @@ int r600_init(struct radeon_device *rdev)
 
 void r600_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r600_audio_fini(rdev);
  r600_cp_fini(rdev);
- r600_dma_fini(rdev);
  r600_irq_fini(rdev);
  radeon_wb_fini(rdev);
  radeon_ib_pool_fini(rdev);
diff --git a/drivers/gpu/drm/radeon/r600_audio.c b/drivers/gpu/drm/radeon/r600_audio.c
index 47fc2b8..bffac10 100644
--- a/drivers/gpu/drm/radeon/r600_audio.c
+++ b/drivers/gpu/drm/radeon/r600_audio.c
@@ -142,12 +142,15 @@ void r600_audio_update_hdmi(struct work_struct *work)
 }
 
 /* enable the audio stream */
-static void r600_audio_enable(struct radeon_device *rdev,
-         struct r600_audio_pin *pin,
-         bool enable)
+void r600_audio_enable(struct radeon_device *rdev,
+         struct r600_audio_pin *pin,
+         bool enable)
 {
  u32 value = 0;
 
+ if (!pin)
+  return;
+
  if (ASIC_IS_DCE4(rdev)) {
   if (enable) {
    value |= 0x81000000; /* Required to enable audio */
@@ -158,7 +161,6 @@ static void r600_audio_enable(struct radeon_device *rdev,
   WREG32_P(R600_AUDIO_ENABLE,
     enable ? 0x81000000 : 0x0, ~0x81000000);
  }
- DRM_INFO("%s audio %d support\n", enable ? "Enabling" : "Disabling", pin->id);
 }
 
 /*
@@ -178,8 +180,8 @@ int r600_audio_init(struct radeon_device *rdev)
  rdev->audio.pin[0].status_bits = 0;
  rdev->audio.pin[0].category_code = 0;
  rdev->audio.pin[0].id = 0;
-
- r600_audio_enable(rdev, &rdev->audio.pin[0], true);
+ /* disable audio.  it will be set up later */
+ r600_audio_enable(rdev, &rdev->audio.pin[0], false);
 
  return 0;
 }
diff --git a/drivers/gpu/drm/radeon/r600_cp.c b/drivers/gpu/drm/radeon/r600_cp.c
index d8eb48b..8c9b7e2 100644
--- a/drivers/gpu/drm/radeon/r600_cp.c
+++ b/drivers/gpu/drm/radeon/r600_cp.c
@@ -2515,7 +2515,7 @@ int r600_cp_dispatch_texture(struct drm_device *dev,
   buf = radeon_freelist_get(dev);
   if (!buf) {
    DRM_DEBUG("EAGAIN\n");
-   if (DRM_COPY_TO_USER(tex->image, image, sizeof(*image)))
+   if (copy_to_user(tex->image, image, sizeof(*image)))
     return -EFAULT;
    return -EAGAIN;
   }
@@ -2528,7 +2528,7 @@ int r600_cp_dispatch_texture(struct drm_device *dev,
   buffer =
       (u32 *) ((char *)dev->agp_buffer_map->handle + buf->offset);
 
-  if (DRM_COPY_FROM_USER(buffer, data, pass_size)) {
+  if (copy_from_user(buffer, data, pass_size)) {
    DRM_ERROR("EFAULT on pad, %d bytes\n", pass_size);
    return -EFAULT;
   }
diff --git a/drivers/gpu/drm/radeon/r600_cs.c b/drivers/gpu/drm/radeon/r600_cs.c
index 56130bf..2812c7d 100644
--- a/drivers/gpu/drm/radeon/r600_cs.c
+++ b/drivers/gpu/drm/radeon/r600_cs.c
@@ -1007,8 +1007,22 @@ static int r600_cs_check_reg(struct radeon_cs_parser *p, u32 reg, u32 idx)
  case R_008C64_SQ_VSTMP_RING_SIZE:
  case R_0288C8_SQ_GS_VERT_ITEMSIZE:
   /* get value to populate the IB don't remove */
-  tmp =radeon_get_ib_value(p, idx);
-  ib[idx] = 0;
+  /*tmp =radeon_get_ib_value(p, idx);
+    ib[idx] = 0;*/
+  break;
+ case SQ_ESGS_RING_BASE:
+ case SQ_GSVS_RING_BASE:
+ case SQ_ESTMP_RING_BASE:
+ case SQ_GSTMP_RING_BASE:
+ case SQ_PSTMP_RING_BASE:
+ case SQ_VSTMP_RING_BASE:
+  r = radeon_cs_packet_next_reloc(p, &reloc, 0);
+  if (r) {
+   dev_warn(p->dev, "bad SET_CONTEXT_REG "
+     "0x%04X\n", reg);
+   return -EINVAL;
+  }
+  ib[idx] += (u32)((reloc->lobj.gpu_offset >> 8) & 0xffffffff);
   break;
  case SQ_CONFIG:
   track->sq_config = radeon_get_ib_value(p, idx);
@@ -2389,7 +2403,7 @@ int r600_cs_legacy(struct drm_device *dev, void *data, struct drm_file *filp,
  ib_chunk = &parser.chunks[parser.chunk_ib_idx];
  parser.ib.length_dw = ib_chunk->length_dw;
  *l = parser.ib.length_dw;
- if (DRM_COPY_FROM_USER(ib, ib_chunk->user_ptr, ib_chunk->length_dw * 4)) {
+ if (copy_from_user(ib, ib_chunk->user_ptr, ib_chunk->length_dw * 4)) {
   r = -EFAULT;
   r600_cs_parser_fini(&parser, r);
   return r;
diff --git a/drivers/gpu/drm/radeon/r600_dma.c b/drivers/gpu/drm/radeon/r600_dma.c
index 7844d15..b2d4c91 100644
--- a/drivers/gpu/drm/radeon/r600_dma.c
+++ b/drivers/gpu/drm/radeon/r600_dma.c
@@ -51,7 +51,14 @@ u32 r600_gpu_check_soft_reset(struct radeon_device *rdev);
 uint32_t r600_dma_get_rptr(struct radeon_device *rdev,
       struct radeon_ring *ring)
 {
- return (radeon_ring_generic_get_rptr(rdev, ring) & 0x3fffc) >> 2;
+ u32 rptr;
+
+ if (rdev->wb.enabled)
+  rptr = rdev->wb.wb[ring->rptr_offs/4];
+ else
+  rptr = RREG32(DMA_RB_RPTR);
+
+ return (rptr & 0x3fffc) >> 2;
 }
 
 /**
@@ -65,7 +72,7 @@ uint32_t r600_dma_get_rptr(struct radeon_device *rdev,
 uint32_t r600_dma_get_wptr(struct radeon_device *rdev,
       struct radeon_ring *ring)
 {
- return (RREG32(ring->wptr_reg) & 0x3fffc) >> 2;
+ return (RREG32(DMA_RB_WPTR) & 0x3fffc) >> 2;
 }
 
 /**
@@ -79,7 +86,7 @@ uint32_t r600_dma_get_wptr(struct radeon_device *rdev,
 void r600_dma_set_wptr(struct radeon_device *rdev,
          struct radeon_ring *ring)
 {
- WREG32(ring->wptr_reg, (ring->wptr << 2) & 0x3fffc);
+ WREG32(DMA_RB_WPTR, (ring->wptr << 2) & 0x3fffc);
 }
 
 /**
@@ -93,7 +100,8 @@ void r600_dma_stop(struct radeon_device *rdev)
 {
  u32 rb_cntl = RREG32(DMA_RB_CNTL);
 
- radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
+ if (rdev->asic->copy.copy_ring_index == R600_RING_TYPE_DMA_INDEX)
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
 
  rb_cntl &= ~DMA_RB_ENABLE;
  WREG32(DMA_RB_CNTL, rb_cntl);
@@ -180,7 +188,8 @@ int r600_dma_resume(struct radeon_device *rdev)
   return r;
  }
 
- radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
+ if (rdev->asic->copy.copy_ring_index == R600_RING_TYPE_DMA_INDEX)
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
 
  return 0;
 }
diff --git a/drivers/gpu/drm/radeon/r600_dpm.c b/drivers/gpu/drm/radeon/r600_dpm.c
index 5513d8f..e4cc9b3 100644
--- a/drivers/gpu/drm/radeon/r600_dpm.c
+++ b/drivers/gpu/drm/radeon/r600_dpm.c
@@ -729,8 +729,8 @@ bool r600_is_uvd_state(u32 class, u32 class2)
  return false;
 }
 
-int r600_set_thermal_temperature_range(struct radeon_device *rdev,
-           int min_temp, int max_temp)
+static int r600_set_thermal_temperature_range(struct radeon_device *rdev,
+           int min_temp, int max_temp)
 {
  int low_temp = 0 * 1000;
  int high_temp = 255 * 1000;
@@ -777,6 +777,22 @@ bool r600_is_internal_thermal_sensor(enum radeon_int_thermal_type sensor)
  }
 }
 
+int r600_dpm_late_enable(struct radeon_device *rdev)
+{
+ int ret;
+
+ if (rdev->irq.installed &&
+     r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
+  ret = r600_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);
+  if (ret)
+   return ret;
+  rdev->irq.dpm_thermal = true;
+  radeon_irq_set(rdev);
+ }
+
+ return 0;
+}
+
 union power_info {
  struct _ATOM_POWERPLAY_INFO info;
  struct _ATOM_POWERPLAY_INFO_V2 info_2;
diff --git a/drivers/gpu/drm/radeon/r600_dpm.h b/drivers/gpu/drm/radeon/r600_dpm.h
index 1000bf9..07eab2b 100644
--- a/drivers/gpu/drm/radeon/r600_dpm.h
+++ b/drivers/gpu/drm/radeon/r600_dpm.h
@@ -213,8 +213,6 @@ void r600_wait_for_power_level(struct radeon_device *rdev,
 void r600_start_dpm(struct radeon_device *rdev);
 void r600_stop_dpm(struct radeon_device *rdev);
 
-int r600_set_thermal_temperature_range(struct radeon_device *rdev,
-           int min_temp, int max_temp);
 bool r600_is_internal_thermal_sensor(enum radeon_int_thermal_type sensor);
 
 int r600_parse_extended_power_table(struct radeon_device *rdev);
diff --git a/drivers/gpu/drm/radeon/r600_hdmi.c b/drivers/gpu/drm/radeon/r600_hdmi.c
index b7d3ecb..85a2bb2 100644
--- a/drivers/gpu/drm/radeon/r600_hdmi.c
+++ b/drivers/gpu/drm/radeon/r600_hdmi.c
@@ -250,7 +250,7 @@ static void r600_hdmi_audio_workaround(struct drm_encoder *encoder)
    value, ~HDMI0_AUDIO_TEST_EN);
 }
 
-void r600_audio_set_dto(struct drm_encoder *encoder, u32 clock)
+static void r600_audio_set_dto(struct drm_encoder *encoder, u32 clock)
 {
  struct drm_device *dev = encoder->dev;
  struct radeon_device *rdev = dev->dev_private;
@@ -329,9 +329,6 @@ static void dce3_2_afmt_write_speaker_allocation(struct drm_encoder *encoder)
  u8 *sadb;
  int sad_count;
 
- /* XXX: setting this register causes hangs on some asics */
- return;
-
  list_for_each_entry(connector, &encoder->dev->mode_config.connector_list, head) {
   if (connector->encoder == encoder) {
    radeon_connector = to_radeon_connector(connector);
@@ -460,6 +457,10 @@ void r600_hdmi_setmode(struct drm_encoder *encoder, struct drm_display_mode *mod
   return;
  offset = dig->afmt->offset;
 
+ /* disable audio prior to setting up hw */
+ dig->afmt->pin = r600_audio_get_pin(rdev);
+ r600_audio_enable(rdev, dig->afmt->pin, false);
+
  r600_audio_set_dto(encoder, mode->clock);
 
  WREG32(HDMI0_VBI_PACKET_CONTROL + offset,
@@ -531,6 +532,9 @@ void r600_hdmi_setmode(struct drm_encoder *encoder, struct drm_display_mode *mod
  WREG32(HDMI0_RAMP_CONTROL3 + offset, 0x00000001);
 
  r600_hdmi_audio_workaround(encoder);
+
+ /* enable audio after to setting up hw */
+ r600_audio_enable(rdev, dig->afmt->pin, true);
 }
 
 /*
@@ -651,11 +655,6 @@ void r600_hdmi_enable(struct drm_encoder *encoder, bool enable)
  if (!enable && !dig->afmt->enabled)
   return;
 
- if (enable)
-  dig->afmt->pin = r600_audio_get_pin(rdev);
- else
-  dig->afmt->pin = NULL;
-
  /* Older chipsets require setting HDMI and routing manually */
  if (!ASIC_IS_DCE3(rdev)) {
   if (enable)
diff --git a/drivers/gpu/drm/radeon/r600d.h b/drivers/gpu/drm/radeon/r600d.h
index ca92f48..37455f6 100644
--- a/drivers/gpu/drm/radeon/r600d.h
+++ b/drivers/gpu/drm/radeon/r600d.h
@@ -701,11 +701,18 @@
 #define RLC_UCODE_DATA                                    0x3f30
 
 #define SRBM_SOFT_RESET                                   0xe60
+#       define SOFT_RESET_BIF                             (1 << 1)
 #       define SOFT_RESET_DMA                             (1 << 12)
 #       define SOFT_RESET_RLC                             (1 << 13)
 #       define SOFT_RESET_UVD                             (1 << 18)
 #       define RV770_SOFT_RESET_DMA                       (1 << 20)
 
+#define BIF_SCRATCH0                                      0x5438
+
+#define BUS_CNTL                                          0x5420
+#       define BIOS_ROM_DIS                               (1 << 1)
+#       define VGA_COHE_SPEC_TIMER_DIS                    (1 << 9)
+
 #define CP_INT_CNTL                                       0xc124
 #       define CNTX_BUSY_INT_ENABLE                       (1 << 19)
 #       define CNTX_EMPTY_INT_ENABLE                      (1 << 20)
diff --git a/drivers/gpu/drm/radeon/radeon.h b/drivers/gpu/drm/radeon/radeon.h
index d307cc2..e887d02 100644
--- a/drivers/gpu/drm/radeon/radeon.h
+++ b/drivers/gpu/drm/radeon/radeon.h
@@ -99,6 +99,7 @@ extern int radeon_fastfb;
 extern int radeon_dpm;
 extern int radeon_aspm;
 extern int radeon_runtime_pm;
+extern int radeon_hard_reset;
 
 /*
  * Copy from radeon_drv.h so we don't have to include both and have conflicting
@@ -142,6 +143,9 @@ extern int radeon_runtime_pm;
 #define RADEON_VA_RESERVED_SIZE   (8 << 20)
 #define RADEON_IB_VM_MAX_SIZE   (64 << 10)
 
+/* hard reset data */
+#define RADEON_ASIC_RESET_DATA                  0x39d5e86b
+
 /* reset flags */
 #define RADEON_RESET_GFX   (1 << 0)
 #define RADEON_RESET_COMPUTE   (1 << 1)
@@ -255,6 +259,7 @@ struct radeon_clock {
  * Power management
  */
 int radeon_pm_init(struct radeon_device *rdev);
+int radeon_pm_late_init(struct radeon_device *rdev);
 void radeon_pm_fini(struct radeon_device *rdev);
 void radeon_pm_compute_clocks(struct radeon_device *rdev);
 void radeon_pm_suspend(struct radeon_device *rdev);
@@ -416,6 +421,11 @@ struct radeon_mman {
  struct ttm_bo_device  bdev;
  bool    mem_global_referenced;
  bool    initialized;
+
+#if defined(CONFIG_DEBUG_FS)
+ struct dentry   *vram;
+ struct dentry   *gtt;
+#endif
 };
 
 /* bo virtual address in a specific vm */
@@ -781,13 +791,11 @@ struct radeon_ring {
  volatile uint32_t *ring;
  unsigned  rptr;
  unsigned  rptr_offs;
- unsigned  rptr_reg;
  unsigned  rptr_save_reg;
  u64   next_rptr_gpu_addr;
  volatile u32  *next_rptr_cpu_addr;
  unsigned  wptr;
  unsigned  wptr_old;
- unsigned  wptr_reg;
  unsigned  ring_size;
  unsigned  ring_free_dw;
  int   count_dw;
@@ -861,6 +869,8 @@ struct radeon_vm {
  struct radeon_fence  *fence;
  /* last flush or NULL if we still need to flush */
  struct radeon_fence  *last_flush;
+ /* last use of vmid */
+ struct radeon_fence  *last_id_use;
 };
 
 struct radeon_vm_manager {
@@ -951,7 +961,7 @@ unsigned radeon_ring_backup(struct radeon_device *rdev, struct radeon_ring *ring
 int radeon_ring_restore(struct radeon_device *rdev, struct radeon_ring *ring,
    unsigned size, uint32_t *data);
 int radeon_ring_init(struct radeon_device *rdev, struct radeon_ring *cp, unsigned ring_size,
-       unsigned rptr_offs, unsigned rptr_reg, unsigned wptr_reg, u32 nop);
+       unsigned rptr_offs, u32 nop);
 void radeon_ring_fini(struct radeon_device *rdev, struct radeon_ring *cp);
 
 
@@ -1777,6 +1787,7 @@ struct radeon_asic {
   int (*init)(struct radeon_device *rdev);
   void (*setup_asic)(struct radeon_device *rdev);
   int (*enable)(struct radeon_device *rdev);
+  int (*late_enable)(struct radeon_device *rdev);
   void (*disable)(struct radeon_device *rdev);
   int (*pre_set_power_state)(struct radeon_device *rdev);
   int (*set_power_state)(struct radeon_device *rdev);
@@ -2652,6 +2663,7 @@ void radeon_ring_write(struct radeon_ring *ring, uint32_t v);
 #define radeon_dpm_init(rdev) rdev->asic->dpm.init((rdev))
 #define radeon_dpm_setup_asic(rdev) rdev->asic->dpm.setup_asic((rdev))
 #define radeon_dpm_enable(rdev) rdev->asic->dpm.enable((rdev))
+#define radeon_dpm_late_enable(rdev) rdev->asic->dpm.late_enable((rdev))
 #define radeon_dpm_disable(rdev) rdev->asic->dpm.disable((rdev))
 #define radeon_dpm_pre_set_power_state(rdev) rdev->asic->dpm.pre_set_power_state((rdev))
 #define radeon_dpm_set_power_state(rdev) rdev->asic->dpm.set_power_state((rdev))
@@ -2670,6 +2682,7 @@ void radeon_ring_write(struct radeon_ring *ring, uint32_t v);
 /* Common functions */
 /* AGP */
 extern int radeon_gpu_reset(struct radeon_device *rdev);
+extern void radeon_pci_config_reset(struct radeon_device *rdev);
 extern void r600_set_bios_scratch_engine_hung(struct radeon_device *rdev, bool hung);
 extern void radeon_agp_disable(struct radeon_device *rdev);
 extern int radeon_modeset_init(struct radeon_device *rdev);
@@ -2734,6 +2747,12 @@ int radeon_vm_bo_rmv(struct radeon_device *rdev,
 void r600_audio_update_hdmi(struct work_struct *work);
 struct r600_audio_pin *r600_audio_get_pin(struct radeon_device *rdev);
 struct r600_audio_pin *dce6_audio_get_pin(struct radeon_device *rdev);
+void r600_audio_enable(struct radeon_device *rdev,
+         struct r600_audio_pin *pin,
+         bool enable);
+void dce6_audio_enable(struct radeon_device *rdev,
+         struct r600_audio_pin *pin,
+         bool enable);
 
 /*
  * R600 vram scratch functions
diff --git a/drivers/gpu/drm/radeon/radeon_acpi.c b/drivers/gpu/drm/radeon/radeon_acpi.c
index 98a9074..77e9d07 100644
--- a/drivers/gpu/drm/radeon/radeon_acpi.c
+++ b/drivers/gpu/drm/radeon/radeon_acpi.c
@@ -25,18 +25,14 @@
 #include <linux/acpi.h>
 #include <linux/slab.h>
 #include <linux/power_supply.h>
-#include <acpi/acpi_drivers.h>
-#include <acpi/acpi_bus.h>
+#include <linux/vga_switcheroo.h>
 #include <acpi/video.h>
-
 #include <drm/drmP.h>
 #include <drm/drm_crtc_helper.h>
 #include "radeon.h"
 #include "radeon_acpi.h"
 #include "atom.h"
 
-#include <linux/vga_switcheroo.h>
-
 #define ACPI_AC_CLASS           "ac_adapter"
 
 extern void radeon_pm_acpi_event_handler(struct radeon_device *rdev);
diff --git a/drivers/gpu/drm/radeon/radeon_asic.c b/drivers/gpu/drm/radeon/radeon_asic.c
index c0425bb..dda02bf 100644
--- a/drivers/gpu/drm/radeon/radeon_asic.c
+++ b/drivers/gpu/drm/radeon/radeon_asic.c
@@ -182,9 +182,9 @@ static struct radeon_asic_ring r100_gfx_ring = {
  .ring_test = &r100_ring_test,
  .ib_test = &r100_ib_test,
  .is_lockup = &r100_gpu_is_lockup,
- .get_rptr = &radeon_ring_generic_get_rptr,
- .get_wptr = &radeon_ring_generic_get_wptr,
- .set_wptr = &radeon_ring_generic_set_wptr,
+ .get_rptr = &r100_gfx_get_rptr,
+ .get_wptr = &r100_gfx_get_wptr,
+ .set_wptr = &r100_gfx_set_wptr,
 };
 
 static struct radeon_asic r100_asic = {
@@ -330,9 +330,9 @@ static struct radeon_asic_ring r300_gfx_ring = {
  .ring_test = &r100_ring_test,
  .ib_test = &r100_ib_test,
  .is_lockup = &r100_gpu_is_lockup,
- .get_rptr = &radeon_ring_generic_get_rptr,
- .get_wptr = &radeon_ring_generic_get_wptr,
- .set_wptr = &radeon_ring_generic_set_wptr,
+ .get_rptr = &r100_gfx_get_rptr,
+ .get_wptr = &r100_gfx_get_wptr,
+ .set_wptr = &r100_gfx_set_wptr,
 };
 
 static struct radeon_asic r300_asic = {
@@ -883,9 +883,9 @@ static struct radeon_asic_ring r600_gfx_ring = {
  .ring_test = &r600_ring_test,
  .ib_test = &r600_ib_test,
  .is_lockup = &r600_gfx_is_lockup,
- .get_rptr = &radeon_ring_generic_get_rptr,
- .get_wptr = &radeon_ring_generic_get_wptr,
- .set_wptr = &radeon_ring_generic_set_wptr,
+ .get_rptr = &r600_gfx_get_rptr,
+ .get_wptr = &r600_gfx_get_wptr,
+ .set_wptr = &r600_gfx_set_wptr,
 };
 
 static struct radeon_asic_ring r600_dma_ring = {
@@ -1045,6 +1045,7 @@ static struct radeon_asic rv6xx_asic = {
   .init = &rv6xx_dpm_init,
   .setup_asic = &rv6xx_setup_asic,
   .enable = &rv6xx_dpm_enable,
+  .late_enable = &r600_dpm_late_enable,
   .disable = &rv6xx_dpm_disable,
   .pre_set_power_state = &r600_dpm_pre_set_power_state,
   .set_power_state = &rv6xx_dpm_set_power_state,
@@ -1135,6 +1136,7 @@ static struct radeon_asic rs780_asic = {
   .init = &rs780_dpm_init,
   .setup_asic = &rs780_dpm_setup_asic,
   .enable = &rs780_dpm_enable,
+  .late_enable = &r600_dpm_late_enable,
   .disable = &rs780_dpm_disable,
   .pre_set_power_state = &r600_dpm_pre_set_power_state,
   .set_power_state = &rs780_dpm_set_power_state,
@@ -1239,6 +1241,7 @@ static struct radeon_asic rv770_asic = {
   .init = &rv770_dpm_init,
   .setup_asic = &rv770_dpm_setup_asic,
   .enable = &rv770_dpm_enable,
+  .late_enable = &rv770_dpm_late_enable,
   .disable = &rv770_dpm_disable,
   .pre_set_power_state = &r600_dpm_pre_set_power_state,
   .set_power_state = &rv770_dpm_set_power_state,
@@ -1267,9 +1270,9 @@ static struct radeon_asic_ring evergreen_gfx_ring = {
  .ring_test = &r600_ring_test,
  .ib_test = &r600_ib_test,
  .is_lockup = &evergreen_gfx_is_lockup,
- .get_rptr = &radeon_ring_generic_get_rptr,
- .get_wptr = &radeon_ring_generic_get_wptr,
- .set_wptr = &radeon_ring_generic_set_wptr,
+ .get_rptr = &r600_gfx_get_rptr,
+ .get_wptr = &r600_gfx_get_wptr,
+ .set_wptr = &r600_gfx_set_wptr,
 };
 
 static struct radeon_asic_ring evergreen_dma_ring = {
@@ -1357,6 +1360,7 @@ static struct radeon_asic evergreen_asic = {
   .init = &cypress_dpm_init,
   .setup_asic = &cypress_dpm_setup_asic,
   .enable = &cypress_dpm_enable,
+  .late_enable = &rv770_dpm_late_enable,
   .disable = &cypress_dpm_disable,
   .pre_set_power_state = &r600_dpm_pre_set_power_state,
   .set_power_state = &cypress_dpm_set_power_state,
@@ -1449,6 +1453,7 @@ static struct radeon_asic sumo_asic = {
   .init = &sumo_dpm_init,
   .setup_asic = &sumo_dpm_setup_asic,
   .enable = &sumo_dpm_enable,
+  .late_enable = &sumo_dpm_late_enable,
   .disable = &sumo_dpm_disable,
   .pre_set_power_state = &sumo_dpm_pre_set_power_state,
   .set_power_state = &sumo_dpm_set_power_state,
@@ -1540,6 +1545,7 @@ static struct radeon_asic btc_asic = {
   .init = &btc_dpm_init,
   .setup_asic = &btc_dpm_setup_asic,
   .enable = &btc_dpm_enable,
+  .late_enable = &rv770_dpm_late_enable,
   .disable = &btc_dpm_disable,
   .pre_set_power_state = &btc_dpm_pre_set_power_state,
   .set_power_state = &btc_dpm_set_power_state,
@@ -1549,7 +1555,7 @@ static struct radeon_asic btc_asic = {
   .get_sclk = &btc_dpm_get_sclk,
   .get_mclk = &btc_dpm_get_mclk,
   .print_power_state = &rv770_dpm_print_power_state,
-  .debugfs_print_current_performance_level = &rv770_dpm_debugfs_print_current_performance_level,
+  .debugfs_print_current_performance_level = &btc_dpm_debugfs_print_current_performance_level,
   .force_performance_level = &rv770_dpm_force_performance_level,
   .vblank_too_short = &btc_dpm_vblank_too_short,
  },
@@ -1570,9 +1576,9 @@ static struct radeon_asic_ring cayman_gfx_ring = {
  .ib_test = &r600_ib_test,
  .is_lockup = &cayman_gfx_is_lockup,
  .vm_flush = &cayman_vm_flush,
- .get_rptr = &radeon_ring_generic_get_rptr,
- .get_wptr = &radeon_ring_generic_get_wptr,
- .set_wptr = &radeon_ring_generic_set_wptr,
+ .get_rptr = &cayman_gfx_get_rptr,
+ .get_wptr = &cayman_gfx_get_wptr,
+ .set_wptr = &cayman_gfx_set_wptr,
 };
 
 static struct radeon_asic_ring cayman_dma_ring = {
@@ -1585,9 +1591,9 @@ static struct radeon_asic_ring cayman_dma_ring = {
  .ib_test = &r600_dma_ib_test,
  .is_lockup = &cayman_dma_is_lockup,
  .vm_flush = &cayman_dma_vm_flush,
- .get_rptr = &r600_dma_get_rptr,
- .get_wptr = &r600_dma_get_wptr,
- .set_wptr = &r600_dma_set_wptr
+ .get_rptr = &cayman_dma_get_rptr,
+ .get_wptr = &cayman_dma_get_wptr,
+ .set_wptr = &cayman_dma_set_wptr
 };
 
 static struct radeon_asic_ring cayman_uvd_ring = {
@@ -1683,6 +1689,7 @@ static struct radeon_asic cayman_asic = {
   .init = &ni_dpm_init,
   .setup_asic = &ni_dpm_setup_asic,
   .enable = &ni_dpm_enable,
+  .late_enable = &rv770_dpm_late_enable,
   .disable = &ni_dpm_disable,
   .pre_set_power_state = &ni_dpm_pre_set_power_state,
   .set_power_state = &ni_dpm_set_power_state,
@@ -1783,6 +1790,7 @@ static struct radeon_asic trinity_asic = {
   .init = &trinity_dpm_init,
   .setup_asic = &trinity_dpm_setup_asic,
   .enable = &trinity_dpm_enable,
+  .late_enable = &trinity_dpm_late_enable,
   .disable = &trinity_dpm_disable,
   .pre_set_power_state = &trinity_dpm_pre_set_power_state,
   .set_power_state = &trinity_dpm_set_power_state,
@@ -1813,9 +1821,9 @@ static struct radeon_asic_ring si_gfx_ring = {
  .ib_test = &r600_ib_test,
  .is_lockup = &si_gfx_is_lockup,
  .vm_flush = &si_vm_flush,
- .get_rptr = &radeon_ring_generic_get_rptr,
- .get_wptr = &radeon_ring_generic_get_wptr,
- .set_wptr = &radeon_ring_generic_set_wptr,
+ .get_rptr = &cayman_gfx_get_rptr,
+ .get_wptr = &cayman_gfx_get_wptr,
+ .set_wptr = &cayman_gfx_set_wptr,
 };
 
 static struct radeon_asic_ring si_dma_ring = {
@@ -1828,9 +1836,9 @@ static struct radeon_asic_ring si_dma_ring = {
  .ib_test = &r600_dma_ib_test,
  .is_lockup = &si_dma_is_lockup,
  .vm_flush = &si_dma_vm_flush,
- .get_rptr = &r600_dma_get_rptr,
- .get_wptr = &r600_dma_get_wptr,
- .set_wptr = &r600_dma_set_wptr,
+ .get_rptr = &cayman_dma_get_rptr,
+ .get_wptr = &cayman_dma_get_wptr,
+ .set_wptr = &cayman_dma_set_wptr,
 };
 
 static struct radeon_asic si_asic = {
@@ -1913,6 +1921,7 @@ static struct radeon_asic si_asic = {
   .init = &si_dpm_init,
   .setup_asic = &si_dpm_setup_asic,
   .enable = &si_dpm_enable,
+  .late_enable = &si_dpm_late_enable,
   .disable = &si_dpm_disable,
   .pre_set_power_state = &si_dpm_pre_set_power_state,
   .set_power_state = &si_dpm_set_power_state,
@@ -1943,9 +1952,9 @@ static struct radeon_asic_ring ci_gfx_ring = {
  .ib_test = &cik_ib_test,
  .is_lockup = &cik_gfx_is_lockup,
  .vm_flush = &cik_vm_flush,
- .get_rptr = &radeon_ring_generic_get_rptr,
- .get_wptr = &radeon_ring_generic_get_wptr,
- .set_wptr = &radeon_ring_generic_set_wptr,
+ .get_rptr = &cik_gfx_get_rptr,
+ .get_wptr = &cik_gfx_get_wptr,
+ .set_wptr = &cik_gfx_set_wptr,
 };
 
 static struct radeon_asic_ring ci_cp_ring = {
@@ -1958,9 +1967,9 @@ static struct radeon_asic_ring ci_cp_ring = {
  .ib_test = &cik_ib_test,
  .is_lockup = &cik_gfx_is_lockup,
  .vm_flush = &cik_vm_flush,
- .get_rptr = &cik_compute_ring_get_rptr,
- .get_wptr = &cik_compute_ring_get_wptr,
- .set_wptr = &cik_compute_ring_set_wptr,
+ .get_rptr = &cik_compute_get_rptr,
+ .get_wptr = &cik_compute_get_wptr,
+ .set_wptr = &cik_compute_set_wptr,
 };
 
 static struct radeon_asic_ring ci_dma_ring = {
@@ -1973,9 +1982,9 @@ static struct radeon_asic_ring ci_dma_ring = {
  .ib_test = &cik_sdma_ib_test,
  .is_lockup = &cik_sdma_is_lockup,
  .vm_flush = &cik_dma_vm_flush,
- .get_rptr = &r600_dma_get_rptr,
- .get_wptr = &r600_dma_get_wptr,
- .set_wptr = &r600_dma_set_wptr,
+ .get_rptr = &cik_sdma_get_rptr,
+ .get_wptr = &cik_sdma_get_wptr,
+ .set_wptr = &cik_sdma_set_wptr,
 };
 
 static struct radeon_asic ci_asic = {
@@ -2058,6 +2067,7 @@ static struct radeon_asic ci_asic = {
   .init = &ci_dpm_init,
   .setup_asic = &ci_dpm_setup_asic,
   .enable = &ci_dpm_enable,
+  .late_enable = &ci_dpm_late_enable,
   .disable = &ci_dpm_disable,
   .pre_set_power_state = &ci_dpm_pre_set_power_state,
   .set_power_state = &ci_dpm_set_power_state,
@@ -2159,6 +2169,7 @@ static struct radeon_asic kv_asic = {
   .init = &kv_dpm_init,
   .setup_asic = &kv_dpm_setup_asic,
   .enable = &kv_dpm_enable,
+  .late_enable = &kv_dpm_late_enable,
   .disable = &kv_dpm_disable,
   .pre_set_power_state = &kv_dpm_pre_set_power_state,
   .set_power_state = &kv_dpm_set_power_state,
@@ -2449,7 +2460,7 @@ int radeon_asic_init(struct radeon_device *rdev)
    rdev->cg_flags =
     RADEON_CG_SUPPORT_GFX_MGCG |
     RADEON_CG_SUPPORT_GFX_MGLS |
-    /*RADEON_CG_SUPPORT_GFX_CGCG |*/
+    RADEON_CG_SUPPORT_GFX_CGCG |
     RADEON_CG_SUPPORT_GFX_CGLS |
     RADEON_CG_SUPPORT_GFX_CGTS |
     RADEON_CG_SUPPORT_GFX_CGTS_LS |
@@ -2468,7 +2479,7 @@ int radeon_asic_init(struct radeon_device *rdev)
    rdev->cg_flags =
     RADEON_CG_SUPPORT_GFX_MGCG |
     RADEON_CG_SUPPORT_GFX_MGLS |
-    /*RADEON_CG_SUPPORT_GFX_CGCG |*/
+    RADEON_CG_SUPPORT_GFX_CGCG |
     RADEON_CG_SUPPORT_GFX_CGLS |
     RADEON_CG_SUPPORT_GFX_CGTS |
     RADEON_CG_SUPPORT_GFX_CP_LS |
@@ -2493,7 +2504,7 @@ int radeon_asic_init(struct radeon_device *rdev)
    rdev->cg_flags =
     RADEON_CG_SUPPORT_GFX_MGCG |
     RADEON_CG_SUPPORT_GFX_MGLS |
-    /*RADEON_CG_SUPPORT_GFX_CGCG |*/
+    RADEON_CG_SUPPORT_GFX_CGCG |
     RADEON_CG_SUPPORT_GFX_CGLS |
     RADEON_CG_SUPPORT_GFX_CGTS |
     RADEON_CG_SUPPORT_GFX_CGTS_LS |
@@ -2521,7 +2532,7 @@ int radeon_asic_init(struct radeon_device *rdev)
    rdev->cg_flags =
     RADEON_CG_SUPPORT_GFX_MGCG |
     RADEON_CG_SUPPORT_GFX_MGLS |
-    /*RADEON_CG_SUPPORT_GFX_CGCG |*/
+    RADEON_CG_SUPPORT_GFX_CGCG |
     RADEON_CG_SUPPORT_GFX_CGLS |
     RADEON_CG_SUPPORT_GFX_CGTS |
     RADEON_CG_SUPPORT_GFX_CGTS_LS |
diff --git a/drivers/gpu/drm/radeon/radeon_asic.h b/drivers/gpu/drm/radeon/radeon_asic.h
index c9fd97b..ae637cf 100644
--- a/drivers/gpu/drm/radeon/radeon_asic.h
+++ b/drivers/gpu/drm/radeon/radeon_asic.h
@@ -47,13 +47,6 @@ u8 atombios_get_backlight_level(struct radeon_encoder *radeon_encoder);
 void radeon_legacy_set_backlight_level(struct radeon_encoder *radeon_encoder, u8 level);
 u8 radeon_legacy_get_backlight_level(struct radeon_encoder *radeon_encoder);
 
-u32 radeon_ring_generic_get_rptr(struct radeon_device *rdev,
-     struct radeon_ring *ring);
-u32 radeon_ring_generic_get_wptr(struct radeon_device *rdev,
-     struct radeon_ring *ring);
-void radeon_ring_generic_set_wptr(struct radeon_device *rdev,
-      struct radeon_ring *ring);
-
 /*
  * r100,rv100,rs100,rv200,rs200
  */
@@ -148,6 +141,13 @@ extern void r100_post_page_flip(struct radeon_device *rdev, int crtc);
 extern void r100_wait_for_vblank(struct radeon_device *rdev, int crtc);
 extern int r100_mc_wait_for_idle(struct radeon_device *rdev);
 
+u32 r100_gfx_get_rptr(struct radeon_device *rdev,
+        struct radeon_ring *ring);
+u32 r100_gfx_get_wptr(struct radeon_device *rdev,
+        struct radeon_ring *ring);
+void r100_gfx_set_wptr(struct radeon_device *rdev,
+         struct radeon_ring *ring);
+
 /*
  * r200,rv250,rs300,rv280
  */
@@ -368,6 +368,12 @@ int r600_mc_wait_for_idle(struct radeon_device *rdev);
 int r600_pcie_gart_init(struct radeon_device *rdev);
 void r600_scratch_init(struct radeon_device *rdev);
 int r600_init_microcode(struct radeon_device *rdev);
+u32 r600_gfx_get_rptr(struct radeon_device *rdev,
+        struct radeon_ring *ring);
+u32 r600_gfx_get_wptr(struct radeon_device *rdev,
+        struct radeon_ring *ring);
+void r600_gfx_set_wptr(struct radeon_device *rdev,
+         struct radeon_ring *ring);
 /* r600 irq */
 int r600_irq_process(struct radeon_device *rdev);
 int r600_irq_init(struct radeon_device *rdev);
@@ -392,6 +398,7 @@ int rv6xx_get_temp(struct radeon_device *rdev);
 int r600_set_uvd_clocks(struct radeon_device *rdev, u32 vclk, u32 dclk);
 int r600_dpm_pre_set_power_state(struct radeon_device *rdev);
 void r600_dpm_post_set_power_state(struct radeon_device *rdev);
+int r600_dpm_late_enable(struct radeon_device *rdev);
 /* r600 dma */
 uint32_t r600_dma_get_rptr(struct radeon_device *rdev,
       struct radeon_ring *ring);
@@ -454,6 +461,7 @@ int rv770_get_temp(struct radeon_device *rdev);
 /* rv7xx pm */
 int rv770_dpm_init(struct radeon_device *rdev);
 int rv770_dpm_enable(struct radeon_device *rdev);
+int rv770_dpm_late_enable(struct radeon_device *rdev);
 void rv770_dpm_disable(struct radeon_device *rdev);
 int rv770_dpm_set_power_state(struct radeon_device *rdev);
 void rv770_dpm_setup_asic(struct radeon_device *rdev);
@@ -543,8 +551,11 @@ void btc_dpm_fini(struct radeon_device *rdev);
 u32 btc_dpm_get_sclk(struct radeon_device *rdev, bool low);
 u32 btc_dpm_get_mclk(struct radeon_device *rdev, bool low);
 bool btc_dpm_vblank_too_short(struct radeon_device *rdev);
+void btc_dpm_debugfs_print_current_performance_level(struct radeon_device *rdev,
+           struct seq_file *m);
 int sumo_dpm_init(struct radeon_device *rdev);
 int sumo_dpm_enable(struct radeon_device *rdev);
+int sumo_dpm_late_enable(struct radeon_device *rdev);
 void sumo_dpm_disable(struct radeon_device *rdev);
 int sumo_dpm_pre_set_power_state(struct radeon_device *rdev);
 int sumo_dpm_set_power_state(struct radeon_device *rdev);
@@ -591,6 +602,19 @@ void cayman_dma_vm_set_page(struct radeon_device *rdev,
 
 void cayman_dma_vm_flush(struct radeon_device *rdev, int ridx, struct radeon_vm *vm);
 
+u32 cayman_gfx_get_rptr(struct radeon_device *rdev,
+   struct radeon_ring *ring);
+u32 cayman_gfx_get_wptr(struct radeon_device *rdev,
+   struct radeon_ring *ring);
+void cayman_gfx_set_wptr(struct radeon_device *rdev,
+    struct radeon_ring *ring);
+uint32_t cayman_dma_get_rptr(struct radeon_device *rdev,
+        struct radeon_ring *ring);
+uint32_t cayman_dma_get_wptr(struct radeon_device *rdev,
+        struct radeon_ring *ring);
+void cayman_dma_set_wptr(struct radeon_device *rdev,
+    struct radeon_ring *ring);
+
 int ni_dpm_init(struct radeon_device *rdev);
 void ni_dpm_setup_asic(struct radeon_device *rdev);
 int ni_dpm_enable(struct radeon_device *rdev);
@@ -610,6 +634,7 @@ int ni_dpm_force_performance_level(struct radeon_device *rdev,
 bool ni_dpm_vblank_too_short(struct radeon_device *rdev);
 int trinity_dpm_init(struct radeon_device *rdev);
 int trinity_dpm_enable(struct radeon_device *rdev);
+int trinity_dpm_late_enable(struct radeon_device *rdev);
 void trinity_dpm_disable(struct radeon_device *rdev);
 int trinity_dpm_pre_set_power_state(struct radeon_device *rdev);
 int trinity_dpm_set_power_state(struct radeon_device *rdev);
@@ -669,6 +694,7 @@ int si_get_temp(struct radeon_device *rdev);
 int si_dpm_init(struct radeon_device *rdev);
 void si_dpm_setup_asic(struct radeon_device *rdev);
 int si_dpm_enable(struct radeon_device *rdev);
+int si_dpm_late_enable(struct radeon_device *rdev);
 void si_dpm_disable(struct radeon_device *rdev);
 int si_dpm_pre_set_power_state(struct radeon_device *rdev);
 int si_dpm_set_power_state(struct radeon_device *rdev);
@@ -739,17 +765,30 @@ void cik_sdma_vm_set_page(struct radeon_device *rdev,
      uint32_t incr, uint32_t flags);
 void cik_dma_vm_flush(struct radeon_device *rdev, int ridx, struct radeon_vm *vm);
 int cik_ib_parse(struct radeon_device *rdev, struct radeon_ib *ib);
-u32 cik_compute_ring_get_rptr(struct radeon_device *rdev,
-         struct radeon_ring *ring);
-u32 cik_compute_ring_get_wptr(struct radeon_device *rdev,
-         struct radeon_ring *ring);
-void cik_compute_ring_set_wptr(struct radeon_device *rdev,
-          struct radeon_ring *ring);
+u32 cik_gfx_get_rptr(struct radeon_device *rdev,
+       struct radeon_ring *ring);
+u32 cik_gfx_get_wptr(struct radeon_device *rdev,
+       struct radeon_ring *ring);
+void cik_gfx_set_wptr(struct radeon_device *rdev,
+        struct radeon_ring *ring);
+u32 cik_compute_get_rptr(struct radeon_device *rdev,
+    struct radeon_ring *ring);
+u32 cik_compute_get_wptr(struct radeon_device *rdev,
+    struct radeon_ring *ring);
+void cik_compute_set_wptr(struct radeon_device *rdev,
+     struct radeon_ring *ring);
+u32 cik_sdma_get_rptr(struct radeon_device *rdev,
+        struct radeon_ring *ring);
+u32 cik_sdma_get_wptr(struct radeon_device *rdev,
+        struct radeon_ring *ring);
+void cik_sdma_set_wptr(struct radeon_device *rdev,
+         struct radeon_ring *ring);
 int ci_get_temp(struct radeon_device *rdev);
 int kv_get_temp(struct radeon_device *rdev);
 
 int ci_dpm_init(struct radeon_device *rdev);
 int ci_dpm_enable(struct radeon_device *rdev);
+int ci_dpm_late_enable(struct radeon_device *rdev);
 void ci_dpm_disable(struct radeon_device *rdev);
 int ci_dpm_pre_set_power_state(struct radeon_device *rdev);
 int ci_dpm_set_power_state(struct radeon_device *rdev);
@@ -770,6 +809,7 @@ void ci_dpm_powergate_uvd(struct radeon_device *rdev, bool gate);
 
 int kv_dpm_init(struct radeon_device *rdev);
 int kv_dpm_enable(struct radeon_device *rdev);
+int kv_dpm_late_enable(struct radeon_device *rdev);
 void kv_dpm_disable(struct radeon_device *rdev);
 int kv_dpm_pre_set_power_state(struct radeon_device *rdev);
 int kv_dpm_set_power_state(struct radeon_device *rdev);
diff --git a/drivers/gpu/drm/radeon/radeon_atombios.c b/drivers/gpu/drm/radeon/radeon_atombios.c
index dfa6412..3084481 100644
--- a/drivers/gpu/drm/radeon/radeon_atombios.c
+++ b/drivers/gpu/drm/radeon/radeon_atombios.c
@@ -30,27 +30,10 @@
 #include "atom.h"
 #include "atom-bits.h"
 
-/* from radeon_encoder.c */
-extern uint32_t
-radeon_get_encoder_enum(struct drm_device *dev, uint32_t supported_device,
-   uint8_t dac);
-extern void radeon_link_encoder_connector(struct drm_device *dev);
 extern void
 radeon_add_atom_encoder(struct drm_device *dev, uint32_t encoder_enum,
    uint32_t supported_device, u16 caps);
 
-/* from radeon_connector.c */
-extern void
-radeon_add_atom_connector(struct drm_device *dev,
-     uint32_t connector_id,
-     uint32_t supported_device,
-     int connector_type,
-     struct radeon_i2c_bus_rec *i2c_bus,
-     uint32_t igp_lane_info,
-     uint16_t connector_object_id,
-     struct radeon_hpd *hpd,
-     struct radeon_router *router);
-
 /* from radeon_legacy_encoder.c */
 extern void
 radeon_add_legacy_encoder(struct drm_device *dev, uint32_t encoder_enum,
@@ -1528,6 +1511,7 @@ bool radeon_atombios_get_asic_ss_info(struct radeon_device *rdev,
       le16_to_cpu(ss_assign->v1.usSpreadSpectrumPercentage);
      ss->type = ss_assign->v1.ucSpreadSpectrumMode;
      ss->rate = le16_to_cpu(ss_assign->v1.usSpreadRateInKhz);
+     ss->percentage_divider = 100;
      return true;
     }
     ss_assign = (union asic_ss_assignment *)
@@ -1545,6 +1529,7 @@ bool radeon_atombios_get_asic_ss_info(struct radeon_device *rdev,
       le16_to_cpu(ss_assign->v2.usSpreadSpectrumPercentage);
      ss->type = ss_assign->v2.ucSpreadSpectrumMode;
      ss->rate = le16_to_cpu(ss_assign->v2.usSpreadRateIn10Hz);
+     ss->percentage_divider = 100;
      if ((crev == 2) &&
          ((id == ASIC_INTERNAL_ENGINE_SS) ||
           (id == ASIC_INTERNAL_MEMORY_SS)))
@@ -1566,6 +1551,11 @@ bool radeon_atombios_get_asic_ss_info(struct radeon_device *rdev,
       le16_to_cpu(ss_assign->v3.usSpreadSpectrumPercentage);
      ss->type = ss_assign->v3.ucSpreadSpectrumMode;
      ss->rate = le16_to_cpu(ss_assign->v3.usSpreadRateIn10Hz);
+     if (ss_assign->v3.ucSpreadSpectrumMode &
+         SS_MODE_V3_PERCENTAGE_DIV_BY_1000_MASK)
+      ss->percentage_divider = 1000;
+     else
+      ss->percentage_divider = 100;
      if ((id == ASIC_INTERNAL_ENGINE_SS) ||
          (id == ASIC_INTERNAL_MEMORY_SS))
       ss->rate /= 100;
@@ -1809,7 +1799,8 @@ bool radeon_atom_get_tv_timings(struct radeon_device *rdev, int index,
   if (misc & ATOM_DOUBLE_CLOCK_MODE)
    mode->flags |= DRM_MODE_FLAG_DBLSCAN;
 
-  mode->clock = le16_to_cpu(tv_info->aModeTimings[index].usPixelClock) * 10;
+  mode->crtc_clock = mode->clock =
+   le16_to_cpu(tv_info->aModeTimings[index].usPixelClock) * 10;
 
   if (index == 1) {
    /* PAL timings appear to have wrong values for totals */
@@ -1852,7 +1843,8 @@ bool radeon_atom_get_tv_timings(struct radeon_device *rdev, int index,
   if (misc & ATOM_DOUBLE_CLOCK_MODE)
    mode->flags |= DRM_MODE_FLAG_DBLSCAN;
 
-  mode->clock = le16_to_cpu(dtd_timings->usPixClk) * 10;
+  mode->crtc_clock = mode->clock =
+   le16_to_cpu(dtd_timings->usPixClk) * 10;
   break;
  }
  return true;
@@ -3884,16 +3876,18 @@ int radeon_atom_init_mc_reg_table(struct radeon_device *rdev,
        ((u8 *)format + sizeof(ATOM_INIT_REG_INDEX_FORMAT));
      }
      reg_table->last = i;
-     while ((*(u32 *)reg_data != END_OF_REG_DATA_BLOCK) &&
+     while ((le32_to_cpu(*(u32 *)reg_data) != END_OF_REG_DATA_BLOCK) &&
             (num_ranges < VBIOS_MAX_AC_TIMING_ENTRIES)) {
-      t_mem_id = (u8)((*(u32 *)reg_data & MEM_ID_MASK) >> MEM_ID_SHIFT);
+      t_mem_id = (u8)((le32_to_cpu(*(u32 *)reg_data) & MEM_ID_MASK)
+        >> MEM_ID_SHIFT);
       if (module_index == t_mem_id) {
        reg_table->mc_reg_table_entry[num_ranges].mclk_max =
-        (u32)((*(u32 *)reg_data & CLOCK_RANGE_MASK) >> CLOCK_RANGE_SHIFT);
+        (u32)((le32_to_cpu(*(u32 *)reg_data) & CLOCK_RANGE_MASK)
+              >> CLOCK_RANGE_SHIFT);
        for (i = 0, j = 1; i < reg_table->last; i++) {
         if ((reg_table->mc_reg_address[i].pre_reg_data & LOW_NIBBLE_MASK) == DATA_FROM_TABLE) {
          reg_table->mc_reg_table_entry[num_ranges].mc_data[i] =
-          (u32)*((u32 *)reg_data + j);
+          (u32)le32_to_cpu(*((u32 *)reg_data + j));
          j++;
         } else if ((reg_table->mc_reg_address[i].pre_reg_data & LOW_NIBBLE_MASK) == DATA_EQU_PREV) {
          reg_table->mc_reg_table_entry[num_ranges].mc_data[i] =
@@ -3905,7 +3899,7 @@ int radeon_atom_init_mc_reg_table(struct radeon_device *rdev,
       reg_data = (ATOM_MEMORY_SETTING_DATA_BLOCK *)
        ((u8 *)reg_data + le16_to_cpu(reg_block->usRegDataBlkSize));
      }
-     if (*(u32 *)reg_data != END_OF_REG_DATA_BLOCK)
+     if (le32_to_cpu(*(u32 *)reg_data) != END_OF_REG_DATA_BLOCK)
       return -EINVAL;
      reg_table->num_entries = num_ranges;
     } else
diff --git a/drivers/gpu/drm/radeon/radeon_combios.c b/drivers/gpu/drm/radeon/radeon_combios.c
index 68ce360..6651177 100644
--- a/drivers/gpu/drm/radeon/radeon_combios.c
+++ b/drivers/gpu/drm/radeon/radeon_combios.c
@@ -37,22 +37,6 @@
 #include <asm/pci-bridge.h>
 #endif /* CONFIG_PPC_PMAC */
 
-/* from radeon_encoder.c */
-extern uint32_t
-radeon_get_encoder_enum(struct drm_device *dev, uint32_t supported_device,
-   uint8_t dac);
-extern void radeon_link_encoder_connector(struct drm_device *dev);
-
-/* from radeon_connector.c */
-extern void
-radeon_add_legacy_connector(struct drm_device *dev,
-       uint32_t connector_id,
-       uint32_t supported_device,
-       int connector_type,
-       struct radeon_i2c_bus_rec *i2c_bus,
-       uint16_t connector_object_id,
-       struct radeon_hpd *hpd);
-
 /* from radeon_legacy_encoder.c */
 extern void
 radeon_add_legacy_encoder(struct drm_device *dev, uint32_t encoder_enum,
diff --git a/drivers/gpu/drm/radeon/radeon_connectors.c b/drivers/gpu/drm/radeon/radeon_connectors.c
index 20a768a..82d4f86 100644
--- a/drivers/gpu/drm/radeon/radeon_connectors.c
+++ b/drivers/gpu/drm/radeon/radeon_connectors.c
@@ -33,15 +33,6 @@
 
 #include <linux/pm_runtime.h>
 
-extern void
-radeon_combios_connected_scratch_regs(struct drm_connector *connector,
-          struct drm_encoder *encoder,
-          bool connected);
-extern void
-radeon_atombios_connected_scratch_regs(struct drm_connector *connector,
-           struct drm_encoder *encoder,
-           bool connected);
-
 void radeon_connector_hotplug(struct drm_connector *connector)
 {
  struct drm_device *dev = connector->dev;
diff --git a/drivers/gpu/drm/radeon/radeon_cp.c b/drivers/gpu/drm/radeon/radeon_cp.c
index 3cae2bb..bb0d5c3 100644
--- a/drivers/gpu/drm/radeon/radeon_cp.c
+++ b/drivers/gpu/drm/radeon/radeon_cp.c
@@ -2020,10 +2020,10 @@ static int radeon_cp_get_buffers(struct drm_device *dev,
 
   buf->file_priv = file_priv;
 
-  if (DRM_COPY_TO_USER(&d->request_indices[i], &buf->idx,
+  if (copy_to_user(&d->request_indices[i], &buf->idx,
          sizeof(buf->idx)))
    return -EFAULT;
-  if (DRM_COPY_TO_USER(&d->request_sizes[i], &buf->total,
+  if (copy_to_user(&d->request_sizes[i], &buf->total,
          sizeof(buf->total)))
    return -EFAULT;
 
@@ -2228,7 +2228,7 @@ void radeon_commit_ring(drm_radeon_private_t *dev_priv)
 
  dev_priv->ring.tail &= dev_priv->ring.tail_mask;
 
- DRM_MEMORYBARRIER();
+ mb();
  GET_RING_HEAD( dev_priv );
 
  if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
diff --git a/drivers/gpu/drm/radeon/radeon_cs.c b/drivers/gpu/drm/radeon/radeon_cs.c
index 0b36616..dfb5a1d 100644
--- a/drivers/gpu/drm/radeon/radeon_cs.c
+++ b/drivers/gpu/drm/radeon/radeon_cs.c
@@ -138,7 +138,7 @@ static int radeon_cs_get_ring(struct radeon_cs_parser *p, u32 ring, s32 priority
     p->ring = R600_RING_TYPE_DMA_INDEX;
    else
     p->ring = CAYMAN_RING_TYPE_DMA1_INDEX;
-  } else if (p->rdev->family >= CHIP_R600) {
+  } else if (p->rdev->family >= CHIP_RV770) {
    p->ring = R600_RING_TYPE_DMA_INDEX;
   } else {
    return -EINVAL;
@@ -192,7 +192,7 @@ int radeon_cs_parser_init(struct radeon_cs_parser *p, void *data)
   return -ENOMEM;
  }
  chunk_array_ptr = (uint64_t *)(unsigned long)(cs->chunks);
- if (DRM_COPY_FROM_USER(p->chunks_array, chunk_array_ptr,
+ if (copy_from_user(p->chunks_array, chunk_array_ptr,
           sizeof(uint64_t)*cs->num_chunks)) {
   return -EFAULT;
  }
@@ -208,7 +208,7 @@ int radeon_cs_parser_init(struct radeon_cs_parser *p, void *data)
   uint32_t __user *cdata;
 
   chunk_ptr = (void __user*)(unsigned long)p->chunks_array[i];
-  if (DRM_COPY_FROM_USER(&user_chunk, chunk_ptr,
+  if (copy_from_user(&user_chunk, chunk_ptr,
            sizeof(struct drm_radeon_cs_chunk))) {
    return -EFAULT;
   }
@@ -252,7 +252,7 @@ int radeon_cs_parser_init(struct radeon_cs_parser *p, void *data)
   if (p->chunks[i].kdata == NULL) {
    return -ENOMEM;
   }
-  if (DRM_COPY_FROM_USER(p->chunks[i].kdata, cdata, size)) {
+  if (copy_from_user(p->chunks[i].kdata, cdata, size)) {
    return -EFAULT;
   }
   if (p->chunks[i].chunk_id == RADEON_CHUNK_ID_FLAGS) {
@@ -472,7 +472,7 @@ static int radeon_cs_ib_fill(struct radeon_device *rdev, struct radeon_cs_parser
    }
    parser->const_ib.is_const_ib = true;
    parser->const_ib.length_dw = ib_chunk->length_dw;
-   if (DRM_COPY_FROM_USER(parser->const_ib.ptr,
+   if (copy_from_user(parser->const_ib.ptr,
             ib_chunk->user_ptr,
             ib_chunk->length_dw * 4))
     return -EFAULT;
@@ -495,7 +495,7 @@ static int radeon_cs_ib_fill(struct radeon_device *rdev, struct radeon_cs_parser
  parser->ib.length_dw = ib_chunk->length_dw;
  if (ib_chunk->kdata)
   memcpy(parser->ib.ptr, ib_chunk->kdata, ib_chunk->length_dw * 4);
- else if (DRM_COPY_FROM_USER(parser->ib.ptr, ib_chunk->user_ptr, ib_chunk->length_dw * 4))
+ else if (copy_from_user(parser->ib.ptr, ib_chunk->user_ptr, ib_chunk->length_dw * 4))
   return -EFAULT;
  return 0;
 }
diff --git a/drivers/gpu/drm/radeon/radeon_device.c b/drivers/gpu/drm/radeon/radeon_device.c
index 39b033b..044bc98 100644
--- a/drivers/gpu/drm/radeon/radeon_device.c
+++ b/drivers/gpu/drm/radeon/radeon_device.c
@@ -144,6 +144,11 @@ void radeon_program_register_sequence(struct radeon_device *rdev,
  }
 }
 
+void radeon_pci_config_reset(struct radeon_device *rdev)
+{
+ pci_write_config_dword(rdev->pdev, 0x7c, RADEON_ASIC_RESET_DATA);
+}
+
 /**
  * radeon_surface_init - Clear GPU surface registers.
  *
@@ -249,7 +254,7 @@ void radeon_scratch_free(struct radeon_device *rdev, uint32_t reg)
  * Init doorbell driver information (CIK)
  * Returns 0 on success, error on failure.
  */
-int radeon_doorbell_init(struct radeon_device *rdev)
+static int radeon_doorbell_init(struct radeon_device *rdev)
 {
  /* doorbell bar mapping */
  rdev->doorbell.base = pci_resource_start(rdev->pdev, 2);
@@ -278,7 +283,7 @@ int radeon_doorbell_init(struct radeon_device *rdev)
  *
  * Tear down doorbell driver information (CIK)
  */
-void radeon_doorbell_fini(struct radeon_device *rdev)
+static void radeon_doorbell_fini(struct radeon_device *rdev)
 {
  iounmap(rdev->doorbell.ptr);
  rdev->doorbell.ptr = NULL;
@@ -1330,6 +1335,7 @@ int radeon_device_init(struct radeon_device *rdev,
   if (r)
    return r;
  }
+
  if ((radeon_testing & 1)) {
   if (rdev->accel_working)
    radeon_test_moves(rdev);
@@ -1455,7 +1461,6 @@ int radeon_suspend_kms(struct drm_device *dev, bool suspend, bool fbcon)
 
  radeon_save_bios_scratch_regs(rdev);
 
- radeon_pm_suspend(rdev);
  radeon_suspend(rdev);
  radeon_hpd_fini(rdev);
  /* evict remaining vram memory */
@@ -1516,14 +1521,25 @@ int radeon_resume_kms(struct drm_device *dev, bool resume, bool fbcon)
  if (r)
   DRM_ERROR("ib ring test failed (%d).\n", r);
 
- radeon_pm_resume(rdev);
+ if ((rdev->pm.pm_method == PM_METHOD_DPM) && rdev->pm.dpm_enabled) {
+  /* do dpm late init */
+  r = radeon_pm_late_init(rdev);
+  if (r) {
+   rdev->pm.dpm_enabled = false;
+   DRM_ERROR("radeon_pm_late_init failed, disabling dpm\n");
+  }
+ } else {
+  /* resume old pm late */
+  radeon_pm_resume(rdev);
+ }
+
  radeon_restore_bios_scratch_regs(rdev);
 
  if (fbcon) {
   radeon_fbdev_set_suspend(rdev, 0);
   console_unlock();
  }
-       
+
  /* init dig PHYs, disp eng pll */
  if (rdev->is_atom_bios) {
   radeon_atom_encoder_init(rdev);
diff --git a/drivers/gpu/drm/radeon/radeon_display.c b/drivers/gpu/drm/radeon/radeon_display.c
index 7b25381..fbd8b93 100644
--- a/drivers/gpu/drm/radeon/radeon_display.c
+++ b/drivers/gpu/drm/radeon/radeon_display.c
@@ -306,7 +306,7 @@ void radeon_crtc_handle_flip(struct radeon_device *rdev, int crtc_id)
   * to complete in this vblank?
   */
  if (update_pending &&
-     (DRM_SCANOUTPOS_VALID & radeon_get_crtc_scanoutpos(rdev->ddev, crtc_id,
+     (DRM_SCANOUTPOS_VALID & radeon_get_crtc_scanoutpos(rdev->ddev, crtc_id, 0,
               &vpos, &hpos, NULL, NULL)) &&
      ((vpos >= (99 * rdev->mode_info.crtcs[crtc_id]->base.hwmode.crtc_vdisplay)/100) ||
       (vpos < 0 && !ASIC_IS_AVIVO(rdev)))) {
@@ -571,6 +571,8 @@ static void radeon_crtc_init(struct drm_device *dev, int index)
   radeon_crtc->max_cursor_width = CURSOR_WIDTH;
   radeon_crtc->max_cursor_height = CURSOR_HEIGHT;
  }
+ dev->mode_config.cursor_width = radeon_crtc->max_cursor_width;
+ dev->mode_config.cursor_height = radeon_crtc->max_cursor_height;
 
 #if 0
  radeon_crtc->mode_set.crtc = &radeon_crtc->base;
@@ -1464,12 +1466,22 @@ int radeon_modeset_init(struct radeon_device *rdev)
  /* setup afmt */
  radeon_afmt_init(rdev);
 
- /* Initialize power management */
- radeon_pm_init(rdev);
-
  radeon_fbdev_init(rdev);
  drm_kms_helper_poll_init(rdev->ddev);
 
+ if (rdev->pm.dpm_enabled) {
+  /* do dpm late init */
+  ret = radeon_pm_late_init(rdev);
+  if (ret) {
+   rdev->pm.dpm_enabled = false;
+   DRM_ERROR("radeon_pm_late_init failed, disabling dpm\n");
+  }
+  /* set the dpm state for PX since there won't be
+   * a modeset to call this.
+   */
+  radeon_pm_compute_clocks(rdev);
+ }
+
  return 0;
 }
 
@@ -1477,7 +1489,6 @@ void radeon_modeset_fini(struct radeon_device *rdev)
 {
  radeon_fbdev_fini(rdev);
  kfree(rdev->mode_info.bios_hardcoded_edid);
- radeon_pm_fini(rdev);
 
  if (rdev->mode_info.mode_config_initialized) {
   radeon_afmt_fini(rdev);
@@ -1601,6 +1612,7 @@ bool radeon_crtc_scaling_mode_fixup(struct drm_crtc *crtc,
  *
  * \param dev Device to query.
  * \param crtc Crtc to query.
+ * \param flags Flags from caller (DRM_CALLED_FROM_VBLIRQ or 0).
  * \param *vpos Location where vertical scanout position should be stored.
  * \param *hpos Location where horizontal scanout position should go.
  * \param *stime Target location for timestamp taken immediately before
@@ -1622,8 +1634,8 @@ bool radeon_crtc_scaling_mode_fixup(struct drm_crtc *crtc,
  * unknown small number of scanlines wrt. real scanout position.
  *
  */
-int radeon_get_crtc_scanoutpos(struct drm_device *dev, int crtc, int *vpos, int *hpos,
-          ktime_t *stime, ktime_t *etime)
+int radeon_get_crtc_scanoutpos(struct drm_device *dev, int crtc, unsigned int flags,
+          int *vpos, int *hpos, ktime_t *stime, ktime_t *etime)
 {
  u32 stat_crtc = 0, vbl = 0, position = 0;
  int vbl_start, vbl_end, vtotal, ret = 0;
@@ -1765,5 +1777,27 @@ int radeon_get_crtc_scanoutpos(struct drm_device *dev, int crtc, int *vpos, int
  if (in_vbl)
   ret |= DRM_SCANOUTPOS_INVBL;
 
+ /* Is vpos outside nominal vblank area, but less than
+  * 1/100 of a frame height away from start of vblank?
+  * If so, assume this isn't a massively delayed vblank
+  * interrupt, but a vblank interrupt that fired a few
+  * microseconds before true start of vblank. Compensate
+  * by adding a full frame duration to the final timestamp.
+  * Happens, e.g., on ATI R500, R600.
+  *
+  * We only do this if DRM_CALLED_FROM_VBLIRQ.
+  */
+ if ((flags & DRM_CALLED_FROM_VBLIRQ) && !in_vbl) {
+  vbl_start = rdev->mode_info.crtcs[crtc]->base.hwmode.crtc_vdisplay;
+  vtotal = rdev->mode_info.crtcs[crtc]->base.hwmode.crtc_vtotal;
+
+  if (vbl_start - *vpos < vtotal / 100) {
+   *vpos -= vtotal;
+
+   /* Signal this correction as "applied". */
+   ret |= 0x8;
+  }
+ }
+
  return ret;
 }
diff --git a/drivers/gpu/drm/radeon/radeon_drv.c b/drivers/gpu/drm/radeon/radeon_drv.c
index 5fa8196..f633c27 100644
--- a/drivers/gpu/drm/radeon/radeon_drv.c
+++ b/drivers/gpu/drm/radeon/radeon_drv.c
@@ -78,9 +78,10 @@
  *   2.34.0 - Add CIK tiling mode array query
  *   2.35.0 - Add CIK macrotile mode array query
  *   2.36.0 - Fix CIK DCE tiling setup
+ *   2.37.0 - allow GS ring setup on r6xx/r7xx
  */
 #define KMS_DRIVER_MAJOR 2
-#define KMS_DRIVER_MINOR 36
+#define KMS_DRIVER_MINOR 37
 #define KMS_DRIVER_PATCHLEVEL 0
 int radeon_driver_load_kms(struct drm_device *dev, unsigned long flags);
 int radeon_driver_unload_kms(struct drm_device *dev);
@@ -102,13 +103,14 @@ int radeon_get_vblank_timestamp_kms(struct drm_device *dev, int crtc,
 void radeon_driver_irq_preinstall_kms(struct drm_device *dev);
 int radeon_driver_irq_postinstall_kms(struct drm_device *dev);
 void radeon_driver_irq_uninstall_kms(struct drm_device *dev);
-irqreturn_t radeon_driver_irq_handler_kms(DRM_IRQ_ARGS);
+irqreturn_t radeon_driver_irq_handler_kms(int irq, void *arg);
 void radeon_gem_object_free(struct drm_gem_object *obj);
 int radeon_gem_object_open(struct drm_gem_object *obj,
     struct drm_file *file_priv);
 void radeon_gem_object_close(struct drm_gem_object *obj,
     struct drm_file *file_priv);
 extern int radeon_get_crtc_scanoutpos(struct drm_device *dev, int crtc,
+          unsigned int flags,
           int *vpos, int *hpos, ktime_t *stime,
           ktime_t *etime);
 extern const struct drm_ioctl_desc radeon_ioctls_kms[];
@@ -168,6 +170,7 @@ int radeon_fastfb = 0;
 int radeon_dpm = -1;
 int radeon_aspm = -1;
 int radeon_runtime_pm = -1;
+int radeon_hard_reset = 0;
 
 MODULE_PARM_DESC(no_wb, "Disable AGP writeback for scratch registers");
 module_param_named(no_wb, radeon_no_wb, int, 0444);
@@ -232,6 +235,9 @@ module_param_named(aspm, radeon_aspm, int, 0444);
 MODULE_PARM_DESC(runpm, "PX runtime pm (1 = force enable, 0 = disable, -1 = PX only default)");
 module_param_named(runpm, radeon_runtime_pm, int, 0444);
 
+MODULE_PARM_DESC(hard_reset, "PCI config reset (1 = force enable, 0 = disable (default))");
+module_param_named(hard_reset, radeon_hard_reset, int, 0444);
+
 static struct pci_device_id pciidlist[] = {
  radeon_PCI_IDS
 };
@@ -397,11 +403,15 @@ static int radeon_pmops_runtime_suspend(struct device *dev)
  struct drm_device *drm_dev = pci_get_drvdata(pdev);
  int ret;
 
- if (radeon_runtime_pm == 0)
-  return -EINVAL;
+ if (radeon_runtime_pm == 0) {
+  pm_runtime_forbid(dev);
+  return -EBUSY;
+ }
 
- if (radeon_runtime_pm == -1 && !radeon_is_px())
-  return -EINVAL;
+ if (radeon_runtime_pm == -1 && !radeon_is_px()) {
+  pm_runtime_forbid(dev);
+  return -EBUSY;
+ }
 
  drm_dev->switch_power_state = DRM_SWITCH_POWER_CHANGING;
  drm_kms_helper_poll_disable(drm_dev);
@@ -450,12 +460,15 @@ static int radeon_pmops_runtime_idle(struct device *dev)
  struct drm_device *drm_dev = pci_get_drvdata(pdev);
  struct drm_crtc *crtc;
 
- if (radeon_runtime_pm == 0)
+ if (radeon_runtime_pm == 0) {
+  pm_runtime_forbid(dev);
   return -EBUSY;
+ }
 
  /* are we PX enabled? */
  if (radeon_runtime_pm == -1 && !radeon_is_px()) {
   DRM_DEBUG_DRIVER("failing to power off - not px\n");
+  pm_runtime_forbid(dev);
   return -EBUSY;
  }
 
diff --git a/drivers/gpu/drm/radeon/radeon_drv.h b/drivers/gpu/drm/radeon/radeon_drv.h
index 00e0d44..dafd812 100644
--- a/drivers/gpu/drm/radeon/radeon_drv.h
+++ b/drivers/gpu/drm/radeon/radeon_drv.h
@@ -405,7 +405,7 @@ extern void radeon_do_release(struct drm_device * dev);
 extern u32 radeon_get_vblank_counter(struct drm_device *dev, int crtc);
 extern int radeon_enable_vblank(struct drm_device *dev, int crtc);
 extern void radeon_disable_vblank(struct drm_device *dev, int crtc);
-extern irqreturn_t radeon_driver_irq_handler(DRM_IRQ_ARGS);
+extern irqreturn_t radeon_driver_irq_handler(int irq, void *arg);
 extern void radeon_driver_irq_preinstall(struct drm_device * dev);
 extern int radeon_driver_irq_postinstall(struct drm_device *dev);
 extern void radeon_driver_irq_uninstall(struct drm_device * dev);
diff --git a/drivers/gpu/drm/radeon/radeon_fence.c b/drivers/gpu/drm/radeon/radeon_fence.c
index d3a86e4..c37cb79 100644
--- a/drivers/gpu/drm/radeon/radeon_fence.c
+++ b/drivers/gpu/drm/radeon/radeon_fence.c
@@ -121,7 +121,7 @@ int radeon_fence_emit(struct radeon_device *rdev,
  (*fence)->seq = ++rdev->fence_drv[ring].sync_seq[ring];
  (*fence)->ring = ring;
  radeon_fence_ring_emit(rdev, ring, *fence);
- trace_radeon_fence_emit(rdev->ddev, (*fence)->seq);
+ trace_radeon_fence_emit(rdev->ddev, ring, (*fence)->seq);
  return 0;
 }
 
@@ -313,7 +313,7 @@ static int radeon_fence_wait_seq(struct radeon_device *rdev, u64 *target_seq,
     continue;
 
    last_seq[i] = atomic64_read(&rdev->fence_drv[i].last_seq);
-   trace_radeon_fence_wait_begin(rdev->ddev, target_seq[i]);
+   trace_radeon_fence_wait_begin(rdev->ddev, i, target_seq[i]);
    radeon_irq_kms_sw_irq_get(rdev, i);
   }
 
@@ -332,7 +332,7 @@ static int radeon_fence_wait_seq(struct radeon_device *rdev, u64 *target_seq,
     continue;
 
    radeon_irq_kms_sw_irq_put(rdev, i);
-   trace_radeon_fence_wait_end(rdev->ddev, target_seq[i]);
+   trace_radeon_fence_wait_end(rdev->ddev, i, target_seq[i]);
   }
 
   if (unlikely(r < 0))
@@ -841,6 +841,8 @@ static int radeon_debugfs_fence_info(struct seq_file *m, void *data)
   if (!rdev->fence_drv[i].initialized)
    continue;
 
+  radeon_fence_process(rdev, i);
+
   seq_printf(m, "--- ring %d ---\n", i);
   seq_printf(m, "Last signaled fence 0x%016llx\n",
       (unsigned long long)atomic64_read(&rdev->fence_drv[i].last_seq));
diff --git a/drivers/gpu/drm/radeon/radeon_gart.c b/drivers/gpu/drm/radeon/radeon_gart.c
index 96e4400..a8f9b46 100644
--- a/drivers/gpu/drm/radeon/radeon_gart.c
+++ b/drivers/gpu/drm/radeon/radeon_gart.c
@@ -713,7 +713,7 @@ struct radeon_fence *radeon_vm_grab_id(struct radeon_device *rdev,
  unsigned i;
 
  /* check if the id is still valid */
- if (vm->fence && vm->fence == rdev->vm_manager.active[vm->id])
+ if (vm->last_id_use && vm->last_id_use == rdev->vm_manager.active[vm->id])
   return NULL;
 
  /* we definately need to flush */
@@ -726,6 +726,7 @@ struct radeon_fence *radeon_vm_grab_id(struct radeon_device *rdev,
   if (fence == NULL) {
    /* found a free one */
    vm->id = i;
+   trace_radeon_vm_grab_id(vm->id, ring);
    return NULL;
   }
 
@@ -769,6 +770,9 @@ void radeon_vm_fence(struct radeon_device *rdev,
 
  radeon_fence_unref(&vm->fence);
  vm->fence = radeon_fence_ref(fence);
+
+ radeon_fence_unref(&vm->last_id_use);
+ vm->last_id_use = radeon_fence_ref(fence);
 }
 
 /**
@@ -1303,6 +1307,8 @@ void radeon_vm_init(struct radeon_device *rdev, struct radeon_vm *vm)
 {
  vm->id = 0;
  vm->fence = NULL;
+ vm->last_flush = NULL;
+ vm->last_id_use = NULL;
  mutex_init(&vm->mutex);
  INIT_LIST_HEAD(&vm->list);
  INIT_LIST_HEAD(&vm->va);
@@ -1341,5 +1347,6 @@ void radeon_vm_fini(struct radeon_device *rdev, struct radeon_vm *vm)
  }
  radeon_fence_unref(&vm->fence);
  radeon_fence_unref(&vm->last_flush);
+ radeon_fence_unref(&vm->last_id_use);
  mutex_unlock(&vm->mutex);
 }
diff --git a/drivers/gpu/drm/radeon/radeon_gem.c b/drivers/gpu/drm/radeon/radeon_gem.c
index 805c5e5..b96c819 100644
--- a/drivers/gpu/drm/radeon/radeon_gem.c
+++ b/drivers/gpu/drm/radeon/radeon_gem.c
@@ -86,7 +86,7 @@ retry:
  return 0;
 }
 
-int radeon_gem_set_domain(struct drm_gem_object *gobj,
+static int radeon_gem_set_domain(struct drm_gem_object *gobj,
      uint32_t rdomain, uint32_t wdomain)
 {
  struct radeon_bo *robj;
diff --git a/drivers/gpu/drm/radeon/radeon_irq.c b/drivers/gpu/drm/radeon/radeon_irq.c
index 8d68e97..244b19b 100644
--- a/drivers/gpu/drm/radeon/radeon_irq.c
+++ b/drivers/gpu/drm/radeon/radeon_irq.c
@@ -181,7 +181,7 @@ static u32 radeon_acknowledge_irqs(drm_radeon_private_t *dev_priv, u32 *r500_dis
  * tied to dma at all, this is just a hangover from dri prehistory.
  */
 
-irqreturn_t radeon_driver_irq_handler(DRM_IRQ_ARGS)
+irqreturn_t radeon_driver_irq_handler(int irq, void *arg)
 {
  struct drm_device *dev = (struct drm_device *) arg;
  drm_radeon_private_t *dev_priv =
@@ -203,7 +203,7 @@ irqreturn_t radeon_driver_irq_handler(DRM_IRQ_ARGS)
 
  /* SW interrupt */
  if (stat & RADEON_SW_INT_TEST)
-  DRM_WAKEUP(&dev_priv->swi_queue);
+  wake_up(&dev_priv->swi_queue);
 
  /* VBLANK interrupt */
  if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RS600) {
@@ -249,7 +249,7 @@ static int radeon_wait_irq(struct drm_device * dev, int swi_nr)
 
  dev_priv->stats.boxes |= RADEON_BOX_WAIT_IDLE;
 
- DRM_WAIT_ON(ret, dev_priv->swi_queue, 3 * DRM_HZ,
+ DRM_WAIT_ON(ret, dev_priv->swi_queue, 3 * HZ,
       RADEON_READ(RADEON_LAST_SWI_REG) >= swi_nr);
 
  return ret;
@@ -302,7 +302,7 @@ int radeon_irq_emit(struct drm_device *dev, void *data, struct drm_file *file_pr
 
  result = radeon_emit_irq(dev);
 
- if (DRM_COPY_TO_USER(emit->irq_seq, &result, sizeof(int))) {
+ if (copy_to_user(emit->irq_seq, &result, sizeof(int))) {
   DRM_ERROR("copy_to_user\n");
   return -EFAULT;
  }
@@ -354,7 +354,7 @@ int radeon_driver_irq_postinstall(struct drm_device *dev)
      (drm_radeon_private_t *) dev->dev_private;
 
  atomic_set(&dev_priv->swi_emitted, 0);
- DRM_INIT_WAITQUEUE(&dev_priv->swi_queue);
+ init_waitqueue_head(&dev_priv->swi_queue);
 
  dev->max_vblank_count = 0x001fffff;
 
diff --git a/drivers/gpu/drm/radeon/radeon_irq_kms.c b/drivers/gpu/drm/radeon/radeon_irq_kms.c
index ec6240b..089c9ff 100644
--- a/drivers/gpu/drm/radeon/radeon_irq_kms.c
+++ b/drivers/gpu/drm/radeon/radeon_irq_kms.c
@@ -39,13 +39,13 @@
 /**
  * radeon_driver_irq_handler_kms - irq handler for KMS
  *
- * @DRM_IRQ_ARGS: args
+ * @int irq, void *arg: args
  *
  * This is the irq handler for the radeon KMS driver (all asics).
  * radeon_irq_process is a macro that points to the per-asic
  * irq handler callback.
  */
-irqreturn_t radeon_driver_irq_handler_kms(DRM_IRQ_ARGS)
+irqreturn_t radeon_driver_irq_handler_kms(int irq, void *arg)
 {
  struct drm_device *dev = (struct drm_device *) arg;
  struct radeon_device *rdev = dev->dev_private;
diff --git a/drivers/gpu/drm/radeon/radeon_kms.c b/drivers/gpu/drm/radeon/radeon_kms.c
index 4818b44..66ed3ea 100644
--- a/drivers/gpu/drm/radeon/radeon_kms.c
+++ b/drivers/gpu/drm/radeon/radeon_kms.c
@@ -199,7 +199,7 @@ static void radeon_set_filp_rights(struct drm_device *dev,
  * etc. (all asics).
  * Returns 0 on success, -EINVAL on failure.
  */
-int radeon_info_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
+static int radeon_info_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
 {
  struct radeon_device *rdev = dev->dev_private;
  struct drm_radeon_info *info = data;
@@ -231,7 +231,7 @@ int radeon_info_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
    *value = rdev->accel_working;
   break;
  case RADEON_INFO_CRTC_FROM_ID:
-  if (DRM_COPY_FROM_USER(value, value_ptr, sizeof(uint32_t))) {
+  if (copy_from_user(value, value_ptr, sizeof(uint32_t))) {
    DRM_ERROR("copy_from_user %s:%u\n", __func__, __LINE__);
    return -EFAULT;
   }
@@ -277,7 +277,7 @@ int radeon_info_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
    *
    * When returning, the value is 1 if filp owns hyper-z access,
    * 0 otherwise. */
-  if (DRM_COPY_FROM_USER(value, value_ptr, sizeof(uint32_t))) {
+  if (copy_from_user(value, value_ptr, sizeof(uint32_t))) {
    DRM_ERROR("copy_from_user %s:%u\n", __func__, __LINE__);
    return -EFAULT;
   }
@@ -289,7 +289,7 @@ int radeon_info_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
   break;
  case RADEON_INFO_WANT_CMASK:
   /* The same logic as Hyper-Z. */
-  if (DRM_COPY_FROM_USER(value, value_ptr, sizeof(uint32_t))) {
+  if (copy_from_user(value, value_ptr, sizeof(uint32_t))) {
    DRM_ERROR("copy_from_user %s:%u\n", __func__, __LINE__);
    return -EFAULT;
   }
@@ -425,7 +425,7 @@ int radeon_info_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
   *value = rdev->fastfb_working;
   break;
  case RADEON_INFO_RING_WORKING:
-  if (DRM_COPY_FROM_USER(value, value_ptr, sizeof(uint32_t))) {
+  if (copy_from_user(value, value_ptr, sizeof(uint32_t))) {
    DRM_ERROR("copy_from_user %s:%u\n", __func__, __LINE__);
    return -EFAULT;
   }
@@ -478,11 +478,18 @@ int radeon_info_ioctl(struct drm_device *dev, void *data, struct drm_file *filp)
    DRM_DEBUG_KMS("BACKEND_ENABLED_MASK is si+ only!\n");
   }
   break;
+ case RADEON_INFO_MAX_SCLK:
+  if ((rdev->pm.pm_method == PM_METHOD_DPM) &&
+      rdev->pm.dpm_enabled)
+   *value = rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.sclk * 10;
+  else
+   *value = rdev->pm.default_sclk * 10;
+  break;
  default:
   DRM_DEBUG_KMS("Invalid request %d\n", info->request);
   return -EINVAL;
  }
- if (DRM_COPY_TO_USER(value_ptr, (char*)value, value_size)) {
+ if (copy_to_user(value_ptr, (char*)value, value_size)) {
   DRM_ERROR("copy_to_user %s:%u\n", __func__, __LINE__);
   return -EFAULT;
  }
@@ -726,11 +733,12 @@ int radeon_get_vblank_timestamp_kms(struct drm_device *dev, int crtc,
  /* Helper routine in DRM core does all the work: */
  return drm_calc_vbltimestamp_from_scanoutpos(dev, crtc, max_error,
            vblank_time, flags,
-           drmcrtc);
+           drmcrtc, &drmcrtc->hwmode);
 }
 
 #define KMS_INVALID_IOCTL(name)      \
-int name(struct drm_device *dev, void *data, struct drm_file *file_priv)\
+static int name(struct drm_device *dev, void *data, struct drm_file \
+  *file_priv)      \
 {         \
  DRM_ERROR("invalid ioctl with kms %s\n", __func__);  \
  return -EINVAL;       \
diff --git a/drivers/gpu/drm/radeon/radeon_mem.c b/drivers/gpu/drm/radeon/radeon_mem.c
index d54d2d7..146d253 100644
--- a/drivers/gpu/drm/radeon/radeon_mem.c
+++ b/drivers/gpu/drm/radeon/radeon_mem.c
@@ -243,7 +243,7 @@ int radeon_mem_alloc(struct drm_device *dev, void *data, struct drm_file *file_p
  if (!block)
   return -ENOMEM;
 
- if (DRM_COPY_TO_USER(alloc->region_offset, &block->start,
+ if (copy_to_user(alloc->region_offset, &block->start,
         sizeof(int))) {
   DRM_ERROR("copy_to_user\n");
   return -EFAULT;
diff --git a/drivers/gpu/drm/radeon/radeon_mode.h b/drivers/gpu/drm/radeon/radeon_mode.h
index 3f0dd66..402dbe3 100644
--- a/drivers/gpu/drm/radeon/radeon_mode.h
+++ b/drivers/gpu/drm/radeon/radeon_mode.h
@@ -291,6 +291,7 @@ struct radeon_tv_regs {
 
 struct radeon_atom_ss {
  uint16_t percentage;
+ uint16_t percentage_divider;
  uint8_t type;
  uint16_t step;
  uint8_t delay;
@@ -624,6 +625,30 @@ struct atom_voltage_table
  struct atom_voltage_table_entry entries[MAX_VOLTAGE_ENTRIES];
 };
 
+
+extern void
+radeon_add_atom_connector(struct drm_device *dev,
+     uint32_t connector_id,
+     uint32_t supported_device,
+     int connector_type,
+     struct radeon_i2c_bus_rec *i2c_bus,
+     uint32_t igp_lane_info,
+     uint16_t connector_object_id,
+     struct radeon_hpd *hpd,
+     struct radeon_router *router);
+extern void
+radeon_add_legacy_connector(struct drm_device *dev,
+       uint32_t connector_id,
+       uint32_t supported_device,
+       int connector_type,
+       struct radeon_i2c_bus_rec *i2c_bus,
+       uint16_t connector_object_id,
+       struct radeon_hpd *hpd);
+extern uint32_t
+radeon_get_encoder_enum(struct drm_device *dev, uint32_t supported_device,
+   uint8_t dac);
+extern void radeon_link_encoder_connector(struct drm_device *dev);
+
 extern enum radeon_tv_std
 radeon_combios_get_tv_info(struct radeon_device *rdev);
 extern enum radeon_tv_std
@@ -631,6 +656,15 @@ radeon_atombios_get_tv_info(struct radeon_device *rdev);
 extern void radeon_atombios_get_default_voltages(struct radeon_device *rdev,
        u16 *vddc, u16 *vddci, u16 *mvdd);
 
+extern void
+radeon_combios_connected_scratch_regs(struct drm_connector *connector,
+          struct drm_encoder *encoder,
+          bool connected);
+extern void
+radeon_atombios_connected_scratch_regs(struct drm_connector *connector,
+           struct drm_encoder *encoder,
+           bool connected);
+
 extern struct drm_connector *
 radeon_get_connector_for_encoder(struct drm_encoder *encoder);
 extern struct drm_connector *
@@ -666,6 +700,7 @@ extern void radeon_atom_ext_encoder_setup_ddc(struct drm_encoder *encoder);
 extern struct drm_encoder *radeon_get_external_encoder(struct drm_encoder *encoder);
 extern int radeon_dp_i2c_aux_ch(struct i2c_adapter *adapter, int mode,
     u8 write_byte, u8 *read_byte);
+void radeon_atom_copy_swap(u8 *dst, u8 *src, u8 num_bytes, bool to_le);
 
 extern void radeon_i2c_init(struct radeon_device *rdev);
 extern void radeon_i2c_fini(struct radeon_device *rdev);
@@ -766,6 +801,7 @@ extern int radeon_crtc_cursor_move(struct drm_crtc *crtc,
        int x, int y);
 
 extern int radeon_get_crtc_scanoutpos(struct drm_device *dev, int crtc,
+          unsigned int flags,
           int *vpos, int *hpos, ktime_t *stime,
           ktime_t *etime);
 
diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c
index c0fa4aa..08595cf 100644
--- a/drivers/gpu/drm/radeon/radeon_object.c
+++ b/drivers/gpu/drm/radeon/radeon_object.c
@@ -46,7 +46,7 @@ static void radeon_bo_clear_surface_reg(struct radeon_bo *bo);
  * function are calling it.
  */
 
-void radeon_bo_clear_va(struct radeon_bo *bo)
+static void radeon_bo_clear_va(struct radeon_bo *bo)
 {
  struct radeon_bo_va *bo_va, *tmp;
 
diff --git a/drivers/gpu/drm/radeon/radeon_pm.c b/drivers/gpu/drm/radeon/radeon_pm.c
index 1045487..927d6ce 100644
--- a/drivers/gpu/drm/radeon/radeon_pm.c
+++ b/drivers/gpu/drm/radeon/radeon_pm.c
@@ -945,6 +945,10 @@ void radeon_dpm_enable_uvd(struct radeon_device *rdev, bool enable)
 
  if (rdev->asic->dpm.powergate_uvd) {
   mutex_lock(&rdev->pm.mutex);
+  /* don't powergate anything if we
+     have active but pause streams */
+  enable |= rdev->pm.dpm.sd > 0;
+  enable |= rdev->pm.dpm.hd > 0;
   /* enable/disable UVD */
   radeon_dpm_powergate_uvd(rdev, !enable);
   mutex_unlock(&rdev->pm.mutex);
@@ -1055,25 +1059,27 @@ static void radeon_pm_resume_dpm(struct radeon_device *rdev)
  radeon_dpm_setup_asic(rdev);
  ret = radeon_dpm_enable(rdev);
  mutex_unlock(&rdev->pm.mutex);
- if (ret) {
-  DRM_ERROR("radeon: dpm resume failed\n");
-  if ((rdev->family >= CHIP_BARTS) &&
-      (rdev->family <= CHIP_CAYMAN) &&
-      rdev->mc_fw) {
-   if (rdev->pm.default_vddc)
-    radeon_atom_set_voltage(rdev, rdev->pm.default_vddc,
-       SET_VOLTAGE_TYPE_ASIC_VDDC);
-   if (rdev->pm.default_vddci)
-    radeon_atom_set_voltage(rdev, rdev->pm.default_vddci,
-       SET_VOLTAGE_TYPE_ASIC_VDDCI);
-   if (rdev->pm.default_sclk)
-    radeon_set_engine_clock(rdev, rdev->pm.default_sclk);
-   if (rdev->pm.default_mclk)
-    radeon_set_memory_clock(rdev, rdev->pm.default_mclk);
-  }
- } else {
-  rdev->pm.dpm_enabled = true;
-  radeon_pm_compute_clocks(rdev);
+ if (ret)
+  goto dpm_resume_fail;
+ rdev->pm.dpm_enabled = true;
+ radeon_pm_compute_clocks(rdev);
+ return;
+
+dpm_resume_fail:
+ DRM_ERROR("radeon: dpm resume failed\n");
+ if ((rdev->family >= CHIP_BARTS) &&
+     (rdev->family <= CHIP_CAYMAN) &&
+     rdev->mc_fw) {
+  if (rdev->pm.default_vddc)
+   radeon_atom_set_voltage(rdev, rdev->pm.default_vddc,
+      SET_VOLTAGE_TYPE_ASIC_VDDC);
+  if (rdev->pm.default_vddci)
+   radeon_atom_set_voltage(rdev, rdev->pm.default_vddci,
+      SET_VOLTAGE_TYPE_ASIC_VDDCI);
+  if (rdev->pm.default_sclk)
+   radeon_set_engine_clock(rdev, rdev->pm.default_sclk);
+  if (rdev->pm.default_mclk)
+   radeon_set_memory_clock(rdev, rdev->pm.default_mclk);
  }
 }
 
@@ -1193,51 +1199,50 @@ static int radeon_pm_init_dpm(struct radeon_device *rdev)
  radeon_dpm_setup_asic(rdev);
  ret = radeon_dpm_enable(rdev);
  mutex_unlock(&rdev->pm.mutex);
- if (ret) {
-  rdev->pm.dpm_enabled = false;
-  if ((rdev->family >= CHIP_BARTS) &&
-      (rdev->family <= CHIP_CAYMAN) &&
-      rdev->mc_fw) {
-   if (rdev->pm.default_vddc)
-    radeon_atom_set_voltage(rdev, rdev->pm.default_vddc,
-       SET_VOLTAGE_TYPE_ASIC_VDDC);
-   if (rdev->pm.default_vddci)
-    radeon_atom_set_voltage(rdev, rdev->pm.default_vddci,
-       SET_VOLTAGE_TYPE_ASIC_VDDCI);
-   if (rdev->pm.default_sclk)
-    radeon_set_engine_clock(rdev, rdev->pm.default_sclk);
-   if (rdev->pm.default_mclk)
-    radeon_set_memory_clock(rdev, rdev->pm.default_mclk);
-  }
-  DRM_ERROR("radeon: dpm initialization failed\n");
-  return ret;
- }
+ if (ret)
+  goto dpm_failed;
  rdev->pm.dpm_enabled = true;
- radeon_pm_compute_clocks(rdev);
-
- if (rdev->pm.num_power_states > 1) {
-  ret = device_create_file(rdev->dev, &dev_attr_power_dpm_state);
-  if (ret)
-   DRM_ERROR("failed to create device file for dpm state\n");
-  ret = device_create_file(rdev->dev, &dev_attr_power_dpm_force_performance_level);
-  if (ret)
-   DRM_ERROR("failed to create device file for dpm state\n");
-  /* XXX: these are noops for dpm but are here for backwards compat */
-  ret = device_create_file(rdev->dev, &dev_attr_power_profile);
-  if (ret)
-   DRM_ERROR("failed to create device file for power profile\n");
-  ret = device_create_file(rdev->dev, &dev_attr_power_method);
-  if (ret)
-   DRM_ERROR("failed to create device file for power method\n");
 
-  if (radeon_debugfs_pm_init(rdev)) {
-   DRM_ERROR("Failed to register debugfs file for dpm!\n");
-  }
+ ret = device_create_file(rdev->dev, &dev_attr_power_dpm_state);
+ if (ret)
+  DRM_ERROR("failed to create device file for dpm state\n");
+ ret = device_create_file(rdev->dev, &dev_attr_power_dpm_force_performance_level);
+ if (ret)
+  DRM_ERROR("failed to create device file for dpm state\n");
+ /* XXX: these are noops for dpm but are here for backwards compat */
+ ret = device_create_file(rdev->dev, &dev_attr_power_profile);
+ if (ret)
+  DRM_ERROR("failed to create device file for power profile\n");
+ ret = device_create_file(rdev->dev, &dev_attr_power_method);
+ if (ret)
+  DRM_ERROR("failed to create device file for power method\n");
 
-  DRM_INFO("radeon: dpm initialized\n");
+ if (radeon_debugfs_pm_init(rdev)) {
+  DRM_ERROR("Failed to register debugfs file for dpm!\n");
  }
 
+ DRM_INFO("radeon: dpm initialized\n");
+
  return 0;
+
+dpm_failed:
+ rdev->pm.dpm_enabled = false;
+ if ((rdev->family >= CHIP_BARTS) &&
+     (rdev->family <= CHIP_CAYMAN) &&
+     rdev->mc_fw) {
+  if (rdev->pm.default_vddc)
+   radeon_atom_set_voltage(rdev, rdev->pm.default_vddc,
+      SET_VOLTAGE_TYPE_ASIC_VDDC);
+  if (rdev->pm.default_vddci)
+   radeon_atom_set_voltage(rdev, rdev->pm.default_vddci,
+      SET_VOLTAGE_TYPE_ASIC_VDDCI);
+  if (rdev->pm.default_sclk)
+   radeon_set_engine_clock(rdev, rdev->pm.default_sclk);
+  if (rdev->pm.default_mclk)
+   radeon_set_memory_clock(rdev, rdev->pm.default_mclk);
+ }
+ DRM_ERROR("radeon: dpm initialization failed\n");
+ return ret;
 }
 
 int radeon_pm_init(struct radeon_device *rdev)
@@ -1255,10 +1260,6 @@ int radeon_pm_init(struct radeon_device *rdev)
  case CHIP_TURKS:
  case CHIP_CAICOS:
  case CHIP_CAYMAN:
- case CHIP_BONAIRE:
- case CHIP_KABINI:
- case CHIP_KAVERI:
- case CHIP_HAWAII:
   /* DPM requires the RLC, RV770+ dGPU requires SMC */
   if (!rdev->rlc_fw)
    rdev->pm.pm_method = PM_METHOD_PROFILE;
@@ -1289,6 +1290,10 @@ int radeon_pm_init(struct radeon_device *rdev)
  case CHIP_VERDE:
  case CHIP_OLAND:
  case CHIP_HAINAN:
+ case CHIP_BONAIRE:
+ case CHIP_KABINI:
+ case CHIP_KAVERI:
+ case CHIP_HAWAII:
   /* DPM requires the RLC, RV770+ dGPU requires SMC */
   if (!rdev->rlc_fw)
    rdev->pm.pm_method = PM_METHOD_PROFILE;
@@ -1313,6 +1318,18 @@ int radeon_pm_init(struct radeon_device *rdev)
   return radeon_pm_init_old(rdev);
 }
 
+int radeon_pm_late_init(struct radeon_device *rdev)
+{
+ int ret = 0;
+
+ if (rdev->pm.pm_method == PM_METHOD_DPM) {
+  mutex_lock(&rdev->pm.mutex);
+  ret = radeon_dpm_late_enable(rdev);
+  mutex_unlock(&rdev->pm.mutex);
+ }
+ return ret;
+}
+
 static void radeon_pm_fini_old(struct radeon_device *rdev)
 {
  if (rdev->pm.num_power_states > 1) {
@@ -1447,6 +1464,9 @@ static void radeon_pm_compute_clocks_dpm(struct radeon_device *rdev)
  struct drm_crtc *crtc;
  struct radeon_crtc *radeon_crtc;
 
+ if (!rdev->pm.dpm_enabled)
+  return;
+
  mutex_lock(&rdev->pm.mutex);
 
  /* update active crtc counts */
@@ -1491,7 +1511,7 @@ static bool radeon_pm_in_vbl(struct radeon_device *rdev)
   */
  for (crtc = 0; (crtc < rdev->num_crtc) && in_vbl; crtc++) {
   if (rdev->pm.active_crtcs & (1 << crtc)) {
-   vbl_status = radeon_get_crtc_scanoutpos(rdev->ddev, crtc, &vpos, &hpos, NULL, NULL);
+   vbl_status = radeon_get_crtc_scanoutpos(rdev->ddev, crtc, 0, &vpos, &hpos, NULL, NULL);
    if ((vbl_status & DRM_SCANOUTPOS_VALID) &&
        !(vbl_status & DRM_SCANOUTPOS_INVBL))
     in_vbl = false;
diff --git a/drivers/gpu/drm/radeon/radeon_ring.c b/drivers/gpu/drm/radeon/radeon_ring.c
index 39a5d8e..15e44a7 100644
--- a/drivers/gpu/drm/radeon/radeon_ring.c
+++ b/drivers/gpu/drm/radeon/radeon_ring.c
@@ -332,36 +332,6 @@ bool radeon_ring_supports_scratch_reg(struct radeon_device *rdev,
  }
 }
 
-u32 radeon_ring_generic_get_rptr(struct radeon_device *rdev,
-     struct radeon_ring *ring)
-{
- u32 rptr;
-
- if (rdev->wb.enabled)
-  rptr = le32_to_cpu(rdev->wb.wb[ring->rptr_offs/4]);
- else
-  rptr = RREG32(ring->rptr_reg);
-
- return rptr;
-}
-
-u32 radeon_ring_generic_get_wptr(struct radeon_device *rdev,
-     struct radeon_ring *ring)
-{
- u32 wptr;
-
- wptr = RREG32(ring->wptr_reg);
-
- return wptr;
-}
-
-void radeon_ring_generic_set_wptr(struct radeon_device *rdev,
-      struct radeon_ring *ring)
-{
- WREG32(ring->wptr_reg, ring->wptr);
- (void)RREG32(ring->wptr_reg);
-}
-
 /**
  * radeon_ring_free_size - update the free size
  *
@@ -463,7 +433,7 @@ void radeon_ring_commit(struct radeon_device *rdev, struct radeon_ring *ring)
  while (ring->wptr & ring->align_mask) {
   radeon_ring_write(ring, ring->nop);
  }
- DRM_MEMORYBARRIER();
+ mb();
  radeon_ring_set_wptr(rdev, ring);
 }
 
@@ -689,22 +659,18 @@ int radeon_ring_restore(struct radeon_device *rdev, struct radeon_ring *ring,
  * @ring: radeon_ring structure holding ring information
  * @ring_size: size of the ring
  * @rptr_offs: offset of the rptr writeback location in the WB buffer
- * @rptr_reg: MMIO offset of the rptr register
- * @wptr_reg: MMIO offset of the wptr register
  * @nop: nop packet for this ring
  *
  * Initialize the driver information for the selected ring (all asics).
  * Returns 0 on success, error on failure.
  */
 int radeon_ring_init(struct radeon_device *rdev, struct radeon_ring *ring, unsigned ring_size,
-       unsigned rptr_offs, unsigned rptr_reg, unsigned wptr_reg, u32 nop)
+       unsigned rptr_offs, u32 nop)
 {
  int r;
 
  ring->ring_size = ring_size;
  ring->rptr_offs = rptr_offs;
- ring->rptr_reg = rptr_reg;
- ring->wptr_reg = wptr_reg;
  ring->nop = nop;
  /* Allocate ring buffer */
  if (ring->ring_obj == NULL) {
@@ -790,34 +756,54 @@ static int radeon_debugfs_ring_info(struct seq_file *m, void *data)
  struct radeon_device *rdev = dev->dev_private;
  int ridx = *(int*)node->info_ent->data;
  struct radeon_ring *ring = &rdev->ring[ridx];
+
+ uint32_t rptr, wptr, rptr_next;
  unsigned count, i, j;
- u32 tmp;
 
  radeon_ring_free_size(rdev, ring);
  count = (ring->ring_size / 4) - ring->ring_free_dw;
- tmp = radeon_ring_get_wptr(rdev, ring);
- seq_printf(m, "wptr(0x%04x): 0x%08x [%5d]\n", ring->wptr_reg, tmp, tmp);
- tmp = radeon_ring_get_rptr(rdev, ring);
- seq_printf(m, "rptr(0x%04x): 0x%08x [%5d]\n", ring->rptr_reg, tmp, tmp);
+
+ wptr = radeon_ring_get_wptr(rdev, ring);
+ seq_printf(m, "wptr: 0x%08x [%5d]\n",
+     wptr, wptr);
+
+ rptr = radeon_ring_get_rptr(rdev, ring);
+ seq_printf(m, "rptr: 0x%08x [%5d]\n",
+     rptr, rptr);
+
  if (ring->rptr_save_reg) {
-  seq_printf(m, "rptr next(0x%04x): 0x%08x\n", ring->rptr_save_reg,
-      RREG32(ring->rptr_save_reg));
- }
- seq_printf(m, "driver's copy of the wptr: 0x%08x [%5d]\n", ring->wptr, ring->wptr);
- seq_printf(m, "driver's copy of the rptr: 0x%08x [%5d]\n", ring->rptr, ring->rptr);
- seq_printf(m, "last semaphore signal addr : 0x%016llx\n", ring->last_semaphore_signal_addr);
- seq_printf(m, "last semaphore wait addr   : 0x%016llx\n", ring->last_semaphore_wait_addr);
+  rptr_next = RREG32(ring->rptr_save_reg);
+  seq_printf(m, "rptr next(0x%04x): 0x%08x [%5d]\n",
+      ring->rptr_save_reg, rptr_next, rptr_next);
+ } else
+  rptr_next = ~0;
+
+ seq_printf(m, "driver's copy of the wptr: 0x%08x [%5d]\n",
+     ring->wptr, ring->wptr);
+ seq_printf(m, "driver's copy of the rptr: 0x%08x [%5d]\n",
+     ring->rptr, ring->rptr);
+ seq_printf(m, "last semaphore signal addr : 0x%016llx\n",
+     ring->last_semaphore_signal_addr);
+ seq_printf(m, "last semaphore wait addr   : 0x%016llx\n",
+     ring->last_semaphore_wait_addr);
  seq_printf(m, "%u free dwords in ring\n", ring->ring_free_dw);
  seq_printf(m, "%u dwords in ring\n", count);
+
+ if (!ring->ready)
+  return 0;
+
  /* print 8 dw before current rptr as often it's the last executed
   * packet that is the root issue
   */
- i = (ring->rptr + ring->ptr_mask + 1 - 32) & ring->ptr_mask;
- if (ring->ready) {
-  for (j = 0; j <= (count + 32); j++) {
-   seq_printf(m, "r[%5d]=0x%08x\n", i, ring->ring[i]);
-   i = (i + 1) & ring->ptr_mask;
-  }
+ i = (rptr + ring->ptr_mask + 1 - 32) & ring->ptr_mask;
+ for (j = 0; j <= (count + 32); j++) {
+  seq_printf(m, "r[%5d]=0x%08x", i, ring->ring[i]);
+  if (rptr == i)
+   seq_puts(m, " *");
+  if (rptr_next == i)
+   seq_puts(m, " #");
+  seq_puts(m, "\n");
+  i = (i + 1) & ring->ptr_mask;
  }
  return 0;
 }
diff --git a/drivers/gpu/drm/radeon/radeon_sa.c b/drivers/gpu/drm/radeon/radeon_sa.c
index f0bac68..c062580 100644
--- a/drivers/gpu/drm/radeon/radeon_sa.c
+++ b/drivers/gpu/drm/radeon/radeon_sa.c
@@ -402,13 +402,15 @@ void radeon_sa_bo_dump_debug_info(struct radeon_sa_manager *sa_manager,
 
  spin_lock(&sa_manager->wq.lock);
  list_for_each_entry(i, &sa_manager->olist, olist) {
+  uint64_t soffset = i->soffset + sa_manager->gpu_addr;
+  uint64_t eoffset = i->eoffset + sa_manager->gpu_addr;
   if (&i->olist == sa_manager->hole) {
    seq_printf(m, ">");
   } else {
    seq_printf(m, " ");
   }
-  seq_printf(m, "[0x%08x 0x%08x] size %8d",
-      i->soffset, i->eoffset, i->eoffset - i->soffset);
+  seq_printf(m, "[0x%010llx 0x%010llx] size %8lld",
+      soffset, eoffset, eoffset - soffset);
   if (i->fence) {
    seq_printf(m, " protected by 0x%016llx on ring %d",
        i->fence->seq, i->fence->ring);
diff --git a/drivers/gpu/drm/radeon/radeon_state.c b/drivers/gpu/drm/radeon/radeon_state.c
index 4d20910..956ab7f 100644
--- a/drivers/gpu/drm/radeon/radeon_state.c
+++ b/drivers/gpu/drm/radeon/radeon_state.c
@@ -1810,7 +1810,7 @@ static int radeon_cp_dispatch_texture(struct drm_device * dev,
   }
   if (!buf) {
    DRM_DEBUG("EAGAIN\n");
-   if (DRM_COPY_TO_USER(tex->image, image, sizeof(*image)))
+   if (copy_to_user(tex->image, image, sizeof(*image)))
     return -EFAULT;
    return -EAGAIN;
   }
@@ -1823,7 +1823,7 @@ static int radeon_cp_dispatch_texture(struct drm_device * dev,
 
 #define RADEON_COPY_MT(_buf, _data, _width) \
  do { \
-  if (DRM_COPY_FROM_USER(_buf, _data, (_width))) {\
+  if (copy_from_user(_buf, _data, (_width))) {\
    DRM_ERROR("EFAULT on pad, %d bytes\n", (_width)); \
    return -EFAULT; \
   } \
@@ -2168,7 +2168,7 @@ static int radeon_cp_clear(struct drm_device *dev, void *data, struct drm_file *
  if (sarea_priv->nbox > RADEON_NR_SAREA_CLIPRECTS)
   sarea_priv->nbox = RADEON_NR_SAREA_CLIPRECTS;
 
- if (DRM_COPY_FROM_USER(&depth_boxes, clear->depth_boxes,
+ if (copy_from_user(&depth_boxes, clear->depth_boxes,
           sarea_priv->nbox * sizeof(depth_boxes[0])))
   return -EFAULT;
 
@@ -2436,7 +2436,7 @@ static int radeon_cp_texture(struct drm_device *dev, void *data, struct drm_file
   return -EINVAL;
  }
 
- if (DRM_COPY_FROM_USER(&image,
+ if (copy_from_user(&image,
           (drm_radeon_tex_image_t __user *) tex->image,
           sizeof(image)))
   return -EFAULT;
@@ -2460,7 +2460,7 @@ static int radeon_cp_stipple(struct drm_device *dev, void *data, struct drm_file
 
  LOCK_TEST_WITH_RETURN(dev, file_priv);
 
- if (DRM_COPY_FROM_USER(&mask, stipple->mask, 32 * sizeof(u32)))
+ if (copy_from_user(&mask, stipple->mask, 32 * sizeof(u32)))
   return -EFAULT;
 
  RING_SPACE_TEST_WITH_RETURN(dev_priv);
@@ -2585,13 +2585,13 @@ static int radeon_cp_vertex2(struct drm_device *dev, void *data, struct drm_file
   drm_radeon_prim_t prim;
   drm_radeon_tcl_prim_t tclprim;
 
-  if (DRM_COPY_FROM_USER(&prim, &vertex->prim[i], sizeof(prim)))
+  if (copy_from_user(&prim, &vertex->prim[i], sizeof(prim)))
    return -EFAULT;
 
   if (prim.stateidx != laststate) {
    drm_radeon_state_t state;
 
-   if (DRM_COPY_FROM_USER(&state,
+   if (copy_from_user(&state,
             &vertex->state[prim.stateidx],
             sizeof(state)))
     return -EFAULT;
@@ -2799,7 +2799,7 @@ static int radeon_emit_packet3_cliprect(struct drm_device *dev,
 
  do {
   if (i < cmdbuf->nbox) {
-   if (DRM_COPY_FROM_USER(&box, &boxes[i], sizeof(box)))
+   if (copy_from_user(&box, &boxes[i], sizeof(box)))
     return -EFAULT;
    /* FIXME The second and subsequent times round
     * this loop, send a WAIT_UNTIL_3D_IDLE before
@@ -3116,7 +3116,7 @@ static int radeon_cp_getparam(struct drm_device *dev, void *data, struct drm_fil
   return -EINVAL;
  }
 
- if (DRM_COPY_TO_USER(param->value, &value, sizeof(int))) {
+ if (copy_to_user(param->value, &value, sizeof(int))) {
   DRM_ERROR("copy_to_user\n");
   return -EFAULT;
  }
diff --git a/drivers/gpu/drm/radeon/radeon_trace.h b/drivers/gpu/drm/radeon/radeon_trace.h
index 0473257..f749f2c 100644
--- a/drivers/gpu/drm/radeon/radeon_trace.h
+++ b/drivers/gpu/drm/radeon/radeon_trace.h
@@ -106,42 +106,45 @@ TRACE_EVENT(radeon_vm_set_page,
 
 DECLARE_EVENT_CLASS(radeon_fence_request,
 
-     TP_PROTO(struct drm_device *dev, u32 seqno),
+     TP_PROTO(struct drm_device *dev, int ring, u32 seqno),
 
-     TP_ARGS(dev, seqno),
+     TP_ARGS(dev, ring, seqno),
 
      TP_STRUCT__entry(
         __field(u32, dev)
+        __field(int, ring)
         __field(u32, seqno)
         ),
 
      TP_fast_assign(
       __entry->dev = dev->primary->index;
+      __entry->ring = ring;
       __entry->seqno = seqno;
       ),
 
-     TP_printk("dev=%u, seqno=%u", __entry->dev, __entry->seqno)
+     TP_printk("dev=%u, ring=%d, seqno=%u",
+        __entry->dev, __entry->ring, __entry->seqno)
 );
 
 DEFINE_EVENT(radeon_fence_request, radeon_fence_emit,
 
-     TP_PROTO(struct drm_device *dev, u32 seqno),
+     TP_PROTO(struct drm_device *dev, int ring, u32 seqno),
 
-     TP_ARGS(dev, seqno)
+     TP_ARGS(dev, ring, seqno)
 );
 
 DEFINE_EVENT(radeon_fence_request, radeon_fence_wait_begin,
 
-     TP_PROTO(struct drm_device *dev, u32 seqno),
+     TP_PROTO(struct drm_device *dev, int ring, u32 seqno),
 
-     TP_ARGS(dev, seqno)
+     TP_ARGS(dev, ring, seqno)
 );
 
 DEFINE_EVENT(radeon_fence_request, radeon_fence_wait_end,
 
-     TP_PROTO(struct drm_device *dev, u32 seqno),
+     TP_PROTO(struct drm_device *dev, int ring, u32 seqno),
 
-     TP_ARGS(dev, seqno)
+     TP_ARGS(dev, ring, seqno)
 );
 
 DECLARE_EVENT_CLASS(radeon_semaphore_request,
diff --git a/drivers/gpu/drm/radeon/radeon_ttm.c b/drivers/gpu/drm/radeon/radeon_ttm.c
index 84323c9..040a2a1 100644
--- a/drivers/gpu/drm/radeon/radeon_ttm.c
+++ b/drivers/gpu/drm/radeon/radeon_ttm.c
@@ -39,12 +39,14 @@
 #include <linux/seq_file.h>
 #include <linux/slab.h>
 #include <linux/swiotlb.h>
+#include <linux/debugfs.h>
 #include "radeon_reg.h"
 #include "radeon.h"
 
 #define DRM_FILE_PAGE_OFFSET (0x100000000ULL >> PAGE_SHIFT)
 
 static int radeon_ttm_debugfs_init(struct radeon_device *rdev);
+static void radeon_ttm_debugfs_fini(struct radeon_device *rdev);
 
 static struct radeon_device *radeon_get_rdev(struct ttm_bo_device *bdev)
 {
@@ -142,7 +144,7 @@ static int radeon_init_mem_type(struct ttm_bo_device *bdev, uint32_t type,
   man->flags = TTM_MEMTYPE_FLAG_MAPPABLE | TTM_MEMTYPE_FLAG_CMA;
 #if __OS_HAS_AGP
   if (rdev->flags & RADEON_IS_AGP) {
-   if (!(drm_core_has_AGP(rdev->ddev) && rdev->ddev->agp)) {
+   if (!rdev->ddev->agp) {
     DRM_ERROR("AGP is not enabled for memory type %u\n",
        (unsigned)type);
     return -EINVAL;
@@ -756,6 +758,7 @@ void radeon_ttm_fini(struct radeon_device *rdev)
 
  if (!rdev->mman.initialized)
   return;
+ radeon_ttm_debugfs_fini(rdev);
  if (rdev->stollen_vga_memory) {
   r = radeon_bo_reserve(rdev->stollen_vga_memory, false);
   if (r == 0) {
@@ -835,16 +838,15 @@ int radeon_mmap(struct file *filp, struct vm_area_struct *vma)
  return 0;
 }
 
-
-#define RADEON_DEBUGFS_MEM_TYPES 2
-
 #if defined(CONFIG_DEBUG_FS)
+
 static int radeon_mm_dump_table(struct seq_file *m, void *data)
 {
  struct drm_info_node *node = (struct drm_info_node *)m->private;
- struct drm_mm *mm = (struct drm_mm *)node->info_ent->data;
+ unsigned ttm_pl = *(int *)node->info_ent->data;
  struct drm_device *dev = node->minor->dev;
  struct radeon_device *rdev = dev->dev_private;
+ struct drm_mm *mm = (struct drm_mm *)rdev->mman.bdev.man[ttm_pl].priv;
  int ret;
  struct ttm_bo_global *glob = rdev->mman.bdev.glob;
 
@@ -853,46 +855,169 @@ static int radeon_mm_dump_table(struct seq_file *m, void *data)
  spin_unlock(&glob->lru_lock);
  return ret;
 }
+
+static int ttm_pl_vram = TTM_PL_VRAM;
+static int ttm_pl_tt = TTM_PL_TT;
+
+static struct drm_info_list radeon_ttm_debugfs_list[] = {
+ {"radeon_vram_mm", radeon_mm_dump_table, 0, &ttm_pl_vram},
+ {"radeon_gtt_mm", radeon_mm_dump_table, 0, &ttm_pl_tt},
+ {"ttm_page_pool", ttm_page_alloc_debugfs, 0, NULL},
+#ifdef CONFIG_SWIOTLB
+ {"ttm_dma_page_pool", ttm_dma_page_alloc_debugfs, 0, NULL}
 #endif
+};
 
-static int radeon_ttm_debugfs_init(struct radeon_device *rdev)
+static int radeon_ttm_vram_open(struct inode *inode, struct file *filep)
 {
-#if defined(CONFIG_DEBUG_FS)
- static struct drm_info_list radeon_mem_types_list[RADEON_DEBUGFS_MEM_TYPES+2];
- static char radeon_mem_types_names[RADEON_DEBUGFS_MEM_TYPES+2][32];
- unsigned i;
+ struct radeon_device *rdev = inode->i_private;
+ i_size_write(inode, rdev->mc.mc_vram_size);
+ filep->private_data = inode->i_private;
+ return 0;
+}
 
- for (i = 0; i < RADEON_DEBUGFS_MEM_TYPES; i++) {
-  if (i == 0)
-   sprintf(radeon_mem_types_names[i], "radeon_vram_mm");
-  else
-   sprintf(radeon_mem_types_names[i], "radeon_gtt_mm");
-  radeon_mem_types_list[i].name = radeon_mem_types_names[i];
-  radeon_mem_types_list[i].show = &radeon_mm_dump_table;
-  radeon_mem_types_list[i].driver_features = 0;
-  if (i == 0)
-   radeon_mem_types_list[i].data = rdev->mman.bdev.man[TTM_PL_VRAM].priv;
-  else
-   radeon_mem_types_list[i].data = rdev->mman.bdev.man[TTM_PL_TT].priv;
+static ssize_t radeon_ttm_vram_read(struct file *f, char __user *buf,
+        size_t size, loff_t *pos)
+{
+ struct radeon_device *rdev = f->private_data;
+ ssize_t result = 0;
+ int r;
 
+ if (size & 0x3 || *pos & 0x3)
+  return -EINVAL;
+
+ while (size) {
+  unsigned long flags;
+  uint32_t value;
+
+  if (*pos >= rdev->mc.mc_vram_size)
+   return result;
+
+  spin_lock_irqsave(&rdev->mmio_idx_lock, flags);
+  WREG32(RADEON_MM_INDEX, ((uint32_t)*pos) | 0x80000000);
+  if (rdev->family >= CHIP_CEDAR)
+   WREG32(EVERGREEN_MM_INDEX_HI, *pos >> 31);
+  value = RREG32(RADEON_MM_DATA);
+  spin_unlock_irqrestore(&rdev->mmio_idx_lock, flags);
+
+  r = put_user(value, (uint32_t *)buf);
+  if (r)
+   return r;
+
+  result += 4;
+  buf += 4;
+  *pos += 4;
+  size -= 4;
  }
- /* Add ttm page pool to debugfs */
- sprintf(radeon_mem_types_names[i], "ttm_page_pool");
- radeon_mem_types_list[i].name = radeon_mem_types_names[i];
- radeon_mem_types_list[i].show = &ttm_page_alloc_debugfs;
- radeon_mem_types_list[i].driver_features = 0;
- radeon_mem_types_list[i++].data = NULL;
-#ifdef CONFIG_SWIOTLB
- if (swiotlb_nr_tbl()) {
-  sprintf(radeon_mem_types_names[i], "ttm_dma_page_pool");
-  radeon_mem_types_list[i].name = radeon_mem_types_names[i];
-  radeon_mem_types_list[i].show = &ttm_dma_page_alloc_debugfs;
-  radeon_mem_types_list[i].driver_features = 0;
-  radeon_mem_types_list[i++].data = NULL;
+
+ return result;
+}
+
+static const struct file_operations radeon_ttm_vram_fops = {
+ .owner = THIS_MODULE,
+ .open = radeon_ttm_vram_open,
+ .read = radeon_ttm_vram_read,
+ .llseek = default_llseek
+};
+
+static int radeon_ttm_gtt_open(struct inode *inode, struct file *filep)
+{
+ struct radeon_device *rdev = inode->i_private;
+ i_size_write(inode, rdev->mc.gtt_size);
+ filep->private_data = inode->i_private;
+ return 0;
+}
+
+static ssize_t radeon_ttm_gtt_read(struct file *f, char __user *buf,
+       size_t size, loff_t *pos)
+{
+ struct radeon_device *rdev = f->private_data;
+ ssize_t result = 0;
+ int r;
+
+ while (size) {
+  loff_t p = *pos / PAGE_SIZE;
+  unsigned off = *pos & ~PAGE_MASK;
+  size_t cur_size = min_t(size_t, size, PAGE_SIZE - off);
+  struct page *page;
+  void *ptr;
+
+  if (p >= rdev->gart.num_cpu_pages)
+   return result;
+
+  page = rdev->gart.pages[p];
+  if (page) {
+   ptr = kmap(page);
+   ptr += off;
+
+   r = copy_to_user(buf, ptr, cur_size);
+   kunmap(rdev->gart.pages[p]);
+  } else
+   r = clear_user(buf, cur_size);
+
+  if (r)
+   return -EFAULT;
+
+  result += cur_size;
+  buf += cur_size;
+  *pos += cur_size;
+  size -= cur_size;
  }
+
+ return result;
+}
+
+static const struct file_operations radeon_ttm_gtt_fops = {
+ .owner = THIS_MODULE,
+ .open = radeon_ttm_gtt_open,
+ .read = radeon_ttm_gtt_read,
+ .llseek = default_llseek
+};
+
 #endif
- return radeon_debugfs_add_files(rdev, radeon_mem_types_list, i);
 
+static int radeon_ttm_debugfs_init(struct radeon_device *rdev)
+{
+#if defined(CONFIG_DEBUG_FS)
+ unsigned count;
+
+ struct drm_minor *minor = rdev->ddev->primary;
+ struct dentry *ent, *root = minor->debugfs_root;
+
+ ent = debugfs_create_file("radeon_vram", S_IFREG | S_IRUGO, root,
+      rdev, &radeon_ttm_vram_fops);
+ if (IS_ERR(ent))
+  return PTR_ERR(ent);
+ rdev->mman.vram = ent;
+
+ ent = debugfs_create_file("radeon_gtt", S_IFREG | S_IRUGO, root,
+      rdev, &radeon_ttm_gtt_fops);
+ if (IS_ERR(ent))
+  return PTR_ERR(ent);
+ rdev->mman.gtt = ent;
+
+ count = ARRAY_SIZE(radeon_ttm_debugfs_list);
+
+#ifdef CONFIG_SWIOTLB
+ if (!swiotlb_nr_tbl())
+  --count;
 #endif
+
+ return radeon_debugfs_add_files(rdev, radeon_ttm_debugfs_list, count);
+#else
+
  return 0;
+#endif
+}
+
+static void radeon_ttm_debugfs_fini(struct radeon_device *rdev)
+{
+#if defined(CONFIG_DEBUG_FS)
+
+ debugfs_remove(rdev->mman.vram);
+ rdev->mman.vram = NULL;
+
+ debugfs_remove(rdev->mman.gtt);
+ rdev->mman.gtt = NULL;
+#endif
 }
diff --git a/drivers/gpu/drm/radeon/radeon_uvd.c b/drivers/gpu/drm/radeon/radeon_uvd.c
index 60a0044..3e6804b 100644
--- a/drivers/gpu/drm/radeon/radeon_uvd.c
+++ b/drivers/gpu/drm/radeon/radeon_uvd.c
@@ -781,6 +781,8 @@ static void radeon_uvd_idle_work_handler(struct work_struct *work)
 
  if (radeon_fence_count_emitted(rdev, R600_RING_TYPE_UVD_INDEX) == 0) {
   if ((rdev->pm.pm_method == PM_METHOD_DPM) && rdev->pm.dpm_enabled) {
+   radeon_uvd_count_handles(rdev, &rdev->pm.dpm.sd,
+       &rdev->pm.dpm.hd);
    radeon_dpm_enable_uvd(rdev, false);
   } else {
    radeon_set_uvd_clocks(rdev, 0, 0);
diff --git a/drivers/gpu/drm/radeon/reg_srcs/r600 b/drivers/gpu/drm/radeon/reg_srcs/r600
index 20bfbda..ec0c682 100644
--- a/drivers/gpu/drm/radeon/reg_srcs/r600
+++ b/drivers/gpu/drm/radeon/reg_srcs/r600
@@ -18,6 +18,7 @@ r600 0x9400
 0x00028A3C VGT_GROUP_VECT_1_FMT_CNTL
 0x00028A40 VGT_GS_MODE
 0x00028A6C VGT_GS_OUT_PRIM_TYPE
+0x00028B38 VGT_GS_MAX_VERT_OUT
 0x000088C8 VGT_GS_PER_ES
 0x000088E8 VGT_GS_PER_VS
 0x000088D4 VGT_GS_VERTEX_REUSE
diff --git a/drivers/gpu/drm/radeon/rs400.c b/drivers/gpu/drm/radeon/rs400.c
index 9566b59..130d5cc 100644
--- a/drivers/gpu/drm/radeon/rs400.c
+++ b/drivers/gpu/drm/radeon/rs400.c
@@ -484,6 +484,7 @@ int rs400_resume(struct radeon_device *rdev)
 
 int rs400_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r100_cp_disable(rdev);
  radeon_wb_disable(rdev);
  r100_irq_disable(rdev);
@@ -493,6 +494,7 @@ int rs400_suspend(struct radeon_device *rdev)
 
 void rs400_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r100_cp_fini(rdev);
  radeon_wb_fini(rdev);
  radeon_ib_pool_fini(rdev);
@@ -560,6 +562,9 @@ int rs400_init(struct radeon_device *rdev)
   return r;
  r300_set_reg_safe(rdev);
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->accel_working = true;
  r = rs400_startup(rdev);
  if (r) {
diff --git a/drivers/gpu/drm/radeon/rs600.c b/drivers/gpu/drm/radeon/rs600.c
index 76cc8d3..72d3616 100644
--- a/drivers/gpu/drm/radeon/rs600.c
+++ b/drivers/gpu/drm/radeon/rs600.c
@@ -1058,6 +1058,7 @@ int rs600_resume(struct radeon_device *rdev)
 
 int rs600_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r600_audio_fini(rdev);
  r100_cp_disable(rdev);
  radeon_wb_disable(rdev);
@@ -1068,6 +1069,7 @@ int rs600_suspend(struct radeon_device *rdev)
 
 void rs600_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r600_audio_fini(rdev);
  r100_cp_fini(rdev);
  radeon_wb_fini(rdev);
@@ -1136,6 +1138,9 @@ int rs600_init(struct radeon_device *rdev)
   return r;
  rs600_set_safe_registers(rdev);
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->accel_working = true;
  r = rs600_startup(rdev);
  if (r) {
diff --git a/drivers/gpu/drm/radeon/rs690.c b/drivers/gpu/drm/radeon/rs690.c
index e7dab06..3462b64 100644
--- a/drivers/gpu/drm/radeon/rs690.c
+++ b/drivers/gpu/drm/radeon/rs690.c
@@ -766,6 +766,7 @@ int rs690_resume(struct radeon_device *rdev)
 
 int rs690_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r600_audio_fini(rdev);
  r100_cp_disable(rdev);
  radeon_wb_disable(rdev);
@@ -776,6 +777,7 @@ int rs690_suspend(struct radeon_device *rdev)
 
 void rs690_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r600_audio_fini(rdev);
  r100_cp_fini(rdev);
  radeon_wb_fini(rdev);
@@ -845,6 +847,9 @@ int rs690_init(struct radeon_device *rdev)
   return r;
  rs600_set_safe_registers(rdev);
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->accel_working = true;
  r = rs690_startup(rdev);
  if (r) {
diff --git a/drivers/gpu/drm/radeon/rs780_dpm.c b/drivers/gpu/drm/radeon/rs780_dpm.c
index 6af8505..8512085 100644
--- a/drivers/gpu/drm/radeon/rs780_dpm.c
+++ b/drivers/gpu/drm/radeon/rs780_dpm.c
@@ -623,14 +623,6 @@ int rs780_dpm_enable(struct radeon_device *rdev)
  if (pi->gfx_clock_gating)
   r600_gfx_clockgating_enable(rdev, true);
 
- if (rdev->irq.installed && (rdev->pm.int_thermal_type == THERMAL_TYPE_RV6XX)) {
-  ret = r600_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);
-  if (ret)
-   return ret;
-  rdev->irq.dpm_thermal = true;
-  radeon_irq_set(rdev);
- }
-
  return 0;
 }
 
diff --git a/drivers/gpu/drm/radeon/rv515.c b/drivers/gpu/drm/radeon/rv515.c
index 5d1c316..237dd29 100644
--- a/drivers/gpu/drm/radeon/rv515.c
+++ b/drivers/gpu/drm/radeon/rv515.c
@@ -596,6 +596,7 @@ int rv515_resume(struct radeon_device *rdev)
 
 int rv515_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r100_cp_disable(rdev);
  radeon_wb_disable(rdev);
  rs600_irq_disable(rdev);
@@ -612,6 +613,7 @@ void rv515_set_safe_registers(struct radeon_device *rdev)
 
 void rv515_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r100_cp_fini(rdev);
  radeon_wb_fini(rdev);
  radeon_ib_pool_fini(rdev);
@@ -685,6 +687,9 @@ int rv515_init(struct radeon_device *rdev)
   return r;
  rv515_set_safe_registers(rdev);
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->accel_working = true;
  r = rv515_startup(rdev);
  if (r) {
diff --git a/drivers/gpu/drm/radeon/rv6xx_dpm.c b/drivers/gpu/drm/radeon/rv6xx_dpm.c
index 26633a0..bebf31c 100644
--- a/drivers/gpu/drm/radeon/rv6xx_dpm.c
+++ b/drivers/gpu/drm/radeon/rv6xx_dpm.c
@@ -1546,7 +1546,6 @@ int rv6xx_dpm_enable(struct radeon_device *rdev)
 {
  struct rv6xx_power_info *pi = rv6xx_get_pi(rdev);
  struct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;
- int ret;
 
  if (r600_dynamicpm_enabled(rdev))
   return -EINVAL;
@@ -1594,15 +1593,6 @@ int rv6xx_dpm_enable(struct radeon_device *rdev)
  r600_power_level_enable(rdev, R600_POWER_LEVEL_MEDIUM, true);
  r600_power_level_enable(rdev, R600_POWER_LEVEL_HIGH, true);
 
- if (rdev->irq.installed &&
-     r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
-  ret = r600_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);
-  if (ret)
-   return ret;
-  rdev->irq.dpm_thermal = true;
-  radeon_irq_set(rdev);
- }
-
  rv6xx_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
 
  r600_start_dpm(rdev);
diff --git a/drivers/gpu/drm/radeon/rv770.c b/drivers/gpu/drm/radeon/rv770.c
index c4960ad..fef3107 100644
--- a/drivers/gpu/drm/radeon/rv770.c
+++ b/drivers/gpu/drm/radeon/rv770.c
@@ -1071,7 +1071,8 @@ static void rv770_mc_program(struct radeon_device *rdev)
  */
 void r700_cp_stop(struct radeon_device *rdev)
 {
- radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
+ if (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
  WREG32(CP_ME_CNTL, (CP_ME_HALT | CP_PFP_HALT));
  WREG32(SCRATCH_UMSK, 0);
  rdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;
@@ -1123,6 +1124,35 @@ void r700_cp_fini(struct radeon_device *rdev)
  radeon_scratch_free(rdev, ring->rptr_save_reg);
 }
 
+void rv770_set_clk_bypass_mode(struct radeon_device *rdev)
+{
+ u32 tmp, i;
+
+ if (rdev->flags & RADEON_IS_IGP)
+  return;
+
+ tmp = RREG32(CG_SPLL_FUNC_CNTL_2);
+ tmp &= SCLK_MUX_SEL_MASK;
+ tmp |= SCLK_MUX_SEL(1) | SCLK_MUX_UPDATE;
+ WREG32(CG_SPLL_FUNC_CNTL_2, tmp);
+
+ for (i = 0; i < rdev->usec_timeout; i++) {
+  if (RREG32(CG_SPLL_STATUS) & SPLL_CHG_STATUS)
+   break;
+  udelay(1);
+ }
+
+ tmp &= ~SCLK_MUX_UPDATE;
+ WREG32(CG_SPLL_FUNC_CNTL_2, tmp);
+
+ tmp = RREG32(MPLL_CNTL_MODE);
+ if ((rdev->family == CHIP_RV710) || (rdev->family == CHIP_RV730))
+  tmp &= ~RV730_MPLL_MCLK_SEL;
+ else
+  tmp &= ~MPLL_MCLK_SEL;
+ WREG32(MPLL_CNTL_MODE, tmp);
+}
+
 /*
  * Core functions
  */
@@ -1720,14 +1750,12 @@ static int rv770_startup(struct radeon_device *rdev)
 
  ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP_RPTR_OFFSET,
-        R600_CP_RB_RPTR, R600_CP_RB_WPTR,
         RADEON_CP_PACKET2);
  if (r)
   return r;
 
  ring = &rdev->ring[R600_RING_TYPE_DMA_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, R600_WB_DMA_RPTR_OFFSET,
-        DMA_RB_RPTR, DMA_RB_WPTR,
         DMA_PACKET(DMA_PACKET_NOP, 0, 0, 0));
  if (r)
   return r;
@@ -1746,7 +1774,6 @@ static int rv770_startup(struct radeon_device *rdev)
  ring = &rdev->ring[R600_RING_TYPE_UVD_INDEX];
  if (ring->ring_size) {
   r = radeon_ring_init(rdev, ring, ring->ring_size, 0,
-         UVD_RBC_RB_RPTR, UVD_RBC_RB_WPTR,
          RADEON_CP_PACKET2);
   if (!r)
    r = uvd_v1_0_init(rdev);
@@ -1784,6 +1811,9 @@ int rv770_resume(struct radeon_device *rdev)
  /* init golden registers */
  rv770_init_golden_registers(rdev);
 
+ if (rdev->pm.pm_method == PM_METHOD_DPM)
+  radeon_pm_resume(rdev);
+
  rdev->accel_working = true;
  r = rv770_startup(rdev);
  if (r) {
@@ -1798,6 +1828,7 @@ int rv770_resume(struct radeon_device *rdev)
 
 int rv770_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  r600_audio_fini(rdev);
  uvd_v1_0_fini(rdev);
  radeon_uvd_suspend(rdev);
@@ -1876,6 +1907,9 @@ int rv770_init(struct radeon_device *rdev)
   }
  }
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  rdev->ring[RADEON_RING_TYPE_GFX_INDEX].ring_obj = NULL;
  r600_ring_init(rdev, &rdev->ring[RADEON_RING_TYPE_GFX_INDEX], 1024 * 1024);
 
@@ -1915,6 +1949,7 @@ int rv770_init(struct radeon_device *rdev)
 
 void rv770_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  r700_cp_fini(rdev);
  r600_dma_fini(rdev);
  r600_irq_fini(rdev);
diff --git a/drivers/gpu/drm/radeon/rv770_dpm.c b/drivers/gpu/drm/radeon/rv770_dpm.c
index a239b30..b5f63f5 100644
--- a/drivers/gpu/drm/radeon/rv770_dpm.c
+++ b/drivers/gpu/drm/radeon/rv770_dpm.c
@@ -1863,8 +1863,8 @@ void rv770_enable_auto_throttle_source(struct radeon_device *rdev,
  }
 }
 
-int rv770_set_thermal_temperature_range(struct radeon_device *rdev,
-     int min_temp, int max_temp)
+static int rv770_set_thermal_temperature_range(struct radeon_device *rdev,
+            int min_temp, int max_temp)
 {
  int low_temp = 0 * 1000;
  int high_temp = 255 * 1000;
@@ -1966,6 +1966,15 @@ int rv770_dpm_enable(struct radeon_device *rdev)
  if (pi->mg_clock_gating)
   rv770_mg_clock_gating_enable(rdev, true);
 
+ rv770_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
+
+ return 0;
+}
+
+int rv770_dpm_late_enable(struct radeon_device *rdev)
+{
+ int ret;
+
  if (rdev->irq.installed &&
      r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
   PPSMC_Result result;
@@ -1981,8 +1990,6 @@ int rv770_dpm_enable(struct radeon_device *rdev)
    DRM_DEBUG_KMS("Could not enable thermal interrupts.\n");
  }
 
- rv770_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
-
  return 0;
 }
 
@@ -2167,7 +2174,6 @@ static void rv7xx_parse_pplib_clock_info(struct radeon_device *rdev,
  struct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);
  struct rv7xx_ps *ps = rv770_get_ps(rps);
  u32 sclk, mclk;
- u16 vddc;
  struct rv7xx_pl *pl;
 
  switch (index) {
@@ -2207,8 +2213,8 @@ static void rv7xx_parse_pplib_clock_info(struct radeon_device *rdev,
 
  /* patch up vddc if necessary */
  if (pl->vddc == 0xff01) {
-  if (radeon_atom_get_max_vddc(rdev, 0, 0, &vddc) == 0)
-   pl->vddc = vddc;
+  if (pi->max_vddc)
+   pl->vddc = pi->max_vddc;
  }
 
  if (rps->class & ATOM_PPLIB_CLASSIFICATION_ACPI) {
@@ -2244,14 +2250,12 @@ static void rv7xx_parse_pplib_clock_info(struct radeon_device *rdev,
   pl->vddci = vddci;
  }
 
- if (rdev->family >= CHIP_BARTS) {
-  if ((rps->class & ATOM_PPLIB_CLASSIFICATION_UI_MASK) ==
-      ATOM_PPLIB_CLASSIFICATION_UI_PERFORMANCE) {
-   rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.sclk = pl->sclk;
-   rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.mclk = pl->mclk;
-   rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddc = pl->vddc;
-   rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddci = pl->vddci;
-  }
+ if ((rps->class & ATOM_PPLIB_CLASSIFICATION_UI_MASK) ==
+     ATOM_PPLIB_CLASSIFICATION_UI_PERFORMANCE) {
+  rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.sclk = pl->sclk;
+  rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.mclk = pl->mclk;
+  rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddc = pl->vddc;
+  rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddci = pl->vddci;
  }
 }
 
@@ -2522,14 +2526,7 @@ u32 rv770_dpm_get_mclk(struct radeon_device *rdev, bool low)
 bool rv770_dpm_vblank_too_short(struct radeon_device *rdev)
 {
  u32 vblank_time = r600_dpm_get_vblank_time(rdev);
- u32 switch_limit = 300;
-
- /* quirks */
- /* ASUS K70AF */
- if ((rdev->pdev->device == 0x9553) &&
-     (rdev->pdev->subsystem_vendor == 0x1043) &&
-     (rdev->pdev->subsystem_device == 0x1c42))
-  switch_limit = 200;
+ u32 switch_limit = 200; /* 300 */
 
  /* RV770 */
  /* mclk switching doesn't seem to work reliably on desktop RV770s */
diff --git a/drivers/gpu/drm/radeon/rv770_dpm.h b/drivers/gpu/drm/radeon/rv770_dpm.h
index 9244eff..f776634 100644
--- a/drivers/gpu/drm/radeon/rv770_dpm.h
+++ b/drivers/gpu/drm/radeon/rv770_dpm.h
@@ -283,8 +283,4 @@ int rv770_read_smc_soft_register(struct radeon_device *rdev,
 int rv770_write_smc_soft_register(struct radeon_device *rdev,
       u16 reg_offset, u32 value);
 
-/* thermal */
-int rv770_set_thermal_temperature_range(struct radeon_device *rdev,
-     int min_temp, int max_temp);
-
 #endif
diff --git a/drivers/gpu/drm/radeon/rv770d.h b/drivers/gpu/drm/radeon/rv770d.h
index 1ae2771..3cf1e29 100644
--- a/drivers/gpu/drm/radeon/rv770d.h
+++ b/drivers/gpu/drm/radeon/rv770d.h
@@ -100,14 +100,21 @@
 #define CG_SPLL_FUNC_CNTL_2    0x604
 #define  SCLK_MUX_SEL(x)    ((x) << 0)
 #define  SCLK_MUX_SEL_MASK   (0x1ff << 0)
+#define  SCLK_MUX_UPDATE    (1 << 26)
 #define CG_SPLL_FUNC_CNTL_3    0x608
 #define  SPLL_FB_DIV(x)    ((x) << 0)
 #define  SPLL_FB_DIV_MASK   (0x3ffffff << 0)
 #define  SPLL_DITHEN    (1 << 28)
+#define CG_SPLL_STATUS     0x60c
+#define  SPLL_CHG_STATUS    (1 << 1)
 
 #define SPLL_CNTL_MODE     0x610
 #define  SPLL_DIV_SYNC    (1 << 5)
 
+#define MPLL_CNTL_MODE                                  0x61c
+#       define MPLL_MCLK_SEL                            (1 << 11)
+#       define RV730_MPLL_MCLK_SEL                      (1 << 25)
+
 #define MPLL_AD_FUNC_CNTL    0x624
 #define  CLKF(x)     ((x) << 0)
 #define  CLKF_MASK    (0x7f << 0)
diff --git a/drivers/gpu/drm/radeon/si.c b/drivers/gpu/drm/radeon/si.c
index 4a2e532..9a124d0 100644
--- a/drivers/gpu/drm/radeon/si.c
+++ b/drivers/gpu/drm/radeon/si.c
@@ -80,6 +80,8 @@ extern void evergreen_print_gpu_status_regs(struct radeon_device *rdev);
 extern bool evergreen_is_display_hung(struct radeon_device *rdev);
 static void si_enable_gui_idle_interrupt(struct radeon_device *rdev,
       bool enable);
+static void si_init_pg(struct radeon_device *rdev);
+static void si_init_cg(struct radeon_device *rdev);
 static void si_fini_pg(struct radeon_device *rdev);
 static void si_fini_cg(struct radeon_device *rdev);
 static void si_rlc_stop(struct radeon_device *rdev);
@@ -1460,7 +1462,7 @@ static const u32 hainan_io_mc_regs[TAHITI_IO_MC_REGS_SIZE][2] = {
 };
 
 /* ucode loading */
-static int si_mc_load_microcode(struct radeon_device *rdev)
+int si_mc_load_microcode(struct radeon_device *rdev)
 {
  const __be32 *fw_data;
  u32 running, blackout = 0;
@@ -3247,7 +3249,8 @@ static void si_cp_enable(struct radeon_device *rdev, bool enable)
  if (enable)
   WREG32(CP_ME_CNTL, 0);
  else {
-  radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
+  if (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)
+   radeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);
   WREG32(CP_ME_CNTL, (CP_ME_HALT | CP_PFP_HALT | CP_CE_HALT));
   WREG32(SCRATCH_UMSK, 0);
   rdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;
@@ -3508,6 +3511,9 @@ static int si_cp_resume(struct radeon_device *rdev)
 
  si_enable_gui_idle_interrupt(rdev, true);
 
+ if (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)
+  radeon_ttm_set_active_vram_size(rdev, rdev->mc.real_vram_size);
+
  return 0;
 }
 
@@ -3724,6 +3730,106 @@ static void si_gpu_soft_reset(struct radeon_device *rdev, u32 reset_mask)
  evergreen_print_gpu_status_regs(rdev);
 }
 
+static void si_set_clk_bypass_mode(struct radeon_device *rdev)
+{
+ u32 tmp, i;
+
+ tmp = RREG32(CG_SPLL_FUNC_CNTL);
+ tmp |= SPLL_BYPASS_EN;
+ WREG32(CG_SPLL_FUNC_CNTL, tmp);
+
+ tmp = RREG32(CG_SPLL_FUNC_CNTL_2);
+ tmp |= SPLL_CTLREQ_CHG;
+ WREG32(CG_SPLL_FUNC_CNTL_2, tmp);
+
+ for (i = 0; i < rdev->usec_timeout; i++) {
+  if (RREG32(SPLL_STATUS) & SPLL_CHG_STATUS)
+   break;
+  udelay(1);
+ }
+
+ tmp = RREG32(CG_SPLL_FUNC_CNTL_2);
+ tmp &= ~(SPLL_CTLREQ_CHG | SCLK_MUX_UPDATE);
+ WREG32(CG_SPLL_FUNC_CNTL_2, tmp);
+
+ tmp = RREG32(MPLL_CNTL_MODE);
+ tmp &= ~MPLL_MCLK_SEL;
+ WREG32(MPLL_CNTL_MODE, tmp);
+}
+
+static void si_spll_powerdown(struct radeon_device *rdev)
+{
+ u32 tmp;
+
+ tmp = RREG32(SPLL_CNTL_MODE);
+ tmp |= SPLL_SW_DIR_CONTROL;
+ WREG32(SPLL_CNTL_MODE, tmp);
+
+ tmp = RREG32(CG_SPLL_FUNC_CNTL);
+ tmp |= SPLL_RESET;
+ WREG32(CG_SPLL_FUNC_CNTL, tmp);
+
+ tmp = RREG32(CG_SPLL_FUNC_CNTL);
+ tmp |= SPLL_SLEEP;
+ WREG32(CG_SPLL_FUNC_CNTL, tmp);
+
+ tmp = RREG32(SPLL_CNTL_MODE);
+ tmp &= ~SPLL_SW_DIR_CONTROL;
+ WREG32(SPLL_CNTL_MODE, tmp);
+}
+
+static void si_gpu_pci_config_reset(struct radeon_device *rdev)
+{
+ struct evergreen_mc_save save;
+ u32 tmp, i;
+
+ dev_info(rdev->dev, "GPU pci config reset\n");
+
+ /* disable dpm? */
+
+ /* disable cg/pg */
+ si_fini_pg(rdev);
+ si_fini_cg(rdev);
+
+ /* Disable CP parsing/prefetching */
+ WREG32(CP_ME_CNTL, CP_ME_HALT | CP_PFP_HALT | CP_CE_HALT);
+ /* dma0 */
+ tmp = RREG32(DMA_RB_CNTL + DMA0_REGISTER_OFFSET);
+ tmp &= ~DMA_RB_ENABLE;
+ WREG32(DMA_RB_CNTL + DMA0_REGISTER_OFFSET, tmp);
+ /* dma1 */
+ tmp = RREG32(DMA_RB_CNTL + DMA1_REGISTER_OFFSET);
+ tmp &= ~DMA_RB_ENABLE;
+ WREG32(DMA_RB_CNTL + DMA1_REGISTER_OFFSET, tmp);
+ /* XXX other engines? */
+
+ /* halt the rlc, disable cp internal ints */
+ si_rlc_stop(rdev);
+
+ udelay(50);
+
+ /* disable mem access */
+ evergreen_mc_stop(rdev, &save);
+ if (evergreen_mc_wait_for_idle(rdev)) {
+  dev_warn(rdev->dev, "Wait for MC idle timed out !\n");
+ }
+
+ /* set mclk/sclk to bypass */
+ si_set_clk_bypass_mode(rdev);
+ /* powerdown spll */
+ si_spll_powerdown(rdev);
+ /* disable BM */
+ pci_clear_master(rdev->pdev);
+ /* reset */
+ radeon_pci_config_reset(rdev);
+ /* wait for asic to come out of reset */
+ for (i = 0; i < rdev->usec_timeout; i++) {
+  if (RREG32(CONFIG_MEMSIZE) != 0xffffffff)
+   break;
+  udelay(1);
+ }
+}
+
 int si_asic_reset(struct radeon_device *rdev)
 {
  u32 reset_mask;
@@ -3733,10 +3839,17 @@ int si_asic_reset(struct radeon_device *rdev)
  if (reset_mask)
   r600_set_bios_scratch_engine_hung(rdev, true);
 
+ /* try soft reset */
  si_gpu_soft_reset(rdev, reset_mask);
 
  reset_mask = si_gpu_check_soft_reset(rdev);
 
+ /* try pci config reset */
+ if (reset_mask && radeon_hard_reset)
+  si_gpu_pci_config_reset(rdev);
+
+ reset_mask = si_gpu_check_soft_reset(rdev);
+
  if (!reset_mask)
   r600_set_bios_scratch_engine_hung(rdev, false);
 
@@ -5212,8 +5325,8 @@ static void si_enable_hdp_ls(struct radeon_device *rdev,
   WREG32(HDP_MEM_POWER_LS, data);
 }
 
-void si_update_cg(struct radeon_device *rdev,
-    u32 block, bool enable)
+static void si_update_cg(struct radeon_device *rdev,
+    u32 block, bool enable)
 {
  if (block & RADEON_CG_BLOCK_GFX) {
   si_enable_gui_idle_interrupt(rdev, false);
@@ -5379,6 +5492,9 @@ static void si_init_pg(struct radeon_device *rdev)
   si_init_ao_cu_mask(rdev);
   if (rdev->pg_flags & RADEON_PG_SUPPORT_GFX_PG) {
    si_init_gfx_cgpg(rdev);
+  } else {
+   WREG32(RLC_SAVE_AND_RESTORE_BASE, rdev->rlc.save_restore_gpu_addr >> 8);
+   WREG32(RLC_CLEAR_STATE_RESTORE_BASE, rdev->rlc.clear_state_gpu_addr >> 8);
   }
   si_enable_dma_pg(rdev, true);
   si_enable_gfx_cgpg(rdev, true);
@@ -6328,10 +6444,12 @@ static int si_startup(struct radeon_device *rdev)
 
  si_mc_program(rdev);
 
- r = si_mc_load_microcode(rdev);
- if (r) {
-  DRM_ERROR("Failed to load MC firmware!\n");
-  return r;
+ if (!rdev->pm.dpm_enabled) {
+  r = si_mc_load_microcode(rdev);
+  if (r) {
+   DRM_ERROR("Failed to load MC firmware!\n");
+   return r;
+  }
  }
 
  r = si_pcie_gart_enable(rdev);
@@ -6416,37 +6534,30 @@ static int si_startup(struct radeon_device *rdev)
 
  ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP_RPTR_OFFSET,
-        CP_RB0_RPTR, CP_RB0_WPTR,
         RADEON_CP_PACKET2);
  if (r)
   return r;
 
  ring = &rdev->ring[CAYMAN_RING_TYPE_CP1_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP1_RPTR_OFFSET,
-        CP_RB1_RPTR, CP_RB1_WPTR,
         RADEON_CP_PACKET2);
  if (r)
   return r;
 
  ring = &rdev->ring[CAYMAN_RING_TYPE_CP2_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP2_RPTR_OFFSET,
-        CP_RB2_RPTR, CP_RB2_WPTR,
         RADEON_CP_PACKET2);
  if (r)
   return r;
 
  ring = &rdev->ring[R600_RING_TYPE_DMA_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, R600_WB_DMA_RPTR_OFFSET,
-        DMA_RB_RPTR + DMA0_REGISTER_OFFSET,
-        DMA_RB_WPTR + DMA0_REGISTER_OFFSET,
         DMA_PACKET(DMA_PACKET_NOP, 0, 0, 0, 0));
  if (r)
   return r;
 
  ring = &rdev->ring[CAYMAN_RING_TYPE_DMA1_INDEX];
  r = radeon_ring_init(rdev, ring, ring->ring_size, CAYMAN_WB_DMA1_RPTR_OFFSET,
-        DMA_RB_RPTR + DMA1_REGISTER_OFFSET,
-        DMA_RB_WPTR + DMA1_REGISTER_OFFSET,
         DMA_PACKET(DMA_PACKET_NOP, 0, 0, 0, 0));
  if (r)
   return r;
@@ -6466,7 +6577,6 @@ static int si_startup(struct radeon_device *rdev)
   ring = &rdev->ring[R600_RING_TYPE_UVD_INDEX];
   if (ring->ring_size) {
    r = radeon_ring_init(rdev, ring, ring->ring_size, 0,
-          UVD_RBC_RB_RPTR, UVD_RBC_RB_WPTR,
           RADEON_CP_PACKET2);
    if (!r)
     r = uvd_v1_0_init(rdev);
@@ -6508,6 +6618,9 @@ int si_resume(struct radeon_device *rdev)
  /* init golden registers */
  si_init_golden_registers(rdev);
 
+ if (rdev->pm.pm_method == PM_METHOD_DPM)
+  radeon_pm_resume(rdev);
+
  rdev->accel_working = true;
  r = si_startup(rdev);
  if (r) {
@@ -6522,6 +6635,7 @@ int si_resume(struct radeon_device *rdev)
 
 int si_suspend(struct radeon_device *rdev)
 {
+ radeon_pm_suspend(rdev);
  dce6_audio_fini(rdev);
  radeon_vm_manager_fini(rdev);
  si_cp_enable(rdev, false);
@@ -6604,6 +6718,9 @@ int si_init(struct radeon_device *rdev)
   }
  }
 
+ /* Initialize power management */
+ radeon_pm_init(rdev);
+
  ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];
  ring->ring_obj = NULL;
  r600_ring_init(rdev, ring, 1024 * 1024);
@@ -6670,6 +6787,7 @@ int si_init(struct radeon_device *rdev)
 
 void si_fini(struct radeon_device *rdev)
 {
+ radeon_pm_fini(rdev);
  si_cp_fini(rdev);
  cayman_dma_fini(rdev);
  si_fini_pg(rdev);
diff --git a/drivers/gpu/drm/radeon/si_dpm.c b/drivers/gpu/drm/radeon/si_dpm.c
index 0d50df3..0a2f5b4 100644
--- a/drivers/gpu/drm/radeon/si_dpm.c
+++ b/drivers/gpu/drm/radeon/si_dpm.c
@@ -1738,6 +1738,8 @@ struct evergreen_power_info *evergreen_get_pi(struct radeon_device *rdev);
 struct ni_power_info *ni_get_pi(struct radeon_device *rdev);
 struct ni_ps *ni_get_ps(struct radeon_ps *rps);
 
+extern int si_mc_load_microcode(struct radeon_device *rdev);
+
 static int si_populate_voltage_value(struct radeon_device *rdev,
          const struct atom_voltage_table *table,
          u16 value, SISLANDS_SMC_VOLTAGE_VALUE *voltage);
@@ -1753,9 +1755,6 @@ static int si_calculate_sclk_params(struct radeon_device *rdev,
         u32 engine_clock,
         SISLANDS_SMC_SCLK_VALUE *sclk);
 
-extern void si_update_cg(struct radeon_device *rdev,
-    u32 block, bool enable);
-
 static struct si_power_info *si_get_pi(struct radeon_device *rdev)
 {
         struct si_power_info *pi = rdev->pm.dpm.priv;
@@ -5753,6 +5752,11 @@ static void si_set_pcie_lane_width_in_smc(struct radeon_device *rdev,
 
 void si_dpm_setup_asic(struct radeon_device *rdev)
 {
+ int r;
+
+ r = si_mc_load_microcode(rdev);
+ if (r)
+  DRM_ERROR("Failed to load MC firmware!\n");
  rv770_get_memory_type(rdev);
  si_read_clock_registers(rdev);
  si_enable_acpi_power_management(rdev);
@@ -5790,13 +5794,6 @@ int si_dpm_enable(struct radeon_device *rdev)
  struct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;
  int ret;
 
- si_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-       RADEON_CG_BLOCK_MC |
-       RADEON_CG_BLOCK_SDMA |
-       RADEON_CG_BLOCK_BIF |
-       RADEON_CG_BLOCK_UVD |
-       RADEON_CG_BLOCK_HDP), false);
-
  if (si_is_smc_running(rdev))
   return -EINVAL;
  if (pi->voltage_control)
@@ -5899,6 +5896,17 @@ int si_dpm_enable(struct radeon_device *rdev)
  si_enable_sclk_control(rdev, true);
  si_start_dpm(rdev);
 
+ si_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
+
+ ni_update_current_ps(rdev, boot_ps);
+
+ return 0;
+}
+
+int si_dpm_late_enable(struct radeon_device *rdev)
+{
+ int ret;
+
  if (rdev->irq.installed &&
      r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
   PPSMC_Result result;
@@ -5914,17 +5922,6 @@ int si_dpm_enable(struct radeon_device *rdev)
    DRM_DEBUG_KMS("Could not enable thermal interrupts.\n");
  }
 
- si_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);
-
- si_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-       RADEON_CG_BLOCK_MC |
-       RADEON_CG_BLOCK_SDMA |
-       RADEON_CG_BLOCK_BIF |
-       RADEON_CG_BLOCK_UVD |
-       RADEON_CG_BLOCK_HDP), true);
-
- ni_update_current_ps(rdev, boot_ps);
-
  return 0;
 }
 
@@ -5933,13 +5930,6 @@ void si_dpm_disable(struct radeon_device *rdev)
  struct rv7xx_power_info *pi = rv770_get_pi(rdev);
  struct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;
 
- si_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-       RADEON_CG_BLOCK_MC |
-       RADEON_CG_BLOCK_SDMA |
-       RADEON_CG_BLOCK_BIF |
-       RADEON_CG_BLOCK_UVD |
-       RADEON_CG_BLOCK_HDP), false);
-
  if (!si_is_smc_running(rdev))
   return;
  si_disable_ulv(rdev);
@@ -6004,13 +5994,6 @@ int si_dpm_set_power_state(struct radeon_device *rdev)
  struct radeon_ps *old_ps = &eg_pi->current_rps;
  int ret;
 
- si_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-       RADEON_CG_BLOCK_MC |
-       RADEON_CG_BLOCK_SDMA |
-       RADEON_CG_BLOCK_BIF |
-       RADEON_CG_BLOCK_UVD |
-       RADEON_CG_BLOCK_HDP), false);
-
  ret = si_disable_ulv(rdev);
  if (ret) {
   DRM_ERROR("si_disable_ulv failed\n");
@@ -6103,13 +6086,6 @@ int si_dpm_set_power_state(struct radeon_device *rdev)
   return ret;
  }
 
- si_update_cg(rdev, (RADEON_CG_BLOCK_GFX |
-       RADEON_CG_BLOCK_MC |
-       RADEON_CG_BLOCK_SDMA |
-       RADEON_CG_BLOCK_BIF |
-       RADEON_CG_BLOCK_UVD |
-       RADEON_CG_BLOCK_HDP), true);
-
  return 0;
 }
 
@@ -6496,7 +6472,8 @@ void si_dpm_fini(struct radeon_device *rdev)
 void si_dpm_debugfs_print_current_performance_level(struct radeon_device *rdev,
           struct seq_file *m)
 {
- struct radeon_ps *rps = rdev->pm.dpm.current_ps;
+ struct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);
+ struct radeon_ps *rps = &eg_pi->current_rps;
  struct ni_ps *ps = ni_get_ps(rps);
  struct rv7xx_pl *pl;
  u32 current_index =
diff --git a/drivers/gpu/drm/radeon/si_smc.c b/drivers/gpu/drm/radeon/si_smc.c
index d422a1c..e80efcf 100644
--- a/drivers/gpu/drm/radeon/si_smc.c
+++ b/drivers/gpu/drm/radeon/si_smc.c
@@ -28,6 +28,7 @@
 #include "sid.h"
 #include "ppsmc.h"
 #include "radeon_ucode.h"
+#include "sislands_smc.h"
 
 static int si_set_smc_sram_address(struct radeon_device *rdev,
        u32 smc_address, u32 limit)
diff --git a/drivers/gpu/drm/radeon/sid.h b/drivers/gpu/drm/radeon/sid.h
index 9a68e76..9239a6d 100644
--- a/drivers/gpu/drm/radeon/sid.h
+++ b/drivers/gpu/drm/radeon/sid.h
@@ -94,6 +94,8 @@
 #define CG_SPLL_FUNC_CNTL_2    0x604
 #define  SCLK_MUX_SEL(x)    ((x) << 0)
 #define  SCLK_MUX_SEL_MASK   (0x1ff << 0)
+#define  SPLL_CTLREQ_CHG    (1 << 23)
+#define  SCLK_MUX_UPDATE    (1 << 26)
 #define CG_SPLL_FUNC_CNTL_3    0x608
 #define  SPLL_FB_DIV(x)    ((x) << 0)
 #define  SPLL_FB_DIV_MASK   (0x3ffffff << 0)
@@ -101,7 +103,10 @@
 #define  SPLL_DITHEN    (1 << 28)
 #define CG_SPLL_FUNC_CNTL_4    0x60c
 
+#define SPLL_STATUS     0x614
+#define  SPLL_CHG_STATUS    (1 << 1)
 #define SPLL_CNTL_MODE     0x618
+#define  SPLL_SW_DIR_CONTROL   (1 << 0)
 # define SPLL_REFCLK_SEL(x)   ((x) << 8)
 # define SPLL_REFCLK_SEL_MASK   0xFF00
 
@@ -559,6 +564,8 @@
 #       define MRDCK0_BYPASS                            (1 << 24)
 #       define MRDCK1_BYPASS                            (1 << 25)
 
+#define MPLL_CNTL_MODE     0x2bb0
+#       define MPLL_MCLK_SEL                            (1 << 11)
 #define MPLL_FUNC_CNTL     0x2bb4
 #define  BWCTRL(x)    ((x) << 20)
 #define  BWCTRL_MASK    (0xff << 20)
diff --git a/drivers/gpu/drm/radeon/sislands_smc.h b/drivers/gpu/drm/radeon/sislands_smc.h
index 5578e98..10e945a 100644
--- a/drivers/gpu/drm/radeon/sislands_smc.h
+++ b/drivers/gpu/drm/radeon/sislands_smc.h
@@ -374,8 +374,6 @@ typedef struct Smc_SIslands_DTE_Configuration Smc_SIslands_DTE_Configuration;
 
 #pragma pack(pop)
 
-int si_set_smc_sram_address(struct radeon_device *rdev,
-       u32 smc_address, u32 limit);
 int si_copy_bytes_to_smc(struct radeon_device *rdev,
     u32 smc_start_address,
     const u8 *src, u32 byte_count, u32 limit);
diff --git a/drivers/gpu/drm/radeon/sumo_dpm.c b/drivers/gpu/drm/radeon/sumo_dpm.c
index 96ea6db..8b47b3c 100644
--- a/drivers/gpu/drm/radeon/sumo_dpm.c
+++ b/drivers/gpu/drm/radeon/sumo_dpm.c
@@ -71,7 +71,7 @@ static const u32 sumo_dtc[SUMO_PM_NUMBER_OF_TC] =
  SUMO_DTC_DFLT_14,
 };
 
-struct sumo_ps *sumo_get_ps(struct radeon_ps *rps)
+static struct sumo_ps *sumo_get_ps(struct radeon_ps *rps)
 {
  struct sumo_ps *ps = rps->ps_priv;
 
@@ -1202,14 +1202,10 @@ static void sumo_update_requested_ps(struct radeon_device *rdev,
 int sumo_dpm_enable(struct radeon_device *rdev)
 {
  struct sumo_power_info *pi = sumo_get_pi(rdev);
- int ret;
 
  if (sumo_dpm_enabled(rdev))
   return -EINVAL;
 
- ret = sumo_enable_clock_power_gating(rdev);
- if (ret)
-  return ret;
  sumo_program_bootup_state(rdev);
  sumo_init_bsp(rdev);
  sumo_reset_am(rdev);
@@ -1233,6 +1229,19 @@ int sumo_dpm_enable(struct radeon_device *rdev)
  if (pi->enable_boost)
   sumo_enable_boost_timer(rdev);
 
+ sumo_update_current_ps(rdev, rdev->pm.dpm.boot_ps);
+
+ return 0;
+}
+
+int sumo_dpm_late_enable(struct radeon_device *rdev)
+{
+ int ret;
+
+ ret = sumo_enable_clock_power_gating(rdev);
+ if (ret)
+  return ret;
+
  if (rdev->irq.installed &&
      r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
   ret = sumo_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);
@@ -1242,8 +1251,6 @@ int sumo_dpm_enable(struct radeon_device *rdev)
   radeon_irq_set(rdev);
  }
 
- sumo_update_current_ps(rdev, rdev->pm.dpm.boot_ps);
-
  return 0;
 }
 
@@ -1800,7 +1807,7 @@ void sumo_dpm_debugfs_print_current_performance_level(struct radeon_device *rdev
             struct seq_file *m)
 {
  struct sumo_power_info *pi = sumo_get_pi(rdev);
- struct radeon_ps *rps = rdev->pm.dpm.current_ps;
+ struct radeon_ps *rps = &pi->current_rps;
  struct sumo_ps *ps = sumo_get_ps(rps);
  struct sumo_pl *pl;
  u32 current_index =
diff --git a/drivers/gpu/drm/radeon/sumo_smc.c b/drivers/gpu/drm/radeon/sumo_smc.c
index 18abba5..fb081d2 100644
--- a/drivers/gpu/drm/radeon/sumo_smc.c
+++ b/drivers/gpu/drm/radeon/sumo_smc.c
@@ -31,7 +31,6 @@
 #define SUMO_SMU_SERVICE_ROUTINE_ALTVDDNB_NOTIFY  27
 #define SUMO_SMU_SERVICE_ROUTINE_GFX_SRV_ID_20  20
 
-struct sumo_ps *sumo_get_ps(struct radeon_ps *rps);
 struct sumo_power_info *sumo_get_pi(struct radeon_device *rdev);
 
 static void sumo_send_msg_to_smu(struct radeon_device *rdev, u32 id)
diff --git a/drivers/gpu/drm/radeon/trinity_dpm.c b/drivers/gpu/drm/radeon/trinity_dpm.c
index d700698..2da0e17 100644
--- a/drivers/gpu/drm/radeon/trinity_dpm.c
+++ b/drivers/gpu/drm/radeon/trinity_dpm.c
@@ -342,14 +342,14 @@ static void trinity_apply_state_adjust_rules(struct radeon_device *rdev,
           struct radeon_ps *new_rps,
           struct radeon_ps *old_rps);
 
-struct trinity_ps *trinity_get_ps(struct radeon_ps *rps)
+static struct trinity_ps *trinity_get_ps(struct radeon_ps *rps)
 {
  struct trinity_ps *ps = rps->ps_priv;
 
  return ps;
 }
 
-struct trinity_power_info *trinity_get_pi(struct radeon_device *rdev)
+static struct trinity_power_info *trinity_get_pi(struct radeon_device *rdev)
 {
  struct trinity_power_info *pi = rdev->pm.dpm.priv;
 
@@ -1082,7 +1082,6 @@ void trinity_dpm_enable_bapm(struct radeon_device *rdev, bool enable)
 int trinity_dpm_enable(struct radeon_device *rdev)
 {
  struct trinity_power_info *pi = trinity_get_pi(rdev);
- int ret;
 
  trinity_acquire_mutex(rdev);
 
@@ -1091,7 +1090,6 @@ int trinity_dpm_enable(struct radeon_device *rdev)
   return -EINVAL;
  }
 
- trinity_enable_clock_power_gating(rdev);
  trinity_program_bootup_state(rdev);
  sumo_program_vc(rdev, 0x00C00033);
  trinity_start_am(rdev);
@@ -1105,6 +1103,18 @@ int trinity_dpm_enable(struct radeon_device *rdev)
  trinity_dpm_bapm_enable(rdev, false);
  trinity_release_mutex(rdev);
 
+ trinity_update_current_ps(rdev, rdev->pm.dpm.boot_ps);
+
+ return 0;
+}
+
+int trinity_dpm_late_enable(struct radeon_device *rdev)
+{
+ int ret;
+
+ trinity_acquire_mutex(rdev);
+ trinity_enable_clock_power_gating(rdev);
+
  if (rdev->irq.installed &&
      r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {
   ret = trinity_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);
@@ -1115,8 +1125,7 @@ int trinity_dpm_enable(struct radeon_device *rdev)
   rdev->irq.dpm_thermal = true;
   radeon_irq_set(rdev);
  }
-
- trinity_update_current_ps(rdev, rdev->pm.dpm.boot_ps);
+ trinity_release_mutex(rdev);
 
  return 0;
 }
@@ -1917,7 +1926,8 @@ void trinity_dpm_print_power_state(struct radeon_device *rdev,
 void trinity_dpm_debugfs_print_current_performance_level(struct radeon_device *rdev,
         struct seq_file *m)
 {
- struct radeon_ps *rps = rdev->pm.dpm.current_ps;
+ struct trinity_power_info *pi = trinity_get_pi(rdev);
+ struct radeon_ps *rps = &pi->current_rps;
  struct trinity_ps *ps = trinity_get_ps(rps);
  struct trinity_pl *pl;
  u32 current_index =
diff --git a/drivers/gpu/drm/radeon/trinity_smc.c b/drivers/gpu/drm/radeon/trinity_smc.c
index 9672bcb..99dd045 100644
--- a/drivers/gpu/drm/radeon/trinity_smc.c
+++ b/drivers/gpu/drm/radeon/trinity_smc.c
@@ -27,9 +27,6 @@
 #include "trinity_dpm.h"
 #include "ppsmc.h"
 
-struct trinity_ps *trinity_get_ps(struct radeon_ps *rps);
-struct trinity_power_info *trinity_get_pi(struct radeon_device *rdev);
-
 static int trinity_notify_message_to_smu(struct radeon_device *rdev, u32 id)
 {
  int i;
diff --git a/drivers/gpu/drm/radeon/uvd_v2_2.c b/drivers/gpu/drm/radeon/uvd_v2_2.c
index 824550d..d177100 100644
--- a/drivers/gpu/drm/radeon/uvd_v2_2.c
+++ b/drivers/gpu/drm/radeon/uvd_v2_2.c
@@ -57,7 +57,6 @@ void uvd_v2_2_fence_emit(struct radeon_device *rdev,
  radeon_ring_write(ring, 0);
  radeon_ring_write(ring, PACKET0(UVD_GPCOM_VCPU_CMD, 0));
  radeon_ring_write(ring, 2);
- return;
 }
 
 /**
diff --git a/drivers/gpu/drm/savage/savage_bci.c b/drivers/gpu/drm/savage/savage_bci.c
index b17d071..d2b2df9 100644
--- a/drivers/gpu/drm/savage/savage_bci.c
+++ b/drivers/gpu/drm/savage/savage_bci.c
@@ -49,7 +49,7 @@ savage_bci_wait_fifo_shadow(drm_savage_private_t * dev_priv, unsigned int n)
 #endif
 
  for (i = 0; i < SAVAGE_DEFAULT_USEC_TIMEOUT; i++) {
-  DRM_MEMORYBARRIER();
+  mb();
   status = dev_priv->status_ptr[0];
   if ((status & mask) < threshold)
    return 0;
@@ -123,7 +123,7 @@ savage_bci_wait_event_shadow(drm_savage_private_t * dev_priv, uint16_t e)
  int i;
 
  for (i = 0; i < SAVAGE_EVENT_USEC_TIMEOUT; i++) {
-  DRM_MEMORYBARRIER();
+  mb();
   status = dev_priv->status_ptr[1];
   if ((((status & 0xffff) - e) & 0xffff) <= 0x7fff ||
       (status & 0xffff) == 0)
@@ -449,7 +449,7 @@ static void savage_dma_flush(drm_savage_private_t * dev_priv)
   }
  }
 
- DRM_MEMORYBARRIER();
+ mb();
 
  /* do flush ... */
  phys_addr = dev_priv->cmd_dma->offset +
@@ -990,10 +990,10 @@ static int savage_bci_get_buffers(struct drm_device *dev,
 
   buf->file_priv = file_priv;
 
-  if (DRM_COPY_TO_USER(&d->request_indices[i],
+  if (copy_to_user(&d->request_indices[i],
          &buf->idx, sizeof(buf->idx)))
    return -EFAULT;
-  if (DRM_COPY_TO_USER(&d->request_sizes[i],
+  if (copy_to_user(&d->request_sizes[i],
          &buf->total, sizeof(buf->total)))
    return -EFAULT;
 
diff --git a/drivers/gpu/drm/savage/savage_state.c b/drivers/gpu/drm/savage/savage_state.c
index b35e75e..c01ad0a 100644
--- a/drivers/gpu/drm/savage/savage_state.c
+++ b/drivers/gpu/drm/savage/savage_state.c
@@ -992,7 +992,7 @@ int savage_bci_cmdbuf(struct drm_device *dev, void *data, struct drm_file *file_
   if (kcmd_addr == NULL)
    return -ENOMEM;
 
-  if (DRM_COPY_FROM_USER(kcmd_addr, cmdbuf->cmd_addr,
+  if (copy_from_user(kcmd_addr, cmdbuf->cmd_addr,
            cmdbuf->size * 8))
   {
    kfree(kcmd_addr);
@@ -1007,7 +1007,7 @@ int savage_bci_cmdbuf(struct drm_device *dev, void *data, struct drm_file *file_
    goto done;
   }
 
-  if (DRM_COPY_FROM_USER(kvb_addr, cmdbuf->vb_addr,
+  if (copy_from_user(kvb_addr, cmdbuf->vb_addr,
            cmdbuf->vb_size)) {
    ret = -EFAULT;
    goto done;
@@ -1022,7 +1022,7 @@ int savage_bci_cmdbuf(struct drm_device *dev, void *data, struct drm_file *file_
    goto done;
   }
 
-  if (DRM_COPY_FROM_USER(kbox_addr, cmdbuf->box_addr,
+  if (copy_from_user(kbox_addr, cmdbuf->box_addr,
            cmdbuf->nbox * sizeof(struct drm_clip_rect))) {
    ret = -EFAULT;
    goto done;
@@ -1032,7 +1032,7 @@ int savage_bci_cmdbuf(struct drm_device *dev, void *data, struct drm_file *file_
 
  /* Make sure writes to DMA buffers are finished before sending
   * DMA commands to the graphics hardware. */
- DRM_MEMORYBARRIER();
+ mb();
 
  /* Coming from user space. Don't know if the Xserver has
   * emitted wait commands. Assuming the worst. */
diff --git a/drivers/gpu/drm/sis/sis_drv.c b/drivers/gpu/drm/sis/sis_drv.c
index 4383b74..756f787 100644
--- a/drivers/gpu/drm/sis/sis_drv.c
+++ b/drivers/gpu/drm/sis/sis_drv.c
@@ -94,7 +94,7 @@ static int sis_driver_open(struct drm_device *dev, struct drm_file *file)
  return 0;
 }
 
-void sis_driver_postclose(struct drm_device *dev, struct drm_file *file)
+static void sis_driver_postclose(struct drm_device *dev, struct drm_file *file)
 {
  struct sis_file_private *file_priv = file->driver_priv;
 
diff --git a/drivers/gpu/drm/sis/sis_mm.c b/drivers/gpu/drm/sis/sis_mm.c
index 01857d8..0573be0 100644
--- a/drivers/gpu/drm/sis/sis_mm.c
+++ b/drivers/gpu/drm/sis/sis_mm.c
@@ -266,7 +266,7 @@ int sis_idle(struct drm_device *dev)
   * because its polling frequency is too low.
   */
 
- end = jiffies + (DRM_HZ * 3);
+ end = jiffies + (HZ * 3);
 
  for (i = 0; i < 4; ++i) {
   do {
diff --git a/drivers/gpu/drm/ttm/ttm_agp_backend.c b/drivers/gpu/drm/ttm/ttm_agp_backend.c
index 3302f99..764be36 100644
--- a/drivers/gpu/drm/ttm/ttm_agp_backend.c
+++ b/drivers/gpu/drm/ttm/ttm_agp_backend.c
@@ -126,6 +126,7 @@ struct ttm_tt *ttm_agp_tt_create(struct ttm_bo_device *bdev,
  agp_be->ttm.func = &ttm_agp_func;
 
  if (ttm_tt_init(&agp_be->ttm, bdev, size, page_flags, dummy_read_page)) {
+  kfree(agp_be);
   return NULL;
  }
 
diff --git a/drivers/gpu/drm/ttm/ttm_bo.c b/drivers/gpu/drm/ttm/ttm_bo.c
index d8d88bd..214b799 100644
--- a/drivers/gpu/drm/ttm/ttm_bo.c
+++ b/drivers/gpu/drm/ttm/ttm_bo.c
@@ -959,7 +959,7 @@ int ttm_bo_mem_space(struct ttm_buffer_object *bo,
 }
 EXPORT_SYMBOL(ttm_bo_mem_space);
 
-int ttm_bo_move_buffer(struct ttm_buffer_object *bo,
+static int ttm_bo_move_buffer(struct ttm_buffer_object *bo,
    struct ttm_placement *placement,
    bool interruptible,
    bool no_wait_gpu)
diff --git a/drivers/gpu/drm/ttm/ttm_bo_util.c b/drivers/gpu/drm/ttm/ttm_bo_util.c
index 4061521..1df856f 100644
--- a/drivers/gpu/drm/ttm/ttm_bo_util.c
+++ b/drivers/gpu/drm/ttm/ttm_bo_util.c
@@ -187,7 +187,7 @@ void ttm_mem_io_free_vm(struct ttm_buffer_object *bo)
  }
 }
 
-int ttm_mem_reg_ioremap(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem,
+static int ttm_mem_reg_ioremap(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem,
    void **virtual)
 {
  struct ttm_mem_type_manager *man = &bdev->man[mem->mem_type];
@@ -219,7 +219,7 @@ int ttm_mem_reg_ioremap(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem,
  return 0;
 }
 
-void ttm_mem_reg_iounmap(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem,
+static void ttm_mem_reg_iounmap(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem,
     void *virtual)
 {
  struct ttm_mem_type_manager *man;
@@ -594,7 +594,7 @@ int ttm_bo_kmap(struct ttm_buffer_object *bo,
  if (start_page > bo->num_pages)
   return -EINVAL;
 #if 0
- if (num_pages > 1 && !DRM_SUSER(DRM_CURPROC))
+ if (num_pages > 1 && !capable(CAP_SYS_ADMIN))
   return -EPERM;
 #endif
  (void) ttm_mem_io_lock(man, false);
diff --git a/drivers/gpu/drm/ttm/ttm_bo_vm.c b/drivers/gpu/drm/ttm/ttm_bo_vm.c
index 6440eea..0ce48e5 100644
--- a/drivers/gpu/drm/ttm/ttm_bo_vm.c
+++ b/drivers/gpu/drm/ttm/ttm_bo_vm.c
@@ -132,6 +132,15 @@ static int ttm_bo_vm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
   return VM_FAULT_NOPAGE;
  }
 
+ /*
+  * Refuse to fault imported pages. This should be handled
+  * (if at all) by redirecting mmap to the exporter.
+  */
+ if (bo->ttm && (bo->ttm->page_flags & TTM_PAGE_FLAG_SG)) {
+  retval = VM_FAULT_SIGBUS;
+  goto out_unlock;
+ }
+
  if (bdev->driver->fault_reserve_notify) {
   ret = bdev->driver->fault_reserve_notify(bo);
   switch (ret) {
@@ -217,10 +226,17 @@ static int ttm_bo_vm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
    } else if (unlikely(!page)) {
     break;
    }
+   page->mapping = vma->vm_file->f_mapping;
+   page->index = drm_vma_node_start(&bo->vma_node) +
+    page_offset;
    pfn = page_to_pfn(page);
   }
 
-  ret = vm_insert_mixed(&cvma, address, pfn);
+  if (vma->vm_flags & VM_MIXEDMAP)
+   ret = vm_insert_mixed(&cvma, address, pfn);
+  else
+   ret = vm_insert_pfn(&cvma, address, pfn);
+
   /*
    * Somebody beat us to this PTE or prefaulting to
    * an already populated PTE, or prefaulting error.
@@ -250,6 +266,8 @@ static void ttm_bo_vm_open(struct vm_area_struct *vma)
  struct ttm_buffer_object *bo =
      (struct ttm_buffer_object *)vma->vm_private_data;
 
+ WARN_ON(bo->bdev->dev_mapping != vma->vm_file->f_mapping);
+
  (void)ttm_bo_reference(bo);
 }
 
@@ -319,7 +337,16 @@ int ttm_bo_mmap(struct file *filp, struct vm_area_struct *vma,
   */
 
  vma->vm_private_data = bo;
- vma->vm_flags |= VM_IO | VM_MIXEDMAP | VM_DONTEXPAND | VM_DONTDUMP;
+
+ /*
+  * We'd like to use VM_PFNMAP on shared mappings, where
+  * (vma->vm_flags & VM_SHARED) != 0, for performance reasons,
+  * but for some reason VM_PFNMAP + x86 PAT + write-combine is very
+  * bad for performance. Until that has been sorted out, use
+  * VM_MIXEDMAP on all mappings. See freedesktop.org bug #75719
+  */
+ vma->vm_flags |= VM_MIXEDMAP;
+ vma->vm_flags |= VM_IO | VM_DONTEXPAND | VM_DONTDUMP;
  return 0;
 out_unref:
  ttm_bo_unref(&bo);
@@ -334,7 +361,8 @@ int ttm_fbdev_mmap(struct vm_area_struct *vma, struct ttm_buffer_object *bo)
 
  vma->vm_ops = &ttm_bo_vm_ops;
  vma->vm_private_data = ttm_bo_reference(bo);
- vma->vm_flags |= VM_IO | VM_MIXEDMAP | VM_DONTEXPAND;
+ vma->vm_flags |= VM_MIXEDMAP;
+ vma->vm_flags |= VM_IO | VM_DONTEXPAND;
  return 0;
 }
 EXPORT_SYMBOL(ttm_fbdev_mmap);
diff --git a/drivers/gpu/drm/ttm/ttm_lock.c b/drivers/gpu/drm/ttm/ttm_lock.c
index 3daa9a3..6a95454 100644
--- a/drivers/gpu/drm/ttm/ttm_lock.c
+++ b/drivers/gpu/drm/ttm/ttm_lock.c
@@ -186,14 +186,6 @@ int ttm_write_lock(struct ttm_lock *lock, bool interruptible)
 }
 EXPORT_SYMBOL(ttm_write_lock);
 
-void ttm_write_lock_downgrade(struct ttm_lock *lock)
-{
- spin_lock(&lock->lock);
- lock->rw = 1;
- wake_up_all(&lock->queue);
- spin_unlock(&lock->lock);
-}
-
 static int __ttm_vt_unlock(struct ttm_lock *lock)
 {
  int ret = 0;
diff --git a/drivers/gpu/drm/ttm/ttm_object.c b/drivers/gpu/drm/ttm/ttm_object.c
index 6fe7b92..53b51c4 100644
--- a/drivers/gpu/drm/ttm/ttm_object.c
+++ b/drivers/gpu/drm/ttm/ttm_object.c
@@ -68,7 +68,7 @@
 
 struct ttm_object_file {
  struct ttm_object_device *tdev;
- rwlock_t lock;
+ spinlock_t lock;
  struct list_head ref_list;
  struct drm_open_hash ref_hash[TTM_REF_NUM];
  struct kref refcount;
@@ -118,6 +118,7 @@ struct ttm_object_device {
  */
 
 struct ttm_ref_object {
+ struct rcu_head rcu_head;
  struct drm_hash_item hash;
  struct list_head head;
  struct kref kref;
@@ -210,10 +211,9 @@ static void ttm_release_base(struct kref *kref)
   * call_rcu() or ttm_base_object_kfree().
   */
 
- if (base->refcount_release) {
-  ttm_object_file_unref(&base->tfile);
+ ttm_object_file_unref(&base->tfile);
+ if (base->refcount_release)
   base->refcount_release(&base);
- }
 }
 
 void ttm_base_object_unref(struct ttm_base_object **p_base)
@@ -229,32 +229,46 @@ EXPORT_SYMBOL(ttm_base_object_unref);
 struct ttm_base_object *ttm_base_object_lookup(struct ttm_object_file *tfile,
             uint32_t key)
 {
- struct ttm_object_device *tdev = tfile->tdev;
- struct ttm_base_object *uninitialized_var(base);
+ struct ttm_base_object *base = NULL;
  struct drm_hash_item *hash;
+ struct drm_open_hash *ht = &tfile->ref_hash[TTM_REF_USAGE];
  int ret;
 
  rcu_read_lock();
- ret = drm_ht_find_item_rcu(&tdev->object_hash, key, &hash);
+ ret = drm_ht_find_item_rcu(ht, key, &hash);
 
  if (likely(ret == 0)) {
-  base = drm_hash_entry(hash, struct ttm_base_object, hash);
-  ret = kref_get_unless_zero(&base->refcount) ? 0 : -EINVAL;
+  base = drm_hash_entry(hash, struct ttm_ref_object, hash)->obj;
+  if (!kref_get_unless_zero(&base->refcount))
+   base = NULL;
  }
  rcu_read_unlock();
 
- if (unlikely(ret != 0))
-  return NULL;
+ return base;
+}
+EXPORT_SYMBOL(ttm_base_object_lookup);
 
- if (tfile != base->tfile && !base->shareable) {
-  pr_err("Attempted access of non-shareable object\n");
-  ttm_base_object_unref(&base);
-  return NULL;
+struct ttm_base_object *
+ttm_base_object_lookup_for_ref(struct ttm_object_device *tdev, uint32_t key)
+{
+ struct ttm_base_object *base = NULL;
+ struct drm_hash_item *hash;
+ struct drm_open_hash *ht = &tdev->object_hash;
+ int ret;
+
+ rcu_read_lock();
+ ret = drm_ht_find_item_rcu(ht, key, &hash);
+
+ if (likely(ret == 0)) {
+  base = drm_hash_entry(hash, struct ttm_base_object, hash);
+  if (!kref_get_unless_zero(&base->refcount))
+   base = NULL;
  }
+ rcu_read_unlock();
 
  return base;
 }
-EXPORT_SYMBOL(ttm_base_object_lookup);
+EXPORT_SYMBOL(ttm_base_object_lookup_for_ref);
 
 int ttm_ref_object_add(struct ttm_object_file *tfile,
          struct ttm_base_object *base,
@@ -266,21 +280,25 @@ int ttm_ref_object_add(struct ttm_object_file *tfile,
  struct ttm_mem_global *mem_glob = tfile->tdev->mem_glob;
  int ret = -EINVAL;
 
+ if (base->tfile != tfile && !base->shareable)
+  return -EPERM;
+
  if (existed != NULL)
   *existed = true;
 
  while (ret == -EINVAL) {
-  read_lock(&tfile->lock);
-  ret = drm_ht_find_item(ht, base->hash.key, &hash);
+  rcu_read_lock();
+  ret = drm_ht_find_item_rcu(ht, base->hash.key, &hash);
 
   if (ret == 0) {
    ref = drm_hash_entry(hash, struct ttm_ref_object, hash);
-   kref_get(&ref->kref);
-   read_unlock(&tfile->lock);
-   break;
+   if (kref_get_unless_zero(&ref->kref)) {
+    rcu_read_unlock();
+    break;
+   }
   }
 
-  read_unlock(&tfile->lock);
+  rcu_read_unlock();
   ret = ttm_mem_global_alloc(mem_glob, sizeof(*ref),
         false, false);
   if (unlikely(ret != 0))
@@ -297,19 +315,19 @@ int ttm_ref_object_add(struct ttm_object_file *tfile,
   ref->ref_type = ref_type;
   kref_init(&ref->kref);
 
-  write_lock(&tfile->lock);
-  ret = drm_ht_insert_item(ht, &ref->hash);
+  spin_lock(&tfile->lock);
+  ret = drm_ht_insert_item_rcu(ht, &ref->hash);
 
   if (likely(ret == 0)) {
    list_add_tail(&ref->head, &tfile->ref_list);
    kref_get(&base->refcount);
-   write_unlock(&tfile->lock);
+   spin_unlock(&tfile->lock);
    if (existed != NULL)
     *existed = false;
    break;
   }
 
-  write_unlock(&tfile->lock);
+  spin_unlock(&tfile->lock);
   BUG_ON(ret != -EINVAL);
 
   ttm_mem_global_free(mem_glob, sizeof(*ref));
@@ -330,17 +348,17 @@ static void ttm_ref_object_release(struct kref *kref)
  struct ttm_mem_global *mem_glob = tfile->tdev->mem_glob;
 
  ht = &tfile->ref_hash[ref->ref_type];
- (void)drm_ht_remove_item(ht, &ref->hash);
+ (void)drm_ht_remove_item_rcu(ht, &ref->hash);
  list_del(&ref->head);
- write_unlock(&tfile->lock);
+ spin_unlock(&tfile->lock);
 
  if (ref->ref_type != TTM_REF_USAGE && base->ref_obj_release)
   base->ref_obj_release(base, ref->ref_type);
 
  ttm_base_object_unref(&ref->obj);
  ttm_mem_global_free(mem_glob, sizeof(*ref));
- kfree(ref);
- write_lock(&tfile->lock);
+ kfree_rcu(ref, rcu_head);
+ spin_lock(&tfile->lock);
 }
 
 int ttm_ref_object_base_unref(struct ttm_object_file *tfile,
@@ -351,15 +369,15 @@ int ttm_ref_object_base_unref(struct ttm_object_file *tfile,
  struct drm_hash_item *hash;
  int ret;
 
- write_lock(&tfile->lock);
+ spin_lock(&tfile->lock);
  ret = drm_ht_find_item(ht, key, &hash);
  if (unlikely(ret != 0)) {
-  write_unlock(&tfile->lock);
+  spin_unlock(&tfile->lock);
   return -EINVAL;
  }
  ref = drm_hash_entry(hash, struct ttm_ref_object, hash);
  kref_put(&ref->kref, ttm_ref_object_release);
- write_unlock(&tfile->lock);
+ spin_unlock(&tfile->lock);
  return 0;
 }
 EXPORT_SYMBOL(ttm_ref_object_base_unref);
@@ -372,7 +390,7 @@ void ttm_object_file_release(struct ttm_object_file **p_tfile)
  struct ttm_object_file *tfile = *p_tfile;
 
  *p_tfile = NULL;
- write_lock(&tfile->lock);
+ spin_lock(&tfile->lock);
 
  /*
   * Since we release the lock within the loop, we have to
@@ -388,7 +406,7 @@ void ttm_object_file_release(struct ttm_object_file **p_tfile)
  for (i = 0; i < TTM_REF_NUM; ++i)
   drm_ht_remove(&tfile->ref_hash[i]);
 
- write_unlock(&tfile->lock);
+ spin_unlock(&tfile->lock);
  ttm_object_file_unref(&tfile);
 }
 EXPORT_SYMBOL(ttm_object_file_release);
@@ -404,7 +422,7 @@ struct ttm_object_file *ttm_object_file_init(struct ttm_object_device *tdev,
  if (unlikely(tfile == NULL))
   return NULL;
 
- rwlock_init(&tfile->lock);
+ spin_lock_init(&tfile->lock);
  tfile->tdev = tdev;
  kref_init(&tfile->refcount);
  INIT_LIST_HEAD(&tfile->ref_list);
diff --git a/drivers/gpu/drm/ttm/ttm_tt.c b/drivers/gpu/drm/ttm/ttm_tt.c
index 210d503..75f3190 100644
--- a/drivers/gpu/drm/ttm/ttm_tt.c
+++ b/drivers/gpu/drm/ttm/ttm_tt.c
@@ -170,9 +170,8 @@ void ttm_tt_destroy(struct ttm_tt *ttm)
   ttm_tt_unbind(ttm);
  }
 
- if (ttm->state == tt_unbound) {
-  ttm->bdev->driver->ttm_tt_unpopulate(ttm);
- }
+ if (ttm->state == tt_unbound)
+  ttm_tt_unpopulate(ttm);
 
  if (!(ttm->page_flags & TTM_PAGE_FLAG_PERSISTENT_SWAP) &&
      ttm->swap_storage)
@@ -362,7 +361,7 @@ int ttm_tt_swapout(struct ttm_tt *ttm, struct file *persistent_swap_storage)
   page_cache_release(to_page);
  }
 
- ttm->bdev->driver->ttm_tt_unpopulate(ttm);
+ ttm_tt_unpopulate(ttm);
  ttm->swap_storage = swap_storage;
  ttm->page_flags |= TTM_PAGE_FLAG_SWAPPED;
  if (persistent_swap_storage)
@@ -375,3 +374,26 @@ out_err:
 
  return ret;
 }
+
+static void ttm_tt_clear_mapping(struct ttm_tt *ttm)
+{
+ pgoff_t i;
+ struct page **page = ttm->pages;
+
+ if (ttm->page_flags & TTM_PAGE_FLAG_SG)
+  return;
+
+ for (i = 0; i < ttm->num_pages; ++i) {
+  (*page)->mapping = NULL;
+  (*page++)->index = 0;
+ }
+}
+
+void ttm_tt_unpopulate(struct ttm_tt *ttm)
+{
+ if (ttm->state == tt_unpopulated)
+  return;
+
+ ttm_tt_clear_mapping(ttm);
+ ttm->bdev->driver->ttm_tt_unpopulate(ttm);
+}
diff --git a/drivers/gpu/drm/udl/udl_fb.c b/drivers/gpu/drm/udl/udl_fb.c
index 97e9d61..dbadd49 100644
--- a/drivers/gpu/drm/udl/udl_fb.c
+++ b/drivers/gpu/drm/udl/udl_fb.c
@@ -403,15 +403,17 @@ static int udl_user_framebuffer_dirty(struct drm_framebuffer *fb,
  int i;
  int ret = 0;
 
+ drm_modeset_lock_all(fb->dev);
+
  if (!ufb->active_16)
-  return 0;
+  goto unlock;
 
  if (ufb->obj->base.import_attach) {
   ret = dma_buf_begin_cpu_access(ufb->obj->base.import_attach->dmabuf,
             0, ufb->obj->base.size,
             DMA_FROM_DEVICE);
   if (ret)
-   return ret;
+   goto unlock;
  }
 
  for (i = 0; i < num_clips; i++) {
@@ -419,7 +421,7 @@ static int udl_user_framebuffer_dirty(struct drm_framebuffer *fb,
       clips[i].x2 - clips[i].x1,
       clips[i].y2 - clips[i].y1);
   if (ret)
-   break;
+   goto unlock;
  }
 
  if (ufb->obj->base.import_attach) {
@@ -427,6 +429,10 @@ static int udl_user_framebuffer_dirty(struct drm_framebuffer *fb,
            0, ufb->obj->base.size,
            DMA_FROM_DEVICE);
  }
+
+ unlock:
+ drm_modeset_unlock_all(fb->dev);
+
  return ret;
 }
 
diff --git a/drivers/gpu/drm/udl/udl_gem.c b/drivers/gpu/drm/udl/udl_gem.c
index 8d67b94..0394811 100644
--- a/drivers/gpu/drm/udl/udl_gem.c
+++ b/drivers/gpu/drm/udl/udl_gem.c
@@ -177,8 +177,10 @@ void udl_gem_free_object(struct drm_gem_object *gem_obj)
  if (obj->vmapping)
   udl_gem_vunmap(obj);
 
- if (gem_obj->import_attach)
+ if (gem_obj->import_attach) {
   drm_prime_gem_destroy(gem_obj, obj->sg);
+  put_device(gem_obj->dev->dev);
+ }
 
  if (obj->pages)
   udl_gem_put_pages(obj);
@@ -256,9 +258,12 @@ struct drm_gem_object *udl_gem_prime_import(struct drm_device *dev,
  int ret;
 
  /* need to attach */
+ get_device(dev->dev);
  attach = dma_buf_attach(dma_buf, dev->dev);
- if (IS_ERR(attach))
+ if (IS_ERR(attach)) {
+  put_device(dev->dev);
   return ERR_CAST(attach);
+ }
 
  get_dma_buf(dma_buf);
 
@@ -282,6 +287,6 @@ fail_unmap:
 fail_detach:
  dma_buf_detach(dma_buf, attach);
  dma_buf_put(dma_buf);
-
+ put_device(dev->dev);
  return ERR_PTR(ret);
 }
diff --git a/drivers/gpu/drm/via/via_dma.c b/drivers/gpu/drm/via/via_dma.c
index 652f9b4..a18479c 100644
--- a/drivers/gpu/drm/via/via_dma.c
+++ b/drivers/gpu/drm/via/via_dma.c
@@ -60,7 +60,7 @@
  dev_priv->dma_low += 8;     \
 }
 
-#define via_flush_write_combine() DRM_MEMORYBARRIER()
+#define via_flush_write_combine() mb()
 
 #define VIA_OUT_RING_QW(w1, w2) do {  \
  *vb++ = (w1);    \
@@ -234,13 +234,13 @@ static int via_dma_init(struct drm_device *dev, void *data, struct drm_file *fil
 
  switch (init->func) {
  case VIA_INIT_DMA:
-  if (!DRM_SUSER(DRM_CURPROC))
+  if (!capable(CAP_SYS_ADMIN))
    retcode = -EPERM;
   else
    retcode = via_initialize(dev, dev_priv, init);
   break;
  case VIA_CLEANUP_DMA:
-  if (!DRM_SUSER(DRM_CURPROC))
+  if (!capable(CAP_SYS_ADMIN))
    retcode = -EPERM;
   else
    retcode = via_dma_cleanup(dev);
@@ -273,7 +273,7 @@ static int via_dispatch_cmdbuffer(struct drm_device *dev, drm_via_cmdbuffer_t *c
  if (cmd->size > VIA_PCI_BUF_SIZE)
   return -ENOMEM;
 
- if (DRM_COPY_FROM_USER(dev_priv->pci_buf, cmd->buf, cmd->size))
+ if (copy_from_user(dev_priv->pci_buf, cmd->buf, cmd->size))
   return -EFAULT;
 
  /*
@@ -346,7 +346,7 @@ static int via_dispatch_pci_cmdbuffer(struct drm_device *dev,
 
  if (cmd->size > VIA_PCI_BUF_SIZE)
   return -ENOMEM;
- if (DRM_COPY_FROM_USER(dev_priv->pci_buf, cmd->buf, cmd->size))
+ if (copy_from_user(dev_priv->pci_buf, cmd->buf, cmd->size))
   return -EFAULT;
 
  if ((ret =
@@ -543,7 +543,7 @@ static void via_cmdbuf_start(drm_via_private_t *dev_priv)
 
  VIA_WRITE(VIA_REG_TRANSPACE, pause_addr_hi);
  VIA_WRITE(VIA_REG_TRANSPACE, pause_addr_lo);
- DRM_WRITEMEMORYBARRIER();
+ wmb();
  VIA_WRITE(VIA_REG_TRANSPACE, command | HC_HAGPCMNT_MASK);
  VIA_READ(VIA_REG_TRANSPACE);
 
diff --git a/drivers/gpu/drm/via/via_dmablit.c b/drivers/gpu/drm/via/via_dmablit.c
index 8b0f259..ba33cf6 100644
--- a/drivers/gpu/drm/via/via_dmablit.c
+++ b/drivers/gpu/drm/via/via_dmablit.c
@@ -217,7 +217,7 @@ via_fire_dmablit(struct drm_device *dev, drm_via_sg_info_t *vsg, int engine)
  VIA_WRITE(VIA_PCI_DMA_MR0  + engine*0x04, VIA_DMA_MR_CM | VIA_DMA_MR_TDIE);
  VIA_WRITE(VIA_PCI_DMA_BCR0 + engine*0x10, 0);
  VIA_WRITE(VIA_PCI_DMA_DPR0 + engine*0x10, vsg->chain_start);
- DRM_WRITEMEMORYBARRIER();
+ wmb();
  VIA_WRITE(VIA_PCI_DMA_CSR0 + engine*0x04, VIA_DMA_CSR_DE | VIA_DMA_CSR_TS);
  VIA_READ(VIA_PCI_DMA_CSR0 + engine*0x04);
 }
@@ -338,7 +338,7 @@ via_dmablit_handler(struct drm_device *dev, int engine, int from_irq)
 
   blitq->blits[cur]->aborted = blitq->aborting;
   blitq->done_blit_handle++;
-  DRM_WAKEUP(blitq->blit_queue + cur);
+  wake_up(blitq->blit_queue + cur);
 
   cur++;
   if (cur >= VIA_NUM_BLIT_SLOTS)
@@ -363,7 +363,7 @@ via_dmablit_handler(struct drm_device *dev, int engine, int from_irq)
 
   via_abort_dmablit(dev, engine);
   blitq->aborting = 1;
-  blitq->end = jiffies + DRM_HZ;
+  blitq->end = jiffies + HZ;
  }
 
  if (!blitq->is_active) {
@@ -372,7 +372,7 @@ via_dmablit_handler(struct drm_device *dev, int engine, int from_irq)
    blitq->is_active = 1;
    blitq->cur = cur;
    blitq->num_outstanding--;
-   blitq->end = jiffies + DRM_HZ;
+   blitq->end = jiffies + HZ;
    if (!timer_pending(&blitq->poll_timer))
     mod_timer(&blitq->poll_timer, jiffies + 1);
   } else {
@@ -436,7 +436,7 @@ via_dmablit_sync(struct drm_device *dev, uint32_t handle, int engine)
  int ret = 0;
 
  if (via_dmablit_active(blitq, engine, handle, &queue)) {
-  DRM_WAIT_ON(ret, *queue, 3 * DRM_HZ,
+  DRM_WAIT_ON(ret, *queue, 3 * HZ,
        !via_dmablit_active(blitq, engine, handle, NULL));
  }
  DRM_DEBUG("DMA blit sync handle 0x%x engine %d returned %d\n",
@@ -521,7 +521,7 @@ via_dmablit_workqueue(struct work_struct *work)
 
   spin_unlock_irqrestore(&blitq->blit_lock, irqsave);
 
-  DRM_WAKEUP(&blitq->busy_queue);
+  wake_up(&blitq->busy_queue);
 
   via_free_sg_info(dev->pdev, cur_sg);
   kfree(cur_sg);
@@ -561,8 +561,8 @@ via_init_dmablit(struct drm_device *dev)
   blitq->aborting = 0;
   spin_lock_init(&blitq->blit_lock);
   for (j = 0; j < VIA_NUM_BLIT_SLOTS; ++j)
-   DRM_INIT_WAITQUEUE(blitq->blit_queue + j);
-  DRM_INIT_WAITQUEUE(&blitq->busy_queue);
+   init_waitqueue_head(blitq->blit_queue + j);
+  init_waitqueue_head(&blitq->busy_queue);
   INIT_WORK(&blitq->wq, via_dmablit_workqueue);
   setup_timer(&blitq->poll_timer, via_dmablit_timer,
     (unsigned long)blitq);
@@ -688,7 +688,7 @@ via_dmablit_grab_slot(drm_via_blitq_t *blitq, int engine)
  while (blitq->num_free == 0) {
   spin_unlock_irqrestore(&blitq->blit_lock, irqsave);
 
-  DRM_WAIT_ON(ret, blitq->busy_queue, DRM_HZ, blitq->num_free > 0);
+  DRM_WAIT_ON(ret, blitq->busy_queue, HZ, blitq->num_free > 0);
   if (ret)
    return (-EINTR == ret) ? -EAGAIN : ret;
 
@@ -713,7 +713,7 @@ via_dmablit_release_slot(drm_via_blitq_t *blitq)
  spin_lock_irqsave(&blitq->blit_lock, irqsave);
  blitq->num_free++;
  spin_unlock_irqrestore(&blitq->blit_lock, irqsave);
- DRM_WAKEUP(&blitq->busy_queue);
+ wake_up(&blitq->busy_queue);
 }
 
 /*
diff --git a/drivers/gpu/drm/via/via_drv.c b/drivers/gpu/drm/via/via_drv.c
index 92684a9..50abc2a 100644
--- a/drivers/gpu/drm/via/via_drv.c
+++ b/drivers/gpu/drm/via/via_drv.c
@@ -46,7 +46,7 @@ static int via_driver_open(struct drm_device *dev, struct drm_file *file)
  return 0;
 }
 
-void via_driver_postclose(struct drm_device *dev, struct drm_file *file)
+static void via_driver_postclose(struct drm_device *dev, struct drm_file *file)
 {
  struct via_file_private *file_priv = file->driver_priv;
 
diff --git a/drivers/gpu/drm/via/via_drv.h b/drivers/gpu/drm/via/via_drv.h
index a811ef2..ad02732 100644
--- a/drivers/gpu/drm/via/via_drv.h
+++ b/drivers/gpu/drm/via/via_drv.h
@@ -138,7 +138,7 @@ extern u32 via_get_vblank_counter(struct drm_device *dev, int crtc);
 extern int via_enable_vblank(struct drm_device *dev, int crtc);
 extern void via_disable_vblank(struct drm_device *dev, int crtc);
 
-extern irqreturn_t via_driver_irq_handler(DRM_IRQ_ARGS);
+extern irqreturn_t via_driver_irq_handler(int irq, void *arg);
 extern void via_driver_irq_preinstall(struct drm_device *dev);
 extern int via_driver_irq_postinstall(struct drm_device *dev);
 extern void via_driver_irq_uninstall(struct drm_device *dev);
diff --git a/drivers/gpu/drm/via/via_irq.c b/drivers/gpu/drm/via/via_irq.c
index ac98964..1319433 100644
--- a/drivers/gpu/drm/via/via_irq.c
+++ b/drivers/gpu/drm/via/via_irq.c
@@ -104,7 +104,7 @@ u32 via_get_vblank_counter(struct drm_device *dev, int crtc)
  return atomic_read(&dev_priv->vbl_received);
 }
 
-irqreturn_t via_driver_irq_handler(DRM_IRQ_ARGS)
+irqreturn_t via_driver_irq_handler(int irq, void *arg)
 {
  struct drm_device *dev = (struct drm_device *) arg;
  drm_via_private_t *dev_priv = (drm_via_private_t *) dev->dev_private;
@@ -138,7 +138,7 @@ irqreturn_t via_driver_irq_handler(DRM_IRQ_ARGS)
  for (i = 0; i < dev_priv->num_irqs; ++i) {
   if (status & cur_irq->pending_mask) {
    atomic_inc(&cur_irq->irq_received);
-   DRM_WAKEUP(&cur_irq->irq_queue);
+   wake_up(&cur_irq->irq_queue);
    handled = 1;
    if (dev_priv->irq_map[drm_via_irq_dma0_td] == i)
     via_dmablit_handler(dev, 0, 1);
@@ -239,12 +239,12 @@ via_driver_irq_wait(struct drm_device *dev, unsigned int irq, int force_sequence
  cur_irq = dev_priv->via_irqs + real_irq;
 
  if (masks[real_irq][2] && !force_sequence) {
-  DRM_WAIT_ON(ret, cur_irq->irq_queue, 3 * DRM_HZ,
+  DRM_WAIT_ON(ret, cur_irq->irq_queue, 3 * HZ,
        ((VIA_READ(masks[irq][2]) & masks[irq][3]) ==
         masks[irq][4]));
   cur_irq_sequence = atomic_read(&cur_irq->irq_received);
  } else {
-  DRM_WAIT_ON(ret, cur_irq->irq_queue, 3 * DRM_HZ,
+  DRM_WAIT_ON(ret, cur_irq->irq_queue, 3 * HZ,
        (((cur_irq_sequence =
           atomic_read(&cur_irq->irq_received)) -
          *sequence) <= (1 << 23)));
@@ -287,7 +287,7 @@ void via_driver_irq_preinstall(struct drm_device *dev)
    atomic_set(&cur_irq->irq_received, 0);
    cur_irq->enable_mask = dev_priv->irq_masks[i][0];
    cur_irq->pending_mask = dev_priv->irq_masks[i][1];
-   DRM_INIT_WAITQUEUE(&cur_irq->irq_queue);
+   init_waitqueue_head(&cur_irq->irq_queue);
    dev_priv->irq_enable_mask |= cur_irq->enable_mask;
    dev_priv->irq_pending_mask |= cur_irq->pending_mask;
    cur_irq++;
diff --git a/drivers/gpu/drm/via/via_video.c b/drivers/gpu/drm/via/via_video.c
index 6569efa..a9ffbad 100644
--- a/drivers/gpu/drm/via/via_video.c
+++ b/drivers/gpu/drm/via/via_video.c
@@ -36,7 +36,7 @@ void via_init_futex(drm_via_private_t *dev_priv)
  DRM_DEBUG("\n");
 
  for (i = 0; i < VIA_NR_XVMC_LOCKS; ++i) {
-  DRM_INIT_WAITQUEUE(&(dev_priv->decoder_queue[i]));
+  init_waitqueue_head(&(dev_priv->decoder_queue[i]));
   XVMCLOCKPTR(dev_priv->sarea_priv, i)->lock = 0;
  }
 }
@@ -58,7 +58,7 @@ void via_release_futex(drm_via_private_t *dev_priv, int context)
   if ((_DRM_LOCKING_CONTEXT(*lock) == context)) {
    if (_DRM_LOCK_IS_HELD(*lock)
        && (*lock & _DRM_LOCK_CONT)) {
-    DRM_WAKEUP(&(dev_priv->decoder_queue[i]));
+    wake_up(&(dev_priv->decoder_queue[i]));
    }
    *lock = 0;
   }
@@ -83,10 +83,10 @@ int via_decoder_futex(struct drm_device *dev, void *data, struct drm_file *file_
  switch (fx->func) {
  case VIA_FUTEX_WAIT:
   DRM_WAIT_ON(ret, dev_priv->decoder_queue[fx->lock],
-       (fx->ms / 10) * (DRM_HZ / 100), *lock != fx->val);
+       (fx->ms / 10) * (HZ / 100), *lock != fx->val);
   return ret;
  case VIA_FUTEX_WAKE:
-  DRM_WAKEUP(&(dev_priv->decoder_queue[fx->lock]));
+  wake_up(&(dev_priv->decoder_queue[fx->lock]));
   return 0;
  }
  return 0;
diff --git a/drivers/gpu/drm/vmwgfx/Makefile b/drivers/gpu/drm/vmwgfx/Makefile
index 9f8b690..458cdf6 100644
--- a/drivers/gpu/drm/vmwgfx/Makefile
+++ b/drivers/gpu/drm/vmwgfx/Makefile
@@ -6,6 +6,6 @@ vmwgfx-y := vmwgfx_execbuf.o vmwgfx_gmr.o vmwgfx_kms.o vmwgfx_drv.o \
      vmwgfx_fifo.o vmwgfx_irq.o vmwgfx_ldu.o vmwgfx_ttm_glue.o \
      vmwgfx_overlay.o vmwgfx_marker.o vmwgfx_gmrid_manager.o \
      vmwgfx_fence.o vmwgfx_dmabuf.o vmwgfx_scrn.o vmwgfx_context.o \
-     vmwgfx_surface.o vmwgfx_prime.o
+     vmwgfx_surface.o vmwgfx_prime.o vmwgfx_mob.o vmwgfx_shader.o
 
 obj-$(CONFIG_DRM_VMWGFX) := vmwgfx.o
diff --git a/drivers/gpu/drm/vmwgfx/svga3d_reg.h b/drivers/gpu/drm/vmwgfx/svga3d_reg.h
index d0e085e..f58dc7d 100644
--- a/drivers/gpu/drm/vmwgfx/svga3d_reg.h
+++ b/drivers/gpu/drm/vmwgfx/svga3d_reg.h
@@ -34,6 +34,8 @@
 
 #include "svga_reg.h"
 
+typedef uint32 PPN;
+typedef __le64 PPN64;
 
 /*
  * 3D Hardware Version
@@ -71,6 +73,9 @@ typedef uint32 SVGA3dBool; /* 32-bit Bool definition */
 #define SVGA3D_MAX_CONTEXT_IDS                  256
 #define SVGA3D_MAX_SURFACE_IDS                  (32 * 1024)
 
+#define SVGA3D_NUM_TEXTURE_UNITS                32
+#define SVGA3D_NUM_LIGHTS                       8
+
 /*
  * Surface formats.
  *
@@ -81,6 +86,7 @@ typedef uint32 SVGA3dBool; /* 32-bit Bool definition */
  */
 
 typedef enum SVGA3dSurfaceFormat {
+   SVGA3D_FORMAT_MIN                   = 0,
    SVGA3D_FORMAT_INVALID               = 0,
 
    SVGA3D_X8R8G8B8                     = 1,
@@ -134,12 +140,6 @@ typedef enum SVGA3dSurfaceFormat {
    SVGA3D_RG_S10E5                     = 35,
    SVGA3D_RG_S23E8                     = 36,
 
-   /*
-    * Any surface can be used as a buffer object, but SVGA3D_BUFFER is
-    * the most efficient format to use when creating new surfaces
-    * expressly for index or vertex data.
-    */
-
    SVGA3D_BUFFER                       = 37,
 
    SVGA3D_Z_D24X8                      = 38,
@@ -159,15 +159,109 @@ typedef enum SVGA3dSurfaceFormat {
    /* Video format with alpha */
    SVGA3D_AYUV                         = 45,
 
+   SVGA3D_R32G32B32A32_TYPELESS        = 46,
+   SVGA3D_R32G32B32A32_FLOAT           = 25,
+   SVGA3D_R32G32B32A32_UINT            = 47,
+   SVGA3D_R32G32B32A32_SINT            = 48,
+   SVGA3D_R32G32B32_TYPELESS           = 49,
+   SVGA3D_R32G32B32_FLOAT              = 50,
+   SVGA3D_R32G32B32_UINT               = 51,
+   SVGA3D_R32G32B32_SINT               = 52,
+   SVGA3D_R16G16B16A16_TYPELESS        = 53,
+   SVGA3D_R16G16B16A16_FLOAT           = 24,
+   SVGA3D_R16G16B16A16_UNORM           = 41,
+   SVGA3D_R16G16B16A16_UINT            = 54,
+   SVGA3D_R16G16B16A16_SNORM           = 55,
+   SVGA3D_R16G16B16A16_SINT            = 56,
+   SVGA3D_R32G32_TYPELESS              = 57,
+   SVGA3D_R32G32_FLOAT                 = 36,
+   SVGA3D_R32G32_UINT                  = 58,
+   SVGA3D_R32G32_SINT                  = 59,
+   SVGA3D_R32G8X24_TYPELESS            = 60,
+   SVGA3D_D32_FLOAT_S8X24_UINT         = 61,
+   SVGA3D_R32_FLOAT_X8X24_TYPELESS     = 62,
+   SVGA3D_X32_TYPELESS_G8X24_UINT      = 63,
+   SVGA3D_R10G10B10A2_TYPELESS         = 64,
+   SVGA3D_R10G10B10A2_UNORM            = 26,
+   SVGA3D_R10G10B10A2_UINT             = 65,
+   SVGA3D_R11G11B10_FLOAT              = 66,
+   SVGA3D_R8G8B8A8_TYPELESS            = 67,
+   SVGA3D_R8G8B8A8_UNORM               = 68,
+   SVGA3D_R8G8B8A8_UNORM_SRGB          = 69,
+   SVGA3D_R8G8B8A8_UINT                = 70,
+   SVGA3D_R8G8B8A8_SNORM               = 28,
+   SVGA3D_R8G8B8A8_SINT                = 71,
+   SVGA3D_R16G16_TYPELESS              = 72,
+   SVGA3D_R16G16_FLOAT                 = 35,
+   SVGA3D_R16G16_UNORM                 = 40,
+   SVGA3D_R16G16_UINT                  = 73,
+   SVGA3D_R16G16_SNORM                 = 39,
+   SVGA3D_R16G16_SINT                  = 74,
+   SVGA3D_R32_TYPELESS                 = 75,
+   SVGA3D_D32_FLOAT                    = 76,
+   SVGA3D_R32_FLOAT                    = 34,
+   SVGA3D_R32_UINT                     = 77,
+   SVGA3D_R32_SINT                     = 78,
+   SVGA3D_R24G8_TYPELESS               = 79,
+   SVGA3D_D24_UNORM_S8_UINT            = 80,
+   SVGA3D_R24_UNORM_X8_TYPELESS        = 81,
+   SVGA3D_X24_TYPELESS_G8_UINT         = 82,
+   SVGA3D_R8G8_TYPELESS                = 83,
+   SVGA3D_R8G8_UNORM                   = 84,
+   SVGA3D_R8G8_UINT                    = 85,
+   SVGA3D_R8G8_SNORM                   = 27,
+   SVGA3D_R8G8_SINT                    = 86,
+   SVGA3D_R16_TYPELESS                 = 87,
+   SVGA3D_R16_FLOAT                    = 33,
+   SVGA3D_D16_UNORM                    = 8,
+   SVGA3D_R16_UNORM                    = 88,
+   SVGA3D_R16_UINT                     = 89,
+   SVGA3D_R16_SNORM                    = 90,
+   SVGA3D_R16_SINT                     = 91,
+   SVGA3D_R8_TYPELESS                  = 92,
+   SVGA3D_R8_UNORM                     = 93,
+   SVGA3D_R8_UINT                      = 94,
+   SVGA3D_R8_SNORM                     = 95,
+   SVGA3D_R8_SINT                      = 96,
+   SVGA3D_A8_UNORM                     = 32,
+   SVGA3D_R1_UNORM                     = 97,
+   SVGA3D_R9G9B9E5_SHAREDEXP           = 98,
+   SVGA3D_R8G8_B8G8_UNORM              = 99,
+   SVGA3D_G8R8_G8B8_UNORM              = 100,
+   SVGA3D_BC1_TYPELESS                 = 101,
+   SVGA3D_BC1_UNORM                    = 15,
+   SVGA3D_BC1_UNORM_SRGB               = 102,
+   SVGA3D_BC2_TYPELESS                 = 103,
+   SVGA3D_BC2_UNORM                    = 17,
+   SVGA3D_BC2_UNORM_SRGB               = 104,
+   SVGA3D_BC3_TYPELESS                 = 105,
+   SVGA3D_BC3_UNORM                    = 19,
+   SVGA3D_BC3_UNORM_SRGB               = 106,
+   SVGA3D_BC4_TYPELESS                 = 107,
    SVGA3D_BC4_UNORM                    = 108,
+   SVGA3D_BC4_SNORM                    = 109,
+   SVGA3D_BC5_TYPELESS                 = 110,
    SVGA3D_BC5_UNORM                    = 111,
+   SVGA3D_BC5_SNORM                    = 112,
+   SVGA3D_B5G6R5_UNORM                 = 3,
+   SVGA3D_B5G5R5A1_UNORM               = 5,
+   SVGA3D_B8G8R8A8_UNORM               = 2,
+   SVGA3D_B8G8R8X8_UNORM               = 1,
+   SVGA3D_R10G10B10_XR_BIAS_A2_UNORM   = 113,
+   SVGA3D_B8G8R8A8_TYPELESS            = 114,
+   SVGA3D_B8G8R8A8_UNORM_SRGB          = 115,
+   SVGA3D_B8G8R8X8_TYPELESS            = 116,
+   SVGA3D_B8G8R8X8_UNORM_SRGB          = 117,
 
    /* Advanced D3D9 depth formats. */
    SVGA3D_Z_DF16                       = 118,
    SVGA3D_Z_DF24                       = 119,
    SVGA3D_Z_D24S8_INT                  = 120,
 
-   SVGA3D_FORMAT_MAX
+   /* Planar video formats. */
+   SVGA3D_YV12                         = 121,
+
+   SVGA3D_FORMAT_MAX                   = 122,
 } SVGA3dSurfaceFormat;
 
 typedef uint32 SVGA3dColor; /* a, r, g, b */
@@ -957,15 +1051,21 @@ typedef enum {
 } SVGA3dCubeFace;
 
 typedef enum {
+   SVGA3D_SHADERTYPE_INVALID                    = 0,
+   SVGA3D_SHADERTYPE_MIN                        = 1,
    SVGA3D_SHADERTYPE_VS                         = 1,
    SVGA3D_SHADERTYPE_PS                         = 2,
-   SVGA3D_SHADERTYPE_MAX
+   SVGA3D_SHADERTYPE_MAX                        = 3,
+   SVGA3D_SHADERTYPE_GS                         = 3,
 } SVGA3dShaderType;
 
+#define SVGA3D_NUM_SHADERTYPE (SVGA3D_SHADERTYPE_MAX - SVGA3D_SHADERTYPE_MIN)
+
 typedef enum {
    SVGA3D_CONST_TYPE_FLOAT                      = 0,
    SVGA3D_CONST_TYPE_INT                        = 1,
    SVGA3D_CONST_TYPE_BOOL                       = 2,
+   SVGA3D_CONST_TYPE_MAX
 } SVGA3dShaderConstType;
 
 #define SVGA3D_MAX_SURFACE_FACES                6
@@ -1056,9 +1156,84 @@ typedef enum {
 #define SVGA_3D_CMD_GENERATE_MIPMAPS       SVGA_3D_CMD_BASE + 31
 #define SVGA_3D_CMD_ACTIVATE_SURFACE       SVGA_3D_CMD_BASE + 40
 #define SVGA_3D_CMD_DEACTIVATE_SURFACE     SVGA_3D_CMD_BASE + 41
-#define SVGA_3D_CMD_MAX                    SVGA_3D_CMD_BASE + 42
-
-#define SVGA_3D_CMD_FUTURE_MAX             2000
+#define SVGA_3D_CMD_SCREEN_DMA               1082
+#define SVGA_3D_CMD_SET_UNITY_SURFACE_COOKIE 1083
+#define SVGA_3D_CMD_OPEN_CONTEXT_SURFACE     1084
+
+#define SVGA_3D_CMD_LOGICOPS_BITBLT          1085
+#define SVGA_3D_CMD_LOGICOPS_TRANSBLT        1086
+#define SVGA_3D_CMD_LOGICOPS_STRETCHBLT      1087
+#define SVGA_3D_CMD_LOGICOPS_COLORFILL       1088
+#define SVGA_3D_CMD_LOGICOPS_ALPHABLEND      1089
+#define SVGA_3D_CMD_LOGICOPS_CLEARTYPEBLEND  1090
+
+#define SVGA_3D_CMD_SET_OTABLE_BASE          1091
+#define SVGA_3D_CMD_READBACK_OTABLE          1092
+
+#define SVGA_3D_CMD_DEFINE_GB_MOB            1093
+#define SVGA_3D_CMD_DESTROY_GB_MOB           1094
+#define SVGA_3D_CMD_REDEFINE_GB_MOB          1095
+#define SVGA_3D_CMD_UPDATE_GB_MOB_MAPPING    1096
+
+#define SVGA_3D_CMD_DEFINE_GB_SURFACE        1097
+#define SVGA_3D_CMD_DESTROY_GB_SURFACE       1098
+#define SVGA_3D_CMD_BIND_GB_SURFACE          1099
+#define SVGA_3D_CMD_COND_BIND_GB_SURFACE     1100
+#define SVGA_3D_CMD_UPDATE_GB_IMAGE          1101
+#define SVGA_3D_CMD_UPDATE_GB_SURFACE        1102
+#define SVGA_3D_CMD_READBACK_GB_IMAGE        1103
+#define SVGA_3D_CMD_READBACK_GB_SURFACE      1104
+#define SVGA_3D_CMD_INVALIDATE_GB_IMAGE      1105
+#define SVGA_3D_CMD_INVALIDATE_GB_SURFACE    1106
+
+#define SVGA_3D_CMD_DEFINE_GB_CONTEXT        1107
+#define SVGA_3D_CMD_DESTROY_GB_CONTEXT       1108
+#define SVGA_3D_CMD_BIND_GB_CONTEXT          1109
+#define SVGA_3D_CMD_READBACK_GB_CONTEXT      1110
+#define SVGA_3D_CMD_INVALIDATE_GB_CONTEXT    1111
+
+#define SVGA_3D_CMD_DEFINE_GB_SHADER         1112
+#define SVGA_3D_CMD_DESTROY_GB_SHADER        1113
+#define SVGA_3D_CMD_BIND_GB_SHADER           1114
+
+#define SVGA_3D_CMD_SET_OTABLE_BASE64        1115
+
+#define SVGA_3D_CMD_BEGIN_GB_QUERY           1116
+#define SVGA_3D_CMD_END_GB_QUERY             1117
+#define SVGA_3D_CMD_WAIT_FOR_GB_QUERY        1118
+
+#define SVGA_3D_CMD_NOP                      1119
+
+#define SVGA_3D_CMD_ENABLE_GART              1120
+#define SVGA_3D_CMD_DISABLE_GART             1121
+#define SVGA_3D_CMD_MAP_MOB_INTO_GART        1122
+#define SVGA_3D_CMD_UNMAP_GART_RANGE         1123
+
+#define SVGA_3D_CMD_DEFINE_GB_SCREENTARGET   1124
+#define SVGA_3D_CMD_DESTROY_GB_SCREENTARGET  1125
+#define SVGA_3D_CMD_BIND_GB_SCREENTARGET     1126
+#define SVGA_3D_CMD_UPDATE_GB_SCREENTARGET   1127
+
+#define SVGA_3D_CMD_READBACK_GB_IMAGE_PARTIAL   1128
+#define SVGA_3D_CMD_INVALIDATE_GB_IMAGE_PARTIAL 1129
+
+#define SVGA_3D_CMD_SET_GB_SHADERCONSTS_INLINE  1130
+#define SVGA_3D_CMD_GB_SCREEN_DMA               1131
+#define SVGA_3D_CMD_BIND_GB_SURFACE_WITH_PITCH  1132
+#define SVGA_3D_CMD_GB_MOB_FENCE                1133
+#define SVGA_3D_CMD_DEFINE_GB_SURFACE_V2        1134
+#define SVGA_3D_CMD_DEFINE_GB_MOB64          1135
+#define SVGA_3D_CMD_REDEFINE_GB_MOB64        1136
+#define SVGA_3D_CMD_NOP_ERROR                1137
+
+#define SVGA_3D_CMD_RESERVED1                1138
+#define SVGA_3D_CMD_RESERVED2                1139
+#define SVGA_3D_CMD_RESERVED3                1140
+#define SVGA_3D_CMD_RESERVED4                1141
+#define SVGA_3D_CMD_RESERVED5                1142
+
+#define SVGA_3D_CMD_MAX                      1142
+#define SVGA_3D_CMD_FUTURE_MAX               3000
 
 /*
  * Common substructures used in multiple FIFO commands:
@@ -1750,6 +1925,507 @@ struct {
 
 
 /*
+ * Guest-backed surface definitions.
+ */
+
+typedef uint32 SVGAMobId;
+
+typedef enum SVGAMobFormat {
+   SVGA3D_MOBFMT_INVALID = SVGA3D_INVALID_ID,
+   SVGA3D_MOBFMT_PTDEPTH_0 = 0,
+   SVGA3D_MOBFMT_PTDEPTH_1 = 1,
+   SVGA3D_MOBFMT_PTDEPTH_2 = 2,
+   SVGA3D_MOBFMT_RANGE     = 3,
+   SVGA3D_MOBFMT_PTDEPTH64_0 = 4,
+   SVGA3D_MOBFMT_PTDEPTH64_1 = 5,
+   SVGA3D_MOBFMT_PTDEPTH64_2 = 6,
+   SVGA3D_MOBFMT_MAX,
+} SVGAMobFormat;
+
+/*
+ * Sizes of opaque types.
+ */
+
+#define SVGA3D_OTABLE_MOB_ENTRY_SIZE 16
+#define SVGA3D_OTABLE_CONTEXT_ENTRY_SIZE 8
+#define SVGA3D_OTABLE_SURFACE_ENTRY_SIZE 64
+#define SVGA3D_OTABLE_SHADER_ENTRY_SIZE 16
+#define SVGA3D_OTABLE_SCREEN_TARGET_ENTRY_SIZE 64
+#define SVGA3D_CONTEXT_DATA_SIZE 16384
+
+/*
+ * SVGA3dCmdSetOTableBase --
+ *
+ * This command allows the guest to specify the base PPN of the
+ * specified object table.
+ */
+
+typedef enum {
+   SVGA_OTABLE_MOB           = 0,
+   SVGA_OTABLE_MIN           = 0,
+   SVGA_OTABLE_SURFACE       = 1,
+   SVGA_OTABLE_CONTEXT       = 2,
+   SVGA_OTABLE_SHADER        = 3,
+   SVGA_OTABLE_SCREEN_TARGET = 4,
+   SVGA_OTABLE_DX9_MAX       = 5,
+   SVGA_OTABLE_MAX           = 8
+} SVGAOTableType;
+
+typedef
+struct {
+   SVGAOTableType type;
+   PPN baseAddress;
+   uint32 sizeInBytes;
+   uint32 validSizeInBytes;
+   SVGAMobFormat ptDepth;
+} __packed
+SVGA3dCmdSetOTableBase;  /* SVGA_3D_CMD_SET_OTABLE_BASE */
+
+typedef
+struct {
+   SVGAOTableType type;
+   PPN64 baseAddress;
+   uint32 sizeInBytes;
+   uint32 validSizeInBytes;
+   SVGAMobFormat ptDepth;
+} __packed
+SVGA3dCmdSetOTableBase64;  /* SVGA_3D_CMD_SET_OTABLE_BASE64 */
+
+typedef
+struct {
+   SVGAOTableType type;
+} __packed
+SVGA3dCmdReadbackOTable;  /* SVGA_3D_CMD_READBACK_OTABLE */
+
+/*
+ * Define a memory object (Mob) in the OTable.
+ */
+
+typedef
+struct SVGA3dCmdDefineGBMob {
+   SVGAMobId mobid;
+   SVGAMobFormat ptDepth;
+   PPN base;
+   uint32 sizeInBytes;
+} __packed
+SVGA3dCmdDefineGBMob;   /* SVGA_3D_CMD_DEFINE_GB_MOB */
+
+
+/*
+ * Destroys an object in the OTable.
+ */
+
+typedef
+struct SVGA3dCmdDestroyGBMob {
+   SVGAMobId mobid;
+} __packed
+SVGA3dCmdDestroyGBMob;   /* SVGA_3D_CMD_DESTROY_GB_MOB */
+
+/*
+ * Redefine an object in the OTable.
+ */
+
+typedef
+struct SVGA3dCmdRedefineGBMob {
+   SVGAMobId mobid;
+   SVGAMobFormat ptDepth;
+   PPN base;
+   uint32 sizeInBytes;
+} __packed
+SVGA3dCmdRedefineGBMob;   /* SVGA_3D_CMD_REDEFINE_GB_MOB */
+
+/*
+ * Define a memory object (Mob) in the OTable with a PPN64 base.
+ */
+
+typedef
+struct SVGA3dCmdDefineGBMob64 {
+   SVGAMobId mobid;
+   SVGAMobFormat ptDepth;
+   PPN64 base;
+   uint32 sizeInBytes;
+} __packed
+SVGA3dCmdDefineGBMob64;   /* SVGA_3D_CMD_DEFINE_GB_MOB64 */
+
+/*
+ * Redefine an object in the OTable with PPN64 base.
+ */
+
+typedef
+struct SVGA3dCmdRedefineGBMob64 {
+   SVGAMobId mobid;
+   SVGAMobFormat ptDepth;
+   PPN64 base;
+   uint32 sizeInBytes;
+} __packed
+SVGA3dCmdRedefineGBMob64;   /* SVGA_3D_CMD_REDEFINE_GB_MOB64 */
+
+/*
+ * Notification that the page tables have been modified.
+ */
+
+typedef
+struct SVGA3dCmdUpdateGBMobMapping {
+   SVGAMobId mobid;
+} __packed
+SVGA3dCmdUpdateGBMobMapping;   /* SVGA_3D_CMD_UPDATE_GB_MOB_MAPPING */
+
+/*
+ * Define a guest-backed surface.
+ */
+
+typedef
+struct SVGA3dCmdDefineGBSurface {
+   uint32 sid;
+   SVGA3dSurfaceFlags surfaceFlags;
+   SVGA3dSurfaceFormat format;
+   uint32 numMipLevels;
+   uint32 multisampleCount;
+   SVGA3dTextureFilter autogenFilter;
+   SVGA3dSize size;
+} __packed
+SVGA3dCmdDefineGBSurface;   /* SVGA_3D_CMD_DEFINE_GB_SURFACE */
+
+/*
+ * Destroy a guest-backed surface.
+ */
+
+typedef
+struct SVGA3dCmdDestroyGBSurface {
+   uint32 sid;
+} __packed
+SVGA3dCmdDestroyGBSurface;   /* SVGA_3D_CMD_DESTROY_GB_SURFACE */
+
+/*
+ * Bind a guest-backed surface to an object.
+ */
+
+typedef
+struct SVGA3dCmdBindGBSurface {
+   uint32 sid;
+   SVGAMobId mobid;
+} __packed
+SVGA3dCmdBindGBSurface;   /* SVGA_3D_CMD_BIND_GB_SURFACE */
+
+/*
+ * Conditionally bind a mob to a guest backed surface if testMobid
+ * matches the currently bound mob.  Optionally issue a readback on
+ * the surface while it is still bound to the old mobid if the mobid
+ * is changed by this command.
+ */
+
+#define SVGA3D_COND_BIND_GB_SURFACE_FLAG_READBACK (1 << 0)
+
+typedef
+struct{
+   uint32 sid;
+   SVGAMobId testMobid;
+   SVGAMobId mobid;
+   uint32 flags;
+} __packed
+SVGA3dCmdCondBindGBSurface;          /* SVGA_3D_CMD_COND_BIND_GB_SURFACE */
+
+/*
+ * Update an image in a guest-backed surface.
+ * (Inform the device that the guest-contents have been updated.)
+ */
+
+typedef
+struct SVGA3dCmdUpdateGBImage {
+   SVGA3dSurfaceImageId image;
+   SVGA3dBox box;
+} __packed
+SVGA3dCmdUpdateGBImage;   /* SVGA_3D_CMD_UPDATE_GB_IMAGE */
+
+/*
+ * Update an entire guest-backed surface.
+ * (Inform the device that the guest-contents have been updated.)
+ */
+
+typedef
+struct SVGA3dCmdUpdateGBSurface {
+   uint32 sid;
+} __packed
+SVGA3dCmdUpdateGBSurface;   /* SVGA_3D_CMD_UPDATE_GB_SURFACE */
+
+/*
+ * Readback an image in a guest-backed surface.
+ * (Request the device to flush the dirty contents into the guest.)
+ */
+
+typedef
+struct SVGA3dCmdReadbackGBImage {
+   SVGA3dSurfaceImageId image;
+} __packed
+SVGA3dCmdReadbackGBImage;   /* SVGA_3D_CMD_READBACK_GB_IMAGE*/
+
+/*
+ * Readback an entire guest-backed surface.
+ * (Request the device to flush the dirty contents into the guest.)
+ */
+
+typedef
+struct SVGA3dCmdReadbackGBSurface {
+   uint32 sid;
+} __packed
+SVGA3dCmdReadbackGBSurface;   /* SVGA_3D_CMD_READBACK_GB_SURFACE */
+
+/*
+ * Readback a sub rect of an image in a guest-backed surface.  After
+ * issuing this command the driver is required to issue an update call
+ * of the same region before issuing any other commands that reference
+ * this surface or rendering is not guaranteed.
+ */
+
+typedef
+struct SVGA3dCmdReadbackGBImagePartial {
+   SVGA3dSurfaceImageId image;
+   SVGA3dBox box;
+   uint32 invertBox;
+} __packed
+SVGA3dCmdReadbackGBImagePartial; /* SVGA_3D_CMD_READBACK_GB_IMAGE_PARTIAL */
+
+/*
+ * Invalidate an image in a guest-backed surface.
+ * (Notify the device that the contents can be lost.)
+ */
+
+typedef
+struct SVGA3dCmdInvalidateGBImage {
+   SVGA3dSurfaceImageId image;
+} __packed
+SVGA3dCmdInvalidateGBImage;   /* SVGA_3D_CMD_INVALIDATE_GB_IMAGE */
+
+/*
+ * Invalidate an entire guest-backed surface.
+ * (Notify the device that the contents if all images can be lost.)
+ */
+
+typedef
+struct SVGA3dCmdInvalidateGBSurface {
+   uint32 sid;
+} __packed
+SVGA3dCmdInvalidateGBSurface; /* SVGA_3D_CMD_INVALIDATE_GB_SURFACE */
+
+/*
+ * Invalidate a sub rect of an image in a guest-backed surface.  After
+ * issuing this command the driver is required to issue an update call
+ * of the same region before issuing any other commands that reference
+ * this surface or rendering is not guaranteed.
+ */
+
+typedef
+struct SVGA3dCmdInvalidateGBImagePartial {
+   SVGA3dSurfaceImageId image;
+   SVGA3dBox box;
+   uint32 invertBox;
+} __packed
+SVGA3dCmdInvalidateGBImagePartial; /* SVGA_3D_CMD_INVALIDATE_GB_IMAGE_PARTIAL */
+
+/*
+ * Define a guest-backed context.
+ */
+
+typedef
+struct SVGA3dCmdDefineGBContext {
+   uint32 cid;
+} __packed
+SVGA3dCmdDefineGBContext;   /* SVGA_3D_CMD_DEFINE_GB_CONTEXT */
+
+/*
+ * Destroy a guest-backed context.
+ */
+
+typedef
+struct SVGA3dCmdDestroyGBContext {
+   uint32 cid;
+} __packed
+SVGA3dCmdDestroyGBContext;   /* SVGA_3D_CMD_DESTROY_GB_CONTEXT */
+
+/*
+ * Bind a guest-backed context.
+ *
+ * validContents should be set to 0 for new contexts,
+ * and 1 if this is an old context which is getting paged
+ * back on to the device.
+ *
+ * For new contexts, it is recommended that the driver
+ * issue commands to initialize all interesting state
+ * prior to rendering.
+ */
+
+typedef
+struct SVGA3dCmdBindGBContext {
+   uint32 cid;
+   SVGAMobId mobid;
+   uint32 validContents;
+} __packed
+SVGA3dCmdBindGBContext;   /* SVGA_3D_CMD_BIND_GB_CONTEXT */
+
+/*
+ * Readback a guest-backed context.
+ * (Request that the device flush the contents back into guest memory.)
+ */
+
+typedef
+struct SVGA3dCmdReadbackGBContext {
+   uint32 cid;
+} __packed
+SVGA3dCmdReadbackGBContext;   /* SVGA_3D_CMD_READBACK_GB_CONTEXT */
+
+/*
+ * Invalidate a guest-backed context.
+ */
+typedef
+struct SVGA3dCmdInvalidateGBContext {
+   uint32 cid;
+} __packed
+SVGA3dCmdInvalidateGBContext;   /* SVGA_3D_CMD_INVALIDATE_GB_CONTEXT */
+
+/*
+ * Define a guest-backed shader.
+ */
+
+typedef
+struct SVGA3dCmdDefineGBShader {
+   uint32 shid;
+   SVGA3dShaderType type;
+   uint32 sizeInBytes;
+} __packed
+SVGA3dCmdDefineGBShader;   /* SVGA_3D_CMD_DEFINE_GB_SHADER */
+
+/*
+ * Bind a guest-backed shader.
+ */
+
+typedef struct SVGA3dCmdBindGBShader {
+   uint32 shid;
+   SVGAMobId mobid;
+   uint32 offsetInBytes;
+} __packed
+SVGA3dCmdBindGBShader;   /* SVGA_3D_CMD_BIND_GB_SHADER */
+
+/*
+ * Destroy a guest-backed shader.
+ */
+
+typedef struct SVGA3dCmdDestroyGBShader {
+   uint32 shid;
+} __packed
+SVGA3dCmdDestroyGBShader;   /* SVGA_3D_CMD_DESTROY_GB_SHADER */
+
+typedef
+struct {
+   uint32                  cid;
+   uint32                  regStart;
+   SVGA3dShaderType        shaderType;
+   SVGA3dShaderConstType   constType;
+
+   /*
+    * Followed by a variable number of shader constants.
+    *
+    * Note that FLOAT and INT constants are 4-dwords in length, while
+    * BOOL constants are 1-dword in length.
+    */
+} __packed
+SVGA3dCmdSetGBShaderConstInline;
+/* SVGA_3D_CMD_SET_GB_SHADERCONSTS_INLINE */
+
+typedef
+struct {
+   uint32               cid;
+   SVGA3dQueryType      type;
+} __packed
+SVGA3dCmdBeginGBQuery;           /* SVGA_3D_CMD_BEGIN_GB_QUERY */
+
+typedef
+struct {
+   uint32               cid;
+   SVGA3dQueryType      type;
+   SVGAMobId mobid;
+   uint32 offset;
+} __packed
+SVGA3dCmdEndGBQuery;                  /* SVGA_3D_CMD_END_GB_QUERY */
+
+
+/*
+ * SVGA_3D_CMD_WAIT_FOR_GB_QUERY --
+ *
+ *    The semantics of this command are identical to the
+ *    SVGA_3D_CMD_WAIT_FOR_QUERY except that the results are written
+ *    to a Mob instead of a GMR.
+ */
+
+typedef
+struct {
+   uint32               cid;
+   SVGA3dQueryType      type;
+   SVGAMobId mobid;
+   uint32 offset;
+} __packed
+SVGA3dCmdWaitForGBQuery;          /* SVGA_3D_CMD_WAIT_FOR_GB_QUERY */
+
+typedef
+struct {
+   SVGAMobId mobid;
+   uint32 fbOffset;
+   uint32 initalized;
+} __packed
+SVGA3dCmdEnableGart;              /* SVGA_3D_CMD_ENABLE_GART */
+
+typedef
+struct {
+   SVGAMobId mobid;
+   uint32 gartOffset;
+} __packed
+SVGA3dCmdMapMobIntoGart;          /* SVGA_3D_CMD_MAP_MOB_INTO_GART */
+
+
+typedef
+struct {
+   uint32 gartOffset;
+   uint32 numPages;
+} __packed
+SVGA3dCmdUnmapGartRange;          /* SVGA_3D_CMD_UNMAP_GART_RANGE */
+
+
+/*
+ * Screen Targets
+ */
+#define SVGA_STFLAG_PRIMARY (1 << 0)
+
+typedef
+struct {
+   uint32 stid;
+   uint32 width;
+   uint32 height;
+   int32 xRoot;
+   int32 yRoot;
+   uint32 flags;
+} __packed
+SVGA3dCmdDefineGBScreenTarget;    /* SVGA_3D_CMD_DEFINE_GB_SCREENTARGET */
+
+typedef
+struct {
+   uint32 stid;
+} __packed
+SVGA3dCmdDestroyGBScreenTarget;  /* SVGA_3D_CMD_DESTROY_GB_SCREENTARGET */
+
+typedef
+struct {
+   uint32 stid;
+   SVGA3dSurfaceImageId image;
+} __packed
+SVGA3dCmdBindGBScreenTarget;  /* SVGA_3D_CMD_BIND_GB_SCREENTARGET */
+
+typedef
+struct {
+   uint32 stid;
+   SVGA3dBox box;
+} __packed
+SVGA3dCmdUpdateGBScreenTarget;  /* SVGA_3D_CMD_UPDATE_GB_SCREENTARGET */
+
+/*
  * Capability query index.
  *
  * Notes:
@@ -1879,10 +2555,41 @@ typedef enum {
    SVGA3D_DEVCAP_SURFACEFMT_BC5_UNORM              = 83,
 
    /*
-    * Don't add new caps into the previous section; the values in this
-    * enumeration must not change. You can put new values right before
-    * SVGA3D_DEVCAP_MAX.
+    * Deprecated.
+    */
+   SVGA3D_DEVCAP_VGPU10                            = 84,
+
+   /*
+    * This contains several SVGA_3D_CAPS_VIDEO_DECODE elements
+    * ored together, one for every type of video decoding supported.
+    */
+   SVGA3D_DEVCAP_VIDEO_DECODE                      = 85,
+
+   /*
+    * This contains several SVGA_3D_CAPS_VIDEO_PROCESS elements
+    * ored together, one for every type of video processing supported.
+    */
+   SVGA3D_DEVCAP_VIDEO_PROCESS                     = 86,
+
+   SVGA3D_DEVCAP_LINE_AA                           = 87,  /* boolean */
+   SVGA3D_DEVCAP_LINE_STIPPLE                      = 88,  /* boolean */
+   SVGA3D_DEVCAP_MAX_LINE_WIDTH                    = 89,  /* float */
+   SVGA3D_DEVCAP_MAX_AA_LINE_WIDTH                 = 90,  /* float */
+
+   SVGA3D_DEVCAP_SURFACEFMT_YV12                   = 91,
+
+   /*
+    * Does the host support the SVGA logic ops commands?
+    */
+   SVGA3D_DEVCAP_LOGICOPS                          = 92,
+
+   /*
+    * What support does the host have for screen targets?
+    *
+    * See the SVGA3D_SCREENTARGET_CAP bits below.
     */
+   SVGA3D_DEVCAP_SCREENTARGETS                     = 93,
+
    SVGA3D_DEVCAP_MAX                                  /* This must be the last index. */
 } SVGA3dDevCapIndex;
 
@@ -1893,4 +2600,28 @@ typedef union {
    float  f;
 } SVGA3dDevCapResult;
 
+typedef enum {
+   SVGA3DCAPS_RECORD_UNKNOWN        = 0,
+   SVGA3DCAPS_RECORD_DEVCAPS_MIN    = 0x100,
+   SVGA3DCAPS_RECORD_DEVCAPS        = 0x100,
+   SVGA3DCAPS_RECORD_DEVCAPS_MAX    = 0x1ff,
+} SVGA3dCapsRecordType;
+
+typedef
+struct SVGA3dCapsRecordHeader {
+   uint32 length;
+   SVGA3dCapsRecordType type;
+}
+SVGA3dCapsRecordHeader;
+
+typedef
+struct SVGA3dCapsRecord {
+   SVGA3dCapsRecordHeader header;
+   uint32 data[1];
+}
+SVGA3dCapsRecord;
+
+
+typedef uint32 SVGA3dCapPair[2];
+
 #endif /* _SVGA3D_REG_H_ */
diff --git a/drivers/gpu/drm/vmwgfx/svga3d_surfacedefs.h b/drivers/gpu/drm/vmwgfx/svga3d_surfacedefs.h
index 8369c3b..ef33850 100644
--- a/drivers/gpu/drm/vmwgfx/svga3d_surfacedefs.h
+++ b/drivers/gpu/drm/vmwgfx/svga3d_surfacedefs.h
@@ -38,8 +38,11 @@
 
 #define DIV_ROUND_UP(x, y)  (((x) + (y) - 1) / (y))
 #define max_t(type, x, y)  ((x) > (y) ? (x) : (y))
+#define min_t(type, x, y)  ((x) < (y) ? (x) : (y))
 #define surf_size_struct SVGA3dSize
 #define u32 uint32
+#define u64 uint64_t
+#define U32_MAX ((u32)~0U)
 
 #endif /* __KERNEL__ */
 
@@ -704,8 +707,8 @@ static const struct svga3d_surface_desc svga3d_surface_descs[] = {
 
 static inline u32 clamped_umul32(u32 a, u32 b)
 {
- uint64_t tmp = (uint64_t) a*b;
- return (tmp > (uint64_t) ((u32) -1)) ? (u32) -1 : tmp;
+ u64 tmp = (u64) a*b;
+ return (tmp > (u64) U32_MAX) ? U32_MAX : tmp;
 }
 
 static inline const struct svga3d_surface_desc *
@@ -834,7 +837,7 @@ svga3dsurface_get_serialized_size(SVGA3dSurfaceFormat format,
       bool cubemap)
 {
  const struct svga3d_surface_desc *desc = svga3dsurface_get_desc(format);
- u32 total_size = 0;
+ u64 total_size = 0;
  u32 mip;
 
  for (mip = 0; mip < num_mip_levels; mip++) {
@@ -847,7 +850,7 @@ svga3dsurface_get_serialized_size(SVGA3dSurfaceFormat format,
  if (cubemap)
   total_size *= SVGA3D_MAX_SURFACE_FACES;
 
- return total_size;
+ return (u32) min_t(u64, total_size, (u64) U32_MAX);
 }
 
 
diff --git a/drivers/gpu/drm/vmwgfx/svga_reg.h b/drivers/gpu/drm/vmwgfx/svga_reg.h
index 01f63cb..11323dd 100644
--- a/drivers/gpu/drm/vmwgfx/svga_reg.h
+++ b/drivers/gpu/drm/vmwgfx/svga_reg.h
@@ -169,7 +169,17 @@ enum {
    SVGA_REG_TRACES = 45,            /* Enable trace-based updates even when FIFO is on */
    SVGA_REG_GMRS_MAX_PAGES = 46,    /* Maximum number of 4KB pages for all GMRs */
    SVGA_REG_MEMORY_SIZE = 47,       /* Total dedicated device memory excluding FIFO */
-   SVGA_REG_TOP = 48,               /* Must be 1 more than the last register */
+   SVGA_REG_COMMAND_LOW = 48,       /* Lower 32 bits and submits commands */
+   SVGA_REG_COMMAND_HIGH = 49,      /* Upper 32 bits of command buffer PA */
+   SVGA_REG_MAX_PRIMARY_BOUNDING_BOX_MEM = 50,   /* Max primary memory */
+   SVGA_REG_SUGGESTED_GBOBJECT_MEM_SIZE_KB = 51, /* Suggested limit on mob mem */
+   SVGA_REG_DEV_CAP = 52,           /* Write dev cap index, read value */
+   SVGA_REG_CMD_PREPEND_LOW = 53,
+   SVGA_REG_CMD_PREPEND_HIGH = 54,
+   SVGA_REG_SCREENTARGET_MAX_WIDTH = 55,
+   SVGA_REG_SCREENTARGET_MAX_HEIGHT = 56,
+   SVGA_REG_MOB_MAX_SIZE = 57,
+   SVGA_REG_TOP = 58,               /* Must be 1 more than the last register */
 
    SVGA_PALETTE_BASE = 1024,        /* Base of SVGA color map */
    /* Next 768 (== 256*3) registers exist for colormap */
@@ -431,7 +441,10 @@ struct SVGASignedPoint {
 #define SVGA_CAP_TRACES             0x00200000
 #define SVGA_CAP_GMR2               0x00400000
 #define SVGA_CAP_SCREEN_OBJECT_2    0x00800000
-
+#define SVGA_CAP_COMMAND_BUFFERS    0x01000000
+#define SVGA_CAP_DEAD1              0x02000000
+#define SVGA_CAP_CMD_BUFFERS_2      0x04000000
+#define SVGA_CAP_GBOBJECTS          0x08000000
 
 /*
  * FIFO register indices.
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_buffer.c b/drivers/gpu/drm/vmwgfx/vmwgfx_buffer.c
index 0489c61..6327cfc 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_buffer.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_buffer.c
@@ -40,6 +40,10 @@ static uint32_t vram_ne_placement_flags = TTM_PL_FLAG_VRAM |
 static uint32_t sys_placement_flags = TTM_PL_FLAG_SYSTEM |
  TTM_PL_FLAG_CACHED;
 
+static uint32_t sys_ne_placement_flags = TTM_PL_FLAG_SYSTEM |
+ TTM_PL_FLAG_CACHED |
+ TTM_PL_FLAG_NO_EVICT;
+
 static uint32_t gmr_placement_flags = VMW_PL_FLAG_GMR |
  TTM_PL_FLAG_CACHED;
 
@@ -47,6 +51,9 @@ static uint32_t gmr_ne_placement_flags = VMW_PL_FLAG_GMR |
  TTM_PL_FLAG_CACHED |
  TTM_PL_FLAG_NO_EVICT;
 
+static uint32_t mob_placement_flags = VMW_PL_FLAG_MOB |
+ TTM_PL_FLAG_CACHED;
+
 struct ttm_placement vmw_vram_placement = {
  .fpfn = 0,
  .lpfn = 0,
@@ -116,16 +123,26 @@ struct ttm_placement vmw_sys_placement = {
  .busy_placement = &sys_placement_flags
 };
 
+struct ttm_placement vmw_sys_ne_placement = {
+ .fpfn = 0,
+ .lpfn = 0,
+ .num_placement = 1,
+ .placement = &sys_ne_placement_flags,
+ .num_busy_placement = 1,
+ .busy_placement = &sys_ne_placement_flags
+};
+
 static uint32_t evictable_placement_flags[] = {
  TTM_PL_FLAG_SYSTEM | TTM_PL_FLAG_CACHED,
  TTM_PL_FLAG_VRAM | TTM_PL_FLAG_CACHED,
- VMW_PL_FLAG_GMR | TTM_PL_FLAG_CACHED
+ VMW_PL_FLAG_GMR | TTM_PL_FLAG_CACHED,
+ VMW_PL_FLAG_MOB | TTM_PL_FLAG_CACHED
 };
 
 struct ttm_placement vmw_evictable_placement = {
  .fpfn = 0,
  .lpfn = 0,
- .num_placement = 3,
+ .num_placement = 4,
  .placement = evictable_placement_flags,
  .num_busy_placement = 1,
  .busy_placement = &sys_placement_flags
@@ -140,10 +157,21 @@ struct ttm_placement vmw_srf_placement = {
  .busy_placement = gmr_vram_placement_flags
 };
 
+struct ttm_placement vmw_mob_placement = {
+ .fpfn = 0,
+ .lpfn = 0,
+ .num_placement = 1,
+ .num_busy_placement = 1,
+ .placement = &mob_placement_flags,
+ .busy_placement = &mob_placement_flags
+};
+
 struct vmw_ttm_tt {
  struct ttm_dma_tt dma_ttm;
  struct vmw_private *dev_priv;
  int gmr_id;
+ struct vmw_mob *mob;
+ int mem_type;
  struct sg_table sgt;
  struct vmw_sg_table vsgt;
  uint64_t sg_alloc_size;
@@ -244,6 +272,7 @@ void vmw_piter_start(struct vmw_piter *viter, const struct vmw_sg_table *vsgt,
   viter->dma_address = &__vmw_piter_dma_addr;
   viter->page = &__vmw_piter_non_sg_page;
   viter->addrs = vsgt->addrs;
+  viter->pages = vsgt->pages;
   break;
  case vmw_dma_map_populate:
  case vmw_dma_map_bind:
@@ -424,6 +453,63 @@ static void vmw_ttm_unmap_dma(struct vmw_ttm_tt *vmw_tt)
  vmw_tt->mapped = false;
 }
 
+
+/**
+ * vmw_bo_map_dma - Make sure buffer object pages are visible to the device
+ *
+ * @bo: Pointer to a struct ttm_buffer_object
+ *
+ * Wrapper around vmw_ttm_map_dma, that takes a TTM buffer object pointer
+ * instead of a pointer to a struct vmw_ttm_backend as argument.
+ * Note that the buffer object must be either pinned or reserved before
+ * calling this function.
+ */
+int vmw_bo_map_dma(struct ttm_buffer_object *bo)
+{
+ struct vmw_ttm_tt *vmw_tt =
+  container_of(bo->ttm, struct vmw_ttm_tt, dma_ttm.ttm);
+
+ return vmw_ttm_map_dma(vmw_tt);
+}
+
+
+/**
+ * vmw_bo_unmap_dma - Make sure buffer object pages are visible to the device
+ *
+ * @bo: Pointer to a struct ttm_buffer_object
+ *
+ * Wrapper around vmw_ttm_unmap_dma, that takes a TTM buffer object pointer
+ * instead of a pointer to a struct vmw_ttm_backend as argument.
+ */
+void vmw_bo_unmap_dma(struct ttm_buffer_object *bo)
+{
+ struct vmw_ttm_tt *vmw_tt =
+  container_of(bo->ttm, struct vmw_ttm_tt, dma_ttm.ttm);
+
+ vmw_ttm_unmap_dma(vmw_tt);
+}
+
+
+/**
+ * vmw_bo_sg_table - Return a struct vmw_sg_table object for a
+ * TTM buffer object
+ *
+ * @bo: Pointer to a struct ttm_buffer_object
+ *
+ * Returns a pointer to a struct vmw_sg_table object. The object should
+ * not be freed after use.
+ * Note that for the device addresses to be valid, the buffer object must
+ * either be reserved or pinned.
+ */
+const struct vmw_sg_table *vmw_bo_sg_table(struct ttm_buffer_object *bo)
+{
+ struct vmw_ttm_tt *vmw_tt =
+  container_of(bo->ttm, struct vmw_ttm_tt, dma_ttm.ttm);
+
+ return &vmw_tt->vsgt;
+}
+
+
 static int vmw_ttm_bind(struct ttm_tt *ttm, struct ttm_mem_reg *bo_mem)
 {
  struct vmw_ttm_tt *vmw_be =
@@ -435,9 +521,27 @@ static int vmw_ttm_bind(struct ttm_tt *ttm, struct ttm_mem_reg *bo_mem)
   return ret;
 
  vmw_be->gmr_id = bo_mem->start;
+ vmw_be->mem_type = bo_mem->mem_type;
+
+ switch (bo_mem->mem_type) {
+ case VMW_PL_GMR:
+  return vmw_gmr_bind(vmw_be->dev_priv, &vmw_be->vsgt,
+        ttm->num_pages, vmw_be->gmr_id);
+ case VMW_PL_MOB:
+  if (unlikely(vmw_be->mob == NULL)) {
+   vmw_be->mob =
+    vmw_mob_create(ttm->num_pages);
+   if (unlikely(vmw_be->mob == NULL))
+    return -ENOMEM;
+  }
 
- return vmw_gmr_bind(vmw_be->dev_priv, &vmw_be->vsgt,
-       ttm->num_pages, vmw_be->gmr_id);
+  return vmw_mob_bind(vmw_be->dev_priv, vmw_be->mob,
+        &vmw_be->vsgt, ttm->num_pages,
+        vmw_be->gmr_id);
+ default:
+  BUG();
+ }
+ return 0;
 }
 
 static int vmw_ttm_unbind(struct ttm_tt *ttm)
@@ -445,7 +549,16 @@ static int vmw_ttm_unbind(struct ttm_tt *ttm)
  struct vmw_ttm_tt *vmw_be =
   container_of(ttm, struct vmw_ttm_tt, dma_ttm.ttm);
 
- vmw_gmr_unbind(vmw_be->dev_priv, vmw_be->gmr_id);
+ switch (vmw_be->mem_type) {
+ case VMW_PL_GMR:
+  vmw_gmr_unbind(vmw_be->dev_priv, vmw_be->gmr_id);
+  break;
+ case VMW_PL_MOB:
+  vmw_mob_unbind(vmw_be->dev_priv, vmw_be->mob);
+  break;
+ default:
+  BUG();
+ }
 
  if (vmw_be->dev_priv->map_mode == vmw_dma_map_bind)
   vmw_ttm_unmap_dma(vmw_be);
@@ -453,6 +566,7 @@ static int vmw_ttm_unbind(struct ttm_tt *ttm)
  return 0;
 }
 
+
 static void vmw_ttm_destroy(struct ttm_tt *ttm)
 {
  struct vmw_ttm_tt *vmw_be =
@@ -463,9 +577,14 @@ static void vmw_ttm_destroy(struct ttm_tt *ttm)
   ttm_dma_tt_fini(&vmw_be->dma_ttm);
  else
   ttm_tt_fini(ttm);
+
+ if (vmw_be->mob)
+  vmw_mob_destroy(vmw_be->mob);
+
  kfree(vmw_be);
 }
 
+
 static int vmw_ttm_populate(struct ttm_tt *ttm)
 {
  struct vmw_ttm_tt *vmw_tt =
@@ -500,6 +619,12 @@ static void vmw_ttm_unpopulate(struct ttm_tt *ttm)
  struct vmw_private *dev_priv = vmw_tt->dev_priv;
  struct ttm_mem_global *glob = vmw_mem_glob(dev_priv);
 
+
+ if (vmw_tt->mob) {
+  vmw_mob_destroy(vmw_tt->mob);
+  vmw_tt->mob = NULL;
+ }
+
  vmw_ttm_unmap_dma(vmw_tt);
  if (dev_priv->map_mode == vmw_dma_alloc_coherent) {
   size_t size =
@@ -517,7 +642,7 @@ static struct ttm_backend_func vmw_ttm_func = {
  .destroy = vmw_ttm_destroy,
 };
 
-struct ttm_tt *vmw_ttm_tt_create(struct ttm_bo_device *bdev,
+static struct ttm_tt *vmw_ttm_tt_create(struct ttm_bo_device *bdev,
      unsigned long size, uint32_t page_flags,
      struct page *dummy_read_page)
 {
@@ -530,6 +655,7 @@ struct ttm_tt *vmw_ttm_tt_create(struct ttm_bo_device *bdev,
 
  vmw_be->dma_ttm.ttm.func = &vmw_ttm_func;
  vmw_be->dev_priv = container_of(bdev, struct vmw_private, bdev);
+ vmw_be->mob = NULL;
 
  if (vmw_be->dev_priv->map_mode == vmw_dma_alloc_coherent)
   ret = ttm_dma_tt_init(&vmw_be->dma_ttm, bdev, size, page_flags,
@@ -546,12 +672,12 @@ out_no_init:
  return NULL;
 }
 
-int vmw_invalidate_caches(struct ttm_bo_device *bdev, uint32_t flags)
+static int vmw_invalidate_caches(struct ttm_bo_device *bdev, uint32_t flags)
 {
  return 0;
 }
 
-int vmw_init_mem_type(struct ttm_bo_device *bdev, uint32_t type,
+static int vmw_init_mem_type(struct ttm_bo_device *bdev, uint32_t type,
         struct ttm_mem_type_manager *man)
 {
  switch (type) {
@@ -571,6 +697,7 @@ int vmw_init_mem_type(struct ttm_bo_device *bdev, uint32_t type,
   man->default_caching = TTM_PL_FLAG_CACHED;
   break;
  case VMW_PL_GMR:
+ case VMW_PL_MOB:
   /*
    * "Guest Memory Regions" is an aperture like feature with
    *  one slot per bo. There is an upper limit of the number of
@@ -589,7 +716,7 @@ int vmw_init_mem_type(struct ttm_bo_device *bdev, uint32_t type,
  return 0;
 }
 
-void vmw_evict_flags(struct ttm_buffer_object *bo,
+static void vmw_evict_flags(struct ttm_buffer_object *bo,
        struct ttm_placement *placement)
 {
  *placement = vmw_sys_placement;
@@ -618,6 +745,7 @@ static int vmw_ttm_io_mem_reserve(struct ttm_bo_device *bdev, struct ttm_mem_reg
  switch (mem->mem_type) {
  case TTM_PL_SYSTEM:
  case VMW_PL_GMR:
+ case VMW_PL_MOB:
   return 0;
  case TTM_PL_VRAM:
   mem->bus.offset = mem->start << PAGE_SHIFT;
@@ -677,6 +805,38 @@ static int vmw_sync_obj_wait(void *sync_obj, bool lazy, bool interruptible)
       VMW_FENCE_WAIT_TIMEOUT);
 }
 
+/**
+ * vmw_move_notify - TTM move_notify_callback
+ *
+ * @bo:             The TTM buffer object about to move.
+ * @mem:            The truct ttm_mem_reg indicating to what memory
+ *                  region the move is taking place.
+ *
+ * Calls move_notify for all subsystems needing it.
+ * (currently only resources).
+ */
+static void vmw_move_notify(struct ttm_buffer_object *bo,
+       struct ttm_mem_reg *mem)
+{
+ vmw_resource_move_notify(bo, mem);
+}
+
+
+/**
+ * vmw_swap_notify - TTM move_notify_callback
+ *
+ * @bo:             The TTM buffer object about to be swapped out.
+ */
+static void vmw_swap_notify(struct ttm_buffer_object *bo)
+{
+ struct ttm_bo_device *bdev = bo->bdev;
+
+ spin_lock(&bdev->fence_lock);
+ ttm_bo_wait(bo, false, false, false);
+ spin_unlock(&bdev->fence_lock);
+}
+
+
 struct ttm_bo_driver vmw_bo_driver = {
  .ttm_tt_create = &vmw_ttm_tt_create,
  .ttm_tt_populate = &vmw_ttm_populate,
@@ -691,8 +851,8 @@ struct ttm_bo_driver vmw_bo_driver = {
  .sync_obj_flush = vmw_sync_obj_flush,
  .sync_obj_unref = vmw_sync_obj_unref,
  .sync_obj_ref = vmw_sync_obj_ref,
- .move_notify = NULL,
- .swap_notify = NULL,
+ .move_notify = vmw_move_notify,
+ .swap_notify = vmw_swap_notify,
  .fault_reserve_notify = &vmw_ttm_fault_reserve_notify,
  .io_mem_reserve = &vmw_ttm_io_mem_reserve,
  .io_mem_free = &vmw_ttm_io_mem_free,
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_context.c b/drivers/gpu/drm/vmwgfx/vmwgfx_context.c
index 00ae092..1e80152 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_context.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_context.c
@@ -32,12 +32,30 @@
 struct vmw_user_context {
  struct ttm_base_object base;
  struct vmw_resource res;
+ struct vmw_ctx_binding_state cbs;
 };
 
+
+
+typedef int (*vmw_scrub_func)(struct vmw_ctx_bindinfo *, bool);
+
 static void vmw_user_context_free(struct vmw_resource *res);
 static struct vmw_resource *
 vmw_user_context_base_to_res(struct ttm_base_object *base);
 
+static int vmw_gb_context_create(struct vmw_resource *res);
+static int vmw_gb_context_bind(struct vmw_resource *res,
+          struct ttm_validate_buffer *val_buf);
+static int vmw_gb_context_unbind(struct vmw_resource *res,
+     bool readback,
+     struct ttm_validate_buffer *val_buf);
+static int vmw_gb_context_destroy(struct vmw_resource *res);
+static int vmw_context_scrub_shader(struct vmw_ctx_bindinfo *bi, bool rebind);
+static int vmw_context_scrub_render_target(struct vmw_ctx_bindinfo *bi,
+        bool rebind);
+static int vmw_context_scrub_texture(struct vmw_ctx_bindinfo *bi, bool rebind);
+static void vmw_context_binding_state_scrub(struct vmw_ctx_binding_state *cbs);
+static void vmw_context_binding_state_kill(struct vmw_ctx_binding_state *cbs);
 static uint64_t vmw_user_context_size;
 
 static const struct vmw_user_resource_conv user_context_conv = {
@@ -62,6 +80,23 @@ static const struct vmw_res_func vmw_legacy_context_func = {
  .unbind = NULL
 };
 
+static const struct vmw_res_func vmw_gb_context_func = {
+ .res_type = vmw_res_context,
+ .needs_backup = true,
+ .may_evict = true,
+ .type_name = "guest backed contexts",
+ .backup_placement = &vmw_mob_placement,
+ .create = vmw_gb_context_create,
+ .destroy = vmw_gb_context_destroy,
+ .bind = vmw_gb_context_bind,
+ .unbind = vmw_gb_context_unbind
+};
+
+static const vmw_scrub_func vmw_scrub_funcs[vmw_ctx_binding_max] = {
+ [vmw_ctx_binding_shader] = vmw_context_scrub_shader,
+ [vmw_ctx_binding_rt] = vmw_context_scrub_render_target,
+ [vmw_ctx_binding_tex] = vmw_context_scrub_texture };
+
 /**
  * Context management:
  */
@@ -76,6 +111,20 @@ static void vmw_hw_context_destroy(struct vmw_resource *res)
  } *cmd;
 
 
+ if (res->func->destroy == vmw_gb_context_destroy) {
+  mutex_lock(&dev_priv->cmdbuf_mutex);
+  mutex_lock(&dev_priv->binding_mutex);
+  (void) vmw_context_binding_state_kill
+   (&container_of(res, struct vmw_user_context, res)->cbs);
+  (void) vmw_gb_context_destroy(res);
+  if (dev_priv->pinned_bo != NULL &&
+      !dev_priv->query_cid_valid)
+   __vmw_execbuf_release_pinned_bo(dev_priv, NULL);
+  mutex_unlock(&dev_priv->binding_mutex);
+  mutex_unlock(&dev_priv->cmdbuf_mutex);
+  return;
+ }
+
  vmw_execbuf_release_pinned_bo(dev_priv);
  cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
  if (unlikely(cmd == NULL)) {
@@ -92,6 +141,33 @@ static void vmw_hw_context_destroy(struct vmw_resource *res)
  vmw_3d_resource_dec(dev_priv, false);
 }
 
+static int vmw_gb_context_init(struct vmw_private *dev_priv,
+          struct vmw_resource *res,
+          void (*res_free) (struct vmw_resource *res))
+{
+ int ret;
+ struct vmw_user_context *uctx =
+  container_of(res, struct vmw_user_context, res);
+
+ ret = vmw_resource_init(dev_priv, res, true,
+    res_free, &vmw_gb_context_func);
+ res->backup_size = SVGA3D_CONTEXT_DATA_SIZE;
+
+ if (unlikely(ret != 0)) {
+  if (res_free)
+   res_free(res);
+  else
+   kfree(res);
+  return ret;
+ }
+
+ memset(&uctx->cbs, 0, sizeof(uctx->cbs));
+ INIT_LIST_HEAD(&uctx->cbs.list);
+
+ vmw_resource_activate(res, vmw_hw_context_destroy);
+ return 0;
+}
+
 static int vmw_context_init(struct vmw_private *dev_priv,
        struct vmw_resource *res,
        void (*res_free) (struct vmw_resource *res))
@@ -103,6 +179,9 @@ static int vmw_context_init(struct vmw_private *dev_priv,
   SVGA3dCmdDefineContext body;
  } *cmd;
 
+ if (dev_priv->has_mob)
+  return vmw_gb_context_init(dev_priv, res, res_free);
+
  ret = vmw_resource_init(dev_priv, res, false,
     res_free, &vmw_legacy_context_func);
 
@@ -154,6 +233,180 @@ struct vmw_resource *vmw_context_alloc(struct vmw_private *dev_priv)
  return (ret == 0) ? res : NULL;
 }
 
+
+static int vmw_gb_context_create(struct vmw_resource *res)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ int ret;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDefineGBContext body;
+ } *cmd;
+
+ if (likely(res->id != -1))
+  return 0;
+
+ ret = vmw_resource_alloc_id(res);
+ if (unlikely(ret != 0)) {
+  DRM_ERROR("Failed to allocate a context id.\n");
+  goto out_no_id;
+ }
+
+ if (unlikely(res->id >= VMWGFX_NUM_GB_CONTEXT)) {
+  ret = -EBUSY;
+  goto out_no_fifo;
+ }
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for context "
+     "creation.\n");
+  ret = -ENOMEM;
+  goto out_no_fifo;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_DEFINE_GB_CONTEXT;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.cid = res->id;
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+ (void) vmw_3d_resource_inc(dev_priv, false);
+
+ return 0;
+
+out_no_fifo:
+ vmw_resource_release_id(res);
+out_no_id:
+ return ret;
+}
+
+static int vmw_gb_context_bind(struct vmw_resource *res,
+          struct ttm_validate_buffer *val_buf)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdBindGBContext body;
+ } *cmd;
+ struct ttm_buffer_object *bo = val_buf->bo;
+
+ BUG_ON(bo->mem.mem_type != VMW_PL_MOB);
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for context "
+     "binding.\n");
+  return -ENOMEM;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_BIND_GB_CONTEXT;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.cid = res->id;
+ cmd->body.mobid = bo->mem.start;
+ cmd->body.validContents = res->backup_dirty;
+ res->backup_dirty = false;
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+
+ return 0;
+}
+
+static int vmw_gb_context_unbind(struct vmw_resource *res,
+     bool readback,
+     struct ttm_validate_buffer *val_buf)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct ttm_buffer_object *bo = val_buf->bo;
+ struct vmw_fence_obj *fence;
+ struct vmw_user_context *uctx =
+  container_of(res, struct vmw_user_context, res);
+
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdReadbackGBContext body;
+ } *cmd1;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdBindGBContext body;
+ } *cmd2;
+ uint32_t submit_size;
+ uint8_t *cmd;
+
+
+ BUG_ON(bo->mem.mem_type != VMW_PL_MOB);
+
+ mutex_lock(&dev_priv->binding_mutex);
+ vmw_context_binding_state_scrub(&uctx->cbs);
+
+ submit_size = sizeof(*cmd2) + (readback ? sizeof(*cmd1) : 0);
+
+ cmd = vmw_fifo_reserve(dev_priv, submit_size);
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for context "
+     "unbinding.\n");
+  mutex_unlock(&dev_priv->binding_mutex);
+  return -ENOMEM;
+ }
+
+ cmd2 = (void *) cmd;
+ if (readback) {
+  cmd1 = (void *) cmd;
+  cmd1->header.id = SVGA_3D_CMD_READBACK_GB_CONTEXT;
+  cmd1->header.size = sizeof(cmd1->body);
+  cmd1->body.cid = res->id;
+  cmd2 = (void *) (&cmd1[1]);
+ }
+ cmd2->header.id = SVGA_3D_CMD_BIND_GB_CONTEXT;
+ cmd2->header.size = sizeof(cmd2->body);
+ cmd2->body.cid = res->id;
+ cmd2->body.mobid = SVGA3D_INVALID_ID;
+
+ vmw_fifo_commit(dev_priv, submit_size);
+ mutex_unlock(&dev_priv->binding_mutex);
+
+ /*
+  * Create a fence object and fence the backup buffer.
+  */
+
+ (void) vmw_execbuf_fence_commands(NULL, dev_priv,
+       &fence, NULL);
+
+ vmw_fence_single_bo(bo, fence);
+
+ if (likely(fence != NULL))
+  vmw_fence_obj_unreference(&fence);
+
+ return 0;
+}
+
+static int vmw_gb_context_destroy(struct vmw_resource *res)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDestroyGBContext body;
+ } *cmd;
+
+ if (likely(res->id == -1))
+  return 0;
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for context "
+     "destruction.\n");
+  return -ENOMEM;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_DESTROY_GB_CONTEXT;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.cid = res->id;
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+ if (dev_priv->query_cid == res->id)
+  dev_priv->query_cid_valid = false;
+ vmw_resource_release_id(res);
+ vmw_3d_resource_dec(dev_priv, false);
+
+ return 0;
+}
+
 /**
  * User-space context management:
  */
@@ -272,3 +525,380 @@ out_unlock:
  return ret;
 
 }
+
+/**
+ * vmw_context_scrub_shader - scrub a shader binding from a context.
+ *
+ * @bi: single binding information.
+ * @rebind: Whether to issue a bind instead of scrub command.
+ */
+static int vmw_context_scrub_shader(struct vmw_ctx_bindinfo *bi, bool rebind)
+{
+ struct vmw_private *dev_priv = bi->ctx->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdSetShader body;
+ } *cmd;
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for shader "
+     "unbinding.\n");
+  return -ENOMEM;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_SET_SHADER;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.cid = bi->ctx->id;
+ cmd->body.type = bi->i1.shader_type;
+ cmd->body.shid = ((rebind) ? bi->res->id : SVGA3D_INVALID_ID);
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+
+ return 0;
+}
+
+/**
+ * vmw_context_scrub_render_target - scrub a render target binding
+ * from a context.
+ *
+ * @bi: single binding information.
+ * @rebind: Whether to issue a bind instead of scrub command.
+ */
+static int vmw_context_scrub_render_target(struct vmw_ctx_bindinfo *bi,
+        bool rebind)
+{
+ struct vmw_private *dev_priv = bi->ctx->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdSetRenderTarget body;
+ } *cmd;
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for render target "
+     "unbinding.\n");
+  return -ENOMEM;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_SETRENDERTARGET;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.cid = bi->ctx->id;
+ cmd->body.type = bi->i1.rt_type;
+ cmd->body.target.sid = ((rebind) ? bi->res->id : SVGA3D_INVALID_ID);
+ cmd->body.target.face = 0;
+ cmd->body.target.mipmap = 0;
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+
+ return 0;
+}
+
+/**
+ * vmw_context_scrub_texture - scrub a texture binding from a context.
+ *
+ * @bi: single binding information.
+ * @rebind: Whether to issue a bind instead of scrub command.
+ *
+ * TODO: Possibly complement this function with a function that takes
+ * a list of texture bindings and combines them to a single command.
+ */
+static int vmw_context_scrub_texture(struct vmw_ctx_bindinfo *bi,
+         bool rebind)
+{
+ struct vmw_private *dev_priv = bi->ctx->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  struct {
+   SVGA3dCmdSetTextureState c;
+   SVGA3dTextureState s1;
+  } body;
+ } *cmd;
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for texture "
+     "unbinding.\n");
+  return -ENOMEM;
+ }
+
+
+ cmd->header.id = SVGA_3D_CMD_SETTEXTURESTATE;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.c.cid = bi->ctx->id;
+ cmd->body.s1.stage = bi->i1.texture_stage;
+ cmd->body.s1.name = SVGA3D_TS_BIND_TEXTURE;
+ cmd->body.s1.value = ((rebind) ? bi->res->id : SVGA3D_INVALID_ID);
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+
+ return 0;
+}
+
+/**
+ * vmw_context_binding_drop: Stop tracking a context binding
+ *
+ * @cb: Pointer to binding tracker storage.
+ *
+ * Stops tracking a context binding, and re-initializes its storage.
+ * Typically used when the context binding is replaced with a binding to
+ * another (or the same, for that matter) resource.
+ */
+static void vmw_context_binding_drop(struct vmw_ctx_binding *cb)
+{
+ list_del(&cb->ctx_list);
+ if (!list_empty(&cb->res_list))
+  list_del(&cb->res_list);
+ cb->bi.ctx = NULL;
+}
+
+/**
+ * vmw_context_binding_add: Start tracking a context binding
+ *
+ * @cbs: Pointer to the context binding state tracker.
+ * @bi: Information about the binding to track.
+ *
+ * Performs basic checks on the binding to make sure arguments are within
+ * bounds and then starts tracking the binding in the context binding
+ * state structure @cbs.
+ */
+int vmw_context_binding_add(struct vmw_ctx_binding_state *cbs,
+       const struct vmw_ctx_bindinfo *bi)
+{
+ struct vmw_ctx_binding *loc;
+
+ switch (bi->bt) {
+ case vmw_ctx_binding_rt:
+  if (unlikely((unsigned)bi->i1.rt_type >= SVGA3D_RT_MAX)) {
+   DRM_ERROR("Illegal render target type %u.\n",
+      (unsigned) bi->i1.rt_type);
+   return -EINVAL;
+  }
+  loc = &cbs->render_targets[bi->i1.rt_type];
+  break;
+ case vmw_ctx_binding_tex:
+  if (unlikely((unsigned)bi->i1.texture_stage >=
+        SVGA3D_NUM_TEXTURE_UNITS)) {
+   DRM_ERROR("Illegal texture/sampler unit %u.\n",
+      (unsigned) bi->i1.texture_stage);
+   return -EINVAL;
+  }
+  loc = &cbs->texture_units[bi->i1.texture_stage];
+  break;
+ case vmw_ctx_binding_shader:
+  if (unlikely((unsigned)bi->i1.shader_type >=
+        SVGA3D_SHADERTYPE_MAX)) {
+   DRM_ERROR("Illegal shader type %u.\n",
+      (unsigned) bi->i1.shader_type);
+   return -EINVAL;
+  }
+  loc = &cbs->shaders[bi->i1.shader_type];
+  break;
+ default:
+  BUG();
+ }
+
+ if (loc->bi.ctx != NULL)
+  vmw_context_binding_drop(loc);
+
+ loc->bi = *bi;
+ loc->bi.scrubbed = false;
+ list_add_tail(&loc->ctx_list, &cbs->list);
+ INIT_LIST_HEAD(&loc->res_list);
+
+ return 0;
+}
+
+/**
+ * vmw_context_binding_transfer: Transfer a context binding tracking entry.
+ *
+ * @cbs: Pointer to the persistent context binding state tracker.
+ * @bi: Information about the binding to track.
+ *
+ */
+static void vmw_context_binding_transfer(struct vmw_ctx_binding_state *cbs,
+      const struct vmw_ctx_bindinfo *bi)
+{
+ struct vmw_ctx_binding *loc;
+
+ switch (bi->bt) {
+ case vmw_ctx_binding_rt:
+  loc = &cbs->render_targets[bi->i1.rt_type];
+  break;
+ case vmw_ctx_binding_tex:
+  loc = &cbs->texture_units[bi->i1.texture_stage];
+  break;
+ case vmw_ctx_binding_shader:
+  loc = &cbs->shaders[bi->i1.shader_type];
+  break;
+ default:
+  BUG();
+ }
+
+ if (loc->bi.ctx != NULL)
+  vmw_context_binding_drop(loc);
+
+ if (bi->res != NULL) {
+  loc->bi = *bi;
+  list_add_tail(&loc->ctx_list, &cbs->list);
+  list_add_tail(&loc->res_list, &bi->res->binding_head);
+ }
+}
+
+/**
+ * vmw_context_binding_kill - Kill a binding on the device
+ * and stop tracking it.
+ *
+ * @cb: Pointer to binding tracker storage.
+ *
+ * Emits FIFO commands to scrub a binding represented by @cb.
+ * Then stops tracking the binding and re-initializes its storage.
+ */
+static void vmw_context_binding_kill(struct vmw_ctx_binding *cb)
+{
+ if (!cb->bi.scrubbed) {
+  (void) vmw_scrub_funcs[cb->bi.bt](&cb->bi, false);
+  cb->bi.scrubbed = true;
+ }
+ vmw_context_binding_drop(cb);
+}
+
+/**
+ * vmw_context_binding_state_kill - Kill all bindings associated with a
+ * struct vmw_ctx_binding state structure, and re-initialize the structure.
+ *
+ * @cbs: Pointer to the context binding state tracker.
+ *
+ * Emits commands to scrub all bindings associated with the
+ * context binding state tracker. Then re-initializes the whole structure.
+ */
+static void vmw_context_binding_state_kill(struct vmw_ctx_binding_state *cbs)
+{
+ struct vmw_ctx_binding *entry, *next;
+
+ list_for_each_entry_safe(entry, next, &cbs->list, ctx_list)
+  vmw_context_binding_kill(entry);
+}
+
+/**
+ * vmw_context_binding_state_scrub - Scrub all bindings associated with a
+ * struct vmw_ctx_binding state structure.
+ *
+ * @cbs: Pointer to the context binding state tracker.
+ *
+ * Emits commands to scrub all bindings associated with the
+ * context binding state tracker.
+ */
+static void vmw_context_binding_state_scrub(struct vmw_ctx_binding_state *cbs)
+{
+ struct vmw_ctx_binding *entry;
+
+ list_for_each_entry(entry, &cbs->list, ctx_list) {
+  if (!entry->bi.scrubbed) {
+   (void) vmw_scrub_funcs[entry->bi.bt](&entry->bi, false);
+   entry->bi.scrubbed = true;
+  }
+ }
+}
+
+/**
+ * vmw_context_binding_res_list_kill - Kill all bindings on a
+ * resource binding list
+ *
+ * @head: list head of resource binding list
+ *
+ * Kills all bindings associated with a specific resource. Typically
+ * called before the resource is destroyed.
+ */
+void vmw_context_binding_res_list_kill(struct list_head *head)
+{
+ struct vmw_ctx_binding *entry, *next;
+
+ list_for_each_entry_safe(entry, next, head, res_list)
+  vmw_context_binding_kill(entry);
+}
+
+/**
+ * vmw_context_binding_res_list_scrub - Scrub all bindings on a
+ * resource binding list
+ *
+ * @head: list head of resource binding list
+ *
+ * Scrub all bindings associated with a specific resource. Typically
+ * called before the resource is evicted.
+ */
+void vmw_context_binding_res_list_scrub(struct list_head *head)
+{
+ struct vmw_ctx_binding *entry;
+
+ list_for_each_entry(entry, head, res_list) {
+  if (!entry->bi.scrubbed) {
+   (void) vmw_scrub_funcs[entry->bi.bt](&entry->bi, false);
+   entry->bi.scrubbed = true;
+  }
+ }
+}
+
+/**
+ * vmw_context_binding_state_transfer - Commit staged binding info
+ *
+ * @ctx: Pointer to context to commit the staged binding info to.
+ * @from: Staged binding info built during execbuf.
+ *
+ * Transfers binding info from a temporary structure to the persistent
+ * structure in the context. This can be done once commands
+ */
+void vmw_context_binding_state_transfer(struct vmw_resource *ctx,
+     struct vmw_ctx_binding_state *from)
+{
+ struct vmw_user_context *uctx =
+  container_of(ctx, struct vmw_user_context, res);
+ struct vmw_ctx_binding *entry, *next;
+
+ list_for_each_entry_safe(entry, next, &from->list, ctx_list)
+  vmw_context_binding_transfer(&uctx->cbs, &entry->bi);
+}
+
+/**
+ * vmw_context_rebind_all - Rebind all scrubbed bindings of a context
+ *
+ * @ctx: The context resource
+ *
+ * Walks through the context binding list and rebinds all scrubbed
+ * resources.
+ */
+int vmw_context_rebind_all(struct vmw_resource *ctx)
+{
+ struct vmw_ctx_binding *entry;
+ struct vmw_user_context *uctx =
+  container_of(ctx, struct vmw_user_context, res);
+ struct vmw_ctx_binding_state *cbs = &uctx->cbs;
+ int ret;
+
+ list_for_each_entry(entry, &cbs->list, ctx_list) {
+  if (likely(!entry->bi.scrubbed))
+   continue;
+
+  if (WARN_ON(entry->bi.res == NULL || entry->bi.res->id ==
+       SVGA3D_INVALID_ID))
+   continue;
+
+  ret = vmw_scrub_funcs[entry->bi.bt](&entry->bi, true);
+  if (unlikely(ret != 0))
+   return ret;
+
+  entry->bi.scrubbed = false;
+ }
+
+ return 0;
+}
+
+/**
+ * vmw_context_binding_list - Return a list of context bindings
+ *
+ * @ctx: The context resource
+ *
+ * Returns the current list of bindings of the given context. Note that
+ * this list becomes stale as soon as the dev_priv::binding_mutex is unlocked.
+ */
+struct list_head *vmw_context_binding_list(struct vmw_resource *ctx)
+{
+ return &(container_of(ctx, struct vmw_user_context, res)->cbs.list);
+}
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_dmabuf.c b/drivers/gpu/drm/vmwgfx/vmwgfx_dmabuf.c
index d4e54fc..a758402 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_dmabuf.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_dmabuf.c
@@ -290,8 +290,7 @@ void vmw_bo_get_guest_ptr(const struct ttm_buffer_object *bo,
 /**
  * vmw_bo_pin - Pin or unpin a buffer object without moving it.
  *
- * @bo: The buffer object. Must be reserved, and present either in VRAM
- * or GMR memory.
+ * @bo: The buffer object. Must be reserved.
  * @pin: Whether to pin or unpin.
  *
  */
@@ -303,10 +302,9 @@ void vmw_bo_pin(struct ttm_buffer_object *bo, bool pin)
  int ret;
 
  lockdep_assert_held(&bo->resv->lock.base);
- BUG_ON(old_mem_type != TTM_PL_VRAM &&
-        old_mem_type != VMW_PL_GMR);
 
- pl_flags = TTM_PL_FLAG_VRAM | VMW_PL_FLAG_GMR | TTM_PL_FLAG_CACHED;
+ pl_flags = TTM_PL_FLAG_VRAM | VMW_PL_FLAG_GMR | VMW_PL_FLAG_MOB
+  | TTM_PL_FLAG_SYSTEM | TTM_PL_FLAG_CACHED;
  if (pin)
   pl_flags |= TTM_PL_FLAG_NO_EVICT;
 
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_drv.c b/drivers/gpu/drm/vmwgfx/vmwgfx_drv.c
index 6c792f7..0083cbf 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_drv.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_drv.c
@@ -112,6 +112,21 @@
 #define DRM_IOCTL_VMW_UPDATE_LAYOUT    \
  DRM_IOW(DRM_COMMAND_BASE + DRM_VMW_UPDATE_LAYOUT, \
    struct drm_vmw_update_layout_arg)
+#define DRM_IOCTL_VMW_CREATE_SHADER    \
+ DRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_CREATE_SHADER, \
+   struct drm_vmw_shader_create_arg)
+#define DRM_IOCTL_VMW_UNREF_SHADER    \
+ DRM_IOW(DRM_COMMAND_BASE + DRM_VMW_UNREF_SHADER, \
+   struct drm_vmw_shader_arg)
+#define DRM_IOCTL_VMW_GB_SURFACE_CREATE    \
+ DRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_GB_SURFACE_CREATE, \
+   union drm_vmw_gb_surface_create_arg)
+#define DRM_IOCTL_VMW_GB_SURFACE_REF    \
+ DRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_GB_SURFACE_REF, \
+   union drm_vmw_gb_surface_reference_arg)
+#define DRM_IOCTL_VMW_SYNCCPU     \
+ DRM_IOW(DRM_COMMAND_BASE + DRM_VMW_SYNCCPU,  \
+   struct drm_vmw_synccpu_arg)
 
 /**
  * The core DRM version of this macro doesn't account for
@@ -177,6 +192,21 @@ static const struct drm_ioctl_desc vmw_ioctls[] = {
  VMW_IOCTL_DEF(VMW_UPDATE_LAYOUT,
         vmw_kms_update_layout_ioctl,
         DRM_MASTER | DRM_UNLOCKED),
+ VMW_IOCTL_DEF(VMW_CREATE_SHADER,
+        vmw_shader_define_ioctl,
+        DRM_AUTH | DRM_UNLOCKED),
+ VMW_IOCTL_DEF(VMW_UNREF_SHADER,
+        vmw_shader_destroy_ioctl,
+        DRM_AUTH | DRM_UNLOCKED),
+ VMW_IOCTL_DEF(VMW_GB_SURFACE_CREATE,
+        vmw_gb_surface_define_ioctl,
+        DRM_AUTH | DRM_UNLOCKED),
+ VMW_IOCTL_DEF(VMW_GB_SURFACE_REF,
+        vmw_gb_surface_reference_ioctl,
+        DRM_AUTH | DRM_UNLOCKED),
+ VMW_IOCTL_DEF(VMW_SYNCCPU,
+        vmw_user_dmabuf_synccpu_ioctl,
+        DRM_AUTH | DRM_UNLOCKED),
 };
 
 static struct pci_device_id vmw_pci_id_list[] = {
@@ -243,38 +273,52 @@ static void vmw_print_capabilities(uint32_t capabilities)
   DRM_INFO("  GMR2.\n");
  if (capabilities & SVGA_CAP_SCREEN_OBJECT_2)
   DRM_INFO("  Screen Object 2.\n");
+ if (capabilities & SVGA_CAP_COMMAND_BUFFERS)
+  DRM_INFO("  Command Buffers.\n");
+ if (capabilities & SVGA_CAP_CMD_BUFFERS_2)
+  DRM_INFO("  Command Buffers 2.\n");
+ if (capabilities & SVGA_CAP_GBOBJECTS)
+  DRM_INFO("  Guest Backed Resources.\n");
 }
 
-
 /**
- * vmw_execbuf_prepare_dummy_query - Initialize a query result structure at
- * the start of a buffer object.
+ * vmw_dummy_query_bo_create - create a bo to hold a dummy query result
  *
- * @dev_priv: The device private structure.
+ * @dev_priv: A device private structure.
  *
- * This function will idle the buffer using an uninterruptible wait, then
- * map the first page and initialize a pending occlusion query result structure,
- * Finally it will unmap the buffer.
+ * This function creates a small buffer object that holds the query
+ * result for dummy queries emitted as query barriers.
+ * The function will then map the first page and initialize a pending
+ * occlusion query result structure, Finally it will unmap the buffer.
+ * No interruptible waits are done within this function.
  *
- * TODO: Since we're only mapping a single page, we should optimize the map
- * to use kmap_atomic / iomap_atomic.
+ * Returns an error if bo creation or initialization fails.
  */
-static void vmw_dummy_query_bo_prepare(struct vmw_private *dev_priv)
+static int vmw_dummy_query_bo_create(struct vmw_private *dev_priv)
 {
+ int ret;
+ struct ttm_buffer_object *bo;
  struct ttm_bo_kmap_obj map;
  volatile SVGA3dQueryResult *result;
  bool dummy;
- int ret;
- struct ttm_bo_device *bdev = &dev_priv->bdev;
- struct ttm_buffer_object *bo = dev_priv->dummy_query_bo;
 
- ttm_bo_reserve(bo, false, false, false, 0);
- spin_lock(&bdev->fence_lock);
- ret = ttm_bo_wait(bo, false, false, false);
- spin_unlock(&bdev->fence_lock);
+ /*
+  * Create the bo as pinned, so that a tryreserve will
+  * immediately succeed. This is because we're the only
+  * user of the bo currently.
+  */
+ ret = ttm_bo_create(&dev_priv->bdev,
+       PAGE_SIZE,
+       ttm_bo_type_device,
+       &vmw_sys_ne_placement,
+       0, false, NULL,
+       &bo);
+
  if (unlikely(ret != 0))
-  (void) vmw_fallback_wait(dev_priv, false, true, 0, false,
-      10*HZ);
+  return ret;
+
+ ret = ttm_bo_reserve(bo, false, true, false, 0);
+ BUG_ON(ret != 0);
 
  ret = ttm_bo_kmap(bo, 0, 1, &map);
  if (likely(ret == 0)) {
@@ -283,34 +327,19 @@ static void vmw_dummy_query_bo_prepare(struct vmw_private *dev_priv)
   result->state = SVGA3D_QUERYSTATE_PENDING;
   result->result32 = 0xff;
   ttm_bo_kunmap(&map);
- } else
-  DRM_ERROR("Dummy query buffer map failed.\n");
+ }
+ vmw_bo_pin(bo, false);
  ttm_bo_unreserve(bo);
-}
 
+ if (unlikely(ret != 0)) {
+  DRM_ERROR("Dummy query buffer map failed.\n");
+  ttm_bo_unref(&bo);
+ } else
+  dev_priv->dummy_query_bo = bo;
 
-/**
- * vmw_dummy_query_bo_create - create a bo to hold a dummy query result
- *
- * @dev_priv: A device private structure.
- *
- * This function creates a small buffer object that holds the query
- * result for dummy queries emitted as query barriers.
- * No interruptible waits are done within this function.
- *
- * Returns an error if bo creation fails.
- */
-static int vmw_dummy_query_bo_create(struct vmw_private *dev_priv)
-{
- return ttm_bo_create(&dev_priv->bdev,
-        PAGE_SIZE,
-        ttm_bo_type_device,
-        &vmw_vram_sys_placement,
-        0, false, NULL,
-        &dev_priv->dummy_query_bo);
+ return ret;
 }
 
-
 static int vmw_request_device(struct vmw_private *dev_priv)
 {
  int ret;
@@ -321,14 +350,24 @@ static int vmw_request_device(struct vmw_private *dev_priv)
   return ret;
  }
  vmw_fence_fifo_up(dev_priv->fman);
+ if (dev_priv->has_mob) {
+  ret = vmw_otables_setup(dev_priv);
+  if (unlikely(ret != 0)) {
+   DRM_ERROR("Unable to initialize "
+      "guest Memory OBjects.\n");
+   goto out_no_mob;
+  }
+ }
  ret = vmw_dummy_query_bo_create(dev_priv);
  if (unlikely(ret != 0))
   goto out_no_query_bo;
- vmw_dummy_query_bo_prepare(dev_priv);
 
  return 0;
 
 out_no_query_bo:
+ if (dev_priv->has_mob)
+  vmw_otables_takedown(dev_priv);
+out_no_mob:
  vmw_fence_fifo_down(dev_priv->fman);
  vmw_fifo_release(dev_priv, &dev_priv->fifo);
  return ret;
@@ -344,10 +383,13 @@ static void vmw_release_device(struct vmw_private *dev_priv)
  BUG_ON(dev_priv->pinned_bo != NULL);
 
  ttm_bo_unref(&dev_priv->dummy_query_bo);
+ if (dev_priv->has_mob)
+  vmw_otables_takedown(dev_priv);
  vmw_fence_fifo_down(dev_priv->fman);
  vmw_fifo_release(dev_priv, &dev_priv->fifo);
 }
 
+
 /**
  * Increase the 3d resource refcount.
  * If the count was prevously zero, initialize the fifo, switching to svga
@@ -562,6 +604,7 @@ static int vmw_driver_load(struct drm_device *dev, unsigned long chipset)
  mutex_init(&dev_priv->hw_mutex);
  mutex_init(&dev_priv->cmdbuf_mutex);
  mutex_init(&dev_priv->release_mutex);
+ mutex_init(&dev_priv->binding_mutex);
  rwlock_init(&dev_priv->resource_lock);
 
  for (i = vmw_res_context; i < vmw_res_max; ++i) {
@@ -623,10 +666,30 @@ static int vmw_driver_load(struct drm_device *dev, unsigned long chipset)
    */
   dev_priv->memory_size = 512*1024*1024;
  }
+ dev_priv->max_mob_pages = 0;
+ dev_priv->max_mob_size = 0;
+ if (dev_priv->capabilities & SVGA_CAP_GBOBJECTS) {
+  uint64_t mem_size =
+   vmw_read(dev_priv,
+     SVGA_REG_SUGGESTED_GBOBJECT_MEM_SIZE_KB);
+
+  dev_priv->max_mob_pages = mem_size * 1024 / PAGE_SIZE;
+  dev_priv->prim_bb_mem =
+   vmw_read(dev_priv,
+     SVGA_REG_MAX_PRIMARY_BOUNDING_BOX_MEM);
+  dev_priv->max_mob_size =
+   vmw_read(dev_priv, SVGA_REG_MOB_MAX_SIZE);
+ } else
+  dev_priv->prim_bb_mem = dev_priv->vram_size;
 
  ret = vmw_dma_masks(dev_priv);
- if (unlikely(ret != 0))
+ if (unlikely(ret != 0)) {
+  mutex_unlock(&dev_priv->hw_mutex);
   goto out_err0;
+ }
+
+ if (unlikely(dev_priv->prim_bb_mem < dev_priv->vram_size))
+  dev_priv->prim_bb_mem = dev_priv->vram_size;
 
  mutex_unlock(&dev_priv->hw_mutex);
 
@@ -640,6 +703,8 @@ static int vmw_driver_load(struct drm_device *dev, unsigned long chipset)
   DRM_INFO("Max dedicated hypervisor surface memory is %u kiB\n",
     (unsigned)dev_priv->memory_size / 1024);
  }
+ DRM_INFO("Maximum display memory size is %u kiB\n",
+   dev_priv->prim_bb_mem / 1024);
  DRM_INFO("VRAM at 0x%08x size is %u kiB\n",
    dev_priv->vram_start, dev_priv->vram_size / 1024);
  DRM_INFO("MMIO at 0x%08x size is %u kiB\n",
@@ -674,12 +739,22 @@ static int vmw_driver_load(struct drm_device *dev, unsigned long chipset)
  dev_priv->has_gmr = true;
  if (((dev_priv->capabilities & (SVGA_CAP_GMR | SVGA_CAP_GMR2)) == 0) ||
      refuse_dma || ttm_bo_init_mm(&dev_priv->bdev, VMW_PL_GMR,
-      dev_priv->max_gmr_ids) != 0) {
+      VMW_PL_GMR) != 0) {
   DRM_INFO("No GMR memory available. "
     "Graphics memory resources are very limited.\n");
   dev_priv->has_gmr = false;
  }
 
+ if (dev_priv->capabilities & SVGA_CAP_GBOBJECTS) {
+  dev_priv->has_mob = true;
+  if (ttm_bo_init_mm(&dev_priv->bdev, VMW_PL_MOB,
+       VMW_PL_MOB) != 0) {
+   DRM_INFO("No MOB memory available. "
+     "3D will be disabled.\n");
+   dev_priv->has_mob = false;
+  }
+ }
+
  dev_priv->mmio_mtrr = arch_phys_wc_add(dev_priv->mmio_start,
             dev_priv->mmio_size);
 
@@ -782,6 +857,8 @@ out_err4:
  iounmap(dev_priv->mmio_virt);
 out_err3:
  arch_phys_wc_del(dev_priv->mmio_mtrr);
+ if (dev_priv->has_mob)
+  (void) ttm_bo_clean_mm(&dev_priv->bdev, VMW_PL_MOB);
  if (dev_priv->has_gmr)
   (void) ttm_bo_clean_mm(&dev_priv->bdev, VMW_PL_GMR);
  (void)ttm_bo_clean_mm(&dev_priv->bdev, TTM_PL_VRAM);
@@ -826,6 +903,8 @@ static int vmw_driver_unload(struct drm_device *dev)
  ttm_object_device_release(&dev_priv->tdev);
  iounmap(dev_priv->mmio_virt);
  arch_phys_wc_del(dev_priv->mmio_mtrr);
+ if (dev_priv->has_mob)
+  (void) ttm_bo_clean_mm(&dev_priv->bdev, VMW_PL_MOB);
  if (dev_priv->has_gmr)
   (void)ttm_bo_clean_mm(&dev_priv->bdev, VMW_PL_GMR);
  (void)ttm_bo_clean_mm(&dev_priv->bdev, TTM_PL_VRAM);
@@ -865,6 +944,7 @@ static void vmw_postclose(struct drm_device *dev,
   drm_master_put(&vmw_fp->locked_master);
  }
 
+ vmw_compat_shader_man_destroy(vmw_fp->shman);
  ttm_object_file_release(&vmw_fp->tfile);
  kfree(vmw_fp);
 }
@@ -884,11 +964,17 @@ static int vmw_driver_open(struct drm_device *dev, struct drm_file *file_priv)
  if (unlikely(vmw_fp->tfile == NULL))
   goto out_no_tfile;
 
+ vmw_fp->shman = vmw_compat_shader_man_create(dev_priv);
+ if (IS_ERR(vmw_fp->shman))
+  goto out_no_shman;
+
  file_priv->driver_priv = vmw_fp;
  dev_priv->bdev.dev_mapping = dev->dev_mapping;
 
  return 0;
 
+out_no_shman:
+ ttm_object_file_release(&vmw_fp->tfile);
 out_no_tfile:
  kfree(vmw_fp);
  return ret;
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_drv.h b/drivers/gpu/drm/vmwgfx/vmwgfx_drv.h
index c0b73b9..0783155 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_drv.h
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_drv.h
@@ -40,9 +40,9 @@
 #include <drm/ttm/ttm_module.h>
 #include "vmwgfx_fence.h"
 
-#define VMWGFX_DRIVER_DATE "20120209"
+#define VMWGFX_DRIVER_DATE "20140228"
 #define VMWGFX_DRIVER_MAJOR 2
-#define VMWGFX_DRIVER_MINOR 4
+#define VMWGFX_DRIVER_MINOR 5
 #define VMWGFX_DRIVER_PATCHLEVEL 0
 #define VMWGFX_FILE_PAGE_OFFSET 0x00100000
 #define VMWGFX_FIFO_STATIC_SIZE (1024*1024)
@@ -50,19 +50,39 @@
 #define VMWGFX_MAX_VALIDATIONS 2048
 #define VMWGFX_MAX_DISPLAYS 16
 #define VMWGFX_CMD_BOUNCE_INIT_SIZE 32768
+#define VMWGFX_ENABLE_SCREEN_TARGET_OTABLE 0
+
+/*
+ * Perhaps we should have sysfs entries for these.
+ */
+#define VMWGFX_NUM_GB_CONTEXT 256
+#define VMWGFX_NUM_GB_SHADER 20000
+#define VMWGFX_NUM_GB_SURFACE 32768
+#define VMWGFX_NUM_GB_SCREEN_TARGET VMWGFX_MAX_DISPLAYS
+#define VMWGFX_NUM_MOB (VMWGFX_NUM_GB_CONTEXT +\
+   VMWGFX_NUM_GB_SHADER +\
+   VMWGFX_NUM_GB_SURFACE +\
+   VMWGFX_NUM_GB_SCREEN_TARGET)
 
 #define VMW_PL_GMR TTM_PL_PRIV0
 #define VMW_PL_FLAG_GMR TTM_PL_FLAG_PRIV0
+#define VMW_PL_MOB TTM_PL_PRIV1
+#define VMW_PL_FLAG_MOB TTM_PL_FLAG_PRIV1
 
 #define VMW_RES_CONTEXT ttm_driver_type0
 #define VMW_RES_SURFACE ttm_driver_type1
 #define VMW_RES_STREAM ttm_driver_type2
 #define VMW_RES_FENCE ttm_driver_type3
+#define VMW_RES_SHADER ttm_driver_type4
+
+struct vmw_compat_shader_manager;
 
 struct vmw_fpriv {
  struct drm_master *locked_master;
  struct ttm_object_file *tfile;
  struct list_head fence_events;
+ bool gb_aware;
+ struct vmw_compat_shader_manager *shman;
 };
 
 struct vmw_dma_buffer {
@@ -82,6 +102,7 @@ struct vmw_dma_buffer {
 struct vmw_validate_buffer {
  struct ttm_validate_buffer base;
  struct drm_hash_item hash;
+ bool validate_as_mob;
 };
 
 struct vmw_res_func;
@@ -98,6 +119,7 @@ struct vmw_resource {
  const struct vmw_res_func *func;
  struct list_head lru_head; /* Protected by the resource lock */
  struct list_head mob_head; /* Protected by @backup reserved */
+ struct list_head binding_head; /* Protected by binding_mutex */
  void (*res_free) (struct vmw_resource *res);
  void (*hw_destroy) (struct vmw_resource *res);
 };
@@ -106,6 +128,7 @@ enum vmw_res_type {
  vmw_res_context,
  vmw_res_surface,
  vmw_res_stream,
+ vmw_res_shader,
  vmw_res_max
 };
 
@@ -154,6 +177,7 @@ struct vmw_fifo_state {
 };
 
 struct vmw_relocation {
+ SVGAMobId *mob_loc;
  SVGAGuestPtr *location;
  uint32_t index;
 };
@@ -229,11 +253,77 @@ struct vmw_piter {
  struct page *(*page)(struct vmw_piter *);
 };
 
+/*
+ * enum vmw_ctx_binding_type - abstract resource to context binding types
+ */
+enum vmw_ctx_binding_type {
+ vmw_ctx_binding_shader,
+ vmw_ctx_binding_rt,
+ vmw_ctx_binding_tex,
+ vmw_ctx_binding_max
+};
+
+/**
+ * struct vmw_ctx_bindinfo - structure representing a single context binding
+ *
+ * @ctx: Pointer to the context structure. NULL means the binding is not
+ * active.
+ * @res: Non ref-counted pointer to the bound resource.
+ * @bt: The binding type.
+ * @i1: Union of information needed to unbind.
+ */
+struct vmw_ctx_bindinfo {
+ struct vmw_resource *ctx;
+ struct vmw_resource *res;
+ enum vmw_ctx_binding_type bt;
+ bool scrubbed;
+ union {
+  SVGA3dShaderType shader_type;
+  SVGA3dRenderTargetType rt_type;
+  uint32 texture_stage;
+ } i1;
+};
+
+/**
+ * struct vmw_ctx_binding - structure representing a single context binding
+ *                        - suitable for tracking in a context
+ *
+ * @ctx_list: List head for context.
+ * @res_list: List head for bound resource.
+ * @bi: Binding info
+ */
+struct vmw_ctx_binding {
+ struct list_head ctx_list;
+ struct list_head res_list;
+ struct vmw_ctx_bindinfo bi;
+};
+
+
+/**
+ * struct vmw_ctx_binding_state - context binding state
+ *
+ * @list: linked list of individual bindings.
+ * @render_targets: Render target bindings.
+ * @texture_units: Texture units/samplers bindings.
+ * @shaders: Shader bindings.
+ *
+ * Note that this structure also provides storage space for the individual
+ * struct vmw_ctx_binding objects, so that no dynamic allocation is needed
+ * for individual bindings.
+ *
+ */
+struct vmw_ctx_binding_state {
+ struct list_head list;
+ struct vmw_ctx_binding render_targets[SVGA3D_RT_MAX];
+ struct vmw_ctx_binding texture_units[SVGA3D_NUM_TEXTURE_UNITS];
+ struct vmw_ctx_binding shaders[SVGA3D_SHADERTYPE_MAX];
+};
+
 struct vmw_sw_context{
  struct drm_open_hash res_ht;
  bool res_ht_initialized;
  bool kernel; /**< is the called made from the kernel */
- struct ttm_object_file *tfile;
+ struct vmw_fpriv *fp;
  struct list_head validate_nodes;
  struct vmw_relocation relocs[VMWGFX_MAX_RELOCATIONS];
  uint32_t cur_reloc;
@@ -250,6 +340,8 @@ struct vmw_sw_context{
  struct vmw_resource *last_query_ctx;
  bool needs_post_query_barrier;
  struct vmw_resource *error_resource;
+ struct vmw_ctx_binding_state staged_bindings;
+ struct list_head staged_shaders;
 };
 
 struct vmw_legacy_display;
@@ -281,6 +373,7 @@ struct vmw_private {
  unsigned int io_start;
  uint32_t vram_start;
  uint32_t vram_size;
+ uint32_t prim_bb_mem;
  uint32_t mmio_start;
  uint32_t mmio_size;
  uint32_t fb_max_width;
@@ -292,8 +385,11 @@ struct vmw_private {
  uint32_t capabilities;
  uint32_t max_gmr_ids;
  uint32_t max_gmr_pages;
+ uint32_t max_mob_pages;
+ uint32_t max_mob_size;
  uint32_t memory_size;
  bool has_gmr;
+ bool has_mob;
  struct mutex hw_mutex;
 
  /*
@@ -369,6 +465,7 @@ struct vmw_private {
 
  struct vmw_sw_context ctx;
  struct mutex cmdbuf_mutex;
+ struct mutex binding_mutex;
 
  /**
   * Operating mode.
@@ -414,6 +511,12 @@ struct vmw_private {
   * DMA mapping stuff.
   */
  enum vmw_dma_map_mode map_mode;
+
+ /*
+  * Guest Backed stuff
+  */
+ struct ttm_buffer_object *otable_bo;
+ struct vmw_otable *otables;
 };
 
 static inline struct vmw_surface *vmw_res_to_srf(struct vmw_resource *res)
@@ -470,23 +573,14 @@ extern void vmw_gmr_unbind(struct vmw_private *dev_priv, int gmr_id);
  * Resource utilities - vmwgfx_resource.c
  */
 struct vmw_user_resource_conv;
-extern const struct vmw_user_resource_conv *user_surface_converter;
-extern const struct vmw_user_resource_conv *user_context_converter;
 
-extern struct vmw_resource *vmw_context_alloc(struct vmw_private *dev_priv);
 extern void vmw_resource_unreference(struct vmw_resource **p_res);
 extern struct vmw_resource *vmw_resource_reference(struct vmw_resource *res);
+extern struct vmw_resource *
+vmw_resource_reference_unless_doomed(struct vmw_resource *res);
 extern int vmw_resource_validate(struct vmw_resource *res);
 extern int vmw_resource_reserve(struct vmw_resource *res, bool no_backup);
 extern bool vmw_resource_needs_backup(const struct vmw_resource *res);
-extern int vmw_context_destroy_ioctl(struct drm_device *dev, void *data,
-         struct drm_file *file_priv);
-extern int vmw_context_define_ioctl(struct drm_device *dev, void *data,
-        struct drm_file *file_priv);
-extern int vmw_context_check(struct vmw_private *dev_priv,
-        struct ttm_object_file *tfile,
-        int id,
-        struct vmw_resource **p_res);
 extern int vmw_user_lookup_handle(struct vmw_private *dev_priv,
       struct ttm_object_file *tfile,
       uint32_t handle,
@@ -498,18 +592,6 @@ extern int vmw_user_resource_lookup_handle(
  uint32_t handle,
  const struct vmw_user_resource_conv *converter,
  struct vmw_resource **p_res);
-extern void vmw_surface_res_free(struct vmw_resource *res);
-extern int vmw_surface_destroy_ioctl(struct drm_device *dev, void *data,
-         struct drm_file *file_priv);
-extern int vmw_surface_define_ioctl(struct drm_device *dev, void *data,
-        struct drm_file *file_priv);
-extern int vmw_surface_reference_ioctl(struct drm_device *dev, void *data,
-           struct drm_file *file_priv);
-extern int vmw_surface_check(struct vmw_private *dev_priv,
-        struct ttm_object_file *tfile,
-        uint32_t handle, int *id);
-extern int vmw_surface_validate(struct vmw_private *dev_priv,
-    struct vmw_surface *srf);
 extern void vmw_dmabuf_bo_free(struct ttm_buffer_object *bo);
 extern int vmw_dmabuf_init(struct vmw_private *dev_priv,
       struct vmw_dma_buffer *vmw_bo,
@@ -518,10 +600,21 @@ extern int vmw_dmabuf_init(struct vmw_private *dev_priv,
       void (*bo_free) (struct ttm_buffer_object *bo));
 extern int vmw_user_dmabuf_verify_access(struct ttm_buffer_object *bo,
       struct ttm_object_file *tfile);
+extern int vmw_user_dmabuf_alloc(struct vmw_private *dev_priv,
+     struct ttm_object_file *tfile,
+     uint32_t size,
+     bool shareable,
+     uint32_t *handle,
+     struct vmw_dma_buffer **p_dma_buf);
+extern int vmw_user_dmabuf_reference(struct ttm_object_file *tfile,
+         struct vmw_dma_buffer *dma_buf,
+         uint32_t *handle);
 extern int vmw_dmabuf_alloc_ioctl(struct drm_device *dev, void *data,
       struct drm_file *file_priv);
 extern int vmw_dmabuf_unref_ioctl(struct drm_device *dev, void *data,
       struct drm_file *file_priv);
+extern int vmw_user_dmabuf_synccpu_ioctl(struct drm_device *dev, void *data,
+      struct drm_file *file_priv);
 extern uint32_t vmw_dmabuf_validate_node(struct ttm_buffer_object *bo,
       uint32_t cur_validate_node);
 extern void vmw_dmabuf_validate_clear(struct ttm_buffer_object *bo);
@@ -621,10 +714,16 @@ extern struct ttm_placement vmw_vram_sys_placement;
 extern struct ttm_placement vmw_vram_gmr_placement;
 extern struct ttm_placement vmw_vram_gmr_ne_placement;
 extern struct ttm_placement vmw_sys_placement;
+extern struct ttm_placement vmw_sys_ne_placement;
 extern struct ttm_placement vmw_evictable_placement;
 extern struct ttm_placement vmw_srf_placement;
+extern struct ttm_placement vmw_mob_placement;
 extern struct ttm_bo_driver vmw_bo_driver;
 extern int vmw_dma_quiescent(struct drm_device *dev);
+extern int vmw_bo_map_dma(struct ttm_buffer_object *bo);
+extern void vmw_bo_unmap_dma(struct ttm_buffer_object *bo);
+extern const struct vmw_sg_table *
+vmw_bo_sg_table(struct ttm_buffer_object *bo);
 extern void vmw_piter_start(struct vmw_piter *viter,
        const struct vmw_sg_table *vsgt,
        unsigned long p_offs);
@@ -700,7 +799,7 @@ extern void vmw_execbuf_copy_fence_user(struct vmw_private *dev_priv,
  * IRQs and wating - vmwgfx_irq.c
  */
 
-extern irqreturn_t vmw_irq_handler(DRM_IRQ_ARGS);
+extern irqreturn_t vmw_irq_handler(int irq, void *arg);
 extern int vmw_wait_seqno(struct vmw_private *dev_priv, bool lazy,
         uint32_t seqno, bool interruptible,
         unsigned long timeout);
@@ -831,6 +930,101 @@ extern int vmw_prime_handle_to_fd(struct drm_device *dev,
       uint32_t handle, uint32_t flags,
       int *prime_fd);
 
+/*
+ * MemoryOBject management -  vmwgfx_mob.c
+ */
+struct vmw_mob;
+extern int vmw_mob_bind(struct vmw_private *dev_priv, struct vmw_mob *mob,
+   const struct vmw_sg_table *vsgt,
+   unsigned long num_data_pages, int32_t mob_id);
+extern void vmw_mob_unbind(struct vmw_private *dev_priv,
+      struct vmw_mob *mob);
+extern void vmw_mob_destroy(struct vmw_mob *mob);
+extern struct vmw_mob *vmw_mob_create(unsigned long data_pages);
+extern int vmw_otables_setup(struct vmw_private *dev_priv);
+extern void vmw_otables_takedown(struct vmw_private *dev_priv);
+
+/*
+ * Context management - vmwgfx_context.c
+ */
+
+extern const struct vmw_user_resource_conv *user_context_converter;
+
+extern struct vmw_resource *vmw_context_alloc(struct vmw_private *dev_priv);
+
+extern int vmw_context_check(struct vmw_private *dev_priv,
+        struct ttm_object_file *tfile,
+        int id,
+        struct vmw_resource **p_res);
+extern int vmw_context_define_ioctl(struct drm_device *dev, void *data,
+        struct drm_file *file_priv);
+extern int vmw_context_destroy_ioctl(struct drm_device *dev, void *data,
+         struct drm_file *file_priv);
+extern int vmw_context_binding_add(struct vmw_ctx_binding_state *cbs,
+       const struct vmw_ctx_bindinfo *ci);
+extern void
+vmw_context_binding_state_transfer(struct vmw_resource *res,
+       struct vmw_ctx_binding_state *cbs);
+extern void vmw_context_binding_res_list_kill(struct list_head *head);
+extern void vmw_context_binding_res_list_scrub(struct list_head *head);
+extern int vmw_context_rebind_all(struct vmw_resource *ctx);
+extern struct list_head *vmw_context_binding_list(struct vmw_resource *ctx);
+
+/*
+ * Surface management - vmwgfx_surface.c
+ */
+
+extern const struct vmw_user_resource_conv *user_surface_converter;
+
+extern void vmw_surface_res_free(struct vmw_resource *res);
+extern int vmw_surface_destroy_ioctl(struct drm_device *dev, void *data,
+         struct drm_file *file_priv);
+extern int vmw_surface_define_ioctl(struct drm_device *dev, void *data,
+        struct drm_file *file_priv);
+extern int vmw_surface_reference_ioctl(struct drm_device *dev, void *data,
+           struct drm_file *file_priv);
+extern int vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,
+           struct drm_file *file_priv);
+extern int vmw_gb_surface_reference_ioctl(struct drm_device *dev, void *data,
+       struct drm_file *file_priv);
+extern int vmw_surface_check(struct vmw_private *dev_priv,
+        struct ttm_object_file *tfile,
+        uint32_t handle, int *id);
+extern int vmw_surface_validate(struct vmw_private *dev_priv,
+    struct vmw_surface *srf);
+
+/*
+ * Shader management - vmwgfx_shader.c
+ */
+
+extern const struct vmw_user_resource_conv *user_shader_converter;
+
+extern int vmw_shader_define_ioctl(struct drm_device *dev, void *data,
+       struct drm_file *file_priv);
+extern int vmw_shader_destroy_ioctl(struct drm_device *dev, void *data,
+        struct drm_file *file_priv);
+extern int vmw_compat_shader_lookup(struct vmw_compat_shader_manager *man,
+        SVGA3dShaderType shader_type,
+        u32 *user_key);
+extern void vmw_compat_shaders_commit(struct vmw_compat_shader_manager *man,
+          struct list_head *list);
+extern void vmw_compat_shaders_revert(struct vmw_compat_shader_manager *man,
+          struct list_head *list);
+extern int vmw_compat_shader_remove(struct vmw_compat_shader_manager *man,
+        u32 user_key,
+        SVGA3dShaderType shader_type,
+        struct list_head *list);
+extern int vmw_compat_shader_add(struct vmw_compat_shader_manager *man,
+     u32 user_key, const void *bytecode,
+     SVGA3dShaderType shader_type,
+     size_t size,
+     struct ttm_object_file *tfile,
+     struct list_head *list);
+extern struct vmw_compat_shader_manager *
+vmw_compat_shader_man_create(struct vmw_private *dev_priv);
+extern void
+vmw_compat_shader_man_destroy(struct vmw_compat_shader_manager *man);
+
 
 /**
  * Inline helper functions
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c b/drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c
index 8b059eb..efb575a 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c
@@ -54,6 +54,8 @@ struct vmw_resource_relocation {
  * @res: Ref-counted pointer to the resource.
  * @switch_backup: Boolean whether to switch backup buffer on unreserve.
  * @new_backup: Refcounted pointer to the new backup buffer.
+ * @staged_bindings: If @res is a context, tracks bindings set up during
+ * the command batch. Otherwise NULL.
  * @new_backup_offset: New backup buffer offset if @new_backup is non-NUll.
  * @first_usage: Set to true the first time the resource is referenced in
  * the command stream.
@@ -65,12 +67,32 @@ struct vmw_resource_val_node {
  struct drm_hash_item hash;
  struct vmw_resource *res;
  struct vmw_dma_buffer *new_backup;
+ struct vmw_ctx_binding_state *staged_bindings;
  unsigned long new_backup_offset;
  bool first_usage;
  bool no_buffer_needed;
 };
 
 /**
+ * struct vmw_cmd_entry - Describe a command for the verifier
+ *
+ * @user_allow: Whether allowed from the execbuf ioctl.
+ * @gb_disable: Whether disabled if guest-backed objects are available.
+ * @gb_enable: Whether enabled iff guest-backed objects are available.
+ */
+struct vmw_cmd_entry {
+ int (*func) (struct vmw_private *, struct vmw_sw_context *,
+       SVGA3dCmdHeader *);
+ bool user_allow;
+ bool gb_disable;
+ bool gb_enable;
+};
+
+#define VMW_CMD_DEF(_cmd, _func, _user_allow, _gb_disable, _gb_enable) \
+ [(_cmd) - SVGA_3D_CMD_BASE] = {(_func), (_user_allow),\
+           (_gb_disable), (_gb_enable)}
+
+/**
  * vmw_resource_unreserve - unreserve resources previously reserved for
  * command submission.
  *
@@ -87,6 +109,18 @@ static void vmw_resource_list_unreserve(struct list_head *list,
   struct vmw_dma_buffer *new_backup =
    backoff ? NULL : val->new_backup;
 
+  /*
+   * Transfer staged context bindings to the
+   * persistent context binding tracker.
+   */
+  if (unlikely(val->staged_bindings)) {
+   if (!backoff) {
+    vmw_context_binding_state_transfer
+     (val->res, val->staged_bindings);
+   }
+   kfree(val->staged_bindings);
+   val->staged_bindings = NULL;
+  }
   vmw_resource_unreserve(res, new_backup,
    val->new_backup_offset);
   vmw_dmabuf_unreference(&val->new_backup);
@@ -146,6 +180,44 @@ static int vmw_resource_val_add(struct vmw_sw_context *sw_context,
 }
 
 /**
+ * vmw_resource_context_res_add - Put resources previously bound to a context on
+ * the validation list
+ *
+ * @dev_priv: Pointer to a device private structure
+ * @sw_context: Pointer to a software context used for this command submission
+ * @ctx: Pointer to the context resource
+ *
+ * This function puts all resources that were previously bound to @ctx on
+ * the resource validation list. This is part of the context state reemission
+ */
+static int vmw_resource_context_res_add(struct vmw_private *dev_priv,
+     struct vmw_sw_context *sw_context,
+     struct vmw_resource *ctx)
+{
+ struct list_head *binding_list;
+ struct vmw_ctx_binding *entry;
+ int ret = 0;
+ struct vmw_resource *res;
+
+ mutex_lock(&dev_priv->binding_mutex);
+ binding_list = vmw_context_binding_list(ctx);
+
+ list_for_each_entry(entry, binding_list, ctx_list) {
+  res = vmw_resource_reference_unless_doomed(entry->bi.res);
+  if (unlikely(res == NULL))
+   continue;
+
+  ret = vmw_resource_val_add(sw_context, entry->bi.res, NULL);
+  vmw_resource_unreference(&res);
+  if (unlikely(ret != 0))
+   break;
+ }
+
+ mutex_unlock(&dev_priv->binding_mutex);
+ return ret;
+}
+
+/**
  * vmw_resource_relocation_add - Add a relocation to the relocation list
  *
  * @list: Pointer to head of relocation list.
@@ -201,8 +273,12 @@ static void vmw_resource_relocations_apply(uint32_t *cb,
 {
  struct vmw_resource_relocation *rel;
 
- list_for_each_entry(rel, list, head)
-  cb[rel->offset] = rel->res->id;
+ list_for_each_entry(rel, list, head) {
+  if (likely(rel->res != NULL))
+   cb[rel->offset] = rel->res->id;
+  else
+   cb[rel->offset] = SVGA_3D_CMD_NOP;
+ }
 }
 
 static int vmw_cmd_invalid(struct vmw_private *dev_priv,
@@ -224,6 +300,7 @@ static int vmw_cmd_ok(struct vmw_private *dev_priv,
  *
  * @sw_context: The software context used for this command submission batch.
  * @bo: The buffer object to add.
+ * @validate_as_mob: Validate this buffer as a MOB.
  * @p_val_node: If non-NULL Will be updated with the validate node number
  * on return.
  *
@@ -232,6 +309,7 @@ static int vmw_cmd_ok(struct vmw_private *dev_priv,
  */
 static int vmw_bo_to_validate_list(struct vmw_sw_context *sw_context,
        struct ttm_buffer_object *bo,
+       bool validate_as_mob,
        uint32_t *p_val_node)
 {
  uint32_t val_node;
@@ -244,6 +322,10 @@ static int vmw_bo_to_validate_list(struct vmw_sw_context *sw_context,
         &hash) == 0)) {
   vval_buf = container_of(hash, struct vmw_validate_buffer,
      hash);
+  if (unlikely(vval_buf->validate_as_mob != validate_as_mob)) {
+   DRM_ERROR("Inconsistent buffer usage.\n");
+   return -EINVAL;
+  }
   val_buf = &vval_buf->base;
   val_node = vval_buf - sw_context->val_bufs;
  } else {
@@ -266,6 +348,7 @@ static int vmw_bo_to_validate_list(struct vmw_sw_context *sw_context,
   val_buf->bo = ttm_bo_reference(bo);
   val_buf->reserved = false;
   list_add_tail(&val_buf->head, &sw_context->validate_nodes);
+  vval_buf->validate_as_mob = validate_as_mob;
  }
 
  sw_context->fence_flags |= DRM_VMW_FENCE_FLAG_EXEC;
@@ -302,7 +385,8 @@ static int vmw_resources_reserve(struct vmw_sw_context *sw_context)
    struct ttm_buffer_object *bo = &res->backup->base;
 
    ret = vmw_bo_to_validate_list
-    (sw_context, bo, NULL);
+    (sw_context, bo,
+     vmw_resource_needs_backup(res), NULL);
 
    if (unlikely(ret != 0))
     return ret;
@@ -339,22 +423,27 @@ static int vmw_resources_validate(struct vmw_sw_context *sw_context)
 }
 
 /**
- * vmw_cmd_res_check - Check that a resource is present and if so, put it
+ * vmw_cmd_compat_res_check - Check that a resource is present and if so, put it
  * on the resource validate list unless it's already there.
  *
  * @dev_priv: Pointer to a device private structure.
  * @sw_context: Pointer to the software context.
  * @res_type: Resource type.
  * @converter: User-space visisble type specific information.
- * @id: Pointer to the location in the command buffer currently being
+ * @id: user-space resource id handle.
+ * @id_loc: Pointer to the location in the command buffer currently being
  * parsed from where the user-space resource id handle is located.
+ * @p_val: Pointer to pointer to resource validalidation node. Populated
+ * on exit.
  */
-static int vmw_cmd_res_check(struct vmw_private *dev_priv,
-        struct vmw_sw_context *sw_context,
-        enum vmw_res_type res_type,
-        const struct vmw_user_resource_conv *converter,
-        uint32_t *id,
-        struct vmw_resource_val_node **p_val)
+static int
+vmw_cmd_compat_res_check(struct vmw_private *dev_priv,
+    struct vmw_sw_context *sw_context,
+    enum vmw_res_type res_type,
+    const struct vmw_user_resource_conv *converter,
+    uint32_t id,
+    uint32_t *id_loc,
+    struct vmw_resource_val_node **p_val)
 {
  struct vmw_res_cache_entry *rcache =
   &sw_context->res_cache[res_type];
@@ -362,15 +451,22 @@ static int vmw_cmd_res_check(struct vmw_private *dev_priv,
  struct vmw_resource_val_node *node;
  int ret;
 
- if (*id == SVGA3D_INVALID_ID)
+ if (id == SVGA3D_INVALID_ID) {
+  if (p_val)
+   *p_val = NULL;
+  if (res_type == vmw_res_context) {
+   DRM_ERROR("Illegal context invalid id.\n");
+   return -EINVAL;
+  }
   return 0;
+ }
 
  /*
   * Fastpath in case of repeated commands referencing the same
   * resource
   */
 
- if (likely(rcache->valid && *id == rcache->handle)) {
+ if (likely(rcache->valid && id == rcache->handle)) {
   const struct vmw_resource *res = rcache->res;
 
   rcache->node->first_usage = false;
@@ -379,28 +475,28 @@ static int vmw_cmd_res_check(struct vmw_private *dev_priv,
 
   return vmw_resource_relocation_add
    (&sw_context->res_relocations, res,
-    id - sw_context->buf_start);
+    id_loc - sw_context->buf_start);
  }
 
  ret = vmw_user_resource_lookup_handle(dev_priv,
-           sw_context->tfile,
-           *id,
+           sw_context->fp->tfile,
+           id,
            converter,
            &res);
  if (unlikely(ret != 0)) {
   DRM_ERROR("Could not find or use resource 0x%08x.\n",
-     (unsigned) *id);
+     (unsigned) id);
   dump_stack();
   return ret;
  }
 
  rcache->valid = true;
  rcache->res = res;
- rcache->handle = *id;
+ rcache->handle = id;
 
  ret = vmw_resource_relocation_add(&sw_context->res_relocations,
        res,
-       id - sw_context->buf_start);
+       id_loc - sw_context->buf_start);
  if (unlikely(ret != 0))
   goto out_no_reloc;
 
@@ -411,6 +507,22 @@ static int vmw_cmd_res_check(struct vmw_private *dev_priv,
  rcache->node = node;
  if (p_val)
   *p_val = node;
+
+ if (dev_priv->has_mob && node->first_usage &&
+     res_type == vmw_res_context) {
+  ret = vmw_resource_context_res_add(dev_priv, sw_context, res);
+  if (unlikely(ret != 0))
+   goto out_no_reloc;
+  node->staged_bindings =
+   kzalloc(sizeof(*node->staged_bindings), GFP_KERNEL);
+  if (node->staged_bindings == NULL) {
+   DRM_ERROR("Failed to allocate context binding "
+      "information.\n");
+   goto out_no_reloc;
+  }
+  INIT_LIST_HEAD(&node->staged_bindings->list);
+ }
+
  vmw_resource_unreference(&res);
  return 0;
 
@@ -422,6 +534,59 @@ out_no_reloc:
 }
 
 /**
+ * vmw_cmd_res_check - Check that a resource is present and if so, put it
+ * on the resource validate list unless it's already there.
+ *
+ * @dev_priv: Pointer to a device private structure.
+ * @sw_context: Pointer to the software context.
+ * @res_type: Resource type.
+ * @converter: User-space visisble type specific information.
+ * @id_loc: Pointer to the location in the command buffer currently being
+ * parsed from where the user-space resource id handle is located.
+ * @p_val: Pointer to pointer to resource validalidation node. Populated
+ * on exit.
+ */
+static int
+vmw_cmd_res_check(struct vmw_private *dev_priv,
+    struct vmw_sw_context *sw_context,
+    enum vmw_res_type res_type,
+    const struct vmw_user_resource_conv *converter,
+    uint32_t *id_loc,
+    struct vmw_resource_val_node **p_val)
+{
+ return vmw_cmd_compat_res_check(dev_priv, sw_context, res_type,
+     converter, *id_loc, id_loc, p_val);
+}
+
+/**
+ * vmw_rebind_contexts - Rebind all resources previously bound to
+ * referenced contexts.
+ *
+ * @sw_context: Pointer to the software context.
+ *
+ * Rebind context binding points that have been scrubbed because of eviction.
+ */
+static int vmw_rebind_contexts(struct vmw_sw_context *sw_context)
+{
+ struct vmw_resource_val_node *val;
+ int ret;
+
+ list_for_each_entry(val, &sw_context->resource_list, head) {
+  if (likely(!val->staged_bindings))
+   continue;
+
+  ret = vmw_context_rebind_all(val->res);
+  if (unlikely(ret != 0)) {
+   if (ret != -ERESTARTSYS)
+    DRM_ERROR("Failed to rebind context.\n");
+   return ret;
+  }
+ }
+
+ return 0;
+}
+
+/**
  * vmw_cmd_cid_check - Check a command header for valid context information.
  *
  * @dev_priv: Pointer to a device private structure.
@@ -437,7 +602,7 @@ static int vmw_cmd_cid_check(struct vmw_private *dev_priv,
 {
  struct vmw_cid_cmd {
   SVGA3dCmdHeader header;
-  __le32 cid;
+  uint32_t cid;
  } *cmd;
 
  cmd = container_of(header, struct vmw_cid_cmd, header);
@@ -453,17 +618,35 @@ static int vmw_cmd_set_render_target_check(struct vmw_private *dev_priv,
   SVGA3dCmdHeader header;
   SVGA3dCmdSetRenderTarget body;
  } *cmd;
+ struct vmw_resource_val_node *ctx_node;
+ struct vmw_resource_val_node *res_node;
  int ret;
 
- ret = vmw_cmd_cid_check(dev_priv, sw_context, header);
+ cmd = container_of(header, struct vmw_sid_cmd, header);
+
+ ret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,
+    user_context_converter, &cmd->body.cid,
+    &ctx_node);
  if (unlikely(ret != 0))
   return ret;
 
- cmd = container_of(header, struct vmw_sid_cmd, header);
  ret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
     user_surface_converter,
-    &cmd->body.target.sid, NULL);
- return ret;
+    &cmd->body.target.sid, &res_node);
+ if (unlikely(ret != 0))
+  return ret;
+
+ if (dev_priv->has_mob) {
+  struct vmw_ctx_bindinfo bi;
+
+  bi.ctx = ctx_node->res;
+  bi.res = res_node ? res_node->res : NULL;
+  bi.bt = vmw_ctx_binding_rt;
+  bi.i1.rt_type = cmd->body.type;
+  return vmw_context_binding_add(ctx_node->staged_bindings, &bi);
+ }
+
+ return 0;
 }
 
 static int vmw_cmd_surface_copy_check(struct vmw_private *dev_priv,
@@ -519,11 +702,6 @@ static int vmw_cmd_blt_surf_screen_check(struct vmw_private *dev_priv,
 
  cmd = container_of(header, struct vmw_sid_cmd, header);
 
- if (unlikely(!sw_context->kernel)) {
-  DRM_ERROR("Kernel only SVGA3d command: %u.\n", cmd->header.id);
-  return -EPERM;
- }
-
  return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
      user_surface_converter,
      &cmd->body.srcImage.sid, NULL);
@@ -541,11 +719,6 @@ static int vmw_cmd_present_check(struct vmw_private *dev_priv,
 
  cmd = container_of(header, struct vmw_sid_cmd, header);
 
- if (unlikely(!sw_context->kernel)) {
-  DRM_ERROR("Kernel only SVGA3d command: %u.\n", cmd->header.id);
-  return -EPERM;
- }
-
  return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
      user_surface_converter, &cmd->body.sid,
      NULL);
@@ -586,7 +759,7 @@ static int vmw_query_bo_switch_prepare(struct vmw_private *dev_priv,
    sw_context->needs_post_query_barrier = true;
    ret = vmw_bo_to_validate_list(sw_context,
             sw_context->cur_query_bo,
-            NULL);
+            dev_priv->has_mob, NULL);
    if (unlikely(ret != 0))
     return ret;
   }
@@ -594,7 +767,7 @@ static int vmw_query_bo_switch_prepare(struct vmw_private *dev_priv,
 
   ret = vmw_bo_to_validate_list(sw_context,
            dev_priv->dummy_query_bo,
-           NULL);
+           dev_priv->has_mob, NULL);
   if (unlikely(ret != 0))
    return ret;
 
@@ -672,6 +845,66 @@ static void vmw_query_bo_switch_commit(struct vmw_private *dev_priv,
 }
 
 /**
+ * vmw_translate_mob_pointer - Prepare to translate a user-space buffer
+ * handle to a MOB id.
+ *
+ * @dev_priv: Pointer to a device private structure.
+ * @sw_context: The software context used for this command batch validation.
+ * @id: Pointer to the user-space handle to be translated.
+ * @vmw_bo_p: Points to a location that, on successful return will carry
+ * a reference-counted pointer to the DMA buffer identified by the
+ * user-space handle in @id.
+ *
+ * This function saves information needed to translate a user-space buffer
+ * handle to a MOB id. The translation does not take place immediately, but
+ * during a call to vmw_apply_relocations(). This function builds a relocation
+ * list and a list of buffers to validate. The former needs to be freed using
+ * either vmw_apply_relocations() or vmw_free_relocations(). The latter
+ * needs to be freed using vmw_clear_validations.
+ */
+static int vmw_translate_mob_ptr(struct vmw_private *dev_priv,
+     struct vmw_sw_context *sw_context,
+     SVGAMobId *id,
+     struct vmw_dma_buffer **vmw_bo_p)
+{
+ struct vmw_dma_buffer *vmw_bo = NULL;
+ struct ttm_buffer_object *bo;
+ uint32_t handle = *id;
+ struct vmw_relocation *reloc;
+ int ret;
+
+ ret = vmw_user_dmabuf_lookup(sw_context->fp->tfile, handle, &vmw_bo);
+ if (unlikely(ret != 0)) {
+  DRM_ERROR("Could not find or use MOB buffer.\n");
+  return -EINVAL;
+ }
+ bo = &vmw_bo->base;
+
+ if (unlikely(sw_context->cur_reloc >= VMWGFX_MAX_RELOCATIONS)) {
+  DRM_ERROR("Max number relocations per submission"
+     " exceeded\n");
+  ret = -EINVAL;
+  goto out_no_reloc;
+ }
+
+ reloc = &sw_context->relocs[sw_context->cur_reloc++];
+ reloc->mob_loc = id;
+ reloc->location = NULL;
+
+ ret = vmw_bo_to_validate_list(sw_context, bo, true, &reloc->index);
+ if (unlikely(ret != 0))
+  goto out_no_reloc;
+
+ *vmw_bo_p = vmw_bo;
+ return 0;
+
+out_no_reloc:
+ vmw_dmabuf_unreference(&vmw_bo);
+ vmw_bo_p = NULL;
+ return ret;
+}
+
+/**
  * vmw_translate_guest_pointer - Prepare to translate a user-space buffer
  * handle to a valid SVGAGuestPtr
  *
@@ -701,7 +934,7 @@ static int vmw_translate_guest_ptr(struct vmw_private *dev_priv,
  struct vmw_relocation *reloc;
  int ret;
 
- ret = vmw_user_dmabuf_lookup(sw_context->tfile, handle, &vmw_bo);
+ ret = vmw_user_dmabuf_lookup(sw_context->fp->tfile, handle, &vmw_bo);
  if (unlikely(ret != 0)) {
   DRM_ERROR("Could not find or use GMR region.\n");
   return -EINVAL;
@@ -718,7 +951,7 @@ static int vmw_translate_guest_ptr(struct vmw_private *dev_priv,
  reloc = &sw_context->relocs[sw_context->cur_reloc++];
  reloc->location = ptr;
 
- ret = vmw_bo_to_validate_list(sw_context, bo, &reloc->index);
+ ret = vmw_bo_to_validate_list(sw_context, bo, false, &reloc->index);
  if (unlikely(ret != 0))
   goto out_no_reloc;
 
@@ -732,6 +965,30 @@ out_no_reloc:
 }
 
 /**
+ * vmw_cmd_begin_gb_query - validate a  SVGA_3D_CMD_BEGIN_GB_QUERY command.
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context used for this command submission.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_begin_gb_query(struct vmw_private *dev_priv,
+      struct vmw_sw_context *sw_context,
+      SVGA3dCmdHeader *header)
+{
+ struct vmw_begin_gb_query_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdBeginGBQuery q;
+ } *cmd;
+
+ cmd = container_of(header, struct vmw_begin_gb_query_cmd,
+      header);
+
+ return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,
+     user_context_converter, &cmd->q.cid,
+     NULL);
+}
+
+/**
  * vmw_cmd_begin_query - validate a  SVGA_3D_CMD_BEGIN_QUERY command.
  *
  * @dev_priv: Pointer to a device private struct.
@@ -750,12 +1007,64 @@ static int vmw_cmd_begin_query(struct vmw_private *dev_priv,
  cmd = container_of(header, struct vmw_begin_query_cmd,
       header);
 
+ if (unlikely(dev_priv->has_mob)) {
+  struct {
+   SVGA3dCmdHeader header;
+   SVGA3dCmdBeginGBQuery q;
+  } gb_cmd;
+
+  BUG_ON(sizeof(gb_cmd) != sizeof(*cmd));
+
+  gb_cmd.header.id = SVGA_3D_CMD_BEGIN_GB_QUERY;
+  gb_cmd.header.size = cmd->header.size;
+  gb_cmd.q.cid = cmd->q.cid;
+  gb_cmd.q.type = cmd->q.type;
+
+  memcpy(cmd, &gb_cmd, sizeof(*cmd));
+  return vmw_cmd_begin_gb_query(dev_priv, sw_context, header);
+ }
+
  return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,
      user_context_converter, &cmd->q.cid,
      NULL);
 }
 
 /**
+ * vmw_cmd_end_gb_query - validate a  SVGA_3D_CMD_END_GB_QUERY command.
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context used for this command submission.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_end_gb_query(struct vmw_private *dev_priv,
+    struct vmw_sw_context *sw_context,
+    SVGA3dCmdHeader *header)
+{
+ struct vmw_dma_buffer *vmw_bo;
+ struct vmw_query_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdEndGBQuery q;
+ } *cmd;
+ int ret;
+
+ cmd = container_of(header, struct vmw_query_cmd, header);
+ ret = vmw_cmd_cid_check(dev_priv, sw_context, header);
+ if (unlikely(ret != 0))
+  return ret;
+
+ ret = vmw_translate_mob_ptr(dev_priv, sw_context,
+        &cmd->q.mobid,
+        &vmw_bo);
+ if (unlikely(ret != 0))
+  return ret;
+
+ ret = vmw_query_bo_switch_prepare(dev_priv, &vmw_bo->base, sw_context);
+
+ vmw_dmabuf_unreference(&vmw_bo);
+ return ret;
+}
+
+/**
  * vmw_cmd_end_query - validate a  SVGA_3D_CMD_END_QUERY command.
  *
  * @dev_priv: Pointer to a device private struct.
@@ -774,6 +1083,25 @@ static int vmw_cmd_end_query(struct vmw_private *dev_priv,
  int ret;
 
  cmd = container_of(header, struct vmw_query_cmd, header);
+ if (dev_priv->has_mob) {
+  struct {
+   SVGA3dCmdHeader header;
+   SVGA3dCmdEndGBQuery q;
+  } gb_cmd;
+
+  BUG_ON(sizeof(gb_cmd) != sizeof(*cmd));
+
+  gb_cmd.header.id = SVGA_3D_CMD_END_GB_QUERY;
+  gb_cmd.header.size = cmd->header.size;
+  gb_cmd.q.cid = cmd->q.cid;
+  gb_cmd.q.type = cmd->q.type;
+  gb_cmd.q.mobid = cmd->q.guestResult.gmrId;
+  gb_cmd.q.offset = cmd->q.guestResult.offset;
+
+  memcpy(cmd, &gb_cmd, sizeof(*cmd));
+  return vmw_cmd_end_gb_query(dev_priv, sw_context, header);
+ }
+
  ret = vmw_cmd_cid_check(dev_priv, sw_context, header);
  if (unlikely(ret != 0))
   return ret;
@@ -790,7 +1118,40 @@ static int vmw_cmd_end_query(struct vmw_private *dev_priv,
  return ret;
 }
 
-/*
+/**
+ * vmw_cmd_wait_gb_query - validate a  SVGA_3D_CMD_WAIT_GB_QUERY command.
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context used for this command submission.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_wait_gb_query(struct vmw_private *dev_priv,
+     struct vmw_sw_context *sw_context,
+     SVGA3dCmdHeader *header)
+{
+ struct vmw_dma_buffer *vmw_bo;
+ struct vmw_query_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdWaitForGBQuery q;
+ } *cmd;
+ int ret;
+
+ cmd = container_of(header, struct vmw_query_cmd, header);
+ ret = vmw_cmd_cid_check(dev_priv, sw_context, header);
+ if (unlikely(ret != 0))
+  return ret;
+
+ ret = vmw_translate_mob_ptr(dev_priv, sw_context,
+        &cmd->q.mobid,
+        &vmw_bo);
+ if (unlikely(ret != 0))
+  return ret;
+
+ vmw_dmabuf_unreference(&vmw_bo);
+ return 0;
+}
+
+/**
  * vmw_cmd_wait_query - validate a  SVGA_3D_CMD_WAIT_QUERY command.
  *
  * @dev_priv: Pointer to a device private struct.
@@ -809,6 +1170,25 @@ static int vmw_cmd_wait_query(struct vmw_private *dev_priv,
  int ret;
 
  cmd = container_of(header, struct vmw_query_cmd, header);
+ if (dev_priv->has_mob) {
+  struct {
+   SVGA3dCmdHeader header;
+   SVGA3dCmdWaitForGBQuery q;
+  } gb_cmd;
+
+  BUG_ON(sizeof(gb_cmd) != sizeof(*cmd));
+
+  gb_cmd.header.id = SVGA_3D_CMD_WAIT_FOR_GB_QUERY;
+  gb_cmd.header.size = cmd->header.size;
+  gb_cmd.q.cid = cmd->q.cid;
+  gb_cmd.q.type = cmd->q.type;
+  gb_cmd.q.mobid = cmd->q.guestResult.gmrId;
+  gb_cmd.q.offset = cmd->q.guestResult.offset;
+
+  memcpy(cmd, &gb_cmd, sizeof(*cmd));
+  return vmw_cmd_wait_gb_query(dev_priv, sw_context, header);
+ }
+
  ret = vmw_cmd_cid_check(dev_priv, sw_context, header);
  if (unlikely(ret != 0))
   return ret;
@@ -853,7 +1233,8 @@ static int vmw_cmd_dma(struct vmw_private *dev_priv,
 
  srf = vmw_res_to_srf(sw_context->res_cache[vmw_res_surface].res);
 
- vmw_kms_cursor_snoop(srf, sw_context->tfile, &vmw_bo->base, header);
+ vmw_kms_cursor_snoop(srf, sw_context->fp->tfile, &vmw_bo->base,
+        header);
 
 out_no_surface:
  vmw_dmabuf_unreference(&vmw_bo);
@@ -921,15 +1302,22 @@ static int vmw_cmd_tex_state(struct vmw_private *dev_priv,
  struct vmw_tex_state_cmd {
   SVGA3dCmdHeader header;
   SVGA3dCmdSetTextureState state;
- };
+ } *cmd;
 
  SVGA3dTextureState *last_state = (SVGA3dTextureState *)
    ((unsigned long) header + header->size + sizeof(header));
  SVGA3dTextureState *cur_state = (SVGA3dTextureState *)
   ((unsigned long) header + sizeof(struct vmw_tex_state_cmd));
+ struct vmw_resource_val_node *ctx_node;
+ struct vmw_resource_val_node *res_node;
  int ret;
 
- ret = vmw_cmd_cid_check(dev_priv, sw_context, header);
+ cmd = container_of(header, struct vmw_tex_state_cmd,
+      header);
+
+ ret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,
+    user_context_converter, &cmd->state.cid,
+    &ctx_node);
  if (unlikely(ret != 0))
   return ret;
 
@@ -939,9 +1327,20 @@ static int vmw_cmd_tex_state(struct vmw_private *dev_priv,
 
   ret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
      user_surface_converter,
-     &cur_state->value, NULL);
+     &cur_state->value, &res_node);
   if (unlikely(ret != 0))
    return ret;
+
+  if (dev_priv->has_mob) {
+   struct vmw_ctx_bindinfo bi;
+
+   bi.ctx = ctx_node->res;
+   bi.res = res_node ? res_node->res : NULL;
+   bi.bt = vmw_ctx_binding_tex;
+   bi.i1.texture_stage = cur_state->stage;
+   vmw_context_binding_add(ctx_node->staged_bindings,
+      &bi);
+  }
  }
 
  return 0;
@@ -971,6 +1370,314 @@ static int vmw_cmd_check_define_gmrfb(struct vmw_private *dev_priv,
 }
 
 /**
+ * vmw_cmd_switch_backup - Utility function to handle backup buffer switching
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @res_type: The resource type.
+ * @converter: Information about user-space binding for this resource type.
+ * @res_id: Pointer to the user-space resource handle in the command stream.
+ * @buf_id: Pointer to the user-space backup buffer handle in the command
+ * stream.
+ * @backup_offset: Offset of backup into MOB.
+ *
+ * This function prepares for registering a switch of backup buffers
+ * in the resource metadata just prior to unreserving.
+ */
+static int vmw_cmd_switch_backup(struct vmw_private *dev_priv,
+     struct vmw_sw_context *sw_context,
+     enum vmw_res_type res_type,
+     const struct vmw_user_resource_conv
+     *converter,
+     uint32_t *res_id,
+     uint32_t *buf_id,
+     unsigned long backup_offset)
+{
+ int ret;
+ struct vmw_dma_buffer *dma_buf;
+ struct vmw_resource_val_node *val_node;
+
+ ret = vmw_cmd_res_check(dev_priv, sw_context, res_type,
+    converter, res_id, &val_node);
+ if (unlikely(ret != 0))
+  return ret;
+
+ ret = vmw_translate_mob_ptr(dev_priv, sw_context, buf_id, &dma_buf);
+ if (unlikely(ret != 0))
+  return ret;
+
+ if (val_node->first_usage)
+  val_node->no_buffer_needed = true;
+
+ vmw_dmabuf_unreference(&val_node->new_backup);
+ val_node->new_backup = dma_buf;
+ val_node->new_backup_offset = backup_offset;
+
+ return 0;
+}
+
+/**
+ * vmw_cmd_bind_gb_surface - Validate an SVGA_3D_CMD_BIND_GB_SURFACE
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_bind_gb_surface(struct vmw_private *dev_priv,
+       struct vmw_sw_context *sw_context,
+       SVGA3dCmdHeader *header)
+{
+ struct vmw_bind_gb_surface_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdBindGBSurface body;
+ } *cmd;
+
+ cmd = container_of(header, struct vmw_bind_gb_surface_cmd, header);
+
+ return vmw_cmd_switch_backup(dev_priv, sw_context, vmw_res_surface,
+         user_surface_converter,
+         &cmd->body.sid, &cmd->body.mobid,
+         0);
+}
+
+/**
+ * vmw_cmd_update_gb_image - Validate an SVGA_3D_CMD_UPDATE_GB_IMAGE
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_update_gb_image(struct vmw_private *dev_priv,
+       struct vmw_sw_context *sw_context,
+       SVGA3dCmdHeader *header)
+{
+ struct vmw_gb_surface_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdUpdateGBImage body;
+ } *cmd;
+
+ cmd = container_of(header, struct vmw_gb_surface_cmd, header);
+
+ return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
+     user_surface_converter,
+     &cmd->body.image.sid, NULL);
+}
+
+/**
+ * vmw_cmd_update_gb_surface - Validate an SVGA_3D_CMD_UPDATE_GB_SURFACE
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_update_gb_surface(struct vmw_private *dev_priv,
+         struct vmw_sw_context *sw_context,
+         SVGA3dCmdHeader *header)
+{
+ struct vmw_gb_surface_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdUpdateGBSurface body;
+ } *cmd;
+
+ cmd = container_of(header, struct vmw_gb_surface_cmd, header);
+
+ return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
+     user_surface_converter,
+     &cmd->body.sid, NULL);
+}
+
+/**
+ * vmw_cmd_readback_gb_image - Validate an SVGA_3D_CMD_READBACK_GB_IMAGE
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_readback_gb_image(struct vmw_private *dev_priv,
+         struct vmw_sw_context *sw_context,
+         SVGA3dCmdHeader *header)
+{
+ struct vmw_gb_surface_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdReadbackGBImage body;
+ } *cmd;
+
+ cmd = container_of(header, struct vmw_gb_surface_cmd, header);
+
+ return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
+     user_surface_converter,
+     &cmd->body.image.sid, NULL);
+}
+
+/**
+ * vmw_cmd_readback_gb_surface - Validate an SVGA_3D_CMD_READBACK_GB_SURFACE
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_readback_gb_surface(struct vmw_private *dev_priv,
+           struct vmw_sw_context *sw_context,
+           SVGA3dCmdHeader *header)
+{
+ struct vmw_gb_surface_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdReadbackGBSurface body;
+ } *cmd;
+
+ cmd = container_of(header, struct vmw_gb_surface_cmd, header);
+
+ return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
+     user_surface_converter,
+     &cmd->body.sid, NULL);
+}
+
+/**
+ * vmw_cmd_invalidate_gb_image - Validate an SVGA_3D_CMD_INVALIDATE_GB_IMAGE
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_invalidate_gb_image(struct vmw_private *dev_priv,
+           struct vmw_sw_context *sw_context,
+           SVGA3dCmdHeader *header)
+{
+ struct vmw_gb_surface_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdInvalidateGBImage body;
+ } *cmd;
+
+ cmd = container_of(header, struct vmw_gb_surface_cmd, header);
+
+ return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
+     user_surface_converter,
+     &cmd->body.image.sid, NULL);
+}
+
+/**
+ * vmw_cmd_invalidate_gb_surface - Validate an
+ * SVGA_3D_CMD_INVALIDATE_GB_SURFACE command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_invalidate_gb_surface(struct vmw_private *dev_priv,
+      struct vmw_sw_context *sw_context,
+      SVGA3dCmdHeader *header)
+{
+ struct vmw_gb_surface_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdInvalidateGBSurface body;
+ } *cmd;
+
+ cmd = container_of(header, struct vmw_gb_surface_cmd, header);
+
+ return vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,
+     user_surface_converter,
+     &cmd->body.sid, NULL);
+}
+
+
+/**
+ * vmw_cmd_shader_define - Validate an SVGA_3D_CMD_SHADER_DEFINE
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_shader_define(struct vmw_private *dev_priv,
+     struct vmw_sw_context *sw_context,
+     SVGA3dCmdHeader *header)
+{
+ struct vmw_shader_define_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDefineShader body;
+ } *cmd;
+ int ret;
+ size_t size;
+
+ cmd = container_of(header, struct vmw_shader_define_cmd,
+      header);
+
+ ret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,
+    user_context_converter, &cmd->body.cid,
+    NULL);
+ if (unlikely(ret != 0))
+  return ret;
+
+ if (unlikely(!dev_priv->has_mob))
+  return 0;
+
+ size = cmd->header.size - sizeof(cmd->body);
+ ret = vmw_compat_shader_add(sw_context->fp->shman,
+        cmd->body.shid, cmd + 1,
+        cmd->body.type, size,
+        sw_context->fp->tfile,
+        &sw_context->staged_shaders);
+ if (unlikely(ret != 0))
+  return ret;
+
+ return vmw_resource_relocation_add(&sw_context->res_relocations,
+        NULL, &cmd->header.id -
+        sw_context->buf_start);
+
+ return 0;
+}
+
+/**
+ * vmw_cmd_shader_destroy - Validate an SVGA_3D_CMD_SHADER_DESTROY
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_shader_destroy(struct vmw_private *dev_priv,
+      struct vmw_sw_context *sw_context,
+      SVGA3dCmdHeader *header)
+{
+ struct vmw_shader_destroy_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDestroyShader body;
+ } *cmd;
+ int ret;
+
+ cmd = container_of(header, struct vmw_shader_destroy_cmd,
+      header);
+
+ ret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,
+    user_context_converter, &cmd->body.cid,
+    NULL);
+ if (unlikely(ret != 0))
+  return ret;
+
+ if (unlikely(!dev_priv->has_mob))
+  return 0;
+
+ ret = vmw_compat_shader_remove(sw_context->fp->shman,
+           cmd->body.shid,
+           cmd->body.type,
+           &sw_context->staged_shaders);
+ if (unlikely(ret != 0))
+  return ret;
+
+ return vmw_resource_relocation_add(&sw_context->res_relocations,
+        NULL, &cmd->header.id -
+        sw_context->buf_start);
+
+ return 0;
+}
+
+/**
  * vmw_cmd_set_shader - Validate an SVGA_3D_CMD_SET_SHADER
  * command
  *
@@ -986,18 +1693,105 @@ static int vmw_cmd_set_shader(struct vmw_private *dev_priv,
   SVGA3dCmdHeader header;
   SVGA3dCmdSetShader body;
  } *cmd;
+ struct vmw_resource_val_node *ctx_node;
  int ret;
 
  cmd = container_of(header, struct vmw_set_shader_cmd,
       header);
 
- ret = vmw_cmd_cid_check(dev_priv, sw_context, header);
+ ret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,
+    user_context_converter, &cmd->body.cid,
+    &ctx_node);
+ if (unlikely(ret != 0))
+  return ret;
+
+ if (dev_priv->has_mob) {
+  struct vmw_ctx_bindinfo bi;
+  struct vmw_resource_val_node *res_node;
+  u32 shid = cmd->body.shid;
+
+  if (shid != SVGA3D_INVALID_ID)
+   (void) vmw_compat_shader_lookup(sw_context->fp->shman,
+       cmd->body.type,
+       &shid);
+
+  ret = vmw_cmd_compat_res_check(dev_priv, sw_context,
+            vmw_res_shader,
+            user_shader_converter,
+            shid,
+            &cmd->body.shid, &res_node);
+  if (unlikely(ret != 0))
+   return ret;
+
+  bi.ctx = ctx_node->res;
+  bi.res = res_node ? res_node->res : NULL;
+  bi.bt = vmw_ctx_binding_shader;
+  bi.i1.shader_type = cmd->body.type;
+  return vmw_context_binding_add(ctx_node->staged_bindings, &bi);
+ }
+
+ return 0;
+}
+
+/**
+ * vmw_cmd_set_shader_const - Validate an SVGA_3D_CMD_SET_SHADER_CONST
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_set_shader_const(struct vmw_private *dev_priv,
+        struct vmw_sw_context *sw_context,
+        SVGA3dCmdHeader *header)
+{
+ struct vmw_set_shader_const_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdSetShaderConst body;
+ } *cmd;
+ int ret;
+
+ cmd = container_of(header, struct vmw_set_shader_const_cmd,
+      header);
+
+ ret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,
+    user_context_converter, &cmd->body.cid,
+    NULL);
  if (unlikely(ret != 0))
   return ret;
 
+ if (dev_priv->has_mob)
+  header->id = SVGA_3D_CMD_SET_GB_SHADERCONSTS_INLINE;
+
  return 0;
 }
 
+/**
+ * vmw_cmd_bind_gb_shader - Validate an SVGA_3D_CMD_BIND_GB_SHADER
+ * command
+ *
+ * @dev_priv: Pointer to a device private struct.
+ * @sw_context: The software context being used for this batch.
+ * @header: Pointer to the command header in the command stream.
+ */
+static int vmw_cmd_bind_gb_shader(struct vmw_private *dev_priv,
+      struct vmw_sw_context *sw_context,
+      SVGA3dCmdHeader *header)
+{
+ struct vmw_bind_gb_shader_cmd {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdBindGBShader body;
+ } *cmd;
+
+ cmd = container_of(header, struct vmw_bind_gb_shader_cmd,
+      header);
+
+ return vmw_cmd_switch_backup(dev_priv, sw_context, vmw_res_shader,
+         user_shader_converter,
+         &cmd->body.shid, &cmd->body.mobid,
+         cmd->body.offsetInBytes);
+}
+
 static int vmw_cmd_check_not_3d(struct vmw_private *dev_priv,
     struct vmw_sw_context *sw_context,
     void *buf, uint32_t *size)
@@ -1041,50 +1835,173 @@ static int vmw_cmd_check_not_3d(struct vmw_private *dev_priv,
  return 0;
 }
 
-typedef int (*vmw_cmd_func) (struct vmw_private *,
-        struct vmw_sw_context *,
-        SVGA3dCmdHeader *);
-
-#define VMW_CMD_DEF(cmd, func) \
- [cmd - SVGA_3D_CMD_BASE] = func
-
-static vmw_cmd_func vmw_cmd_funcs[SVGA_3D_CMD_MAX] = {
- VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_DEFINE, &vmw_cmd_invalid),
- VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_DESTROY, &vmw_cmd_invalid),
- VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_COPY, &vmw_cmd_surface_copy_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_STRETCHBLT, &vmw_cmd_stretch_blt_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_DMA, &vmw_cmd_dma),
- VMW_CMD_DEF(SVGA_3D_CMD_CONTEXT_DEFINE, &vmw_cmd_invalid),
- VMW_CMD_DEF(SVGA_3D_CMD_CONTEXT_DESTROY, &vmw_cmd_invalid),
- VMW_CMD_DEF(SVGA_3D_CMD_SETTRANSFORM, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SETZRANGE, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SETRENDERSTATE, &vmw_cmd_cid_check),
+static const struct vmw_cmd_entry vmw_cmd_entries[SVGA_3D_CMD_MAX] = {
+ VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_DEFINE, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_DESTROY, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_COPY, &vmw_cmd_surface_copy_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_STRETCHBLT, &vmw_cmd_stretch_blt_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_DMA, &vmw_cmd_dma,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_CONTEXT_DEFINE, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_CONTEXT_DESTROY, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETTRANSFORM, &vmw_cmd_cid_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETZRANGE, &vmw_cmd_cid_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETRENDERSTATE, &vmw_cmd_cid_check,
+      true, false, false),
  VMW_CMD_DEF(SVGA_3D_CMD_SETRENDERTARGET,
-      &vmw_cmd_set_render_target_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SETTEXTURESTATE, &vmw_cmd_tex_state),
- VMW_CMD_DEF(SVGA_3D_CMD_SETMATERIAL, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SETLIGHTDATA, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SETLIGHTENABLED, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SETVIEWPORT, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SETCLIPPLANE, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_CLEAR, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_PRESENT, &vmw_cmd_present_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SHADER_DEFINE, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SHADER_DESTROY, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SET_SHADER, &vmw_cmd_set_shader),
- VMW_CMD_DEF(SVGA_3D_CMD_SET_SHADER_CONST, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_DRAW_PRIMITIVES, &vmw_cmd_draw),
- VMW_CMD_DEF(SVGA_3D_CMD_SETSCISSORRECT, &vmw_cmd_cid_check),
- VMW_CMD_DEF(SVGA_3D_CMD_BEGIN_QUERY, &vmw_cmd_begin_query),
- VMW_CMD_DEF(SVGA_3D_CMD_END_QUERY, &vmw_cmd_end_query),
- VMW_CMD_DEF(SVGA_3D_CMD_WAIT_FOR_QUERY, &vmw_cmd_wait_query),
- VMW_CMD_DEF(SVGA_3D_CMD_PRESENT_READBACK, &vmw_cmd_ok),
+      &vmw_cmd_set_render_target_check, true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETTEXTURESTATE, &vmw_cmd_tex_state,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETMATERIAL, &vmw_cmd_cid_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETLIGHTDATA, &vmw_cmd_cid_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETLIGHTENABLED, &vmw_cmd_cid_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETVIEWPORT, &vmw_cmd_cid_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETCLIPPLANE, &vmw_cmd_cid_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_CLEAR, &vmw_cmd_cid_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_PRESENT, &vmw_cmd_present_check,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SHADER_DEFINE, &vmw_cmd_shader_define,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SHADER_DESTROY, &vmw_cmd_shader_destroy,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SET_SHADER, &vmw_cmd_set_shader,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SET_SHADER_CONST, &vmw_cmd_set_shader_const,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_DRAW_PRIMITIVES, &vmw_cmd_draw,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SETSCISSORRECT, &vmw_cmd_cid_check,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_BEGIN_QUERY, &vmw_cmd_begin_query,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_END_QUERY, &vmw_cmd_end_query,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_WAIT_FOR_QUERY, &vmw_cmd_wait_query,
+      true, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_PRESENT_READBACK, &vmw_cmd_ok,
+      true, false, false),
  VMW_CMD_DEF(SVGA_3D_CMD_BLIT_SURFACE_TO_SCREEN,
-      &vmw_cmd_blt_surf_screen_check),
- VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_DEFINE_V2, &vmw_cmd_invalid),
- VMW_CMD_DEF(SVGA_3D_CMD_GENERATE_MIPMAPS, &vmw_cmd_invalid),
- VMW_CMD_DEF(SVGA_3D_CMD_ACTIVATE_SURFACE, &vmw_cmd_invalid),
- VMW_CMD_DEF(SVGA_3D_CMD_DEACTIVATE_SURFACE, &vmw_cmd_invalid),
+      &vmw_cmd_blt_surf_screen_check, false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SURFACE_DEFINE_V2, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_GENERATE_MIPMAPS, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_ACTIVATE_SURFACE, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_DEACTIVATE_SURFACE, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SCREEN_DMA, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SET_UNITY_SURFACE_COOKIE, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_OPEN_CONTEXT_SURFACE, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_LOGICOPS_BITBLT, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_LOGICOPS_TRANSBLT, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_LOGICOPS_STRETCHBLT, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_LOGICOPS_COLORFILL, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_LOGICOPS_ALPHABLEND, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_LOGICOPS_CLEARTYPEBLEND, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_SET_OTABLE_BASE, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_READBACK_OTABLE, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DEFINE_GB_MOB, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DESTROY_GB_MOB, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_REDEFINE_GB_MOB, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_UPDATE_GB_MOB_MAPPING, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DEFINE_GB_SURFACE, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DESTROY_GB_SURFACE, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_BIND_GB_SURFACE, &vmw_cmd_bind_gb_surface,
+      true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_COND_BIND_GB_SURFACE, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_UPDATE_GB_IMAGE, &vmw_cmd_update_gb_image,
+      true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_UPDATE_GB_SURFACE,
+      &vmw_cmd_update_gb_surface, true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_READBACK_GB_IMAGE,
+      &vmw_cmd_readback_gb_image, true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_READBACK_GB_SURFACE,
+      &vmw_cmd_readback_gb_surface, true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_INVALIDATE_GB_IMAGE,
+      &vmw_cmd_invalidate_gb_image, true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_INVALIDATE_GB_SURFACE,
+      &vmw_cmd_invalidate_gb_surface, true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DEFINE_GB_CONTEXT, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DESTROY_GB_CONTEXT, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_BIND_GB_CONTEXT, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_READBACK_GB_CONTEXT, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_INVALIDATE_GB_CONTEXT, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DEFINE_GB_SHADER, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_BIND_GB_SHADER, &vmw_cmd_bind_gb_shader,
+      true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DESTROY_GB_SHADER, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_SET_OTABLE_BASE64, &vmw_cmd_invalid,
+      false, false, false),
+ VMW_CMD_DEF(SVGA_3D_CMD_BEGIN_GB_QUERY, &vmw_cmd_begin_gb_query,
+      true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_END_GB_QUERY, &vmw_cmd_end_gb_query,
+      true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_WAIT_FOR_GB_QUERY, &vmw_cmd_wait_gb_query,
+      true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_NOP, &vmw_cmd_ok,
+      true, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_ENABLE_GART, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DISABLE_GART, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_MAP_MOB_INTO_GART, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_UNMAP_GART_RANGE, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DEFINE_GB_SCREENTARGET, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_DESTROY_GB_SCREENTARGET, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_BIND_GB_SCREENTARGET, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_UPDATE_GB_SCREENTARGET, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_READBACK_GB_IMAGE_PARTIAL, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_INVALIDATE_GB_IMAGE_PARTIAL, &vmw_cmd_invalid,
+      false, false, true),
+ VMW_CMD_DEF(SVGA_3D_CMD_SET_GB_SHADERCONSTS_INLINE, &vmw_cmd_cid_check,
+      true, false, true)
 };
 
 static int vmw_cmd_check(struct vmw_private *dev_priv,
@@ -1095,6 +2012,8 @@ static int vmw_cmd_check(struct vmw_private *dev_priv,
  uint32_t size_remaining = *size;
  SVGA3dCmdHeader *header = (SVGA3dCmdHeader *) buf;
  int ret;
+ const struct vmw_cmd_entry *entry;
+ bool gb = dev_priv->capabilities & SVGA_CAP_GBOBJECTS;
 
  cmd_id = le32_to_cpu(((uint32_t *)buf)[0]);
  /* Handle any none 3D commands */
@@ -1107,18 +2026,43 @@ static int vmw_cmd_check(struct vmw_private *dev_priv,
 
  cmd_id -= SVGA_3D_CMD_BASE;
  if (unlikely(*size > size_remaining))
-  goto out_err;
+  goto out_invalid;
 
  if (unlikely(cmd_id >= SVGA_3D_CMD_MAX - SVGA_3D_CMD_BASE))
-  goto out_err;
+  goto out_invalid;
+
+ entry = &vmw_cmd_entries[cmd_id];
+ if (unlikely(!entry->func))
+  goto out_invalid;
 
- ret = vmw_cmd_funcs[cmd_id](dev_priv, sw_context, header);
+ if (unlikely(!entry->user_allow && !sw_context->kernel))
+  goto out_privileged;
+
+ if (unlikely(entry->gb_disable && gb))
+  goto out_old;
+
+ if (unlikely(entry->gb_enable && !gb))
+  goto out_new;
+
+ ret = entry->func(dev_priv, sw_context, header);
  if (unlikely(ret != 0))
-  goto out_err;
+  goto out_invalid;
 
  return 0;
-out_err:
- DRM_ERROR("Illegal / Invalid SVGA3D command: %d\n",
+out_invalid:
+ DRM_ERROR("Invalid SVGA3D command: %d\n",
+    cmd_id + SVGA_3D_CMD_BASE);
+ return -EINVAL;
+out_privileged:
+ DRM_ERROR("Privileged SVGA3D command: %d\n",
+    cmd_id + SVGA_3D_CMD_BASE);
+ return -EPERM;
+out_old:
+ DRM_ERROR("Deprecated (disallowed) SVGA3D command: %d\n",
+    cmd_id + SVGA_3D_CMD_BASE);
+ return -EINVAL;
+out_new:
+ DRM_ERROR("SVGA3D command: %d not supported by virtual hardware.\n",
     cmd_id + SVGA_3D_CMD_BASE);
  return -EINVAL;
 }
@@ -1174,6 +2118,9 @@ static void vmw_apply_relocations(struct vmw_sw_context *sw_context)
   case VMW_PL_GMR:
    reloc->location->gmrId = bo->mem.start;
    break;
+  case VMW_PL_MOB:
+   *reloc->mob_loc = bo->mem.start;
+   break;
   default:
    BUG();
   }
@@ -1198,6 +2145,8 @@ static void vmw_resource_list_unreference(struct list_head *list)
  list_for_each_entry_safe(val, val_next, list, head) {
   list_del_init(&val->head);
   vmw_resource_unreference(&val->res);
+  if (unlikely(val->staged_bindings))
+   kfree(val->staged_bindings);
   kfree(val);
  }
 }
@@ -1224,7 +2173,8 @@ static void vmw_clear_validations(struct vmw_sw_context *sw_context)
 }
 
 static int vmw_validate_single_buffer(struct vmw_private *dev_priv,
-          struct ttm_buffer_object *bo)
+          struct ttm_buffer_object *bo,
+          bool validate_as_mob)
 {
  int ret;
 
@@ -1238,6 +2188,9 @@ static int vmw_validate_single_buffer(struct vmw_private *dev_priv,
       dev_priv->dummy_query_bo_pinned))
   return 0;
 
+ if (validate_as_mob)
+  return ttm_bo_validate(bo, &vmw_mob_placement, true, false);
+
  /**
   * Put BO in VRAM if there is space, otherwise as a GMR.
   * If there is no space in VRAM and GMR ids are all used up,
@@ -1259,7 +2212,6 @@ static int vmw_validate_single_buffer(struct vmw_private *dev_priv,
  return ret;
 }
 
-
 static int vmw_validate_buffers(struct vmw_private *dev_priv,
     struct vmw_sw_context *sw_context)
 {
@@ -1267,7 +2219,8 @@ static int vmw_validate_buffers(struct vmw_private *dev_priv,
  int ret;
 
  list_for_each_entry(entry, &sw_context->validate_nodes, base.head) {
-  ret = vmw_validate_single_buffer(dev_priv, entry->base.bo);
+  ret = vmw_validate_single_buffer(dev_priv, entry->base.bo,
+       entry->validate_as_mob);
   if (unlikely(ret != 0))
    return ret;
  }
@@ -1461,7 +2414,7 @@ int vmw_execbuf_process(struct drm_file *file_priv,
  } else
   sw_context->kernel = true;
 
- sw_context->tfile = vmw_fpriv(file_priv)->tfile;
+ sw_context->fp = vmw_fpriv(file_priv);
  sw_context->cur_reloc = 0;
  sw_context->cur_val_buf = 0;
  sw_context->fence_flags = 0;
@@ -1478,6 +2431,7 @@ int vmw_execbuf_process(struct drm_file *file_priv,
    goto out_unlock;
   sw_context->res_ht_initialized = true;
  }
+ INIT_LIST_HEAD(&sw_context->staged_shaders);
 
  INIT_LIST_HEAD(&resource_list);
  ret = vmw_cmd_check_all(dev_priv, sw_context, kernel_commands,
@@ -1509,11 +2463,23 @@ int vmw_execbuf_process(struct drm_file *file_priv,
    goto out_err;
  }
 
+ ret = mutex_lock_interruptible(&dev_priv->binding_mutex);
+ if (unlikely(ret != 0)) {
+  ret = -ERESTARTSYS;
+  goto out_err;
+ }
+
+ if (dev_priv->has_mob) {
+  ret = vmw_rebind_contexts(sw_context);
+  if (unlikely(ret != 0))
+   goto out_unlock_binding;
+ }
+
  cmd = vmw_fifo_reserve(dev_priv, command_size);
  if (unlikely(cmd == NULL)) {
   DRM_ERROR("Failed reserving fifo space for commands.\n");
   ret = -ENOMEM;
-  goto out_err;
+  goto out_unlock_binding;
  }
 
  vmw_apply_relocations(sw_context);
@@ -1538,6 +2504,8 @@ int vmw_execbuf_process(struct drm_file *file_priv,
   DRM_ERROR("Fence submission error. Syncing.\n");
 
  vmw_resource_list_unreserve(&sw_context->resource_list, false);
+ mutex_unlock(&dev_priv->binding_mutex);
+
  ttm_eu_fence_buffer_objects(&ticket, &sw_context->validate_nodes,
         (void *) fence);
 
@@ -1558,6 +2526,8 @@ int vmw_execbuf_process(struct drm_file *file_priv,
  }
 
  list_splice_init(&sw_context->resource_list, &resource_list);
+ vmw_compat_shaders_commit(sw_context->fp->shman,
+      &sw_context->staged_shaders);
  mutex_unlock(&dev_priv->cmdbuf_mutex);
 
  /*
@@ -1568,6 +2538,8 @@ int vmw_execbuf_process(struct drm_file *file_priv,
 
  return 0;
 
+out_unlock_binding:
+ mutex_unlock(&dev_priv->binding_mutex);
 out_err:
  ttm_eu_backoff_reservation(&ticket, &sw_context->validate_nodes);
 out_err_nores:
@@ -1582,6 +2554,8 @@ out_unlock:
  list_splice_init(&sw_context->resource_list, &resource_list);
  error_resource = sw_context->error_resource;
  sw_context->error_resource = NULL;
+ vmw_compat_shaders_revert(sw_context->fp->shman,
+      &sw_context->staged_shaders);
  mutex_unlock(&dev_priv->cmdbuf_mutex);
 
  /*
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_fence.c b/drivers/gpu/drm/vmwgfx/vmwgfx_fence.c
index c62d20e..436b013 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_fence.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_fence.c
@@ -271,7 +271,7 @@ void vmw_fence_obj_unreference(struct vmw_fence_obj **fence_p)
  spin_unlock_irq(&fman->lock);
 }
 
-void vmw_fences_perform_actions(struct vmw_fence_manager *fman,
+static void vmw_fences_perform_actions(struct vmw_fence_manager *fman,
     struct list_head *list)
 {
  struct vmw_fence_action *action, *next_action;
@@ -897,7 +897,7 @@ static void vmw_event_fence_action_cleanup(struct vmw_fence_action *action)
  * Note that the action callbacks may be executed before this function
  * returns.
  */
-void vmw_fence_obj_add_action(struct vmw_fence_obj *fence,
+static void vmw_fence_obj_add_action(struct vmw_fence_obj *fence,
          struct vmw_fence_action *action)
 {
  struct vmw_fence_manager *fman = fence->fman;
@@ -993,7 +993,7 @@ struct vmw_event_fence_pending {
  struct drm_vmw_event_fence event;
 };
 
-int vmw_event_fence_action_create(struct drm_file *file_priv,
+static int vmw_event_fence_action_create(struct drm_file *file_priv,
       struct vmw_fence_obj *fence,
       uint32_t flags,
       uint64_t user_data,
@@ -1080,7 +1080,8 @@ int vmw_fence_event_ioctl(struct drm_device *dev, void *data,
   */
  if (arg->handle) {
   struct ttm_base_object *base =
-   ttm_base_object_lookup(vmw_fp->tfile, arg->handle);
+   ttm_base_object_lookup_for_ref(dev_priv->tdev,
+             arg->handle);
 
   if (unlikely(base == NULL)) {
    DRM_ERROR("Fence event invalid fence object handle "
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c b/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c
index 3eb1486..6ccd993 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c
@@ -35,6 +35,23 @@ bool vmw_fifo_have_3d(struct vmw_private *dev_priv)
  uint32_t fifo_min, hwversion;
  const struct vmw_fifo_state *fifo = &dev_priv->fifo;
 
+ if (!(dev_priv->capabilities & SVGA_CAP_3D))
+  return false;
+
+ if (dev_priv->capabilities & SVGA_CAP_GBOBJECTS) {
+  uint32_t result;
+
+  if (!dev_priv->has_mob)
+   return false;
+
+  mutex_lock(&dev_priv->hw_mutex);
+  vmw_write(dev_priv, SVGA_REG_DEV_CAP, SVGA3D_DEVCAP_3D);
+  result = vmw_read(dev_priv, SVGA_REG_DEV_CAP);
+  mutex_unlock(&dev_priv->hw_mutex);
+
+  return (result != 0);
+ }
+
  if (!(dev_priv->capabilities & SVGA_CAP_EXTENDED_FIFO))
   return false;
 
@@ -511,24 +528,16 @@ out_err:
 }
 
 /**
- * vmw_fifo_emit_dummy_query - emits a dummy query to the fifo.
+ * vmw_fifo_emit_dummy_legacy_query - emits a dummy query to the fifo using
+ * legacy query commands.
  *
  * @dev_priv: The device private structure.
  * @cid: The hardware context id used for the query.
  *
- * This function is used to emit a dummy occlusion query with
- * no primitives rendered between query begin and query end.
- * It's used to provide a query barrier, in order to know that when
- * this query is finished, all preceding queries are also finished.
- *
- * A Query results structure should have been initialized at the start
- * of the dev_priv->dummy_query_bo buffer object. And that buffer object
- * must also be either reserved or pinned when this function is called.
- *
- * Returns -ENOMEM on failure to reserve fifo space.
+ * See the vmw_fifo_emit_dummy_query documentation.
  */
-int vmw_fifo_emit_dummy_query(struct vmw_private *dev_priv,
-         uint32_t cid)
+static int vmw_fifo_emit_dummy_legacy_query(struct vmw_private *dev_priv,
+         uint32_t cid)
 {
  /*
   * A query wait without a preceding query end will
@@ -566,3 +575,75 @@ int vmw_fifo_emit_dummy_query(struct vmw_private *dev_priv,
 
  return 0;
 }
+
+/**
+ * vmw_fifo_emit_dummy_gb_query - emits a dummy query to the fifo using
+ * guest-backed resource query commands.
+ *
+ * @dev_priv: The device private structure.
+ * @cid: The hardware context id used for the query.
+ *
+ * See the vmw_fifo_emit_dummy_query documentation.
+ */
+static int vmw_fifo_emit_dummy_gb_query(struct vmw_private *dev_priv,
+     uint32_t cid)
+{
+ /*
+  * A query wait without a preceding query end will
+  * actually finish all queries for this cid
+  * without writing to the query result structure.
+  */
+
+ struct ttm_buffer_object *bo = dev_priv->dummy_query_bo;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdWaitForGBQuery body;
+ } *cmd;
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Out of fifo space for dummy query.\n");
+  return -ENOMEM;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_WAIT_FOR_GB_QUERY;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.cid = cid;
+ cmd->body.type = SVGA3D_QUERYTYPE_OCCLUSION;
+ BUG_ON(bo->mem.mem_type != VMW_PL_MOB);
+ cmd->body.mobid = bo->mem.start;
+ cmd->body.offset = 0;
+
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+
+ return 0;
+}
+
+
+/**
+ * vmw_fifo_emit_dummy_gb_query - emits a dummy query to the fifo using
+ * appropriate resource query commands.
+ *
+ * @dev_priv: The device private structure.
+ * @cid: The hardware context id used for the query.
+ *
+ * This function is used to emit a dummy occlusion query with
+ * no primitives rendered between query begin and query end.
+ * It's used to provide a query barrier, in order to know that when
+ * this query is finished, all preceding queries are also finished.
+ *
+ * A Query results structure should have been initialized at the start
+ * of the dev_priv->dummy_query_bo buffer object. And that buffer object
+ * must also be either reserved or pinned when this function is called.
+ *
+ * Returns -ENOMEM on failure to reserve fifo space.
+ */
+int vmw_fifo_emit_dummy_query(struct vmw_private *dev_priv,
+         uint32_t cid)
+{
+ if (dev_priv->has_mob)
+  return vmw_fifo_emit_dummy_gb_query(dev_priv, cid);
+
+ return vmw_fifo_emit_dummy_legacy_query(dev_priv, cid);
+}
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_gmrid_manager.c b/drivers/gpu/drm/vmwgfx/vmwgfx_gmrid_manager.c
index c5c054a..b1273e8 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_gmrid_manager.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_gmrid_manager.c
@@ -125,10 +125,21 @@ static int vmw_gmrid_man_init(struct ttm_mem_type_manager *man,
   return -ENOMEM;
 
  spin_lock_init(&gman->lock);
- gman->max_gmr_pages = dev_priv->max_gmr_pages;
  gman->used_gmr_pages = 0;
  ida_init(&gman->gmr_ida);
- gman->max_gmr_ids = p_size;
+
+ switch (p_size) {
+ case VMW_PL_GMR:
+  gman->max_gmr_ids = dev_priv->max_gmr_ids;
+  gman->max_gmr_pages = dev_priv->max_gmr_pages;
+  break;
+ case VMW_PL_MOB:
+  gman->max_gmr_ids = VMWGFX_NUM_MOB;
+  gman->max_gmr_pages = dev_priv->max_mob_pages;
+  break;
+ default:
+  BUG();
+ }
  man->priv = (void *) gman;
  return 0;
 }
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c b/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c
index 45d5b5a..47b7094 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c
@@ -29,12 +29,18 @@
 #include <drm/vmwgfx_drm.h>
 #include "vmwgfx_kms.h"
 
+struct svga_3d_compat_cap {
+ SVGA3dCapsRecordHeader header;
+ SVGA3dCapPair pairs[SVGA3D_DEVCAP_MAX];
+};
+
 int vmw_getparam_ioctl(struct drm_device *dev, void *data,
          struct drm_file *file_priv)
 {
  struct vmw_private *dev_priv = vmw_priv(dev);
  struct drm_vmw_getparam_arg *param =
      (struct drm_vmw_getparam_arg *)data;
+ struct vmw_fpriv *vmw_fp = vmw_fpriv(file_priv);
 
  switch (param->param) {
  case DRM_VMW_PARAM_NUM_STREAMS:
@@ -53,13 +59,18 @@ int vmw_getparam_ioctl(struct drm_device *dev, void *data,
   param->value = dev_priv->fifo.capabilities;
   break;
  case DRM_VMW_PARAM_MAX_FB_SIZE:
-  param->value = dev_priv->vram_size;
+  param->value = dev_priv->prim_bb_mem;
   break;
  case DRM_VMW_PARAM_FIFO_HW_VERSION:
  {
   __le32 __iomem *fifo_mem = dev_priv->mmio_virt;
   const struct vmw_fifo_state *fifo = &dev_priv->fifo;
 
+  if ((dev_priv->capabilities & SVGA_CAP_GBOBJECTS)) {
+   param->value = SVGA3D_HWVERSION_WS8_B1;
+   break;
+  }
+
   param->value =
    ioread32(fifo_mem +
      ((fifo->capabilities &
@@ -69,7 +80,30 @@ int vmw_getparam_ioctl(struct drm_device *dev, void *data,
   break;
  }
  case DRM_VMW_PARAM_MAX_SURF_MEMORY:
-  param->value = dev_priv->memory_size;
+  if ((dev_priv->capabilities & SVGA_CAP_GBOBJECTS) &&
+      !vmw_fp->gb_aware)
+   param->value = dev_priv->max_mob_pages * PAGE_SIZE / 2;
+  else
+   param->value = dev_priv->memory_size;
+  break;
+ case DRM_VMW_PARAM_3D_CAPS_SIZE:
+  if ((dev_priv->capabilities & SVGA_CAP_GBOBJECTS) &&
+      vmw_fp->gb_aware)
+   param->value = SVGA3D_DEVCAP_MAX * sizeof(uint32_t);
+  else if (dev_priv->capabilities & SVGA_CAP_GBOBJECTS)
+   param->value = sizeof(struct svga_3d_compat_cap) +
+    sizeof(uint32_t);
+  else
+   param->value = (SVGA_FIFO_3D_CAPS_LAST -
+     SVGA_FIFO_3D_CAPS + 1) *
+    sizeof(uint32_t);
+  break;
+ case DRM_VMW_PARAM_MAX_MOB_MEMORY:
+  vmw_fp->gb_aware = true;
+  param->value = dev_priv->max_mob_pages * PAGE_SIZE;
+  break;
+ case DRM_VMW_PARAM_MAX_MOB_SIZE:
+  param->value = dev_priv->max_mob_size;
   break;
  default:
   DRM_ERROR("Illegal vmwgfx get param request: %d\n",
@@ -80,6 +114,38 @@ int vmw_getparam_ioctl(struct drm_device *dev, void *data,
  return 0;
 }
 
+static int vmw_fill_compat_cap(struct vmw_private *dev_priv, void *bounce,
+          size_t size)
+{
+ struct svga_3d_compat_cap *compat_cap =
+  (struct svga_3d_compat_cap *) bounce;
+ unsigned int i;
+ size_t pair_offset = offsetof(struct svga_3d_compat_cap, pairs);
+ unsigned int max_size;
+
+ if (size < pair_offset)
+  return -EINVAL;
+
+ max_size = (size - pair_offset) / sizeof(SVGA3dCapPair);
+
+ if (max_size > SVGA3D_DEVCAP_MAX)
+  max_size = SVGA3D_DEVCAP_MAX;
+
+ compat_cap->header.length =
+  (pair_offset + max_size * sizeof(SVGA3dCapPair)) / sizeof(u32);
+ compat_cap->header.type = SVGA3DCAPS_RECORD_DEVCAPS;
+
+ mutex_lock(&dev_priv->hw_mutex);
+ for (i = 0; i < max_size; ++i) {
+  vmw_write(dev_priv, SVGA_REG_DEV_CAP, i);
+  compat_cap->pairs[i][0] = i;
+  compat_cap->pairs[i][1] = vmw_read(dev_priv, SVGA_REG_DEV_CAP);
+ }
+ mutex_unlock(&dev_priv->hw_mutex);
+
+ return 0;
+}
+
 
 int vmw_get_cap_3d_ioctl(struct drm_device *dev, void *data,
     struct drm_file *file_priv)
@@ -92,29 +158,58 @@ int vmw_get_cap_3d_ioctl(struct drm_device *dev, void *data,
  void __user *buffer = (void __user *)((unsigned long)(arg->buffer));
  void *bounce;
  int ret;
+ bool gb_objects = !!(dev_priv->capabilities & SVGA_CAP_GBOBJECTS);
+ struct vmw_fpriv *vmw_fp = vmw_fpriv(file_priv);
 
  if (unlikely(arg->pad64 != 0)) {
   DRM_ERROR("Illegal GET_3D_CAP argument.\n");
   return -EINVAL;
  }
 
- size = (SVGA_FIFO_3D_CAPS_LAST - SVGA_FIFO_3D_CAPS + 1) << 2;
+ if (gb_objects && vmw_fp->gb_aware)
+  size = SVGA3D_DEVCAP_MAX * sizeof(uint32_t);
+ else if (gb_objects)
+  size = sizeof(struct svga_3d_compat_cap) + sizeof(uint32_t);
+ else
+  size = (SVGA_FIFO_3D_CAPS_LAST - SVGA_FIFO_3D_CAPS + 1) *
+   sizeof(uint32_t);
 
  if (arg->max_size < size)
   size = arg->max_size;
 
- bounce = vmalloc(size);
+ bounce = vzalloc(size);
  if (unlikely(bounce == NULL)) {
   DRM_ERROR("Failed to allocate bounce buffer for 3D caps.\n");
   return -ENOMEM;
  }
 
- fifo_mem = dev_priv->mmio_virt;
- memcpy_fromio(bounce, &fifo_mem[SVGA_FIFO_3D_CAPS], size);
+ if (gb_objects && vmw_fp->gb_aware) {
+  int i, num;
+  uint32_t *bounce32 = (uint32_t *) bounce;
+
+  num = size / sizeof(uint32_t);
+  if (num > SVGA3D_DEVCAP_MAX)
+   num = SVGA3D_DEVCAP_MAX;
+
+  mutex_lock(&dev_priv->hw_mutex);
+  for (i = 0; i < num; ++i) {
+   vmw_write(dev_priv, SVGA_REG_DEV_CAP, i);
+   *bounce32++ = vmw_read(dev_priv, SVGA_REG_DEV_CAP);
+  }
+  mutex_unlock(&dev_priv->hw_mutex);
+ } else if (gb_objects) {
+  ret = vmw_fill_compat_cap(dev_priv, bounce, size);
+  if (unlikely(ret != 0))
+   goto out_err;
+ } else {
+  fifo_mem = dev_priv->mmio_virt;
+  memcpy_fromio(bounce, &fifo_mem[SVGA_FIFO_3D_CAPS], size);
+ }
 
  ret = copy_to_user(buffer, bounce, size);
  if (ret)
   ret = -EFAULT;
+out_err:
  vfree(bounce);
 
  if (unlikely(ret != 0))
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_irq.c b/drivers/gpu/drm/vmwgfx/vmwgfx_irq.c
index 4640adb..0c42376 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_irq.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_irq.c
@@ -30,7 +30,7 @@
 
 #define VMW_FENCE_WRAP (1 << 24)
 
-irqreturn_t vmw_irq_handler(DRM_IRQ_ARGS)
+irqreturn_t vmw_irq_handler(int irq, void *arg)
 {
  struct drm_device *dev = (struct drm_device *)arg;
  struct vmw_private *dev_priv = vmw_priv(dev);
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_kms.c b/drivers/gpu/drm/vmwgfx/vmwgfx_kms.c
index 03f1c20..8a65041 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_kms.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_kms.c
@@ -40,7 +40,7 @@ struct vmw_clip_rect {
  * Clip @num_rects number of @rects against @clip storing the
  * results in @out_rects and the number of passed rects in @out_num.
  */
-void vmw_clip_cliprects(struct drm_clip_rect *rects,
+static void vmw_clip_cliprects(struct drm_clip_rect *rects,
    int num_rects,
    struct vmw_clip_rect clip,
    SVGASignedRect *out_rects,
@@ -423,7 +423,7 @@ struct vmw_framebuffer_surface {
  struct drm_master *master;
 };
 
-void vmw_framebuffer_surface_destroy(struct drm_framebuffer *framebuffer)
+static void vmw_framebuffer_surface_destroy(struct drm_framebuffer *framebuffer)
 {
  struct vmw_framebuffer_surface *vfbs =
   vmw_framebuffer_to_vfbs(framebuffer);
@@ -589,7 +589,7 @@ out_free_tmp:
  return ret;
 }
 
-int vmw_framebuffer_surface_dirty(struct drm_framebuffer *framebuffer,
+static int vmw_framebuffer_surface_dirty(struct drm_framebuffer *framebuffer,
       struct drm_file *file_priv,
       unsigned flags, unsigned color,
       struct drm_clip_rect *clips,
@@ -609,9 +609,13 @@ int vmw_framebuffer_surface_dirty(struct drm_framebuffer *framebuffer,
  if (!dev_priv->sou_priv)
   return -EINVAL;
 
+ drm_modeset_lock_all(dev_priv->dev);
+
  ret = ttm_read_lock(&vmaster->lock, true);
- if (unlikely(ret != 0))
+ if (unlikely(ret != 0)) {
+  drm_modeset_unlock_all(dev_priv->dev);
   return ret;
+ }
 
  if (!num_clips) {
   num_clips = 1;
@@ -629,6 +633,9 @@ int vmw_framebuffer_surface_dirty(struct drm_framebuffer *framebuffer,
        clips, num_clips, inc, NULL);
 
  ttm_read_unlock(&vmaster->lock);
+
+ drm_modeset_unlock_all(dev_priv->dev);
+
  return 0;
 }
 
@@ -665,9 +672,9 @@ static int vmw_kms_new_framebuffer_surface(struct vmw_private *dev_priv,
 
  if (unlikely(surface->mip_levels[0] != 1 ||
        surface->num_sizes != 1 ||
-       surface->sizes[0].width < mode_cmd->width ||
-       surface->sizes[0].height < mode_cmd->height ||
-       surface->sizes[0].depth != 1)) {
+       surface->base_size.width < mode_cmd->width ||
+       surface->base_size.height < mode_cmd->height ||
+       surface->base_size.depth != 1)) {
   DRM_ERROR("Incompatible surface dimensions "
      "for requested mode.\n");
   return -EINVAL;
@@ -754,7 +761,7 @@ struct vmw_framebuffer_dmabuf {
  struct vmw_dma_buffer *buffer;
 };
 
-void vmw_framebuffer_dmabuf_destroy(struct drm_framebuffer *framebuffer)
+static void vmw_framebuffer_dmabuf_destroy(struct drm_framebuffer *framebuffer)
 {
  struct vmw_framebuffer_dmabuf *vfbd =
   vmw_framebuffer_to_vfbd(framebuffer);
@@ -940,7 +947,7 @@ static int do_dmabuf_dirty_sou(struct drm_file *file_priv,
  return ret;
 }
 
-int vmw_framebuffer_dmabuf_dirty(struct drm_framebuffer *framebuffer,
+static int vmw_framebuffer_dmabuf_dirty(struct drm_framebuffer *framebuffer,
      struct drm_file *file_priv,
      unsigned flags, unsigned color,
      struct drm_clip_rect *clips,
@@ -953,9 +960,13 @@ int vmw_framebuffer_dmabuf_dirty(struct drm_framebuffer *framebuffer,
  struct drm_clip_rect norect;
  int ret, increment = 1;
 
+ drm_modeset_lock_all(dev_priv->dev);
+
  ret = ttm_read_lock(&vmaster->lock, true);
- if (unlikely(ret != 0))
+ if (unlikely(ret != 0)) {
+  drm_modeset_unlock_all(dev_priv->dev);
   return ret;
+ }
 
  if (!num_clips) {
   num_clips = 1;
@@ -979,6 +990,9 @@ int vmw_framebuffer_dmabuf_dirty(struct drm_framebuffer *framebuffer,
  }
 
  ttm_read_unlock(&vmaster->lock);
+
+ drm_modeset_unlock_all(dev_priv->dev);
+
  return ret;
 }
 
@@ -1631,7 +1645,7 @@ bool vmw_kms_validate_mode_vram(struct vmw_private *dev_priv,
     uint32_t pitch,
     uint32_t height)
 {
- return ((u64) pitch * (u64) height) < (u64) dev_priv->vram_size;
+ return ((u64) pitch * (u64) height) < (u64) dev_priv->prim_bb_mem;
 }
 
 
@@ -1663,7 +1677,7 @@ void vmw_disable_vblank(struct drm_device *dev, int crtc)
  * Small shared kms functions.
  */
 
-int vmw_du_update_layout(struct vmw_private *dev_priv, unsigned num,
+static int vmw_du_update_layout(struct vmw_private *dev_priv, unsigned num,
     struct drm_vmw_rect *rects)
 {
  struct drm_device *dev = dev_priv->dev;
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_mob.c b/drivers/gpu/drm/vmwgfx/vmwgfx_mob.c
new file mode 100644
index 0000000..04a64b8
--- /dev/null
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_mob.c
@@ -0,0 +1,656 @@
+/**************************************************************************
+ *
+ * Copyright  2012 VMware, Inc., Palo Alto, CA., USA
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDERS, AUTHORS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM,
+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
+ * USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ **************************************************************************/
+
+#include "vmwgfx_drv.h"
+
+/*
+ * If we set up the screen target otable, screen objects stop working.
+ */
+
+#define VMW_OTABLE_SETUP_SUB ((VMWGFX_ENABLE_SCREEN_TARGET_OTABLE) ? 0 : 1)
+
+#ifdef CONFIG_64BIT
+#define VMW_PPN_SIZE 8
+#define VMW_MOBFMT_PTDEPTH_0 SVGA3D_MOBFMT_PTDEPTH64_0
+#define VMW_MOBFMT_PTDEPTH_1 SVGA3D_MOBFMT_PTDEPTH64_1
+#define VMW_MOBFMT_PTDEPTH_2 SVGA3D_MOBFMT_PTDEPTH64_2
+#else
+#define VMW_PPN_SIZE 4
+#define VMW_MOBFMT_PTDEPTH_0 SVGA3D_MOBFMT_PTDEPTH_0
+#define VMW_MOBFMT_PTDEPTH_1 SVGA3D_MOBFMT_PTDEPTH_1
+#define VMW_MOBFMT_PTDEPTH_2 SVGA3D_MOBFMT_PTDEPTH_2
+#endif
+
+/*
+ * struct vmw_mob - Structure containing page table and metadata for a
+ * Guest Memory OBject.
+ *
+ * @num_pages       Number of pages that make up the page table.
+ * @pt_level        The indirection level of the page table. 0-2.
+ * @pt_root_page    DMA address of the level 0 page of the page table.
+ */
+struct vmw_mob {
+ struct ttm_buffer_object *pt_bo;
+ unsigned long num_pages;
+ unsigned pt_level;
+ dma_addr_t pt_root_page;
+ uint32_t id;
+};
+
+/*
+ * struct vmw_otable - Guest Memory OBject table metadata
+ *
+ * @size:           Size of the table (page-aligned).
+ * @page_table:     Pointer to a struct vmw_mob holding the page table.
+ */
+struct vmw_otable {
+ unsigned long size;
+ struct vmw_mob *page_table;
+};
+
+static int vmw_mob_pt_populate(struct vmw_private *dev_priv,
+          struct vmw_mob *mob);
+static void vmw_mob_pt_setup(struct vmw_mob *mob,
+        struct vmw_piter data_iter,
+        unsigned long num_data_pages);
+
+/*
+ * vmw_setup_otable_base - Issue an object table base setup command to
+ * the device
+ *
+ * @dev_priv:       Pointer to a device private structure
+ * @type:           Type of object table base
+ * @offset          Start of table offset into dev_priv::otable_bo
+ * @otable          Pointer to otable metadata;
+ *
+ * This function returns -ENOMEM if it fails to reserve fifo space,
+ * and may block waiting for fifo space.
+ */
+static int vmw_setup_otable_base(struct vmw_private *dev_priv,
+     SVGAOTableType type,
+     unsigned long offset,
+     struct vmw_otable *otable)
+{
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdSetOTableBase64 body;
+ } *cmd;
+ struct vmw_mob *mob;
+ const struct vmw_sg_table *vsgt;
+ struct vmw_piter iter;
+ int ret;
+
+ BUG_ON(otable->page_table != NULL);
+
+ vsgt = vmw_bo_sg_table(dev_priv->otable_bo);
+ vmw_piter_start(&iter, vsgt, offset >> PAGE_SHIFT);
+ WARN_ON(!vmw_piter_next(&iter));
+
+ mob = vmw_mob_create(otable->size >> PAGE_SHIFT);
+ if (unlikely(mob == NULL)) {
+  DRM_ERROR("Failed creating OTable page table.\n");
+  return -ENOMEM;
+ }
+
+ if (otable->size <= PAGE_SIZE) {
+  mob->pt_level = VMW_MOBFMT_PTDEPTH_0;
+  mob->pt_root_page = vmw_piter_dma_addr(&iter);
+ } else if (vsgt->num_regions == 1) {
+  mob->pt_level = SVGA3D_MOBFMT_RANGE;
+  mob->pt_root_page = vmw_piter_dma_addr(&iter);
+ } else {
+  ret = vmw_mob_pt_populate(dev_priv, mob);
+  if (unlikely(ret != 0))
+   goto out_no_populate;
+
+  vmw_mob_pt_setup(mob, iter, otable->size >> PAGE_SHIFT);
+  mob->pt_level += VMW_MOBFMT_PTDEPTH_1 - SVGA3D_MOBFMT_PTDEPTH_1;
+ }
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for OTable setup.\n");
+  ret = -ENOMEM;
+  goto out_no_fifo;
+ }
+
+ memset(cmd, 0, sizeof(*cmd));
+ cmd->header.id = SVGA_3D_CMD_SET_OTABLE_BASE64;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.type = type;
+ cmd->body.baseAddress = cpu_to_le64(mob->pt_root_page >> PAGE_SHIFT);
+ cmd->body.sizeInBytes = otable->size;
+ cmd->body.validSizeInBytes = 0;
+ cmd->body.ptDepth = mob->pt_level;
+
+ /*
+  * The device doesn't support this, But the otable size is
+  * determined at compile-time, so this BUG shouldn't trigger
+  * randomly.
+  */
+ BUG_ON(mob->pt_level == VMW_MOBFMT_PTDEPTH_2);
+
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+ otable->page_table = mob;
+
+ return 0;
+
+out_no_fifo:
+out_no_populate:
+ vmw_mob_destroy(mob);
+ return ret;
+}
+
+/*
+ * vmw_takedown_otable_base - Issue an object table base takedown command
+ * to the device
+ *
+ * @dev_priv:       Pointer to a device private structure
+ * @type:           Type of object table base
+ *
+ */
+static void vmw_takedown_otable_base(struct vmw_private *dev_priv,
+         SVGAOTableType type,
+         struct vmw_otable *otable)
+{
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdSetOTableBase body;
+ } *cmd;
+ struct ttm_buffer_object *bo;
+
+ if (otable->page_table == NULL)
+  return;
+
+ bo = otable->page_table->pt_bo;
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for OTable "
+     "takedown.\n");
+ } else {
+  memset(cmd, 0, sizeof(*cmd));
+  cmd->header.id = SVGA_3D_CMD_SET_OTABLE_BASE;
+  cmd->header.size = sizeof(cmd->body);
+  cmd->body.type = type;
+  cmd->body.baseAddress = 0;
+  cmd->body.sizeInBytes = 0;
+  cmd->body.validSizeInBytes = 0;
+  cmd->body.ptDepth = SVGA3D_MOBFMT_INVALID;
+  vmw_fifo_commit(dev_priv, sizeof(*cmd));
+ }
+
+ if (bo) {
+  int ret;
+
+  ret = ttm_bo_reserve(bo, false, true, false, NULL);
+  BUG_ON(ret != 0);
+
+  vmw_fence_single_bo(bo, NULL);
+  ttm_bo_unreserve(bo);
+ }
+
+ vmw_mob_destroy(otable->page_table);
+ otable->page_table = NULL;
+}
+
+/*
+ * vmw_otables_setup - Set up guest backed memory object tables
+ *
+ * @dev_priv:       Pointer to a device private structure
+ *
+ * Takes care of the device guest backed surface
+ * initialization, by setting up the guest backed memory object tables.
+ * Returns 0 on success and various error codes on failure. A succesful return
+ * means the object tables can be taken down using the vmw_otables_takedown
+ * function.
+ */
+int vmw_otables_setup(struct vmw_private *dev_priv)
+{
+ unsigned long offset;
+ unsigned long bo_size;
+ struct vmw_otable *otables;
+ SVGAOTableType i;
+ int ret;
+
+ otables = kzalloc(SVGA_OTABLE_DX9_MAX * sizeof(*otables),
+     GFP_KERNEL);
+ if (unlikely(otables == NULL)) {
+  DRM_ERROR("Failed to allocate space for otable "
+     "metadata.\n");
+  return -ENOMEM;
+ }
+
+ otables[SVGA_OTABLE_MOB].size =
+  VMWGFX_NUM_MOB * SVGA3D_OTABLE_MOB_ENTRY_SIZE;
+ otables[SVGA_OTABLE_SURFACE].size =
+  VMWGFX_NUM_GB_SURFACE * SVGA3D_OTABLE_SURFACE_ENTRY_SIZE;
+ otables[SVGA_OTABLE_CONTEXT].size =
+  VMWGFX_NUM_GB_CONTEXT * SVGA3D_OTABLE_CONTEXT_ENTRY_SIZE;
+ otables[SVGA_OTABLE_SHADER].size =
+  VMWGFX_NUM_GB_SHADER * SVGA3D_OTABLE_SHADER_ENTRY_SIZE;
+ otables[SVGA_OTABLE_SCREEN_TARGET].size =
+  VMWGFX_NUM_GB_SCREEN_TARGET *
+  SVGA3D_OTABLE_SCREEN_TARGET_ENTRY_SIZE;
+
+ bo_size = 0;
+ for (i = 0; i < SVGA_OTABLE_DX9_MAX; ++i) {
+  otables[i].size =
+   (otables[i].size + PAGE_SIZE - 1) & PAGE_MASK;
+  bo_size += otables[i].size;
+ }
+
+ ret = ttm_bo_create(&dev_priv->bdev, bo_size,
+       ttm_bo_type_device,
+       &vmw_sys_ne_placement,
+       0, false, NULL,
+       &dev_priv->otable_bo);
+
+ if (unlikely(ret != 0))
+  goto out_no_bo;
+
+ ret = ttm_bo_reserve(dev_priv->otable_bo, false, true, false, NULL);
+ BUG_ON(ret != 0);
+ ret = vmw_bo_driver.ttm_tt_populate(dev_priv->otable_bo->ttm);
+ if (unlikely(ret != 0))
+  goto out_unreserve;
+ ret = vmw_bo_map_dma(dev_priv->otable_bo);
+ if (unlikely(ret != 0))
+  goto out_unreserve;
+
+ ttm_bo_unreserve(dev_priv->otable_bo);
+
+ offset = 0;
+ for (i = 0; i < SVGA_OTABLE_DX9_MAX - VMW_OTABLE_SETUP_SUB; ++i) {
+  ret = vmw_setup_otable_base(dev_priv, i, offset,
+         &otables[i]);
+  if (unlikely(ret != 0))
+   goto out_no_setup;
+  offset += otables[i].size;
+ }
+
+ dev_priv->otables = otables;
+ return 0;
+
+out_unreserve:
+ ttm_bo_unreserve(dev_priv->otable_bo);
+out_no_setup:
+ for (i = 0; i < SVGA_OTABLE_DX9_MAX - VMW_OTABLE_SETUP_SUB; ++i)
+  vmw_takedown_otable_base(dev_priv, i, &otables[i]);
+
+ ttm_bo_unref(&dev_priv->otable_bo);
+out_no_bo:
+ kfree(otables);
+ return ret;
+}
+
+
+/*
+ * vmw_otables_takedown - Take down guest backed memory object tables
+ *
+ * @dev_priv:       Pointer to a device private structure
+ *
+ * Take down the Guest Memory Object tables.
+ */
+void vmw_otables_takedown(struct vmw_private *dev_priv)
+{
+ SVGAOTableType i;
+ struct ttm_buffer_object *bo = dev_priv->otable_bo;
+ int ret;
+
+ for (i = 0; i < SVGA_OTABLE_DX9_MAX - VMW_OTABLE_SETUP_SUB; ++i)
+  vmw_takedown_otable_base(dev_priv, i,
+      &dev_priv->otables[i]);
+
+ ret = ttm_bo_reserve(bo, false, true, false, NULL);
+ BUG_ON(ret != 0);
+
+ vmw_fence_single_bo(bo, NULL);
+ ttm_bo_unreserve(bo);
+
+ ttm_bo_unref(&dev_priv->otable_bo);
+ kfree(dev_priv->otables);
+ dev_priv->otables = NULL;
+}
+
+
+/*
+ * vmw_mob_calculate_pt_pages - Calculate the number of page table pages
+ * needed for a guest backed memory object.
+ *
+ * @data_pages:  Number of data pages in the memory object buffer.
+ */
+static unsigned long vmw_mob_calculate_pt_pages(unsigned long data_pages)
+{
+ unsigned long data_size = data_pages * PAGE_SIZE;
+ unsigned long tot_size = 0;
+
+ while (likely(data_size > PAGE_SIZE)) {
+  data_size = DIV_ROUND_UP(data_size, PAGE_SIZE);
+  data_size *= VMW_PPN_SIZE;
+  tot_size += (data_size + PAGE_SIZE - 1) & PAGE_MASK;
+ }
+
+ return tot_size >> PAGE_SHIFT;
+}
+
+/*
+ * vmw_mob_create - Create a mob, but don't populate it.
+ *
+ * @data_pages:  Number of data pages of the underlying buffer object.
+ */
+struct vmw_mob *vmw_mob_create(unsigned long data_pages)
+{
+ struct vmw_mob *mob = kzalloc(sizeof(*mob), GFP_KERNEL);
+
+ if (unlikely(mob == NULL))
+  return NULL;
+
+ mob->num_pages = vmw_mob_calculate_pt_pages(data_pages);
+
+ return mob;
+}
+
+/*
+ * vmw_mob_pt_populate - Populate the mob pagetable
+ *
+ * @mob:         Pointer to the mob the pagetable of which we want to
+ *               populate.
+ *
+ * This function allocates memory to be used for the pagetable, and
+ * adjusts TTM memory accounting accordingly. Returns ENOMEM if
+ * memory resources aren't sufficient and may cause TTM buffer objects
+ * to be swapped out by using the TTM memory accounting function.
+ */
+static int vmw_mob_pt_populate(struct vmw_private *dev_priv,
+          struct vmw_mob *mob)
+{
+ int ret;
+ BUG_ON(mob->pt_bo != NULL);
+
+ ret = ttm_bo_create(&dev_priv->bdev, mob->num_pages * PAGE_SIZE,
+       ttm_bo_type_device,
+       &vmw_sys_ne_placement,
+       0, false, NULL, &mob->pt_bo);
+ if (unlikely(ret != 0))
+  return ret;
+
+ ret = ttm_bo_reserve(mob->pt_bo, false, true, false, NULL);
+
+ BUG_ON(ret != 0);
+ ret = vmw_bo_driver.ttm_tt_populate(mob->pt_bo->ttm);
+ if (unlikely(ret != 0))
+  goto out_unreserve;
+ ret = vmw_bo_map_dma(mob->pt_bo);
+ if (unlikely(ret != 0))
+  goto out_unreserve;
+
+ ttm_bo_unreserve(mob->pt_bo);
+ 
+ return 0;
+
+out_unreserve:
+ ttm_bo_unreserve(mob->pt_bo);
+ ttm_bo_unref(&mob->pt_bo);
+
+ return ret;
+}
+
+/**
+ * vmw_mob_assign_ppn - Assign a value to a page table entry
+ *
+ * @addr: Pointer to pointer to page table entry.
+ * @val: The page table entry
+ *
+ * Assigns a value to a page table entry pointed to by *@addr and increments
+ * *@addr according to the page table entry size.
+ */
+#if (VMW_PPN_SIZE == 8)
+static void vmw_mob_assign_ppn(__le32 **addr, dma_addr_t val)
+{
+ *((__le64 *) *addr) = cpu_to_le64(val >> PAGE_SHIFT);
+ *addr += 2;
+}
+#else
+static void vmw_mob_assign_ppn(__le32 **addr, dma_addr_t val)
+{
+ *(*addr)++ = cpu_to_le32(val >> PAGE_SHIFT);
+}
+#endif
+
+/*
+ * vmw_mob_build_pt - Build a pagetable
+ *
+ * @data_addr:      Array of DMA addresses to the underlying buffer
+ *                  object's data pages.
+ * @num_data_pages: Number of buffer object data pages.
+ * @pt_pages:       Array of page pointers to the page table pages.
+ *
+ * Returns the number of page table pages actually used.
+ * Uses atomic kmaps of highmem pages to avoid TLB thrashing.
+ */
+static unsigned long vmw_mob_build_pt(struct vmw_piter *data_iter,
+          unsigned long num_data_pages,
+          struct vmw_piter *pt_iter)
+{
+ unsigned long pt_size = num_data_pages * VMW_PPN_SIZE;
+ unsigned long num_pt_pages = DIV_ROUND_UP(pt_size, PAGE_SIZE);
+ unsigned long pt_page;
+ __le32 *addr, *save_addr;
+ unsigned long i;
+ struct page *page;
+
+ for (pt_page = 0; pt_page < num_pt_pages; ++pt_page) {
+  page = vmw_piter_page(pt_iter);
+
+  save_addr = addr = kmap_atomic(page);
+
+  for (i = 0; i < PAGE_SIZE / VMW_PPN_SIZE; ++i) {
+   vmw_mob_assign_ppn(&addr,
+        vmw_piter_dma_addr(data_iter));
+   if (unlikely(--num_data_pages == 0))
+    break;
+   WARN_ON(!vmw_piter_next(data_iter));
+  }
+  kunmap_atomic(save_addr);
+  vmw_piter_next(pt_iter);
+ }
+
+ return num_pt_pages;
+}
+
+/*
+ * vmw_mob_build_pt - Set up a multilevel mob pagetable
+ *
+ * @mob:            Pointer to a mob whose page table needs setting up.
+ * @data_addr       Array of DMA addresses to the buffer object's data
+ *                  pages.
+ * @num_data_pages: Number of buffer object data pages.
+ *
+ * Uses tail recursion to set up a multilevel mob page table.
+ */
+static void vmw_mob_pt_setup(struct vmw_mob *mob,
+        struct vmw_piter data_iter,
+        unsigned long num_data_pages)
+{
+ unsigned long num_pt_pages = 0;
+ struct ttm_buffer_object *bo = mob->pt_bo;
+ struct vmw_piter save_pt_iter;
+ struct vmw_piter pt_iter;
+ const struct vmw_sg_table *vsgt;
+ int ret;
+
+ ret = ttm_bo_reserve(bo, false, true, false, NULL);
+ BUG_ON(ret != 0);
+
+ vsgt = vmw_bo_sg_table(bo);
+ vmw_piter_start(&pt_iter, vsgt, 0);
+ BUG_ON(!vmw_piter_next(&pt_iter));
+ mob->pt_level = 0;
+ while (likely(num_data_pages > 1)) {
+  ++mob->pt_level;
+  BUG_ON(mob->pt_level > 2);
+  save_pt_iter = pt_iter;
+  num_pt_pages = vmw_mob_build_pt(&data_iter, num_data_pages,
+      &pt_iter);
+  data_iter = save_pt_iter;
+  num_data_pages = num_pt_pages;
+ }
+
+ mob->pt_root_page = vmw_piter_dma_addr(&save_pt_iter);
+ ttm_bo_unreserve(bo);
+}
+
+/*
+ * vmw_mob_destroy - Destroy a mob, unpopulating first if necessary.
+ *
+ * @mob:            Pointer to a mob to destroy.
+ */
+void vmw_mob_destroy(struct vmw_mob *mob)
+{
+ if (mob->pt_bo)
+  ttm_bo_unref(&mob->pt_bo);
+ kfree(mob);
+}
+
+/*
+ * vmw_mob_unbind - Hide a mob from the device.
+ *
+ * @dev_priv:       Pointer to a device private.
+ * @mob_id:         Device id of the mob to unbind.
+ */
+void vmw_mob_unbind(struct vmw_private *dev_priv,
+      struct vmw_mob *mob)
+{
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDestroyGBMob body;
+ } *cmd;
+ int ret;
+ struct ttm_buffer_object *bo = mob->pt_bo;
+
+ if (bo) {
+  ret = ttm_bo_reserve(bo, false, true, false, NULL);
+  /*
+   * Noone else should be using this buffer.
+   */
+  BUG_ON(ret != 0);
+ }
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for Memory "
+     "Object unbinding.\n");
+ } else {
+  cmd->header.id = SVGA_3D_CMD_DESTROY_GB_MOB;
+  cmd->header.size = sizeof(cmd->body);
+  cmd->body.mobid = mob->id;
+  vmw_fifo_commit(dev_priv, sizeof(*cmd));
+ }
+ if (bo) {
+  vmw_fence_single_bo(bo, NULL);
+  ttm_bo_unreserve(bo);
+ }
+ vmw_3d_resource_dec(dev_priv, false);
+}
+
+/*
+ * vmw_mob_bind - Make a mob visible to the device after first
+ *                populating it if necessary.
+ *
+ * @dev_priv:       Pointer to a device private.
+ * @mob:            Pointer to the mob we're making visible.
+ * @data_addr:      Array of DMA addresses to the data pages of the underlying
+ *                  buffer object.
+ * @num_data_pages: Number of data pages of the underlying buffer
+ *                  object.
+ * @mob_id:         Device id of the mob to bind
+ *
+ * This function is intended to be interfaced with the ttm_tt backend
+ * code.
+ */
+int vmw_mob_bind(struct vmw_private *dev_priv,
+   struct vmw_mob *mob,
+   const struct vmw_sg_table *vsgt,
+   unsigned long num_data_pages,
+   int32_t mob_id)
+{
+ int ret;
+ bool pt_set_up = false;
+ struct vmw_piter data_iter;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDefineGBMob64 body;
+ } *cmd;
+
+ mob->id = mob_id;
+ vmw_piter_start(&data_iter, vsgt, 0);
+ if (unlikely(!vmw_piter_next(&data_iter)))
+  return 0;
+
+ if (likely(num_data_pages == 1)) {
+  mob->pt_level = VMW_MOBFMT_PTDEPTH_0;
+  mob->pt_root_page = vmw_piter_dma_addr(&data_iter);
+ } else if (vsgt->num_regions == 1) {
+  mob->pt_level = SVGA3D_MOBFMT_RANGE;
+  mob->pt_root_page = vmw_piter_dma_addr(&data_iter);
+ } else if (unlikely(mob->pt_bo == NULL)) {
+  ret = vmw_mob_pt_populate(dev_priv, mob);
+  if (unlikely(ret != 0))
+   return ret;
+
+  vmw_mob_pt_setup(mob, data_iter, num_data_pages);
+  pt_set_up = true;
+  mob->pt_level += VMW_MOBFMT_PTDEPTH_1 - SVGA3D_MOBFMT_PTDEPTH_1;
+ }
+
+ (void) vmw_3d_resource_inc(dev_priv, false);
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for Memory "
+     "Object binding.\n");
+  goto out_no_cmd_space;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_DEFINE_GB_MOB64;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.mobid = mob_id;
+ cmd->body.ptDepth = mob->pt_level;
+ cmd->body.base = cpu_to_le64(mob->pt_root_page >> PAGE_SHIFT);
+ cmd->body.sizeInBytes = num_data_pages * PAGE_SIZE;
+
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+
+ return 0;
+
+out_no_cmd_space:
+ vmw_3d_resource_dec(dev_priv, false);
+ if (pt_set_up)
+  ttm_bo_unref(&mob->pt_bo);
+
+ return -ENOMEM;
+}
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_resource.c b/drivers/gpu/drm/vmwgfx/vmwgfx_resource.c
index 9b5ea2a..9757b57 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_resource.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_resource.c
@@ -88,6 +88,11 @@ struct vmw_resource *vmw_resource_reference(struct vmw_resource *res)
  return res;
 }
 
+struct vmw_resource *
+vmw_resource_reference_unless_doomed(struct vmw_resource *res)
+{
+ return kref_get_unless_zero(&res->kref) ? res : NULL;
+}
 
 /**
  * vmw_resource_release_id - release a resource id to the id manager.
@@ -136,8 +141,12 @@ static void vmw_resource_release(struct kref *kref)
   vmw_dmabuf_unreference(&res->backup);
  }
 
- if (likely(res->hw_destroy != NULL))
+ if (likely(res->hw_destroy != NULL)) {
   res->hw_destroy(res);
+  mutex_lock(&dev_priv->binding_mutex);
+  vmw_context_binding_res_list_kill(&res->binding_head);
+  mutex_unlock(&dev_priv->binding_mutex);
+ }
 
  id = res->id;
  if (res->res_free != NULL)
@@ -215,6 +224,7 @@ int vmw_resource_init(struct vmw_private *dev_priv, struct vmw_resource *res,
  res->func = func;
  INIT_LIST_HEAD(&res->lru_head);
  INIT_LIST_HEAD(&res->mob_head);
+ INIT_LIST_HEAD(&res->binding_head);
  res->id = -1;
  res->backup = NULL;
  res->backup_offset = 0;
@@ -417,8 +427,7 @@ int vmw_dmabuf_init(struct vmw_private *dev_priv,
  INIT_LIST_HEAD(&vmw_bo->res_list);
 
  ret = ttm_bo_init(bdev, &vmw_bo->base, size,
-     (user) ? ttm_bo_type_device :
-     ttm_bo_type_kernel, placement,
+     ttm_bo_type_device, placement,
      0, interruptible,
      NULL, acc_size, NULL, bo_free);
  return ret;
@@ -441,6 +450,21 @@ static void vmw_user_dmabuf_release(struct ttm_base_object **p_base)
  ttm_bo_unref(&bo);
 }
 
+static void vmw_user_dmabuf_ref_obj_release(struct ttm_base_object *base,
+         enum ttm_ref_type ref_type)
+{
+ struct vmw_user_dma_buffer *user_bo;
+ user_bo = container_of(base, struct vmw_user_dma_buffer, prime.base);
+
+ switch (ref_type) {
+ case TTM_REF_SYNCCPU_WRITE:
+  ttm_bo_synccpu_write_release(&user_bo->dma.base);
+  break;
+ default:
+  BUG();
+ }
+}
+
 /**
  * vmw_user_dmabuf_alloc - Allocate a user dma buffer
  *
@@ -471,6 +495,8 @@ int vmw_user_dmabuf_alloc(struct vmw_private *dev_priv,
  }
 
  ret = vmw_dmabuf_init(dev_priv, &user_bo->dma, size,
+         (dev_priv->has_mob) ?
+         &vmw_sys_placement :
          &vmw_vram_sys_placement, true,
          &vmw_user_dmabuf_destroy);
  if (unlikely(ret != 0))
@@ -482,7 +508,8 @@ int vmw_user_dmabuf_alloc(struct vmw_private *dev_priv,
         &user_bo->prime,
         shareable,
         ttm_buffer_type,
-        &vmw_user_dmabuf_release, NULL);
+        &vmw_user_dmabuf_release,
+        &vmw_user_dmabuf_ref_obj_release);
  if (unlikely(ret != 0)) {
   ttm_bo_unref(&tmp);
   goto out_no_base_object;
@@ -515,6 +542,130 @@ int vmw_user_dmabuf_verify_access(struct ttm_buffer_object *bo,
   vmw_user_bo->prime.base.shareable) ? 0 : -EPERM;
 }
 
+/**
+ * vmw_user_dmabuf_synccpu_grab - Grab a struct vmw_user_dma_buffer for cpu
+ * access, idling previous GPU operations on the buffer and optionally
+ * blocking it for further command submissions.
+ *
+ * @user_bo: Pointer to the buffer object being grabbed for CPU access
+ * @tfile: Identifying the caller.
+ * @flags: Flags indicating how the grab should be performed.
+ *
+ * A blocking grab will be automatically released when @tfile is closed.
+ */
+static int vmw_user_dmabuf_synccpu_grab(struct vmw_user_dma_buffer *user_bo,
+     struct ttm_object_file *tfile,
+     uint32_t flags)
+{
+ struct ttm_buffer_object *bo = &user_bo->dma.base;
+ bool existed;
+ int ret;
+
+ if (flags & drm_vmw_synccpu_allow_cs) {
+  struct ttm_bo_device *bdev = bo->bdev;
+
+  spin_lock(&bdev->fence_lock);
+  ret = ttm_bo_wait(bo, false, true,
+      !!(flags & drm_vmw_synccpu_dontblock));
+  spin_unlock(&bdev->fence_lock);
+  return ret;
+ }
+
+ ret = ttm_bo_synccpu_write_grab
+  (bo, !!(flags & drm_vmw_synccpu_dontblock));
+ if (unlikely(ret != 0))
+  return ret;
+
+ ret = ttm_ref_object_add(tfile, &user_bo->prime.base,
+     TTM_REF_SYNCCPU_WRITE, &existed);
+ if (ret != 0 || existed)
+  ttm_bo_synccpu_write_release(&user_bo->dma.base);
+
+ return ret;
+}
+
+/**
+ * vmw_user_dmabuf_synccpu_release - Release a previous grab for CPU access,
+ * and unblock command submission on the buffer if blocked.
+ *
+ * @handle: Handle identifying the buffer object.
+ * @tfile: Identifying the caller.
+ * @flags: Flags indicating the type of release.
+ */
+static int vmw_user_dmabuf_synccpu_release(uint32_t handle,
+        struct ttm_object_file *tfile,
+        uint32_t flags)
+{
+ if (!(flags & drm_vmw_synccpu_allow_cs))
+  return ttm_ref_object_base_unref(tfile, handle,
+       TTM_REF_SYNCCPU_WRITE);
+
+ return 0;
+}
+
+/**
+ * vmw_user_dmabuf_synccpu_release - ioctl function implementing the synccpu
+ * functionality.
+ *
+ * @dev: Identifies the drm device.
+ * @data: Pointer to the ioctl argument.
+ * @file_priv: Identifies the caller.
+ *
+ * This function checks the ioctl arguments for validity and calls the
+ * relevant synccpu functions.
+ */
+int vmw_user_dmabuf_synccpu_ioctl(struct drm_device *dev, void *data,
+      struct drm_file *file_priv)
+{
+ struct drm_vmw_synccpu_arg *arg =
+  (struct drm_vmw_synccpu_arg *) data;
+ struct vmw_dma_buffer *dma_buf;
+ struct vmw_user_dma_buffer *user_bo;
+ struct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;
+ int ret;
+
+ if ((arg->flags & (drm_vmw_synccpu_read | drm_vmw_synccpu_write)) == 0
+     || (arg->flags & ~(drm_vmw_synccpu_read | drm_vmw_synccpu_write |
+          drm_vmw_synccpu_dontblock |
+          drm_vmw_synccpu_allow_cs)) != 0) {
+  DRM_ERROR("Illegal synccpu flags.\n");
+  return -EINVAL;
+ }
+
+ switch (arg->op) {
+ case drm_vmw_synccpu_grab:
+  ret = vmw_user_dmabuf_lookup(tfile, arg->handle, &dma_buf);
+  if (unlikely(ret != 0))
+   return ret;
+
+  user_bo = container_of(dma_buf, struct vmw_user_dma_buffer,
+           dma);
+  ret = vmw_user_dmabuf_synccpu_grab(user_bo, tfile, arg->flags);
+  vmw_dmabuf_unreference(&dma_buf);
+  if (unlikely(ret != 0 && ret != -ERESTARTSYS &&
+        ret != -EBUSY)) {
+   DRM_ERROR("Failed synccpu grab on handle 0x%08x.\n",
+      (unsigned int) arg->handle);
+   return ret;
+  }
+  break;
+ case drm_vmw_synccpu_release:
+  ret = vmw_user_dmabuf_synccpu_release(arg->handle, tfile,
+            arg->flags);
+  if (unlikely(ret != 0)) {
+   DRM_ERROR("Failed synccpu release on handle 0x%08x.\n",
+      (unsigned int) arg->handle);
+   return ret;
+  }
+  break;
+ default:
+  DRM_ERROR("Invalid synccpu operation.\n");
+  return -EINVAL;
+ }
+
+ return 0;
+}
+
 int vmw_dmabuf_alloc_ioctl(struct drm_device *dev, void *data,
       struct drm_file *file_priv)
 {
@@ -591,7 +742,8 @@ int vmw_user_dmabuf_lookup(struct ttm_object_file *tfile,
 }
 
 int vmw_user_dmabuf_reference(struct ttm_object_file *tfile,
-         struct vmw_dma_buffer *dma_buf)
+         struct vmw_dma_buffer *dma_buf,
+         uint32_t *handle)
 {
  struct vmw_user_dma_buffer *user_bo;
 
@@ -599,6 +751,8 @@ int vmw_user_dmabuf_reference(struct ttm_object_file *tfile,
   return -EINVAL;
 
  user_bo = container_of(dma_buf, struct vmw_user_dma_buffer, dma);
+
+ *handle = user_bo->prime.base.hash.key;
  return ttm_ref_object_add(tfile, &user_bo->prime.base,
       TTM_REF_USAGE, NULL);
 }
@@ -1291,11 +1445,54 @@ void vmw_fence_single_bo(struct ttm_buffer_object *bo,
  * @mem:            The truct ttm_mem_reg indicating to what memory
  *                  region the move is taking place.
  *
- * For now does nothing.
+ * Evicts the Guest Backed hardware resource if the backup
+ * buffer is being moved out of MOB memory.
+ * Note that this function should not race with the resource
+ * validation code as long as it accesses only members of struct
+ * resource that remain static while bo::res is !NULL and
+ * while we have @bo reserved. struct resource::backup is *not* a
+ * static member. The resource validation code will take care
+ * to set @bo::res to NULL, while having @bo reserved when the
+ * buffer is no longer bound to the resource, so @bo:res can be
+ * used to determine whether there is a need to unbind and whether
+ * it is safe to unbind.
  */
 void vmw_resource_move_notify(struct ttm_buffer_object *bo,
          struct ttm_mem_reg *mem)
 {
+ struct vmw_dma_buffer *dma_buf;
+
+ if (mem == NULL)
+  return;
+
+ if (bo->destroy != vmw_dmabuf_bo_free &&
+     bo->destroy != vmw_user_dmabuf_destroy)
+  return;
+
+ dma_buf = container_of(bo, struct vmw_dma_buffer, base);
+
+ if (mem->mem_type != VMW_PL_MOB) {
+  struct vmw_resource *res, *n;
+  struct ttm_bo_device *bdev = bo->bdev;
+  struct ttm_validate_buffer val_buf;
+
+  val_buf.bo = bo;
+
+  list_for_each_entry_safe(res, n, &dma_buf->res_list, mob_head) {
+
+   if (unlikely(res->func->unbind == NULL))
+    continue;
+
+   (void) res->func->unbind(res, true, &val_buf);
+   res->backup_dirty = true;
+   res->res_dirty = false;
+   list_del_init(&res->mob_head);
+  }
+
+  spin_lock(&bdev->fence_lock);
+  (void) ttm_bo_wait(bo, false, false, false);
+  spin_unlock(&bdev->fence_lock);
+ }
 }
 
 /**
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_shader.c b/drivers/gpu/drm/vmwgfx/vmwgfx_shader.c
new file mode 100644
index 0000000..ee38565
--- /dev/null
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_shader.c
@@ -0,0 +1,812 @@
+/**************************************************************************
+ *
+ * Copyright  2009-2012 VMware, Inc., Palo Alto, CA., USA
+ * All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDERS, AUTHORS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM,
+ * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+ * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
+ * USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ **************************************************************************/
+
+#include "vmwgfx_drv.h"
+#include "vmwgfx_resource_priv.h"
+#include "ttm/ttm_placement.h"
+
+#define VMW_COMPAT_SHADER_HT_ORDER 12
+
+struct vmw_shader {
+ struct vmw_resource res;
+ SVGA3dShaderType type;
+ uint32_t size;
+};
+
+struct vmw_user_shader {
+ struct ttm_base_object base;
+ struct vmw_shader shader;
+};
+
+/**
+ * enum vmw_compat_shader_state - Staging state for compat shaders
+ */
+enum vmw_compat_shader_state {
+ VMW_COMPAT_COMMITED,
+ VMW_COMPAT_ADD,
+ VMW_COMPAT_DEL
+};
+
+/**
+ * struct vmw_compat_shader - Metadata for compat shaders.
+ *
+ * @handle: The TTM handle of the guest backed shader.
+ * @tfile: The struct ttm_object_file the guest backed shader is registered
+ * with.
+ * @hash: Hash item for lookup.
+ * @head: List head for staging lists or the compat shader manager list.
+ * @state: Staging state.
+ *
+ * The structure is protected by the cmdbuf lock.
+ */
+struct vmw_compat_shader {
+ u32 handle;
+ struct ttm_object_file *tfile;
+ struct drm_hash_item hash;
+ struct list_head head;
+ enum vmw_compat_shader_state state;
+};
+
+/**
+ * struct vmw_compat_shader_manager - Compat shader manager.
+ *
+ * @shaders: Hash table containing staged and commited compat shaders
+ * @list: List of commited shaders.
+ * @dev_priv: Pointer to a device private structure.
+ *
+ * @shaders and @list are protected by the cmdbuf mutex for now.
+ */
+struct vmw_compat_shader_manager {
+ struct drm_open_hash shaders;
+ struct list_head list;
+ struct vmw_private *dev_priv;
+};
+
+static void vmw_user_shader_free(struct vmw_resource *res);
+static struct vmw_resource *
+vmw_user_shader_base_to_res(struct ttm_base_object *base);
+
+static int vmw_gb_shader_create(struct vmw_resource *res);
+static int vmw_gb_shader_bind(struct vmw_resource *res,
+          struct ttm_validate_buffer *val_buf);
+static int vmw_gb_shader_unbind(struct vmw_resource *res,
+     bool readback,
+     struct ttm_validate_buffer *val_buf);
+static int vmw_gb_shader_destroy(struct vmw_resource *res);
+
+static uint64_t vmw_user_shader_size;
+
+static const struct vmw_user_resource_conv user_shader_conv = {
+ .object_type = VMW_RES_SHADER,
+ .base_obj_to_res = vmw_user_shader_base_to_res,
+ .res_free = vmw_user_shader_free
+};
+
+const struct vmw_user_resource_conv *user_shader_converter =
+ &user_shader_conv;
+
+
+static const struct vmw_res_func vmw_gb_shader_func = {
+ .res_type = vmw_res_shader,
+ .needs_backup = true,
+ .may_evict = true,
+ .type_name = "guest backed shaders",
+ .backup_placement = &vmw_mob_placement,
+ .create = vmw_gb_shader_create,
+ .destroy = vmw_gb_shader_destroy,
+ .bind = vmw_gb_shader_bind,
+ .unbind = vmw_gb_shader_unbind
+};
+
+/**
+ * Shader management:
+ */
+
+static inline struct vmw_shader *
+vmw_res_to_shader(struct vmw_resource *res)
+{
+ return container_of(res, struct vmw_shader, res);
+}
+
+static void vmw_hw_shader_destroy(struct vmw_resource *res)
+{
+ (void) vmw_gb_shader_destroy(res);
+}
+
+static int vmw_gb_shader_init(struct vmw_private *dev_priv,
+         struct vmw_resource *res,
+         uint32_t size,
+         uint64_t offset,
+         SVGA3dShaderType type,
+         struct vmw_dma_buffer *byte_code,
+         void (*res_free) (struct vmw_resource *res))
+{
+ struct vmw_shader *shader = vmw_res_to_shader(res);
+ int ret;
+
+ ret = vmw_resource_init(dev_priv, res, true,
+    res_free, &vmw_gb_shader_func);
+
+
+ if (unlikely(ret != 0)) {
+  if (res_free)
+   res_free(res);
+  else
+   kfree(res);
+  return ret;
+ }
+
+ res->backup_size = size;
+ if (byte_code) {
+  res->backup = vmw_dmabuf_reference(byte_code);
+  res->backup_offset = offset;
+ }
+ shader->size = size;
+ shader->type = type;
+
+ vmw_resource_activate(res, vmw_hw_shader_destroy);
+ return 0;
+}
+
+static int vmw_gb_shader_create(struct vmw_resource *res)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct vmw_shader *shader = vmw_res_to_shader(res);
+ int ret;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDefineGBShader body;
+ } *cmd;
+
+ if (likely(res->id != -1))
+  return 0;
+
+ ret = vmw_resource_alloc_id(res);
+ if (unlikely(ret != 0)) {
+  DRM_ERROR("Failed to allocate a shader id.\n");
+  goto out_no_id;
+ }
+
+ if (unlikely(res->id >= VMWGFX_NUM_GB_SHADER)) {
+  ret = -EBUSY;
+  goto out_no_fifo;
+ }
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for shader "
+     "creation.\n");
+  ret = -ENOMEM;
+  goto out_no_fifo;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_DEFINE_GB_SHADER;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.shid = res->id;
+ cmd->body.type = shader->type;
+ cmd->body.sizeInBytes = shader->size;
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+ (void) vmw_3d_resource_inc(dev_priv, false);
+
+ return 0;
+
+out_no_fifo:
+ vmw_resource_release_id(res);
+out_no_id:
+ return ret;
+}
+
+static int vmw_gb_shader_bind(struct vmw_resource *res,
+         struct ttm_validate_buffer *val_buf)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdBindGBShader body;
+ } *cmd;
+ struct ttm_buffer_object *bo = val_buf->bo;
+
+ BUG_ON(bo->mem.mem_type != VMW_PL_MOB);
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for shader "
+     "binding.\n");
+  return -ENOMEM;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_BIND_GB_SHADER;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.shid = res->id;
+ cmd->body.mobid = bo->mem.start;
+ cmd->body.offsetInBytes = 0;
+ res->backup_dirty = false;
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+
+ return 0;
+}
+
+static int vmw_gb_shader_unbind(struct vmw_resource *res,
+    bool readback,
+    struct ttm_validate_buffer *val_buf)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdBindGBShader body;
+ } *cmd;
+ struct vmw_fence_obj *fence;
+
+ BUG_ON(res->backup->base.mem.mem_type != VMW_PL_MOB);
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for shader "
+     "unbinding.\n");
+  return -ENOMEM;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_BIND_GB_SHADER;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.shid = res->id;
+ cmd->body.mobid = SVGA3D_INVALID_ID;
+ cmd->body.offsetInBytes = 0;
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+
+ /*
+  * Create a fence object and fence the backup buffer.
+  */
+
+ (void) vmw_execbuf_fence_commands(NULL, dev_priv,
+       &fence, NULL);
+
+ vmw_fence_single_bo(val_buf->bo, fence);
+
+ if (likely(fence != NULL))
+  vmw_fence_obj_unreference(&fence);
+
+ return 0;
+}
+
+static int vmw_gb_shader_destroy(struct vmw_resource *res)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDestroyGBShader body;
+ } *cmd;
+
+ if (likely(res->id == -1))
+  return 0;
+
+ mutex_lock(&dev_priv->binding_mutex);
+ vmw_context_binding_res_list_scrub(&res->binding_head);
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for shader "
+     "destruction.\n");
+  mutex_unlock(&dev_priv->binding_mutex);
+  return -ENOMEM;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_DESTROY_GB_SHADER;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.shid = res->id;
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+ mutex_unlock(&dev_priv->binding_mutex);
+ vmw_resource_release_id(res);
+ vmw_3d_resource_dec(dev_priv, false);
+
+ return 0;
+}
+
+/**
+ * User-space shader management:
+ */
+
+static struct vmw_resource *
+vmw_user_shader_base_to_res(struct ttm_base_object *base)
+{
+ return &(container_of(base, struct vmw_user_shader, base)->
+   shader.res);
+}
+
+static void vmw_user_shader_free(struct vmw_resource *res)
+{
+ struct vmw_user_shader *ushader =
+  container_of(res, struct vmw_user_shader, shader.res);
+ struct vmw_private *dev_priv = res->dev_priv;
+
+ ttm_base_object_kfree(ushader, base);
+ ttm_mem_global_free(vmw_mem_glob(dev_priv),
+       vmw_user_shader_size);
+}
+
+/**
+ * This function is called when user space has no more references on the
+ * base object. It releases the base-object's reference on the resource object.
+ */
+
+static void vmw_user_shader_base_release(struct ttm_base_object **p_base)
+{
+ struct ttm_base_object *base = *p_base;
+ struct vmw_resource *res = vmw_user_shader_base_to_res(base);
+
+ *p_base = NULL;
+ vmw_resource_unreference(&res);
+}
+
+int vmw_shader_destroy_ioctl(struct drm_device *dev, void *data,
+         struct drm_file *file_priv)
+{
+ struct drm_vmw_shader_arg *arg = (struct drm_vmw_shader_arg *)data;
+ struct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;
+
+ return ttm_ref_object_base_unref(tfile, arg->handle,
+      TTM_REF_USAGE);
+}
+
+static int vmw_shader_alloc(struct vmw_private *dev_priv,
+       struct vmw_dma_buffer *buffer,
+       size_t shader_size,
+       size_t offset,
+       SVGA3dShaderType shader_type,
+       struct ttm_object_file *tfile,
+       u32 *handle)
+{
+ struct vmw_user_shader *ushader;
+ struct vmw_resource *res, *tmp;
+ int ret;
+
+ /*
+  * Approximate idr memory usage with 128 bytes. It will be limited
+  * by maximum number_of shaders anyway.
+  */
+ if (unlikely(vmw_user_shader_size == 0))
+  vmw_user_shader_size =
+   ttm_round_pot(sizeof(struct vmw_user_shader)) + 128;
+
+ ret = ttm_mem_global_alloc(vmw_mem_glob(dev_priv),
+       vmw_user_shader_size,
+       false, true);
+ if (unlikely(ret != 0)) {
+  if (ret != -ERESTARTSYS)
+   DRM_ERROR("Out of graphics memory for shader "
+      "creation.\n");
+  goto out;
+ }
+
+ ushader = kzalloc(sizeof(*ushader), GFP_KERNEL);
+ if (unlikely(ushader == NULL)) {
+  ttm_mem_global_free(vmw_mem_glob(dev_priv),
+        vmw_user_shader_size);
+  ret = -ENOMEM;
+  goto out;
+ }
+
+ res = &ushader->shader.res;
+ ushader->base.shareable = false;
+ ushader->base.tfile = NULL;
+
+ /*
+  * From here on, the destructor takes over resource freeing.
+  */
+
+ ret = vmw_gb_shader_init(dev_priv, res, shader_size,
+     offset, shader_type, buffer,
+     vmw_user_shader_free);
+ if (unlikely(ret != 0))
+  goto out;
+
+ tmp = vmw_resource_reference(res);
+ ret = ttm_base_object_init(tfile, &ushader->base, false,
+       VMW_RES_SHADER,
+       &vmw_user_shader_base_release, NULL);
+
+ if (unlikely(ret != 0)) {
+  vmw_resource_unreference(&tmp);
+  goto out_err;
+ }
+
+ if (handle)
+  *handle = ushader->base.hash.key;
+out_err:
+ vmw_resource_unreference(&res);
+out:
+ return ret;
+}
+
+
+int vmw_shader_define_ioctl(struct drm_device *dev, void *data,
+        struct drm_file *file_priv)
+{
+ struct vmw_private *dev_priv = vmw_priv(dev);
+ struct drm_vmw_shader_create_arg *arg =
+  (struct drm_vmw_shader_create_arg *)data;
+ struct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;
+ struct vmw_master *vmaster = vmw_master(file_priv->master);
+ struct vmw_dma_buffer *buffer = NULL;
+ SVGA3dShaderType shader_type;
+ int ret;
+
+ if (arg->buffer_handle != SVGA3D_INVALID_ID) {
+  ret = vmw_user_dmabuf_lookup(tfile, arg->buffer_handle,
+          &buffer);
+  if (unlikely(ret != 0)) {
+   DRM_ERROR("Could not find buffer for shader "
+      "creation.\n");
+   return ret;
+  }
+
+  if ((u64)buffer->base.num_pages * PAGE_SIZE <
+      (u64)arg->size + (u64)arg->offset) {
+   DRM_ERROR("Illegal buffer- or shader size.\n");
+   ret = -EINVAL;
+   goto out_bad_arg;
+  }
+ }
+
+ switch (arg->shader_type) {
+ case drm_vmw_shader_type_vs:
+  shader_type = SVGA3D_SHADERTYPE_VS;
+  break;
+ case drm_vmw_shader_type_ps:
+  shader_type = SVGA3D_SHADERTYPE_PS;
+  break;
+ case drm_vmw_shader_type_gs:
+  shader_type = SVGA3D_SHADERTYPE_GS;
+  break;
+ default:
+  DRM_ERROR("Illegal shader type.\n");
+  ret = -EINVAL;
+  goto out_bad_arg;
+ }
+
+ ret = ttm_read_lock(&vmaster->lock, true);
+ if (unlikely(ret != 0))
+  goto out_bad_arg;
+
+ ret = vmw_shader_alloc(dev_priv, buffer, arg->size, arg->offset,
+          shader_type, tfile, &arg->shader_handle);
+
+ ttm_read_unlock(&vmaster->lock);
+out_bad_arg:
+ vmw_dmabuf_unreference(&buffer);
+ return ret;
+}
+
+/**
+ * vmw_compat_shader_lookup - Look up a compat shader
+ *
+ * @man: Pointer to the compat shader manager.
+ * @shader_type: The shader type, that combined with the user_key identifies
+ * the shader.
+ * @user_key: On entry, this should be a pointer to the user_key.
+ * On successful exit, it will contain the guest-backed shader's TTM handle.
+ *
+ * Returns 0 on success. Non-zero on failure, in which case the value pointed
+ * to by @user_key is unmodified.
+ */
+int vmw_compat_shader_lookup(struct vmw_compat_shader_manager *man,
+        SVGA3dShaderType shader_type,
+        u32 *user_key)
+{
+ struct drm_hash_item *hash;
+ int ret;
+ unsigned long key = *user_key | (shader_type << 24);
+
+ ret = drm_ht_find_item(&man->shaders, key, &hash);
+ if (unlikely(ret != 0))
+  return ret;
+
+ *user_key = drm_hash_entry(hash, struct vmw_compat_shader,
+       hash)->handle;
+
+ return 0;
+}
+
+/**
+ * vmw_compat_shader_free - Free a compat shader.
+ *
+ * @man: Pointer to the compat shader manager.
+ * @entry: Pointer to a struct vmw_compat_shader.
+ *
+ * Frees a struct vmw_compat_shder entry and drops its reference to the
+ * guest backed shader.
+ */
+static void vmw_compat_shader_free(struct vmw_compat_shader_manager *man,
+       struct vmw_compat_shader *entry)
+{
+ list_del(&entry->head);
+ WARN_ON(drm_ht_remove_item(&man->shaders, &entry->hash));
+ WARN_ON(ttm_ref_object_base_unref(entry->tfile, entry->handle,
+       TTM_REF_USAGE));
+ kfree(entry);
+}
+
+/**
+ * vmw_compat_shaders_commit - Commit a list of compat shader actions.
+ *
+ * @man: Pointer to the compat shader manager.
+ * @list: Caller's list of compat shader actions.
+ *
+ * This function commits a list of compat shader additions or removals.
+ * It is typically called when the execbuf ioctl call triggering these
+ * actions has commited the fifo contents to the device.
+ */
+void vmw_compat_shaders_commit(struct vmw_compat_shader_manager *man,
+          struct list_head *list)
+{
+ struct vmw_compat_shader *entry, *next;
+
+ list_for_each_entry_safe(entry, next, list, head) {
+  list_del(&entry->head);
+  switch (entry->state) {
+  case VMW_COMPAT_ADD:
+   entry->state = VMW_COMPAT_COMMITED;
+   list_add_tail(&entry->head, &man->list);
+   break;
+  case VMW_COMPAT_DEL:
+   ttm_ref_object_base_unref(entry->tfile, entry->handle,
+        TTM_REF_USAGE);
+   kfree(entry);
+   break;
+  default:
+   BUG();
+   break;
+  }
+ }
+}
+
+/**
+ * vmw_compat_shaders_revert - Revert a list of compat shader actions
+ *
+ * @man: Pointer to the compat shader manager.
+ * @list: Caller's list of compat shader actions.
+ *
+ * This function reverts a list of compat shader additions or removals.
+ * It is typically called when the execbuf ioctl call triggering these
+ * actions failed for some reason, and the command stream was never
+ * submitted.
+ */
+void vmw_compat_shaders_revert(struct vmw_compat_shader_manager *man,
+          struct list_head *list)
+{
+ struct vmw_compat_shader *entry, *next;
+ int ret;
+
+ list_for_each_entry_safe(entry, next, list, head) {
+  switch (entry->state) {
+  case VMW_COMPAT_ADD:
+   vmw_compat_shader_free(man, entry);
+   break;
+  case VMW_COMPAT_DEL:
+   ret = drm_ht_insert_item(&man->shaders, &entry->hash);
+   list_del(&entry->head);
+   list_add_tail(&entry->head, &man->list);
+   entry->state = VMW_COMPAT_COMMITED;
+   break;
+  default:
+   BUG();
+   break;
+  }
+ }
+}
+
+/**
+ * vmw_compat_shader_remove - Stage a compat shader for removal.
+ *
+ * @man: Pointer to the compat shader manager
+ * @user_key: The key that is used to identify the shader. The key is
+ * unique to the shader type.
+ * @shader_type: Shader type.
+ * @list: Caller's list of staged shader actions.
+ *
+ * This function stages a compat shader for removal and removes the key from
+ * the shader manager's hash table. If the shader was previously only staged
+ * for addition it is completely removed (But the execbuf code may keep a
+ * reference if it was bound to a context between addition and removal). If
+ * it was previously commited to the manager, it is staged for removal.
+ */
+int vmw_compat_shader_remove(struct vmw_compat_shader_manager *man,
+        u32 user_key, SVGA3dShaderType shader_type,
+        struct list_head *list)
+{
+ struct vmw_compat_shader *entry;
+ struct drm_hash_item *hash;
+ int ret;
+
+ ret = drm_ht_find_item(&man->shaders, user_key | (shader_type << 24),
+          &hash);
+ if (likely(ret != 0))
+  return -EINVAL;
+
+ entry = drm_hash_entry(hash, struct vmw_compat_shader, hash);
+
+ switch (entry->state) {
+ case VMW_COMPAT_ADD:
+  vmw_compat_shader_free(man, entry);
+  break;
+ case VMW_COMPAT_COMMITED:
+  (void) drm_ht_remove_item(&man->shaders, &entry->hash);
+  list_del(&entry->head);
+  entry->state = VMW_COMPAT_DEL;
+  list_add_tail(&entry->head, list);
+  break;
+ default:
+  BUG();
+  break;
+ }
+
+ return 0;
+}
+
+/**
+ * vmw_compat_shader_add - Create a compat shader and add the
+ * key to the manager
+ *
+ * @man: Pointer to the compat shader manager
+ * @user_key: The key that is used to identify the shader. The key is
+ * unique to the shader type.
+ * @bytecode: Pointer to the bytecode of the shader.
+ * @shader_type: Shader type.
+ * @tfile: Pointer to a struct ttm_object_file that the guest-backed shader is
+ * to be created with.
+ * @list: Caller's list of staged shader actions.
+ *
+ * Note that only the key is added to the shader manager's hash table.
+ * The shader is not yet added to the shader manager's list of shaders.
+ */
+int vmw_compat_shader_add(struct vmw_compat_shader_manager *man,
+     u32 user_key, const void *bytecode,
+     SVGA3dShaderType shader_type,
+     size_t size,
+     struct ttm_object_file *tfile,
+     struct list_head *list)
+{
+ struct vmw_dma_buffer *buf;
+ struct ttm_bo_kmap_obj map;
+ bool is_iomem;
+ struct vmw_compat_shader *compat;
+ u32 handle;
+ int ret;
+
+ if (user_key > ((1 << 24) - 1) || (unsigned) shader_type > 16)
+  return -EINVAL;
+
+ /* Allocate and pin a DMA buffer */
+ buf = kzalloc(sizeof(*buf), GFP_KERNEL);
+ if (unlikely(buf == NULL))
+  return -ENOMEM;
+
+ ret = vmw_dmabuf_init(man->dev_priv, buf, size, &vmw_sys_ne_placement,
+         true, vmw_dmabuf_bo_free);
+ if (unlikely(ret != 0))
+  goto out;
+
+ ret = ttm_bo_reserve(&buf->base, false, true, false, NULL);
+ if (unlikely(ret != 0))
+  goto no_reserve;
+
+ /* Map and copy shader bytecode. */
+ ret = ttm_bo_kmap(&buf->base, 0, PAGE_ALIGN(size) >> PAGE_SHIFT,
+     &map);
+ if (unlikely(ret != 0)) {
+  ttm_bo_unreserve(&buf->base);
+  goto no_reserve;
+ }
+
+ memcpy(ttm_kmap_obj_virtual(&map, &is_iomem), bytecode, size);
+ WARN_ON(is_iomem);
+
+ ttm_bo_kunmap(&map);
+ ret = ttm_bo_validate(&buf->base, &vmw_sys_placement, false, true);
+ WARN_ON(ret != 0);
+ ttm_bo_unreserve(&buf->base);
+
+ /* Create a guest-backed shader container backed by the dma buffer */
+ ret = vmw_shader_alloc(man->dev_priv, buf, size, 0, shader_type,
+          tfile, &handle);
+ vmw_dmabuf_unreference(&buf);
+ if (unlikely(ret != 0))
+  goto no_reserve;
+ /*
+  * Create a compat shader structure and stage it for insertion
+  * in the manager
+  */
+ compat = kzalloc(sizeof(*compat), GFP_KERNEL);
+ if (compat == NULL)
+  goto no_compat;
+
+ compat->hash.key = user_key |  (shader_type << 24);
+ ret = drm_ht_insert_item(&man->shaders, &compat->hash);
+ if (unlikely(ret != 0))
+  goto out_invalid_key;
+
+ compat->state = VMW_COMPAT_ADD;
+ compat->handle = handle;
+ compat->tfile = tfile;
+ list_add_tail(&compat->head, list);
+
+ return 0;
+
+out_invalid_key:
+ kfree(compat);
+no_compat:
+ ttm_ref_object_base_unref(tfile, handle, TTM_REF_USAGE);
+no_reserve:
+out:
+ return ret;
+}
+
+/**
+ * vmw_compat_shader_man_create - Create a compat shader manager
+ *
+ * @dev_priv: Pointer to a device private structure.
+ *
+ * Typically done at file open time. If successful returns a pointer to a
+ * compat shader manager. Otherwise returns an error pointer.
+ */
+struct vmw_compat_shader_manager *
+vmw_compat_shader_man_create(struct vmw_private *dev_priv)
+{
+ struct vmw_compat_shader_manager *man;
+ int ret;
+
+ man = kzalloc(sizeof(*man), GFP_KERNEL);
+ if (man == NULL)
+  return ERR_PTR(-ENOMEM);
+
+ man->dev_priv = dev_priv;
+ INIT_LIST_HEAD(&man->list);
+ ret = drm_ht_create(&man->shaders, VMW_COMPAT_SHADER_HT_ORDER);
+ if (ret == 0)
+  return man;
+
+ kfree(man);
+ return ERR_PTR(ret);
+}
+
+/**
+ * vmw_compat_shader_man_destroy - Destroy a compat shader manager
+ *
+ * @man: Pointer to the shader manager to destroy.
+ *
+ * Typically done at file close time.
+ */
+void vmw_compat_shader_man_destroy(struct vmw_compat_shader_manager *man)
+{
+ struct vmw_compat_shader *entry, *next;
+
+ mutex_lock(&man->dev_priv->cmdbuf_mutex);
+ list_for_each_entry_safe(entry, next, &man->list, head)
+  vmw_compat_shader_free(man, entry);
+
+ mutex_unlock(&man->dev_priv->cmdbuf_mutex);
+ kfree(man);
+}
diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c
index 7de2ea8..e7af580 100644
--- a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c
+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c
@@ -41,7 +41,6 @@ struct vmw_user_surface {
  struct ttm_prime_object prime;
  struct vmw_surface srf;
  uint32_t size;
- uint32_t backup_handle;
 };
 
 /**
@@ -68,6 +67,14 @@ static int vmw_legacy_srf_unbind(struct vmw_resource *res,
      struct ttm_validate_buffer *val_buf);
 static int vmw_legacy_srf_create(struct vmw_resource *res);
 static int vmw_legacy_srf_destroy(struct vmw_resource *res);
+static int vmw_gb_surface_create(struct vmw_resource *res);
+static int vmw_gb_surface_bind(struct vmw_resource *res,
+          struct ttm_validate_buffer *val_buf);
+static int vmw_gb_surface_unbind(struct vmw_resource *res,
+     bool readback,
+     struct ttm_validate_buffer *val_buf);
+static int vmw_gb_surface_destroy(struct vmw_resource *res);
+
 
 static const struct vmw_user_resource_conv user_surface_conv = {
  .object_type = VMW_RES_SURFACE,
@@ -93,6 +100,18 @@ static const struct vmw_res_func vmw_legacy_surface_func = {
  .unbind = &vmw_legacy_srf_unbind
 };
 
+static const struct vmw_res_func vmw_gb_surface_func = {
+ .res_type = vmw_res_surface,
+ .needs_backup = true,
+ .may_evict = true,
+ .type_name = "guest backed surfaces",
+ .backup_placement = &vmw_mob_placement,
+ .create = vmw_gb_surface_create,
+ .destroy = vmw_gb_surface_destroy,
+ .bind = vmw_gb_surface_bind,
+ .unbind = vmw_gb_surface_unbind
+};
+
 /**
  * struct vmw_surface_dma - SVGA3D DMA command
  */
@@ -291,6 +310,11 @@ static void vmw_hw_surface_destroy(struct vmw_resource *res)
  struct vmw_surface *srf;
  void *cmd;
 
+ if (res->func->destroy == vmw_gb_surface_destroy) {
+  (void) vmw_gb_surface_destroy(res);
+  return;
+ }
+
  if (res->id != -1) {
 
   cmd = vmw_fifo_reserve(dev_priv, vmw_surface_destroy_size());
@@ -549,12 +573,15 @@ static int vmw_surface_init(struct vmw_private *dev_priv,
  struct vmw_resource *res = &srf->res;
 
  BUG_ON(res_free == NULL);
- (void) vmw_3d_resource_inc(dev_priv, false);
+ if (!dev_priv->has_mob)
+  (void) vmw_3d_resource_inc(dev_priv, false);
  ret = vmw_resource_init(dev_priv, res, true, res_free,
+    (dev_priv->has_mob) ? &vmw_gb_surface_func :
     &vmw_legacy_surface_func);
 
  if (unlikely(ret != 0)) {
-  vmw_3d_resource_dec(dev_priv, false);
+  if (!dev_priv->has_mob)
+   vmw_3d_resource_dec(dev_priv, false);
   res_free(res);
   return ret;
  }
@@ -750,7 +777,7 @@ int vmw_surface_define_ioctl(struct drm_device *dev, void *data,
 
  srf->base_size = *srf->sizes;
  srf->autogen_filter = SVGA3D_TEX_FILTER_NONE;
- srf->multisample_count = 1;
+ srf->multisample_count = 0;
 
  cur_bo_offset = 0;
  cur_offset = srf->offsets;
@@ -803,6 +830,24 @@ int vmw_surface_define_ioctl(struct drm_device *dev, void *data,
  if (unlikely(ret != 0))
   goto out_unlock;
 
+ /*
+  * A gb-aware client referencing a shared surface will
+  * expect a backup buffer to be present.
+  */
+ if (dev_priv->has_mob && req->shareable) {
+  uint32_t backup_handle;
+
+  ret = vmw_user_dmabuf_alloc(dev_priv, tfile,
+         res->backup_size,
+         true,
+         &backup_handle,
+         &res->backup);
+  if (unlikely(ret != 0)) {
+   vmw_resource_unreference(&res);
+   goto out_unlock;
+  }
+ }
+
  tmp = vmw_resource_reference(&srf->res);
  ret = ttm_prime_object_init(tfile, res->backup_size, &user_srf->prime,
         req->shareable, VMW_RES_SURFACE,
@@ -843,6 +888,7 @@ out_unlock:
 int vmw_surface_reference_ioctl(struct drm_device *dev, void *data,
     struct drm_file *file_priv)
 {
+ struct vmw_private *dev_priv = vmw_priv(dev);
  union drm_vmw_surface_reference_arg *arg =
      (union drm_vmw_surface_reference_arg *)data;
  struct drm_vmw_surface_arg *req = &arg->req;
@@ -854,7 +900,7 @@ int vmw_surface_reference_ioctl(struct drm_device *dev, void *data,
  struct ttm_base_object *base;
  int ret = -EINVAL;
 
- base = ttm_base_object_lookup(tfile, req->sid);
+ base = ttm_base_object_lookup_for_ref(dev_priv->tdev, req->sid);
  if (unlikely(base == NULL)) {
   DRM_ERROR("Could not find surface to reference.\n");
   return -EINVAL;
@@ -880,8 +926,8 @@ int vmw_surface_reference_ioctl(struct drm_device *dev, void *data,
      rep->size_addr;
 
  if (user_sizes)
-  ret = copy_to_user(user_sizes, srf->sizes,
-       srf->num_sizes * sizeof(*srf->sizes));
+  ret = copy_to_user(user_sizes, &srf->base_size,
+       sizeof(srf->base_size));
  if (unlikely(ret != 0)) {
   DRM_ERROR("copy_to_user failed %p %u\n",
      user_sizes, srf->num_sizes);
@@ -893,3 +939,436 @@ out_no_reference:
 
  return ret;
 }
+
+/**
+ * vmw_surface_define_encode - Encode a surface_define command.
+ *
+ * @srf: Pointer to a struct vmw_surface object.
+ * @cmd_space: Pointer to memory area in which the commands should be encoded.
+ */
+static int vmw_gb_surface_create(struct vmw_resource *res)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct vmw_surface *srf = vmw_res_to_srf(res);
+ uint32_t cmd_len, submit_len;
+ int ret;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDefineGBSurface body;
+ } *cmd;
+
+ if (likely(res->id != -1))
+  return 0;
+
+ (void) vmw_3d_resource_inc(dev_priv, false);
+ ret = vmw_resource_alloc_id(res);
+ if (unlikely(ret != 0)) {
+  DRM_ERROR("Failed to allocate a surface id.\n");
+  goto out_no_id;
+ }
+
+ if (unlikely(res->id >= VMWGFX_NUM_GB_SURFACE)) {
+  ret = -EBUSY;
+  goto out_no_fifo;
+ }
+
+ cmd_len = sizeof(cmd->body);
+ submit_len = sizeof(*cmd);
+ cmd = vmw_fifo_reserve(dev_priv, submit_len);
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for surface "
+     "creation.\n");
+  ret = -ENOMEM;
+  goto out_no_fifo;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_DEFINE_GB_SURFACE;
+ cmd->header.size = cmd_len;
+ cmd->body.sid = srf->res.id;
+ cmd->body.surfaceFlags = srf->flags;
+ cmd->body.format = cpu_to_le32(srf->format);
+ cmd->body.numMipLevels = srf->mip_levels[0];
+ cmd->body.multisampleCount = srf->multisample_count;
+ cmd->body.autogenFilter = srf->autogen_filter;
+ cmd->body.size.width = srf->base_size.width;
+ cmd->body.size.height = srf->base_size.height;
+ cmd->body.size.depth = srf->base_size.depth;
+ vmw_fifo_commit(dev_priv, submit_len);
+
+ return 0;
+
+out_no_fifo:
+ vmw_resource_release_id(res);
+out_no_id:
+ vmw_3d_resource_dec(dev_priv, false);
+ return ret;
+}
+
+
+static int vmw_gb_surface_bind(struct vmw_resource *res,
+          struct ttm_validate_buffer *val_buf)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdBindGBSurface body;
+ } *cmd1;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdUpdateGBSurface body;
+ } *cmd2;
+ uint32_t submit_size;
+ struct ttm_buffer_object *bo = val_buf->bo;
+
+ BUG_ON(bo->mem.mem_type != VMW_PL_MOB);
+
+ submit_size = sizeof(*cmd1) + (res->backup_dirty ? sizeof(*cmd2) : 0);
+
+ cmd1 = vmw_fifo_reserve(dev_priv, submit_size);
+ if (unlikely(cmd1 == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for surface "
+     "binding.\n");
+  return -ENOMEM;
+ }
+
+ cmd1->header.id = SVGA_3D_CMD_BIND_GB_SURFACE;
+ cmd1->header.size = sizeof(cmd1->body);
+ cmd1->body.sid = res->id;
+ cmd1->body.mobid = bo->mem.start;
+ if (res->backup_dirty) {
+  cmd2 = (void *) &cmd1[1];
+  cmd2->header.id = SVGA_3D_CMD_UPDATE_GB_SURFACE;
+  cmd2->header.size = sizeof(cmd2->body);
+  cmd2->body.sid = res->id;
+  res->backup_dirty = false;
+ }
+ vmw_fifo_commit(dev_priv, submit_size);
+
+ return 0;
+}
+
+static int vmw_gb_surface_unbind(struct vmw_resource *res,
+     bool readback,
+     struct ttm_validate_buffer *val_buf)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct ttm_buffer_object *bo = val_buf->bo;
+ struct vmw_fence_obj *fence;
+
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdReadbackGBSurface body;
+ } *cmd1;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdInvalidateGBSurface body;
+ } *cmd2;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdBindGBSurface body;
+ } *cmd3;
+ uint32_t submit_size;
+ uint8_t *cmd;
+
+
+ BUG_ON(bo->mem.mem_type != VMW_PL_MOB);
+
+ submit_size = sizeof(*cmd3) + (readback ? sizeof(*cmd1) : sizeof(*cmd2));
+ cmd = vmw_fifo_reserve(dev_priv, submit_size);
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for surface "
+     "unbinding.\n");
+  return -ENOMEM;
+ }
+
+ if (readback) {
+  cmd1 = (void *) cmd;
+  cmd1->header.id = SVGA_3D_CMD_READBACK_GB_SURFACE;
+  cmd1->header.size = sizeof(cmd1->body);
+  cmd1->body.sid = res->id;
+  cmd3 = (void *) &cmd1[1];
+ } else {
+  cmd2 = (void *) cmd;
+  cmd2->header.id = SVGA_3D_CMD_INVALIDATE_GB_SURFACE;
+  cmd2->header.size = sizeof(cmd2->body);
+  cmd2->body.sid = res->id;
+  cmd3 = (void *) &cmd2[1];
+ }
+
+ cmd3->header.id = SVGA_3D_CMD_BIND_GB_SURFACE;
+ cmd3->header.size = sizeof(cmd3->body);
+ cmd3->body.sid = res->id;
+ cmd3->body.mobid = SVGA3D_INVALID_ID;
+
+ vmw_fifo_commit(dev_priv, submit_size);
+
+ /*
+  * Create a fence object and fence the backup buffer.
+  */
+
+ (void) vmw_execbuf_fence_commands(NULL, dev_priv,
+       &fence, NULL);
+
+ vmw_fence_single_bo(val_buf->bo, fence);
+
+ if (likely(fence != NULL))
+  vmw_fence_obj_unreference(&fence);
+
+ return 0;
+}
+
+static int vmw_gb_surface_destroy(struct vmw_resource *res)
+{
+ struct vmw_private *dev_priv = res->dev_priv;
+ struct {
+  SVGA3dCmdHeader header;
+  SVGA3dCmdDestroyGBSurface body;
+ } *cmd;
+
+ if (likely(res->id == -1))
+  return 0;
+
+ mutex_lock(&dev_priv->binding_mutex);
+ vmw_context_binding_res_list_scrub(&res->binding_head);
+
+ cmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));
+ if (unlikely(cmd == NULL)) {
+  DRM_ERROR("Failed reserving FIFO space for surface "
+     "destruction.\n");
+  mutex_unlock(&dev_priv->binding_mutex);
+  return -ENOMEM;
+ }
+
+ cmd->header.id = SVGA_3D_CMD_DESTROY_GB_SURFACE;
+ cmd->header.size = sizeof(cmd->body);
+ cmd->body.sid = res->id;
+ vmw_fifo_commit(dev_priv, sizeof(*cmd));
+ mutex_unlock(&dev_priv->binding_mutex);
+ vmw_resource_release_id(res);
+ vmw_3d_resource_dec(dev_priv, false);
+
+ return 0;
+}
+
+/**
+ * vmw_gb_surface_define_ioctl - Ioctl function implementing
+ *                               the user surface define functionality.
+ *
+ * @dev:            Pointer to a struct drm_device.
+ * @data:           Pointer to data copied from / to user-space.
+ * @file_priv:      Pointer to a drm file private structure.
+ */
+int vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,
+    struct drm_file *file_priv)
+{
+ struct vmw_private *dev_priv = vmw_priv(dev);
+ struct vmw_user_surface *user_srf;
+ struct vmw_surface *srf;
+ struct vmw_resource *res;
+ struct vmw_resource *tmp;
+ union drm_vmw_gb_surface_create_arg *arg =
+     (union drm_vmw_gb_surface_create_arg *)data;
+ struct drm_vmw_gb_surface_create_req *req = &arg->req;
+ struct drm_vmw_gb_surface_create_rep *rep = &arg->rep;
+ struct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;
+ int ret;
+ uint32_t size;
+ struct vmw_master *vmaster = vmw_master(file_priv->master);
+ const struct svga3d_surface_desc *desc;
+ uint32_t backup_handle;
+
+ if (unlikely(vmw_user_surface_size == 0))
+  vmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +
+   128;
+
+ size = vmw_user_surface_size + 128;
+
+ desc = svga3dsurface_get_desc(req->format);
+ if (unlikely(desc->block_desc == SVGA3DBLOCKDESC_NONE)) {
+  DRM_ERROR("Invalid surface format for surface creation.\n");
+  return -EINVAL;
+ }
+
+ ret = ttm_read_lock(&vmaster->lock, true);
+ if (unlikely(ret != 0))
+  return ret;
+
+ ret = ttm_mem_global_alloc(vmw_mem_glob(dev_priv),
+       size, false, true);
+ if (unlikely(ret != 0)) {
+  if (ret != -ERESTARTSYS)
+   DRM_ERROR("Out of graphics memory for surface"
+      " creation.\n");
+  goto out_unlock;
+ }
+
+ user_srf = kzalloc(sizeof(*user_srf), GFP_KERNEL);
+ if (unlikely(user_srf == NULL)) {
+  ret = -ENOMEM;
+  goto out_no_user_srf;
+ }
+
+ srf = &user_srf->srf;
+ res = &srf->res;
+
+ srf->flags = req->svga3d_flags;
+ srf->format = req->format;
+ srf->scanout = req->drm_surface_flags & drm_vmw_surface_flag_scanout;
+ srf->mip_levels[0] = req->mip_levels;
+ srf->num_sizes = 1;
+ srf->sizes = NULL;
+ srf->offsets = NULL;
+ user_srf->size = size;
+ srf->base_size = req->base_size;
+ srf->autogen_filter = SVGA3D_TEX_FILTER_NONE;
+ srf->multisample_count = req->multisample_count;
+ res->backup_size = svga3dsurface_get_serialized_size
+   (srf->format, srf->base_size, srf->mip_levels[0],
+    srf->flags & SVGA3D_SURFACE_CUBEMAP);
+
+ user_srf->prime.base.shareable = false;
+ user_srf->prime.base.tfile = NULL;
+
+ /**
+  * From this point, the generic resource management functions
+  * destroy the object on failure.
+  */
+
+ ret = vmw_surface_init(dev_priv, srf, vmw_user_surface_free);
+ if (unlikely(ret != 0))
+  goto out_unlock;
+
+ if (req->buffer_handle != SVGA3D_INVALID_ID) {
+  ret = vmw_user_dmabuf_lookup(tfile, req->buffer_handle,
+          &res->backup);
+ } else if (req->drm_surface_flags &
+     drm_vmw_surface_flag_create_buffer)
+  ret = vmw_user_dmabuf_alloc(dev_priv, tfile,
+         res->backup_size,
+         req->drm_surface_flags &
+         drm_vmw_surface_flag_shareable,
+         &backup_handle,
+         &res->backup);
+
+ if (unlikely(ret != 0)) {
+  vmw_resource_unreference(&res);
+  goto out_unlock;
+ }
+
+ tmp = vmw_resource_reference(&srf->res);
+ ret = ttm_prime_object_init(tfile, res->backup_size, &user_srf->prime,
+        req->drm_surface_flags &
+        drm_vmw_surface_flag_shareable,
+        VMW_RES_SURFACE,
+        &vmw_user_surface_base_release, NULL);
+
+ if (unlikely(ret != 0)) {
+  vmw_resource_unreference(&tmp);
+  vmw_resource_unreference(&res);
+  goto out_unlock;
+ }
+
+ rep->handle = user_srf->prime.base.hash.key;
+ rep->backup_size = res->backup_size;
+ if (res->backup) {
+  rep->buffer_map_handle =
+   drm_vma_node_offset_addr(&res->backup->base.vma_node);
+  rep->buffer_size = res->backup->base.num_pages * PAGE_SIZE;
+  rep->buffer_handle = backup_handle;
+ } else {
+  rep->buffer_map_handle = 0;
+  rep->buffer_size = 0;
+  rep->buffer_handle = SVGA3D_INVALID_ID;
+ }
+
+ vmw_resource_unreference(&res);
+
+ ttm_read_unlock(&vmaster->lock);
+ return 0;
+out_no_user_srf:
+ ttm_mem_global_free(vmw_mem_glob(dev_priv), size);
+out_unlock:
+ ttm_read_unlock(&vmaster->lock);
+ return ret;
+}
+
+/**
+ * vmw_gb_surface_reference_ioctl - Ioctl function implementing
+ *                                  the user surface reference functionality.
+ *
+ * @dev:            Pointer to a struct drm_device.
+ * @data:           Pointer to data copied from / to user-space.
+ * @file_priv:      Pointer to a drm file private structure.
+ */
+int vmw_gb_surface_reference_ioctl(struct drm_device *dev, void *data,
+       struct drm_file *file_priv)
+{
+ struct vmw_private *dev_priv = vmw_priv(dev);
+ union drm_vmw_gb_surface_reference_arg *arg =
+     (union drm_vmw_gb_surface_reference_arg *)data;
+ struct drm_vmw_surface_arg *req = &arg->req;
+ struct drm_vmw_gb_surface_ref_rep *rep = &arg->rep;
+ struct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;
+ struct vmw_surface *srf;
+ struct vmw_user_surface *user_srf;
+ struct ttm_base_object *base;
+ uint32_t backup_handle;
+ int ret = -EINVAL;
+
+ base = ttm_base_object_lookup_for_ref(dev_priv->tdev, req->sid);
+ if (unlikely(base == NULL)) {
+  DRM_ERROR("Could not find surface to reference.\n");
+  return -EINVAL;
+ }
+
+ if (unlikely(ttm_base_object_type(base) != VMW_RES_SURFACE))
+  goto out_bad_resource;
+
+ user_srf = container_of(base, struct vmw_user_surface, prime.base);
+ srf = &user_srf->srf;
+ if (srf->res.backup == NULL) {
+  DRM_ERROR("Shared GB surface is missing a backup buffer.\n");
+  goto out_bad_resource;
+ }
+
+ ret = ttm_ref_object_add(tfile, &user_srf->prime.base,
+     TTM_REF_USAGE, NULL);
+ if (unlikely(ret != 0)) {
+  DRM_ERROR("Could not add a reference to a GB surface.\n");
+  goto out_bad_resource;
+ }
+
+ mutex_lock(&dev_priv->cmdbuf_mutex); /* Protect res->backup */
+ ret = vmw_user_dmabuf_reference(tfile, srf->res.backup,
+     &backup_handle);
+ mutex_unlock(&dev_priv->cmdbuf_mutex);
+
+ if (unlikely(ret != 0)) {
+  DRM_ERROR("Could not add a reference to a GB surface "
+     "backup buffer.\n");
+  (void) ttm_ref_object_base_unref(vmw_fpriv(file_priv)->tfile,
+       req->sid,
+       TTM_REF_USAGE);
+  goto out_bad_resource;
+ }
+
+ rep->creq.svga3d_flags = srf->flags;
+ rep->creq.format = srf->format;
+ rep->creq.mip_levels = srf->mip_levels[0];
+ rep->creq.drm_surface_flags = 0;
+ rep->creq.multisample_count = srf->multisample_count;
+ rep->creq.autogen_filter = srf->autogen_filter;
+ rep->creq.buffer_handle = backup_handle;
+ rep->creq.base_size = srf->base_size;
+ rep->crep.handle = user_srf->prime.base.hash.key;
+ rep->crep.backup_size = srf->res.backup_size;
+ rep->crep.buffer_handle = backup_handle;
+ rep->crep.buffer_map_handle =
+  drm_vma_node_offset_addr(&srf->res.backup->base.vma_node);
+ rep->crep.buffer_size = srf->res.backup->base.num_pages * PAGE_SIZE;
+
+out_bad_resource:
+ ttm_base_object_unref(&base);
+
+ return ret;
+}
diff --git a/include/drm/drmP.h b/include/drm/drmP.h
index 1d4a920..04a7f31 100644
--- a/include/drm/drmP.h
+++ b/include/drm/drmP.h
@@ -56,6 +56,7 @@
 #include <linux/mutex.h>
 #include <linux/io.h>
 #include <linux/slab.h>
+#include <linux/ratelimit.h>
 #if defined(__alpha__) || defined(__powerpc__)
 #include <asm/pgtable.h> /* For pte_wrprotect */
 #endif
@@ -136,7 +137,6 @@ int drm_err(const char *func, const char *format, ...);
 
 /* driver capabilities and requirements mask */
 #define DRIVER_USE_AGP     0x1
-#define DRIVER_REQUIRE_AGP 0x2
 #define DRIVER_PCI_DMA     0x8
 #define DRIVER_SG          0x10
 #define DRIVER_HAVE_DMA    0x20
@@ -180,9 +180,28 @@ int drm_err(const char *func, const char *format, ...);
 #define DRM_ERROR(fmt, ...)    \
  drm_err(__func__, fmt, ##__VA_ARGS__)
 
+/**
+ * Rate limited error output.  Like DRM_ERROR() but won't flood the log.
+ *
+ * \param fmt printf() like format string.
+ * \param arg arguments
+ */
+#define DRM_ERROR_RATELIMITED(fmt, ...)    \
+({         \
+ static DEFINE_RATELIMIT_STATE(_rs,    \
+          DEFAULT_RATELIMIT_INTERVAL, \
+          DEFAULT_RATELIMIT_BURST);  \
+         \
+ if (__ratelimit(&_rs))      \
+  drm_err(__func__, fmt, ##__VA_ARGS__);   \
+})
+
 #define DRM_INFO(fmt, ...)    \
  printk(KERN_INFO "[" DRM_NAME "] " fmt, ##__VA_ARGS__)
 
+#define DRM_INFO_ONCE(fmt, ...)    \
+ printk_once(KERN_INFO "[" DRM_NAME "] " fmt, ##__VA_ARGS__)
+
 /**
  * Debug output.
  *
@@ -422,7 +441,6 @@ struct drm_file {
  struct pid *pid;
  kuid_t uid;
  drm_magic_t magic;
- unsigned long ioctl_count;
  struct list_head lhead;
  struct drm_minor *minor;
  unsigned long lock_count;
@@ -511,7 +529,7 @@ struct drm_device_dma {
  */
 struct drm_agp_mem {
  unsigned long handle;  /**< handle */
- DRM_AGP_MEM *memory;
+ struct agp_memory *memory;
  unsigned long bound;  /**< address */
  int pages;
  struct list_head head;
@@ -523,7 +541,7 @@ struct drm_agp_mem {
  * \sa drm_agp_init() and drm_device::agp.
  */
 struct drm_agp_head {
- DRM_AGP_KERN agp_info;  /**< AGP device information */
+ struct agp_kern_info agp_info;  /**< AGP device information */
  struct list_head memory;
  unsigned long mode;  /**< AGP mode */
  struct agp_bridge_data *bridge;
@@ -607,13 +625,6 @@ struct drm_ati_pcigart_info {
 };
 
 /**
- * GEM specific mm private for tracking GEM objects
- */
-struct drm_gem_mm {
- struct drm_vma_offset_manager vma_manager;
-};
-
-/**
  * This structure defines the drm_mm memory object, which will be used by the
  * DRM for its buffer objects.
  */
@@ -750,10 +761,6 @@ struct drm_bus {
  int (*set_unique)(struct drm_device *dev, struct drm_master *master,
      struct drm_unique *unique);
  int (*irq_by_busid)(struct drm_device *dev, struct drm_irq_busid *p);
- /* hooks that are for PCI */
- int (*agp_init)(struct drm_device *dev);
- void (*agp_destroy)(struct drm_device *dev);
-
 };
 
 /**
@@ -841,6 +848,7 @@ struct drm_driver {
   *
   * \param dev  DRM device.
   * \param crtc Id of the crtc to query.
+  * \param flags Flags from the caller (DRM_CALLED_FROM_VBLIRQ or 0).
   * \param *vpos Target location for current vertical scanout position.
   * \param *hpos Target location for current horizontal scanout position.
   * \param *stime Target location for timestamp taken immediately before
@@ -863,6 +871,7 @@ struct drm_driver {
   *
   */
  int (*get_scanout_position) (struct drm_device *dev, int crtc,
+         unsigned int flags,
          int *vpos, int *hpos, ktime_t *stime,
          ktime_t *etime);
 
@@ -903,7 +912,7 @@ struct drm_driver {
 
  /* these have to be filled in */
 
- irqreturn_t(*irq_handler) (DRM_IRQ_ARGS);
+ irqreturn_t(*irq_handler) (int irq, void *arg);
  void (*irq_preinstall) (struct drm_device *dev);
  int (*irq_postinstall) (struct drm_device *dev);
  void (*irq_uninstall) (struct drm_device *dev);
@@ -995,8 +1004,8 @@ struct drm_driver {
  } kdriver;
  struct drm_bus *bus;
 
- /* List of devices hanging off this driver */
- struct list_head device_list;
+ /* List of devices hanging off this driver with stealth attach. */
+ struct list_head legacy_dev_list;
 };
 
 #define DRM_MINOR_UNASSIGNED 0
@@ -1085,7 +1094,7 @@ struct drm_vblank_crtc {
  * may contain multiple heads.
  */
 struct drm_device {
- struct list_head driver_item; /**< list of devices per driver */
+ struct list_head legacy_dev_list;/**< list of devices per driver for stealth attach cleanup */
  char *devname;   /**< For /proc/interrupts */
  int if_version;   /**< Highest interface version set */
 
@@ -1098,8 +1107,6 @@ struct drm_device {
  /** \name Usage Counters */
  /*@{ */
  int open_count;   /**< Outstanding files open */
- atomic_t ioctl_count;  /**< Outstanding IOCTLs pending */
- atomic_t vma_count;  /**< Outstanding vma areas open */
  int buf_use;   /**< Buffers in use -- cannot alloc */
  atomic_t buf_alloc;  /**< Buffer allocation in progress */
  /*@} */
@@ -1176,7 +1183,6 @@ struct drm_device {
  struct drm_sg_mem *sg; /**< Scatter gather memory */
  unsigned int num_crtcs;                  /**< Number of CRTCs on this device */
  void *dev_private;  /**< device private data */
- void *mm_private;
  struct address_space *dev_mapping;
  struct drm_sigdata sigdata;    /**< For block_all_signals */
  sigset_t sigmask;
@@ -1194,6 +1200,7 @@ struct drm_device {
  /*@{ */
  struct mutex object_name_lock;
  struct idr object_name_idr;
+ struct drm_vma_offset_manager *vma_offset_manager;
  /*@} */
  int switch_power_state;
 
@@ -1268,6 +1275,7 @@ extern unsigned int drm_poll(struct file *filp, struct poll_table_struct *wait);
     /* Memory management support (drm_memory.h) */
 #include <drm/drm_memory.h>
 
+
     /* Misc. IOCTL support (drm_ioctl.h) */
 extern int drm_irq_by_busid(struct drm_device *dev, void *data,
        struct drm_file *file_priv);
@@ -1398,8 +1406,10 @@ extern int drm_calc_vbltimestamp_from_scanoutpos(struct drm_device *dev,
        int crtc, int *max_error,
        struct timeval *vblank_time,
        unsigned flags,
-       struct drm_crtc *refcrtc);
-extern void drm_calc_timestamping_constants(struct drm_crtc *crtc);
+       const struct drm_crtc *refcrtc,
+       const struct drm_display_mode *mode);
+extern void drm_calc_timestamping_constants(struct drm_crtc *crtc,
+         const struct drm_display_mode *mode);
 
 extern bool
 drm_mode_parse_command_line_for_connector(const char *mode_option,
@@ -1461,6 +1471,30 @@ extern int drm_debugfs_create_files(const struct drm_info_list *files,
 extern int drm_debugfs_remove_files(const struct drm_info_list *files,
         int count, struct drm_minor *minor);
 extern int drm_debugfs_cleanup(struct drm_minor *minor);
+#else
+static inline int drm_debugfs_init(struct drm_minor *minor, int minor_id,
+       struct dentry *root)
+{
+ return 0;
+}
+
+static inline int drm_debugfs_create_files(const struct drm_info_list *files,
+        int count, struct dentry *root,
+        struct drm_minor *minor)
+{
+ return 0;
+}
+
+static inline int drm_debugfs_remove_files(const struct drm_info_list *files,
+        int count, struct drm_minor *minor)
+{
+ return 0;
+}
+
+static inline int drm_debugfs_cleanup(struct drm_minor *minor)
+{
+ return 0;
+}
 #endif
 
     /* Info file support */
@@ -1645,6 +1679,7 @@ static __inline__ int drm_pci_device_is_agp(struct drm_device *dev)
 
  return pci_find_capability(dev->pdev, PCI_CAP_ID_AGP);
 }
+void drm_pci_agp_destroy(struct drm_device *dev);
 
 extern int drm_pci_init(struct drm_driver *driver, struct pci_driver *pdriver);
 extern void drm_pci_exit(struct drm_driver *driver, struct pci_driver *pdriver);
@@ -1660,7 +1695,6 @@ extern int drm_pcie_get_speed_cap_mask(struct drm_device *dev, u32 *speed_mask);
 
 /* platform section */
 extern int drm_platform_init(struct drm_driver *driver, struct platform_device *platform_device);
-extern void drm_platform_exit(struct drm_driver *driver, struct platform_device *platform_device);
 
 /* returns true if currently okay to sleep */
 static __inline__ bool drm_can_sleep(void)
diff --git a/include/drm/drm_agpsupport.h b/include/drm/drm_agpsupport.h
index a184eee..86a0218 100644
--- a/include/drm/drm_agpsupport.h
+++ b/include/drm/drm_agpsupport.h
@@ -10,17 +10,16 @@
 
 #if __OS_HAS_AGP
 
-void drm_free_agp(DRM_AGP_MEM * handle, int pages);
-int drm_bind_agp(DRM_AGP_MEM * handle, unsigned int start);
-int drm_unbind_agp(DRM_AGP_MEM * handle);
-DRM_AGP_MEM *drm_agp_bind_pages(struct drm_device *dev,
+void drm_free_agp(struct agp_memory * handle, int pages);
+int drm_bind_agp(struct agp_memory * handle, unsigned int start);
+int drm_unbind_agp(struct agp_memory * handle);
+struct agp_memory *drm_agp_bind_pages(struct drm_device *dev,
     struct page **pages,
     unsigned long num_pages,
     uint32_t gtt_offset,
     uint32_t type);
 
 struct drm_agp_head *drm_agp_init(struct drm_device *dev);
-void drm_agp_destroy(struct drm_agp_head *agp);
 void drm_agp_clear(struct drm_device *dev);
 int drm_agp_acquire(struct drm_device *dev);
 int drm_agp_acquire_ioctl(struct drm_device *dev, void *data,
@@ -46,29 +45,23 @@ int drm_agp_unbind_ioctl(struct drm_device *dev, void *data,
 int drm_agp_bind(struct drm_device *dev, struct drm_agp_binding *request);
 int drm_agp_bind_ioctl(struct drm_device *dev, void *data,
          struct drm_file *file_priv);
-
-static inline int drm_core_has_AGP(struct drm_device *dev)
-{
- return drm_core_check_feature(dev, DRIVER_USE_AGP);
-}
-
 #else /* __OS_HAS_AGP */
 
-static inline void drm_free_agp(DRM_AGP_MEM * handle, int pages)
+static inline void drm_free_agp(struct agp_memory * handle, int pages)
 {
 }
 
-static inline int drm_bind_agp(DRM_AGP_MEM * handle, unsigned int start)
+static inline int drm_bind_agp(struct agp_memory * handle, unsigned int start)
 {
  return -ENODEV;
 }
 
-static inline int drm_unbind_agp(DRM_AGP_MEM * handle)
+static inline int drm_unbind_agp(struct agp_memory * handle)
 {
  return -ENODEV;
 }
 
-static inline DRM_AGP_MEM *drm_agp_bind_pages(struct drm_device *dev,
+static inline struct agp_memory *drm_agp_bind_pages(struct drm_device *dev,
            struct page **pages,
            unsigned long num_pages,
            uint32_t gtt_offset,
@@ -82,10 +75,6 @@ static inline struct drm_agp_head *drm_agp_init(struct drm_device *dev)
  return NULL;
 }
 
-static inline void drm_agp_destroy(struct drm_agp_head *agp)
-{
-}
-
 static inline void drm_agp_clear(struct drm_device *dev)
 {
 }
@@ -183,12 +172,6 @@ static inline int drm_agp_bind_ioctl(struct drm_device *dev, void *data,
 {
  return -ENODEV;
 }
-
-static inline int drm_core_has_AGP(struct drm_device *dev)
-{
- return 0;
-}
-
 #endif /* __OS_HAS_AGP */
 
 #endif /* _DRM_AGPSUPPORT_H_ */
diff --git a/include/drm/drm_crtc.h b/include/drm/drm_crtc.h
index f32c5cd..8f3dee0 100644
--- a/include/drm/drm_crtc.h
+++ b/include/drm/drm_crtc.h
@@ -30,6 +30,7 @@
 #include <linux/types.h>
 #include <linux/idr.h>
 #include <linux/fb.h>
+#include <linux/hdmi.h>
 #include <drm/drm_mode.h>
 
 #include <drm/drm_fourcc.h>
@@ -181,6 +182,7 @@ struct drm_display_mode {
 
  int vrefresh;  /* in Hz */
  int hsync;  /* in kHz */
+ enum hdmi_picture_aspect picture_aspect_ratio;
 };
 
 static inline bool drm_mode_is_stereo(const struct drm_display_mode *mode)
@@ -447,7 +449,7 @@ struct drm_crtc {
  uint16_t *gamma_store;
 
  /* Constants needed for precise vblank and swap timestamping. */
- s64 framedur_ns, linedur_ns, pixeldur_ns;
+ int framedur_ns, linedur_ns, pixeldur_ns;
 
  /* if you are using the helper */
  void *helper_private;
@@ -905,6 +907,9 @@ struct drm_mode_config {
 
  /* whether async page flip is supported or not */
  bool async_page_flip;
+
+ /* cursor size */
+ uint32_t cursor_width, cursor_height;
 };
 
 #define obj_to_crtc(x) container_of(x, struct drm_crtc, base)
@@ -929,6 +934,19 @@ extern int drm_crtc_init(struct drm_device *dev,
     struct drm_crtc *crtc,
     const struct drm_crtc_funcs *funcs);
 extern void drm_crtc_cleanup(struct drm_crtc *crtc);
+extern unsigned int drm_crtc_index(struct drm_crtc *crtc);
+
+/**
+ * drm_crtc_mask - find the mask of a registered CRTC
+ * @crtc: CRTC to find mask for
+ *
+ * Given a registered CRTC, return the mask bit of that CRTC for an
+ * encoder's possible_crtcs field.
+ */
+static inline uint32_t drm_crtc_mask(struct drm_crtc *crtc)
+{
+ return 1 << drm_crtc_index(crtc);
+}
 
 extern void drm_connector_ida_init(void);
 extern void drm_connector_ida_destroy(void);
@@ -950,6 +968,19 @@ extern int drm_encoder_init(struct drm_device *dev,
        const struct drm_encoder_funcs *funcs,
        int encoder_type);
 
+/**
+ * drm_encoder_crtc_ok - can a given crtc drive a given encoder?
+ * @encoder: encoder to test
+ * @crtc: crtc to test
+ *
+ * Return false if @encoder can't be driven by @crtc, true otherwise.
+ */
+static inline bool drm_encoder_crtc_ok(struct drm_encoder *encoder,
+           struct drm_crtc *crtc)
+{
+ return !!(encoder->possible_crtcs & drm_crtc_mask(crtc));
+}
+
 extern int drm_plane_init(struct drm_device *dev,
      struct drm_plane *plane,
      unsigned long possible_crtcs,
diff --git a/include/drm/drm_crtc_helper.h b/include/drm/drm_crtc_helper.h
index ef6ad3a..b1388b5 100644
--- a/include/drm/drm_crtc_helper.h
+++ b/include/drm/drm_crtc_helper.h
@@ -120,8 +120,8 @@ struct drm_encoder_helper_funcs {
  */
 struct drm_connector_helper_funcs {
  int (*get_modes)(struct drm_connector *connector);
- int (*mode_valid)(struct drm_connector *connector,
-     struct drm_display_mode *mode);
+ enum drm_mode_status (*mode_valid)(struct drm_connector *connector,
+        struct drm_display_mode *mode);
  struct drm_encoder *(*best_encoder)(struct drm_connector *connector);
 };
 
diff --git a/include/drm/drm_dp_helper.h b/include/drm/drm_dp_helper.h
index a92c375..1d09050 100644
--- a/include/drm/drm_dp_helper.h
+++ b/include/drm/drm_dp_helper.h
@@ -41,22 +41,22 @@
  * 1.2 formally includes both eDP and DPI definitions.
  */
 
-#define AUX_NATIVE_WRITE 0x8
-#define AUX_NATIVE_READ  0x9
-#define AUX_I2C_WRITE  0x0
-#define AUX_I2C_READ  0x1
-#define AUX_I2C_STATUS  0x2
-#define AUX_I2C_MOT  0x4
-
-#define AUX_NATIVE_REPLY_ACK (0x0 << 4)
-#define AUX_NATIVE_REPLY_NACK (0x1 << 4)
-#define AUX_NATIVE_REPLY_DEFER (0x2 << 4)
-#define AUX_NATIVE_REPLY_MASK (0x3 << 4)
-
-#define AUX_I2C_REPLY_ACK (0x0 << 6)
-#define AUX_I2C_REPLY_NACK (0x1 << 6)
-#define AUX_I2C_REPLY_DEFER (0x2 << 6)
-#define AUX_I2C_REPLY_MASK (0x3 << 6)
+#define DP_AUX_I2C_WRITE  0x0
+#define DP_AUX_I2C_READ   0x1
+#define DP_AUX_I2C_STATUS  0x2
+#define DP_AUX_I2C_MOT   0x4
+#define DP_AUX_NATIVE_WRITE  0x8
+#define DP_AUX_NATIVE_READ  0x9
+
+#define DP_AUX_NATIVE_REPLY_ACK  (0x0 << 0)
+#define DP_AUX_NATIVE_REPLY_NACK (0x1 << 0)
+#define DP_AUX_NATIVE_REPLY_DEFER (0x2 << 0)
+#define DP_AUX_NATIVE_REPLY_MASK (0x3 << 0)
+
+#define DP_AUX_I2C_REPLY_ACK  (0x0 << 2)
+#define DP_AUX_I2C_REPLY_NACK  (0x1 << 2)
+#define DP_AUX_I2C_REPLY_DEFER  (0x2 << 2)
+#define DP_AUX_I2C_REPLY_MASK  (0x3 << 2)
 
 /* AUX CH addresses */
 /* DPCD */
@@ -266,9 +266,10 @@
 
 #define DP_TEST_REQUEST       0x218
 # define DP_TEST_LINK_TRAINING      (1 << 0)
-# define DP_TEST_LINK_PATTERN      (1 << 1)
+# define DP_TEST_LINK_VIDEO_PATTERN     (1 << 1)
 # define DP_TEST_LINK_EDID_READ      (1 << 2)
 # define DP_TEST_LINK_PHY_TEST_PATTERN     (1 << 3) /* DPCD >= 1.1 */
+# define DP_TEST_LINK_FAUX_PATTERN     (1 << 4) /* DPCD >= 1.2 */
 
 #define DP_TEST_LINK_RATE      0x219
 # define DP_LINK_RATE_162      (0x6)
diff --git a/include/drm/drm_mipi_dsi.h b/include/drm/drm_mipi_dsi.h
new file mode 100644
index 0000000..d32628a
--- /dev/null
+++ b/include/drm/drm_mipi_dsi.h
@@ -0,0 +1,158 @@
+/*
+ * MIPI DSI Bus
+ *
+ * Copyright (C) 2012-2013, Samsung Electronics, Co., Ltd.
+ * Andrzej Hajda <a.hajda@samsung.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __DRM_MIPI_DSI_H__
+#define __DRM_MIPI_DSI_H__
+
+#include <linux/device.h>
+
+struct mipi_dsi_host;
+struct mipi_dsi_device;
+
+/**
+ * struct mipi_dsi_msg - read/write DSI buffer
+ * @channel: virtual channel id
+ * @type: payload data type
+ * @tx_len: length of @tx_buf
+ * @tx_buf: data to be written
+ * @rx_len: length of @rx_buf
+ * @rx_buf: data to be read, or NULL
+ */
+struct mipi_dsi_msg {
+ u8 channel;
+ u8 type;
+
+ size_t tx_len;
+ const void *tx_buf;
+
+ size_t rx_len;
+ void *rx_buf;
+};
+
+/**
+ * struct mipi_dsi_host_ops - DSI bus operations
+ * @attach: attach DSI device to DSI host
+ * @detach: detach DSI device from DSI host
+ * @transfer: send and/or receive DSI packet, return number of received bytes,
+ *        or error
+ */
+struct mipi_dsi_host_ops {
+ int (*attach)(struct mipi_dsi_host *host,
+        struct mipi_dsi_device *dsi);
+ int (*detach)(struct mipi_dsi_host *host,
+        struct mipi_dsi_device *dsi);
+ ssize_t (*transfer)(struct mipi_dsi_host *host,
+       struct mipi_dsi_msg *msg);
+};
+
+/**
+ * struct mipi_dsi_host - DSI host device
+ * @dev: driver model device node for this DSI host
+ * @ops: DSI host operations
+ */
+struct mipi_dsi_host {
+ struct device *dev;
+ const struct mipi_dsi_host_ops *ops;
+};
+
+int mipi_dsi_host_register(struct mipi_dsi_host *host);
+void mipi_dsi_host_unregister(struct mipi_dsi_host *host);
+
+/* DSI mode flags */
+
+/* video mode */
+#define MIPI_DSI_MODE_VIDEO  BIT(0)
+/* video burst mode */
+#define MIPI_DSI_MODE_VIDEO_BURST BIT(1)
+/* video pulse mode */
+#define MIPI_DSI_MODE_VIDEO_SYNC_PULSE BIT(2)
+/* enable auto vertical count mode */
+#define MIPI_DSI_MODE_VIDEO_AUTO_VERT BIT(3)
+/* enable hsync-end packets in vsync-pulse and v-porch area */
+#define MIPI_DSI_MODE_VIDEO_HSE  BIT(4)
+/* disable hfront-porch area */
+#define MIPI_DSI_MODE_VIDEO_HFP  BIT(5)
+/* disable hback-porch area */
+#define MIPI_DSI_MODE_VIDEO_HBP  BIT(6)
+/* disable hsync-active area */
+#define MIPI_DSI_MODE_VIDEO_HSA  BIT(7)
+/* flush display FIFO on vsync pulse */
+#define MIPI_DSI_MODE_VSYNC_FLUSH BIT(8)
+/* disable EoT packets in HS mode */
+#define MIPI_DSI_MODE_EOT_PACKET BIT(9)
+
+enum mipi_dsi_pixel_format {
+ MIPI_DSI_FMT_RGB888,
+ MIPI_DSI_FMT_RGB666,
+ MIPI_DSI_FMT_RGB666_PACKED,
+ MIPI_DSI_FMT_RGB565,
+};
+
+/**
+ * struct mipi_dsi_device - DSI peripheral device
+ * @host: DSI host for this peripheral
+ * @dev: driver model device node for this peripheral
+ * @channel: virtual channel assigned to the peripheral
+ * @format: pixel format for video mode
+ * @lanes: number of active data lanes
+ * @mode_flags: DSI operation mode related flags
+ */
+struct mipi_dsi_device {
+ struct mipi_dsi_host *host;
+ struct device dev;
+
+ unsigned int channel;
+ unsigned int lanes;
+ enum mipi_dsi_pixel_format format;
+ unsigned long mode_flags;
+};
+
+#define to_mipi_dsi_device(d) container_of(d, struct mipi_dsi_device, dev)
+
+int mipi_dsi_attach(struct mipi_dsi_device *dsi);
+int mipi_dsi_detach(struct mipi_dsi_device *dsi);
+int mipi_dsi_dcs_write(struct mipi_dsi_device *dsi, unsigned int channel,
+         const void *data, size_t len);
+ssize_t mipi_dsi_dcs_read(struct mipi_dsi_device *dsi, unsigned int channel,
+     u8 cmd, void *data, size_t len);
+
+/**
+ * struct mipi_dsi_driver - DSI driver
+ * @driver: device driver model driver
+ * @probe: callback for device binding
+ * @remove: callback for device unbinding
+ */
+struct mipi_dsi_driver {
+ struct device_driver driver;
+ int(*probe)(struct mipi_dsi_device *dsi);
+ int(*remove)(struct mipi_dsi_device *dsi);
+};
+
+#define to_mipi_dsi_driver(d) container_of(d, struct mipi_dsi_driver, driver)
+
+static inline void *mipi_dsi_get_drvdata(const struct mipi_dsi_device *dsi)
+{
+ return dev_get_drvdata(&dsi->dev);
+}
+
+static inline void mipi_dsi_set_drvdata(struct mipi_dsi_device *dsi, void *data)
+{
+ dev_set_drvdata(&dsi->dev, data);
+}
+
+int mipi_dsi_driver_register(struct mipi_dsi_driver *driver);
+void mipi_dsi_driver_unregister(struct mipi_dsi_driver *driver);
+
+#define module_mipi_dsi_driver(__mipi_dsi_driver) \
+ module_driver(__mipi_dsi_driver, mipi_dsi_driver_register, \
+   mipi_dsi_driver_unregister)
+
+#endif /* __DRM_MIPI_DSI__ */
diff --git a/include/drm/drm_os_linux.h b/include/drm/drm_os_linux.h
index 815fafc..86ab99b 100644
--- a/include/drm/drm_os_linux.h
+++ b/include/drm/drm_os_linux.h
@@ -21,7 +21,6 @@ static inline void writeq(u64 val, void __iomem *reg)
 
 /** Current process ID */
 #define DRM_CURRENTPID   task_pid_nr(current)
-#define DRM_SUSER(p)   capable(CAP_SYS_ADMIN)
 #define DRM_UDELAY(d)   udelay(d)
 /** Read a byte from a MMIO region */
 #define DRM_READ8(map, offset)  readb(((void __iomem *)(map)->handle) + (offset))
@@ -35,45 +34,12 @@ static inline void writeq(u64 val, void __iomem *reg)
 #define DRM_WRITE16(map, offset, val)   writew(val, ((void __iomem *)(map)->handle) + (offset))
 /** Write a dword into a MMIO region */
 #define DRM_WRITE32(map, offset, val) writel(val, ((void __iomem *)(map)->handle) + (offset))
-/** Read memory barrier */
 
 /** Read a qword from a MMIO region - be careful using these unless you really understand them */
 #define DRM_READ64(map, offset)  readq(((void __iomem *)(map)->handle) + (offset))
 /** Write a qword into a MMIO region */
 #define DRM_WRITE64(map, offset, val) writeq(val, ((void __iomem *)(map)->handle) + (offset))
 
-#define DRM_READMEMORYBARRIER()  rmb()
-/** Write memory barrier */
-#define DRM_WRITEMEMORYBARRIER() wmb()
-/** Read/write memory barrier */
-#define DRM_MEMORYBARRIER()  mb()
-
-/** IRQ handler arguments and return type and values */
-#define DRM_IRQ_ARGS  int irq, void *arg
-
-/** AGP types */
-#if __OS_HAS_AGP
-#define DRM_AGP_MEM  struct agp_memory
-#define DRM_AGP_KERN  struct agp_kern_info
-#else
-/* define some dummy types for non AGP supporting kernels */
-struct no_agp_kern {
- unsigned long aper_base;
- unsigned long aper_size;
-};
-#define DRM_AGP_MEM             int
-#define DRM_AGP_KERN            struct no_agp_kern
-#endif
-
-/** Other copying of data to kernel space */
-#define DRM_COPY_FROM_USER(arg1, arg2, arg3)  \
- copy_from_user(arg1, arg2, arg3)
-/** Other copying of data from kernel space */
-#define DRM_COPY_TO_USER(arg1, arg2, arg3)  \
- copy_to_user(arg1, arg2, arg3)
-
-#define DRM_HZ HZ
-
 #define DRM_WAIT_ON( ret, queue, timeout, condition )  \
 do {        \
  DECLARE_WAITQUEUE(entry, current);   \
@@ -97,6 +63,3 @@ do {        \
  __set_current_state(TASK_RUNNING);   \
  remove_wait_queue(&(queue), &entry);   \
 } while (0)
-
-#define DRM_WAKEUP( queue ) wake_up( queue )
-#define DRM_INIT_WAITQUEUE( queue ) init_waitqueue_head( queue )
diff --git a/include/drm/drm_panel.h b/include/drm/drm_panel.h
new file mode 100644
index 0000000..c2ab77a
--- /dev/null
+++ b/include/drm/drm_panel.h
@@ -0,0 +1,82 @@
+/*
+ * Copyright (C) 2013, NVIDIA Corporation.  All rights reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sub license,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#ifndef __DRM_PANEL_H__
+#define __DRM_PANEL_H__
+
+#include <linux/list.h>
+
+struct drm_connector;
+struct drm_device;
+struct drm_panel;
+
+struct drm_panel_funcs {
+ int (*disable)(struct drm_panel *panel);
+ int (*enable)(struct drm_panel *panel);
+ int (*get_modes)(struct drm_panel *panel);
+};
+
+struct drm_panel {
+ struct drm_device *drm;
+ struct drm_connector *connector;
+ struct device *dev;
+
+ const struct drm_panel_funcs *funcs;
+
+ struct list_head list;
+};
+
+static inline int drm_panel_disable(struct drm_panel *panel)
+{
+ if (panel && panel->funcs && panel->funcs->disable)
+  return panel->funcs->disable(panel);
+
+ return panel ? -ENOSYS : -EINVAL;
+}
+
+static inline int drm_panel_enable(struct drm_panel *panel)
+{
+ if (panel && panel->funcs && panel->funcs->enable)
+  return panel->funcs->enable(panel);
+
+ return panel ? -ENOSYS : -EINVAL;
+}
+
+void drm_panel_init(struct drm_panel *panel);
+
+int drm_panel_add(struct drm_panel *panel);
+void drm_panel_remove(struct drm_panel *panel);
+
+int drm_panel_attach(struct drm_panel *panel, struct drm_connector *connector);
+int drm_panel_detach(struct drm_panel *panel);
+
+#ifdef CONFIG_OF
+struct drm_panel *of_drm_find_panel(struct device_node *np);
+#else
+static inline struct drm_panel *of_drm_find_panel(struct device_node *np)
+{
+ return NULL;
+}
+#endif
+
+#endif
diff --git a/include/drm/ttm/ttm_bo_driver.h b/include/drm/ttm/ttm_bo_driver.h
index 8639c85..32d34eb 100644
--- a/include/drm/ttm/ttm_bo_driver.h
+++ b/include/drm/ttm/ttm_bo_driver.h
@@ -681,6 +681,15 @@ extern int ttm_tt_set_placement_caching(struct ttm_tt *ttm, uint32_t placement);
 extern int ttm_tt_swapout(struct ttm_tt *ttm,
      struct file *persistent_swap_storage);
 
+/**
+ * ttm_tt_unpopulate - free pages from a ttm
+ *
+ * @ttm: Pointer to the ttm_tt structure
+ *
+ * Calls the driver method to free all pages from a ttm
+ */
+extern void ttm_tt_unpopulate(struct ttm_tt *ttm);
+
 /*
  * ttm_bo.c
  */
diff --git a/include/drm/ttm/ttm_object.h b/include/drm/ttm/ttm_object.h
index 58b0298..0097cc0 100644
--- a/include/drm/ttm/ttm_object.h
+++ b/include/drm/ttm/ttm_object.h
@@ -190,14 +190,26 @@ extern int ttm_base_object_init(struct ttm_object_file *tfile,
  * @key: Hash key
  *
  * Looks up a struct ttm_base_object with the key @key.
- * Also verifies that the object is visible to the application, by
- * comparing the @tfile argument and checking the object shareable flag.
  */
 
 extern struct ttm_base_object *ttm_base_object_lookup(struct ttm_object_file
             *tfile, uint32_t key);
 
 /**
+ * ttm_base_object_lookup_for_ref
+ *
+ * @tdev: Pointer to a struct ttm_object_device.
+ * @key: Hash key
+ *
+ * Looks up a struct ttm_base_object with the key @key.
+ * This function should only be used when the struct tfile associated with the
+ * caller doesn't yet have a reference to the base object.
+ */
+
+extern struct ttm_base_object *
+ttm_base_object_lookup_for_ref(struct ttm_object_device *tdev, uint32_t key);
+
+/**
  * ttm_base_object_unref
  *
  * @p_base: Pointer to a pointer referencing a struct ttm_base_object.
@@ -218,6 +230,8 @@ extern void ttm_base_object_unref(struct ttm_base_object **p_base);
  * @existed: Upon completion, indicates that an identical reference object
  * already existed, and the refcount was upped on that object instead.
  *
+ * Checks that the base object is shareable and adds a ref object to it.
+ *
  * Adding a ref object to a base object is basically like referencing the
  * base object, but a user-space application holds the reference. When the
  * file corresponding to @tfile is closed, all its reference objects are
diff --git a/include/drm/ttm/ttm_page_alloc.h b/include/drm/ttm/ttm_page_alloc.h
index d1f61bf..49a8284 100644
--- a/include/drm/ttm/ttm_page_alloc.h
+++ b/include/drm/ttm/ttm_page_alloc.h
@@ -29,6 +29,8 @@
 #include <drm/ttm/ttm_bo_driver.h>
 #include <drm/ttm/ttm_memory.h>
 
+struct device;
+
 /**
  * Initialize pool allocator.
  */
diff --git a/include/uapi/drm/drm.h b/include/uapi/drm/drm.h
index 9b24d65..b06c8ed 100644
--- a/include/uapi/drm/drm.h
+++ b/include/uapi/drm/drm.h
@@ -181,7 +181,6 @@ enum drm_map_type {
  _DRM_AGP = 3,    /**< AGP/GART */
  _DRM_SCATTER_GATHER = 4,  /**< Scatter/gather memory for PCI DMA */
  _DRM_CONSISTENT = 5,   /**< Consistent memory for PCI DMA */
- _DRM_GEM = 6,    /**< GEM object (obsolete) */
 };
 
 /**
@@ -620,6 +619,8 @@ struct drm_gem_open {
 #define  DRM_PRIME_CAP_EXPORT  0x2
 #define DRM_CAP_TIMESTAMP_MONOTONIC 0x6
 #define DRM_CAP_ASYNC_PAGE_FLIP  0x7
+#define DRM_CAP_CURSOR_WIDTH  0x8
+#define DRM_CAP_CURSOR_HEIGHT  0x9
 
 /** DRM_IOCTL_GET_CAP ioctl argument type */
 struct drm_get_cap {
diff --git a/include/uapi/drm/i915_drm.h b/include/uapi/drm/i915_drm.h
index 3a4e97b..126bfaa 100644
--- a/include/uapi/drm/i915_drm.h
+++ b/include/uapi/drm/i915_drm.h
@@ -222,6 +222,7 @@ typedef struct _drm_i915_sarea {
 #define DRM_I915_GEM_SET_CACHING 0x2f
 #define DRM_I915_GEM_GET_CACHING 0x30
 #define DRM_I915_REG_READ  0x31
+#define DRM_I915_GET_RESET_STATS 0x32
 
 #define DRM_IOCTL_I915_INIT  DRM_IOW( DRM_COMMAND_BASE + DRM_I915_INIT, drm_i915_init_t)
 #define DRM_IOCTL_I915_FLUSH  DRM_IO ( DRM_COMMAND_BASE + DRM_I915_FLUSH)
@@ -271,6 +272,7 @@ typedef struct _drm_i915_sarea {
 #define DRM_IOCTL_I915_GEM_CONTEXT_CREATE DRM_IOWR (DRM_COMMAND_BASE + DRM_I915_GEM_CONTEXT_CREATE, struct drm_i915_gem_context_create)
 #define DRM_IOCTL_I915_GEM_CONTEXT_DESTROY DRM_IOW (DRM_COMMAND_BASE + DRM_I915_GEM_CONTEXT_DESTROY, struct drm_i915_gem_context_destroy)
 #define DRM_IOCTL_I915_REG_READ   DRM_IOWR (DRM_COMMAND_BASE + DRM_I915_REG_READ, struct drm_i915_reg_read)
+#define DRM_IOCTL_I915_GET_RESET_STATS  DRM_IOWR (DRM_COMMAND_BASE + DRM_I915_GET_RESET_STATS, struct drm_i915_reset_stats)
 
 /* Allow drivers to submit batchbuffers directly to hardware, relying
  * on the security mechanisms provided by hardware.
@@ -719,7 +721,7 @@ struct drm_i915_gem_execbuffer2 {
  */
 #define I915_EXEC_IS_PINNED  (1<<10)
 
-/** Provide a hint to the kernel that the command stream and auxilliary
+/** Provide a hint to the kernel that the command stream and auxiliary
  * state buffers already holds the correct presumed addresses and so the
  * relocation process may be skipped if no buffers need to be moved in
  * preparation for the execbuffer.
@@ -1030,4 +1032,21 @@ struct drm_i915_reg_read {
  __u64 offset;
  __u64 val; /* Return value */
 };
+
+struct drm_i915_reset_stats {
+ __u32 ctx_id;
+ __u32 flags;
+
+ /* All resets since boot/module reload, for all contexts */
+ __u32 reset_count;
+
+ /* Number of batches lost when active in GPU, for this context */
+ __u32 batch_active;
+
+ /* Number of batches lost pending for execution, for this context */
+ __u32 batch_pending;
+
+ __u32 pad;
+};
+
 #endif /* _UAPI_I915_DRM_H_ */
diff --git a/include/uapi/drm/radeon_drm.h b/include/uapi/drm/radeon_drm.h
index fe421e8..d9ea3a7 100644
--- a/include/uapi/drm/radeon_drm.h
+++ b/include/uapi/drm/radeon_drm.h
@@ -985,6 +985,8 @@ struct drm_radeon_cs {
 #define RADEON_INFO_CIK_MACROTILE_MODE_ARRAY 0x18
 /* query the number of render backends */
 #define RADEON_INFO_SI_BACKEND_ENABLED_MASK 0x19
+/* max engine clock - needed for OpenCL */
+#define RADEON_INFO_MAX_SCLK  0x1a
 
 
 struct drm_radeon_info {
diff --git a/include/uapi/drm/vmwgfx_drm.h b/include/uapi/drm/vmwgfx_drm.h
index f854ca4..87792a5 100644
--- a/include/uapi/drm/vmwgfx_drm.h
+++ b/include/uapi/drm/vmwgfx_drm.h
@@ -28,6 +28,10 @@
 #ifndef __VMWGFX_DRM_H__
 #define __VMWGFX_DRM_H__
 
+#ifndef __KERNEL__
+#include <drm.h>
+#endif
+
 #define DRM_VMW_MAX_SURFACE_FACES 6
 #define DRM_VMW_MAX_MIP_LEVELS 24
 
@@ -55,6 +59,11 @@
 #define DRM_VMW_PRESENT              18
 #define DRM_VMW_PRESENT_READBACK     19
 #define DRM_VMW_UPDATE_LAYOUT        20
+#define DRM_VMW_CREATE_SHADER        21
+#define DRM_VMW_UNREF_SHADER         22
+#define DRM_VMW_GB_SURFACE_CREATE    23
+#define DRM_VMW_GB_SURFACE_REF       24
+#define DRM_VMW_SYNCCPU              25
 
 /*************************************************************************/
 /**
@@ -76,6 +85,9 @@
 #define DRM_VMW_PARAM_MAX_FB_SIZE      5
 #define DRM_VMW_PARAM_FIFO_HW_VERSION  6
 #define DRM_VMW_PARAM_MAX_SURF_MEMORY  7
+#define DRM_VMW_PARAM_3D_CAPS_SIZE     8
+#define DRM_VMW_PARAM_MAX_MOB_MEMORY   9
+#define DRM_VMW_PARAM_MAX_MOB_SIZE     10
 
 /**
  * struct drm_vmw_getparam_arg
@@ -788,4 +800,253 @@ struct drm_vmw_update_layout_arg {
  uint64_t rects;
 };
 
+
+/*************************************************************************/
+/**
+ * DRM_VMW_CREATE_SHADER - Create shader
+ *
+ * Creates a shader and optionally binds it to a dma buffer containing
+ * the shader byte-code.
+ */
+
+/**
+ * enum drm_vmw_shader_type - Shader types
+ */
+enum drm_vmw_shader_type {
+ drm_vmw_shader_type_vs = 0,
+ drm_vmw_shader_type_ps,
+ drm_vmw_shader_type_gs
+};
+
+
+/**
+ * struct drm_vmw_shader_create_arg
+ *
+ * @shader_type: Shader type of the shader to create.
+ * @size: Size of the byte-code in bytes.
+ * where the shader byte-code starts
+ * @buffer_handle: Buffer handle identifying the buffer containing the
+ * shader byte-code
+ * @shader_handle: On successful completion contains a handle that
+ * can be used to subsequently identify the shader.
+ * @offset: Offset in bytes into the buffer given by @buffer_handle,
+ *
+ * Input / Output argument to the DRM_VMW_CREATE_SHADER Ioctl.
+ */
+struct drm_vmw_shader_create_arg {
+ enum drm_vmw_shader_type shader_type;
+ uint32_t size;
+ uint32_t buffer_handle;
+ uint32_t shader_handle;
+ uint64_t offset;
+};
+
+/*************************************************************************/
+/**
+ * DRM_VMW_UNREF_SHADER - Unreferences a shader
+ *
+ * Destroys a user-space reference to a shader, optionally destroying
+ * it.
+ */
+
+/**
+ * struct drm_vmw_shader_arg
+ *
+ * @handle: Handle identifying the shader to destroy.
+ *
+ * Input argument to the DRM_VMW_UNREF_SHADER ioctl.
+ */
+struct drm_vmw_shader_arg {
+ uint32_t handle;
+ uint32_t pad64;
+};
+
+/*************************************************************************/
+/**
+ * DRM_VMW_GB_SURFACE_CREATE - Create a host guest-backed surface.
+ *
+ * Allocates a surface handle and queues a create surface command
+ * for the host on the first use of the surface. The surface ID can
+ * be used as the surface ID in commands referencing the surface.
+ */
+
+/**
+ * enum drm_vmw_surface_flags
+ *
+ * @drm_vmw_surface_flag_shareable:     Whether the surface is shareable
+ * @drm_vmw_surface_flag_scanout:       Whether the surface is a scanout
+ *                                      surface.
+ * @drm_vmw_surface_flag_create_buffer: Create a backup buffer if none is
+ *                                      given.
+ */
+enum drm_vmw_surface_flags {
+ drm_vmw_surface_flag_shareable = (1 << 0),
+ drm_vmw_surface_flag_scanout = (1 << 1),
+ drm_vmw_surface_flag_create_buffer = (1 << 2)
+};
+
+/**
+ * struct drm_vmw_gb_surface_create_req
+ *
+ * @svga3d_flags:     SVGA3d surface flags for the device.
+ * @format:           SVGA3d format.
+ * @mip_level:        Number of mip levels for all faces.
+ * @drm_surface_flags Flags as described above.
+ * @multisample_count Future use. Set to 0.
+ * @autogen_filter    Future use. Set to 0.
+ * @buffer_handle     Buffer handle of backup buffer. SVGA3D_INVALID_ID
+ *                    if none.
+ * @base_size         Size of the base mip level for all faces.
+ *
+ * Input argument to the  DRM_VMW_GB_SURFACE_CREATE Ioctl.
+ * Part of output argument for the DRM_VMW_GB_SURFACE_REF Ioctl.
+ */
+struct drm_vmw_gb_surface_create_req {
+ uint32_t svga3d_flags;
+ uint32_t format;
+ uint32_t mip_levels;
+ enum drm_vmw_surface_flags drm_surface_flags;
+ uint32_t multisample_count;
+ uint32_t autogen_filter;
+ uint32_t buffer_handle;
+ uint32_t pad64;
+ struct drm_vmw_size base_size;
+};
+
+/**
+ * struct drm_vmw_gb_surface_create_rep
+ *
+ * @handle:            Surface handle.
+ * @backup_size:       Size of backup buffers for this surface.
+ * @buffer_handle:     Handle of backup buffer. SVGA3D_INVALID_ID if none.
+ * @buffer_size:       Actual size of the buffer identified by
+ *                     @buffer_handle
+ * @buffer_map_handle: Offset into device address space for the buffer
+ *                     identified by @buffer_handle.
+ *
+ * Part of output argument for the DRM_VMW_GB_SURFACE_REF ioctl.
+ * Output argument for the DRM_VMW_GB_SURFACE_CREATE ioctl.
+ */
+struct drm_vmw_gb_surface_create_rep {
+ uint32_t handle;
+ uint32_t backup_size;
+ uint32_t buffer_handle;
+ uint32_t buffer_size;
+ uint64_t buffer_map_handle;
+};
+
+/**
+ * union drm_vmw_gb_surface_create_arg
+ *
+ * @req: Input argument as described above.
+ * @rep: Output argument as described above.
+ *
+ * Argument to the DRM_VMW_GB_SURFACE_CREATE ioctl.
+ */
+union drm_vmw_gb_surface_create_arg {
+ struct drm_vmw_gb_surface_create_rep rep;
+ struct drm_vmw_gb_surface_create_req req;
+};
+
+/*************************************************************************/
+/**
+ * DRM_VMW_GB_SURFACE_REF - Reference a host surface.
+ *
+ * Puts a reference on a host surface with a given handle, as previously
+ * returned by the DRM_VMW_GB_SURFACE_CREATE ioctl.
+ * A reference will make sure the surface isn't destroyed while we hold
+ * it and will allow the calling client to use the surface handle in
+ * the command stream.
+ *
+ * On successful return, the Ioctl returns the surface information given
+ * to and returned from the DRM_VMW_GB_SURFACE_CREATE ioctl.
+ */
+
+/**
+ * struct drm_vmw_gb_surface_reference_arg
+ *
+ * @creq: The data used as input when the surface was created, as described
+ *        above at "struct drm_vmw_gb_surface_create_req"
+ * @crep: Additional data output when the surface was created, as described
+ *        above at "struct drm_vmw_gb_surface_create_rep"
+ *
+ * Output Argument to the DRM_VMW_GB_SURFACE_REF ioctl.
+ */
+struct drm_vmw_gb_surface_ref_rep {
+ struct drm_vmw_gb_surface_create_req creq;
+ struct drm_vmw_gb_surface_create_rep crep;
+};
+
+/**
+ * union drm_vmw_gb_surface_reference_arg
+ *
+ * @req: Input data as described above at "struct drm_vmw_surface_arg"
+ * @rep: Output data as described above at "struct drm_vmw_gb_surface_ref_rep"
+ *
+ * Argument to the DRM_VMW_GB_SURFACE_REF Ioctl.
+ */
+union drm_vmw_gb_surface_reference_arg {
+ struct drm_vmw_gb_surface_ref_rep rep;
+ struct drm_vmw_surface_arg req;
+};
+
+
+/*************************************************************************/
+/**
+ * DRM_VMW_SYNCCPU - Sync a DMA buffer / MOB for CPU access.
+ *
+ * Idles any previously submitted GPU operations on the buffer and
+ * by default blocks command submissions that reference the buffer.
+ * If the file descriptor used to grab a blocking CPU sync is closed, the
+ * cpu sync is released.
+ * The flags argument indicates how the grab / release operation should be
+ * performed:
+ */
+
+/**
+ * enum drm_vmw_synccpu_flags - Synccpu flags:
+ *
+ * @drm_vmw_synccpu_read: Sync for read. If sync is done for read only, it's a
+ * hint to the kernel to allow command submissions that references the buffer
+ * for read-only.
+ * @drm_vmw_synccpu_write: Sync for write. Block all command submissions
+ * referencing this buffer.
+ * @drm_vmw_synccpu_dontblock: Dont wait for GPU idle, but rather return
+ * -EBUSY should the buffer be busy.
+ * @drm_vmw_synccpu_allow_cs: Allow command submission that touches the buffer
+ * while the buffer is synced for CPU. This is similar to the GEM bo idle
+ * behavior.
+ */
+enum drm_vmw_synccpu_flags {
+ drm_vmw_synccpu_read = (1 << 0),
+ drm_vmw_synccpu_write = (1 << 1),
+ drm_vmw_synccpu_dontblock = (1 << 2),
+ drm_vmw_synccpu_allow_cs = (1 << 3)
+};
+
+/**
+ * enum drm_vmw_synccpu_op - Synccpu operations:
+ *
+ * @drm_vmw_synccpu_grab:    Grab the buffer for CPU operations
+ * @drm_vmw_synccpu_release: Release a previous grab.
+ */
+enum drm_vmw_synccpu_op {
+ drm_vmw_synccpu_grab,
+ drm_vmw_synccpu_release
+};
+
+/**
+ * struct drm_vmw_synccpu_arg
+ *
+ * @op:        The synccpu operation as described above.
+ * @handle:       Handle identifying the buffer object.
+ * @flags:       Flags as described above.
+ */
+struct drm_vmw_synccpu_arg {
+ enum drm_vmw_synccpu_op op;
+ enum drm_vmw_synccpu_flags flags;
+ uint32_t handle;
+ uint32_t pad64;
+};
+
 #endif
-- 
1.7.1