From 0df09d0e619abb31258c70c910e14e27566b002c Mon Sep 17 00:00:00 2001
From: Don Zickus <dzickus@redhat.com>
Date: Fri, 12 Sep 2014 18:09:35 -0400
Subject: [virt] kvm/ppc: book3s hv - Add new state for transactional memory

Message-id: <1410545655-205645-347-git-send-email-dzickus@redhat.com>
Patchwork-id: 94556
O-Subject: [RHEL7 PATCH 346/626] KVM: PPC: Book3S HV: Add new state for transactional memory
Bugzilla: 1127366
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: David Gibson <dgibson@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1127366

commit 7b490411c37f7ab7965cbdfe5e3ec28eadb6db5b
Author: Michael Neuling <mikey@neuling.org>
Date:   Wed Jan 8 21:25:32 2014 +1100

    KVM: PPC: Book3S HV: Add new state for transactional memory

    Add new state for transactional memory (TM) to kvm_vcpu_arch.  Also add
    asm-offset bits that are going to be required.

    This also moves the existing TFHAR, TFIAR and TEXASR SPRs into a
    CONFIG_PPC_TRANSACTIONAL_MEM section.  This requires some code changes to
    ensure we still compile with CONFIG_PPC_TRANSACTIONAL_MEM=N.  Much of the added
    the added #ifdefs are removed in a later patch when the bulk of the TM code is
    added.

    Signed-off-by: Michael Neuling <mikey@neuling.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    [agraf: fix merge conflict]
    Signed-off-by: Alexander Graf <agraf@suse.de>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/include/asm/kvm_host.h b/arch/powerpc/include/asm/kvm_host.h
index 69e0134..8ca6611 100644
--- a/arch/powerpc/include/asm/kvm_host.h
+++ b/arch/powerpc/include/asm/kvm_host.h
@@ -490,9 +490,6 @@ struct kvm_vcpu_arch {
  ulong ppr;
  ulong pspb;
  ulong fscr;
- ulong tfhar;
- ulong tfiar;
- ulong texasr;
  ulong ebbhr;
  ulong ebbrr;
  ulong bescr;
@@ -541,6 +538,27 @@ struct kvm_vcpu_arch {
  u64 siar;
  u64 sdar;
  u64 sier;
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+ u64 tfhar;
+ u64 texasr;
+ u64 tfiar;
+
+ u32 cr_tm;
+ u64 lr_tm;
+ u64 ctr_tm;
+ u64 amr_tm;
+ u64 ppr_tm;
+ u64 dscr_tm;
+ u64 tar_tm;
+
+ ulong gpr_tm[32];
+
+ struct thread_fp_state fp_tm;
+
+ struct thread_vr_state vr_tm;
+ u32 vrsave_tm; /* also USPRG0 */
+
+#endif
 
 #ifdef CONFIG_KVM_EXIT_TIMING
  struct mutex exit_timing_lock;
diff --git a/arch/powerpc/kernel/asm-offsets.c b/arch/powerpc/kernel/asm-offsets.c
index d6f215a..09f57df 100644
--- a/arch/powerpc/kernel/asm-offsets.c
+++ b/arch/powerpc/kernel/asm-offsets.c
@@ -523,9 +523,6 @@ int main(void)
  DEFINE(VCPU_PPR, offsetof(struct kvm_vcpu, arch.ppr));
  DEFINE(VCPU_FSCR, offsetof(struct kvm_vcpu, arch.fscr));
  DEFINE(VCPU_PSPB, offsetof(struct kvm_vcpu, arch.pspb));
- DEFINE(VCPU_TFHAR, offsetof(struct kvm_vcpu, arch.tfhar));
- DEFINE(VCPU_TFIAR, offsetof(struct kvm_vcpu, arch.tfiar));
- DEFINE(VCPU_TEXASR, offsetof(struct kvm_vcpu, arch.texasr));
  DEFINE(VCPU_EBBHR, offsetof(struct kvm_vcpu, arch.ebbhr));
  DEFINE(VCPU_EBBRR, offsetof(struct kvm_vcpu, arch.ebbrr));
  DEFINE(VCPU_BESCR, offsetof(struct kvm_vcpu, arch.bescr));
@@ -547,6 +544,22 @@ int main(void)
  DEFINE(VCPU_SLB_E, offsetof(struct kvmppc_slb, orige));
  DEFINE(VCPU_SLB_V, offsetof(struct kvmppc_slb, origv));
  DEFINE(VCPU_SLB_SIZE, sizeof(struct kvmppc_slb));
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+ DEFINE(VCPU_TFHAR, offsetof(struct kvm_vcpu, arch.tfhar));
+ DEFINE(VCPU_TFIAR, offsetof(struct kvm_vcpu, arch.tfiar));
+ DEFINE(VCPU_TEXASR, offsetof(struct kvm_vcpu, arch.texasr));
+ DEFINE(VCPU_GPR_TM, offsetof(struct kvm_vcpu, arch.gpr_tm));
+ DEFINE(VCPU_FPRS_TM, offsetof(struct kvm_vcpu, arch.fp_tm.fpr));
+ DEFINE(VCPU_VRS_TM, offsetof(struct kvm_vcpu, arch.vr_tm.vr));
+ DEFINE(VCPU_VRSAVE_TM, offsetof(struct kvm_vcpu, arch.vrsave_tm));
+ DEFINE(VCPU_CR_TM, offsetof(struct kvm_vcpu, arch.cr_tm));
+ DEFINE(VCPU_LR_TM, offsetof(struct kvm_vcpu, arch.lr_tm));
+ DEFINE(VCPU_CTR_TM, offsetof(struct kvm_vcpu, arch.ctr_tm));
+ DEFINE(VCPU_AMR_TM, offsetof(struct kvm_vcpu, arch.amr_tm));
+ DEFINE(VCPU_PPR_TM, offsetof(struct kvm_vcpu, arch.ppr_tm));
+ DEFINE(VCPU_DSCR_TM, offsetof(struct kvm_vcpu, arch.dscr_tm));
+ DEFINE(VCPU_TAR_TM, offsetof(struct kvm_vcpu, arch.tar_tm));
+#endif
 
 #ifdef CONFIG_PPC_BOOK3S_64
 #ifdef CONFIG_KVM_BOOK3S_PR_POSSIBLE
diff --git a/arch/powerpc/kvm/book3s_hv.c b/arch/powerpc/kvm/book3s_hv.c
index ede6ec1..be0c7f4 100644
--- a/arch/powerpc/kvm/book3s_hv.c
+++ b/arch/powerpc/kvm/book3s_hv.c
@@ -851,6 +851,7 @@ static int kvmppc_get_one_reg_hv(struct kvm_vcpu *vcpu, u64 id,
  case KVM_REG_PPC_IAMR:
   *val = get_reg_val(id, vcpu->arch.iamr);
   break;
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
  case KVM_REG_PPC_TFHAR:
   *val = get_reg_val(id, vcpu->arch.tfhar);
   break;
@@ -860,6 +861,7 @@ static int kvmppc_get_one_reg_hv(struct kvm_vcpu *vcpu, u64 id,
  case KVM_REG_PPC_TEXASR:
   *val = get_reg_val(id, vcpu->arch.texasr);
   break;
+#endif
  case KVM_REG_PPC_FSCR:
   *val = get_reg_val(id, vcpu->arch.fscr);
   break;
@@ -1006,6 +1008,7 @@ static int kvmppc_set_one_reg_hv(struct kvm_vcpu *vcpu, u64 id,
  case KVM_REG_PPC_IAMR:
   vcpu->arch.iamr = set_reg_val(id, *val);
   break;
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
  case KVM_REG_PPC_TFHAR:
   vcpu->arch.tfhar = set_reg_val(id, *val);
   break;
@@ -1015,6 +1018,7 @@ static int kvmppc_set_one_reg_hv(struct kvm_vcpu *vcpu, u64 id,
  case KVM_REG_PPC_TEXASR:
   vcpu->arch.texasr = set_reg_val(id, *val);
   break;
+#endif
  case KVM_REG_PPC_FSCR:
   vcpu->arch.fscr = set_reg_val(id, *val);
   break;
diff --git a/arch/powerpc/kvm/book3s_hv_rmhandlers.S b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
index e3e8224..334668d 100644
--- a/arch/powerpc/kvm/book3s_hv_rmhandlers.S
+++ b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
@@ -705,13 +705,15 @@ END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_207S)
  ld r6, VCPU_VTB(r4)
  mtspr SPRN_IC, r5
  mtspr SPRN_VTB, r6
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
  ld r5, VCPU_TFHAR(r4)
  ld r6, VCPU_TFIAR(r4)
  ld r7, VCPU_TEXASR(r4)
- ld r8, VCPU_EBBHR(r4)
  mtspr SPRN_TFHAR, r5
  mtspr SPRN_TFIAR, r6
  mtspr SPRN_TEXASR, r7
+#endif
+ ld r8, VCPU_EBBHR(r4)
  mtspr SPRN_EBBHR, r8
  ld r5, VCPU_EBBRR(r4)
  ld r6, VCPU_BESCR(r4)
@@ -1122,13 +1124,15 @@ END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_207S)
  std r5, VCPU_IC(r9)
  std r6, VCPU_VTB(r9)
  std r7, VCPU_TAR(r9)
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
  mfspr r5, SPRN_TFHAR
  mfspr r6, SPRN_TFIAR
  mfspr r7, SPRN_TEXASR
- mfspr r8, SPRN_EBBHR
  std r5, VCPU_TFHAR(r9)
  std r6, VCPU_TFIAR(r9)
  std r7, VCPU_TEXASR(r9)
+#endif
+ mfspr r8, SPRN_EBBHR
  std r8, VCPU_EBBHR(r9)
  mfspr r5, SPRN_EBBRR
  mfspr r6, SPRN_BESCR
@@ -1502,6 +1506,73 @@ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_207S)
 1: addi r8,r8,16
  .endr
 
+ /* Save DEC */
+ mfspr r5,SPRN_DEC
+ mftb r6
+ extsw r5,r5
+ add r5,r5,r6
+ std r5,VCPU_DEC_EXPIRES(r9)
+
+BEGIN_FTR_SECTION
+ b 8f
+END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_207S)
+ /* Turn on TM so we can access TFHAR/TFIAR/TEXASR */
+ mfmsr r8
+ li r0, 1
+ rldimi r8, r0, MSR_TM_LG, 63-MSR_TM_LG
+ mtmsrd r8
+
+ /* Save POWER8-specific registers */
+ mfspr r5, SPRN_IAMR
+ mfspr r6, SPRN_PSPB
+ mfspr r7, SPRN_FSCR
+ std r5, VCPU_IAMR(r9)
+ stw r6, VCPU_PSPB(r9)
+ std r7, VCPU_FSCR(r9)
+ mfspr r5, SPRN_IC
+ mfspr r6, SPRN_VTB
+ mfspr r7, SPRN_TAR
+ std r5, VCPU_IC(r9)
+ std r6, VCPU_VTB(r9)
+ std r7, VCPU_TAR(r9)
+#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+ mfspr r5, SPRN_TFHAR
+ mfspr r6, SPRN_TFIAR
+ mfspr r7, SPRN_TEXASR
+ std r5, VCPU_TFHAR(r9)
+ std r6, VCPU_TFIAR(r9)
+ std r7, VCPU_TEXASR(r9)
+#endif
+ mfspr r8, SPRN_EBBHR
+ std r8, VCPU_EBBHR(r9)
+ mfspr r5, SPRN_EBBRR
+ mfspr r6, SPRN_BESCR
+ mfspr r7, SPRN_CSIGR
+ mfspr r8, SPRN_TACR
+ std r5, VCPU_EBBRR(r9)
+ std r6, VCPU_BESCR(r9)
+ std r7, VCPU_CSIGR(r9)
+ std r8, VCPU_TACR(r9)
+ mfspr r5, SPRN_TCSCR
+ mfspr r6, SPRN_ACOP
+ mfspr r7, SPRN_PID
+ mfspr r8, SPRN_WORT
+ std r5, VCPU_TCSCR(r9)
+ std r6, VCPU_ACOP(r9)
+ stw r7, VCPU_GUEST_PID(r9)
+ std r8, VCPU_WORT(r9)
+8:
+
+ /* Save and reset AMR and UAMOR before turning on the MMU */
+BEGIN_FTR_SECTION
+ mfspr r5,SPRN_AMR
+ mfspr r6,SPRN_UAMOR
+ std r5,VCPU_AMR(r9)
+ std r6,VCPU_UAMOR(r9)
+ li r6,0
+ mtspr SPRN_AMR,r6
+END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206)
+
  /* Unset guest mode */
  li r0, KVM_GUEST_MODE_NONE
  stb r0, HSTATE_IN_GUEST(r13)
-- 
1.7.1