From 8332922a0c3d6bacb3185e8d8267973ab64d272e Mon Sep 17 00:00:00 2001
From: Jiri Benc <jbenc@redhat.com>
Date: Wed, 7 Jan 2015 10:56:56 -0500
Subject: [net] net_dma: revert 'copied_early'

Message-id: <42495700a42936c3f1fc9e254da3da186249bc40.1420627472.git.jbenc@redhat.com>
Patchwork-id: 102512
O-Subject: [RHEL7.1 net PATCH 3/5] net_dma: revert 'copied_early'
Bugzilla: 1173444
RH-Acked-by: Jiri Pirko <jpirko@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: Don Zickus <dzickus@redhat.com>
RH-Acked-by: Kyle McMartin <kmcmarti@redhat.com>
RH-Acked-by: Alex Williamson <alex.williamson@redhat.com>
RH-Acked-by: Myron Stowe <mstowe@redhat.com>

Bugzilla: https://bugzilla.redhat.com/show_bug.cgi?id=1173444
Brew: https://brewweb.devel.redhat.com/taskinfo?taskID=8460333

commit d27f9bc104375a0a835cf68bb88fc9cec69125da
Author: Dan Williams <dan.j.williams@intel.com>
Date:   Mon Dec 30 11:37:15 2013 -0800

    net_dma: revert 'copied_early'

    Now that tcp_dma_try_early_copy() is gone nothing ever sets
    copied_early.

    Also reverts "53240c208776 tcp: Fix possible double-ack w/ user dma"
    since it is no longer necessary.

    Cc: Ali Saidi <saidi@engin.umich.edu>
    Cc: James Morris <jmorris@namei.org>
    Cc: Patrick McHardy <kaber@trash.net>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Cc: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    Cc: Neal Cardwell <ncardwell@google.com>
    Reported-by: Dave Jones <davej@redhat.com>
    Acked-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

Signed-off-by: Jiri Benc <jbenc@redhat.com>
Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
index a7ca55e..6896f0d 100644
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@ -5148,19 +5148,15 @@ int tcp_rcv_established(struct sock *sk, struct sk_buff *skb,
    }
   } else {
    int eaten = 0;
-   int copied_early = 0;
    bool fragstolen = false;
 
-   if (tp->copied_seq == tp->rcv_nxt &&
-       len - tcp_header_len <= tp->ucopy.len) {
-    if (tp->ucopy.task == current &&
-        sock_owned_by_user(sk) && !copied_early) {
-     __set_current_state(TASK_RUNNING);
+   if (tp->ucopy.task == current &&
+       tp->copied_seq == tp->rcv_nxt &&
+       len - tcp_header_len <= tp->ucopy.len &&
+       sock_owned_by_user(sk)) {
+    __set_current_state(TASK_RUNNING);
 
-     if (!tcp_copy_to_iovec(sk, skb, tcp_header_len))
-      eaten = 1;
-    }
-    if (eaten) {
+    if (!tcp_copy_to_iovec(sk, skb, tcp_header_len)) {
      /* Predicted packet is in window by definition.
       * seq == rcv_nxt and rcv_wup <= rcv_nxt.
       * Hence, check seq<=rcv_wup reduces to:
@@ -5176,9 +5172,8 @@ int tcp_rcv_established(struct sock *sk, struct sk_buff *skb,
      __skb_pull(skb, tcp_header_len);
      tp->rcv_nxt = TCP_SKB_CB(skb)->end_seq;
      NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPHPHITSTOUSER);
+     eaten = 1;
     }
-    if (copied_early)
-     tcp_cleanup_rbuf(sk, skb->len);
    }
    if (!eaten) {
     if (tcp_checksum_complete_user(sk, skb))
@@ -5215,8 +5210,7 @@ int tcp_rcv_established(struct sock *sk, struct sk_buff *skb,
      goto no_ack;
    }
 
-   if (!copied_early || tp->rcv_nxt != tp->rcv_wup)
-    __tcp_ack_snd_check(sk, 0);
+   __tcp_ack_snd_check(sk, 0);
 no_ack:
    if (eaten)
     kfree_skb_partial(skb, fragstolen);
-- 
1.7.1