From d92548b1df87cefb0c2b4ed5576605a28e5a8156 Mon Sep 17 00:00:00 2001
From: Amir Vadai <avadai@redhat.com>
Date: Thu, 11 Sep 2014 11:59:39 -0400
Subject: [ethernet] mlx4: call gro handler for encapsulated frames

Message-id: <f8c8dd93da92cd3491ed70e9599d17236f34082d.1410425016.git.avadai@redhat.com>
Patchwork-id: 93610
O-Subject: [Patch RHEL7.1 V1 043/197] net/mlx4_en: call gro handler for encapsulated frames
Bugzilla: 1107617 1107618 1107619 1107620
RH-Acked-by: Jes Sorensen <Jes.Sorensen@redhat.com>

From: Eric Dumazet <edumazet@google.com>

In order to use the native GRO handling of encapsulated protocols on
mlx4, we need to call napi_gro_receive() instead of netif_receive_skb()
unless busy polling is in action.

While we are at it, rename mlx4_en_cq_ll_polling() to
mlx4_en_cq_busy_polling()

Tested with GRE tunnel : GRO aggregation is now performed on the
ethernet device instead of being done later on gre device.

Signed-off-by: Eric Dumazet <edumazet@google.com>
Cc: Amir Vadai <amirv@mellanox.com>
Cc: Jerry Chu <hkchu@google.com>
Cc: Or Gerlitz <ogerlitz@mellanox.com>
Acked-By: Amir Vadai <amirv@mellanox.com>
Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit e6a767582942d6fd9da0ddea673f5a7017a365c7)
Signed-off-by: Amir Vadai <avadai@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/drivers/net/ethernet/mellanox/mlx4/en_rx.c b/drivers/net/ethernet/mellanox/mlx4/en_rx.c
index 0fd1e1c..1e3dd02 100644
--- a/drivers/net/ethernet/mellanox/mlx4/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_rx.c
@@ -723,7 +723,7 @@ int mlx4_en_process_rx_cq(struct net_device *dev, struct mlx4_en_cq *cq, int bud
      * - not an IP fragment
      * - no LLS polling in progress
      */
-    if (!mlx4_en_cq_ll_polling(cq) &&
+    if (!mlx4_en_cq_busy_polling(cq) &&
         (dev->features & NETIF_F_GRO)) {
      struct sk_buff *gro_skb = napi_get_frags(&cq->napi);
      if (!gro_skb)
@@ -815,8 +815,10 @@ int mlx4_en_process_rx_cq(struct net_device *dev, struct mlx4_en_cq *cq, int bud
 
   skb_mark_napi_id(skb, &cq->napi);
 
-  /* Push it up the stack */
-  netif_receive_skb(skb);
+  if (!mlx4_en_cq_busy_polling(cq))
+   napi_gro_receive(&cq->napi, skb);
+  else
+   netif_receive_skb(skb);
 
 next:
   for (nr = 0; nr < priv->num_frags; nr++)
diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index 2f1e200..fe7bdfe 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -661,7 +661,7 @@ static inline bool mlx4_en_cq_unlock_poll(struct mlx4_en_cq *cq)
 }
 
 /* true if a socket is polling, even if it did not get the lock */
-static inline bool mlx4_en_cq_ll_polling(struct mlx4_en_cq *cq)
+static inline bool mlx4_en_cq_busy_polling(struct mlx4_en_cq *cq)
 {
  WARN_ON(!(cq->state & MLX4_CQ_LOCKED));
  return cq->state & CQ_USER_PEND;
@@ -691,7 +691,7 @@ static inline bool mlx4_en_cq_unlock_poll(struct mlx4_en_cq *cq)
  return false;
 }
 
-static inline bool mlx4_en_cq_ll_polling(struct mlx4_en_cq *cq)
+static inline bool mlx4_en_cq_busy_polling(struct mlx4_en_cq *cq)
 {
  return false;
 }
-- 
1.7.1