From d7270175133e84bd393fb95ae5c1a8e212afffaf Mon Sep 17 00:00:00 2001
From: Don Zickus <dzickus@redhat.com>
Date: Fri, 12 Sep 2014 18:08:22 -0400
Subject: [powerpc] Implement arch_spin_is_locked() using arch_spin_value_unlocked()

Message-id: <1410545655-205645-274-git-send-email-dzickus@redhat.com>
Patchwork-id: 94296
O-Subject: [RHEL7 PATCH 273/626] powerpc: Implement arch_spin_is_locked() using arch_spin_value_unlocked()
Bugzilla: 1127366
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: David Gibson <dgibson@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1127366

commit 7179ba52889bef7e5e23f72908270e1ab2b7fc6f
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Jan 15 18:14:29 2014 +1100

    powerpc: Implement arch_spin_is_locked() using arch_spin_value_unlocked()

    At a glance these are just the inverse of each other. The one subtlety
    is that arch_spin_value_unlocked() takes the lock by value, rather than
    as a pointer, which is important for the lockref code.

    On the other hand arch_spin_is_locked() doesn't really care, so
    implement it in terms of arch_spin_value_unlocked().

    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/include/asm/spinlock.h b/arch/powerpc/include/asm/spinlock.h
index 2ef3cc8..35aa339 100644
--- a/arch/powerpc/include/asm/spinlock.h
+++ b/arch/powerpc/include/asm/spinlock.h
@@ -30,8 +30,6 @@
 
 #define smp_mb__after_unlock_lock() smp_mb()  /* Full ordering for lock. */
 
-#define arch_spin_is_locked(x)  ((x)->slock != 0)
-
 #ifdef CONFIG_PPC64
 /* use 0x800000yy when locked, where yy == CPU number */
 #ifdef __BIG_ENDIAN__
@@ -61,6 +59,11 @@ static __always_inline int arch_spin_value_unlocked(arch_spinlock_t lock)
  return lock.slock == 0;
 }
 
+static inline int arch_spin_is_locked(arch_spinlock_t *lock)
+{
+ return !arch_spin_value_unlocked(*lock);
+}
+
 /*
  * This returns the old value in the lock, so we succeeded
  * in getting the lock if the return value is 0.
-- 
1.7.1