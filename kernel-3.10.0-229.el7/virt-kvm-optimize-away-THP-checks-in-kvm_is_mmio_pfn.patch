From 6a57bed358597e5eae6b9ecb1a2fbf12deaadf6c Mon Sep 17 00:00:00 2001
From: Paolo Bonzini <pbonzini@redhat.com>
Date: Tue, 22 Jul 2014 14:36:41 -0400
Subject: [virt] kvm: optimize away THP checks in kvm_is_mmio_pfn()

Message-id: <1406040016-3289-7-git-send-email-pbonzini@redhat.com>
Patchwork-id: 86085
O-Subject: [RHEL7 PATCH v2 006/221] kvm: optimize away THP checks in kvm_is_mmio_pfn()
Bugzilla: 1116936
RH-Acked-by: Radim Krcmar <rkrcmar@redhat.com>
RH-Acked-by: Bandan Das <bsd@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>

From: Andrea Arcangeli <aarcange@redhat.com>

The checks on PG_reserved in the page structure on head and tail pages
aren't necessary because split_huge_page wouldn't transfer the
PG_reserved bit from head to tail anyway.

This was a forward-thinking check done in the case PageReserved was
set by a driver-owned page mapped in userland with something like
remap_pfn_range in a VM_PFNMAP region, but using hugepmds (not
possible right now). It was meant to be very safe, but it's overkill
as it's unlikely split_huge_page could ever run without the driver
noticing and tearing down the hugepage itself.

And if a driver in the future will really want to map a reserved
hugepage in userland using an huge pmd it should simply take care of
marking all subpages reserved too to keep KVM safe. This of course
would require such a hypothetical driver to tear down the huge pmd
itself and splitting the hugepage itself, instead of relaying on
split_huge_page, but that sounds very reasonable, especially
considering split_huge_page wouldn't currently transfer the reserved
bit anyway.

Signed-off-by: Andrea Arcangeli <aarcange@redhat.com>
Signed-off-by: Gleb Natapov <gleb@redhat.com>
(cherry picked from commit 11feeb498086a3a5907b8148bdf1786a9b18fc55)
Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index c9705e2..a0e7412 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -102,28 +102,8 @@ static bool largepages_enabled = true;
 
 bool kvm_is_mmio_pfn(pfn_t pfn)
 {
- if (pfn_valid(pfn)) {
-  int reserved;
-  struct page *tail = pfn_to_page(pfn);
-  struct page *head = compound_trans_head(tail);
-  reserved = PageReserved(head);
-  if (head != tail) {
-   /*
-    * "head" is not a dangling pointer
-    * (compound_trans_head takes care of that)
-    * but the hugepage may have been splitted
-    * from under us (and we may not hold a
-    * reference count on the head page so it can
-    * be reused before we run PageReferenced), so
-    * we've to check PageTail before returning
-    * what we just read.
-    */
-   smp_rmb();
-   if (PageTail(tail))
-    return reserved;
-  }
-  return PageReserved(tail);
- }
+ if (pfn_valid(pfn))
+  return PageReserved(pfn_to_page(pfn));
 
  return true;
 }
-- 
1.7.1