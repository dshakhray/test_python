From c32fe581cd7c444aa818864f29664f4d3ea65ce1 Mon Sep 17 00:00:00 2001
From: Prarit Bhargava <prarit@redhat.com>
Date: Thu, 28 Aug 2014 14:22:10 -0400
Subject: [cpufreq] Invoke __cpufreq_remove_dev_finish() after releasing cpu_hotplug.lock

Message-id: <1409235879-1283-37-git-send-email-prarit@redhat.com>
Patchwork-id: 89380
O-Subject: [RHEL7.1 PATCH BZ 1134639 036/185] cpufreq: Invoke __cpufreq_remove_dev_finish() after releasing cpu_hotplug.lock
Bugzilla: 1134369
RH-Acked-by: Stefan Assmann <sassmann@redhat.com>
RH-Acked-by: Mark Langsdorf <mlangsdo@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>

Bugzilla: https://bugzilla.redhat.com/show_bug.cgi?id=1134639

commit 1aee40ac9c86759c05f2ceb4523642b22fc8ea36
Author: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
Date:   Sat Sep 7 01:23:27 2013 +0530

    cpufreq: Invoke __cpufreq_remove_dev_finish() after releasing cpu_hotplug.lock

    __cpufreq_remove_dev_finish() handles the kobject cleanup for a CPU going
    offline. But because we destroy the kobject towards the end of the CPU offline
    phase, there are certain race windows where a task can try to write to a
    cpufreq sysfs file (eg: using store_scaling_max_freq()) while we are taking
    that CPU offline, and this can bump up the kobject refcount, which in turn might
    hinder the CPU offline task from running to completion. (It can also cause
    other more serious problems such as trying to acquire a destroyed timer-mutex
    etc., depending on the exact stage of the cleanup at which the task managed to
    take a new refcount).

    To fix the race window, we will need to synchronize those store_*() call-sites
    with CPU hotplug, using get_online_cpus()/put_online_cpus(). However, that
    in turn can cause a total deadlock because it can end up waiting for the
    CPU offline task to complete, with incremented refcount!

    Write to sysfs                            CPU offline task
    --------------                            ----------------
    kobj_refcnt++

                                              Acquire cpu_hotplug.lock

    get_online_cpus();

           Wait for kobj_refcnt to drop to zero

                         **DEADLOCK**

    A simple way to avoid this problem is to perform the kobject cleanup in the
    CPU offline path, with the cpu_hotplug.lock *released*. That is, we can
    perform the wait-for-kobj-refcnt-to-drop as well as the subsequent cleanup
    in the CPU_POST_DEAD stage of CPU offline, which is run with cpu_hotplug.lock
    released. Doing this helps us avoid deadlocks due to holding kobject refcounts
    and waiting on each other on the cpu_hotplug.lock.

    (Note: We can't move all of the cpufreq CPU offline steps to the
    CPU_POST_DEAD stage, because certain things such as stopping the governors
    have to be done before the outgoing CPU is marked offline. So retain those
    parts in the CPU_DOWN_PREPARE stage itself).

    Reported-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

Cc: Lenny Szubowicz <lszubowi@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/drivers/cpufreq/cpufreq.c b/drivers/cpufreq/cpufreq.c
index 6ed11d1..c938fd1 100644
--- a/drivers/cpufreq/cpufreq.c
+++ b/drivers/cpufreq/cpufreq.c
@@ -2049,6 +2049,9 @@ static int cpufreq_cpu_callback(struct notifier_block *nfb,
 
   case CPU_DOWN_PREPARE:
    __cpufreq_remove_dev_prepare(dev, NULL, frozen);
+   break;
+
+  case CPU_POST_DEAD:
    __cpufreq_remove_dev_finish(dev, NULL, frozen);
    break;
 
-- 
1.7.1