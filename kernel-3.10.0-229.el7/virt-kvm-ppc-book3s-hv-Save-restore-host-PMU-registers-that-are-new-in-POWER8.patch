From 7b5c08d21341958e6104d50382aa37f59a121648 Mon Sep 17 00:00:00 2001
From: Don Zickus <dzickus@redhat.com>
Date: Fri, 12 Sep 2014 18:09:44 -0400
Subject: [virt] kvm/ppc: book3s hv - Save/restore host PMU registers that are new in POWER8

Message-id: <1410545655-205645-356-git-send-email-dzickus@redhat.com>
Patchwork-id: 94364
O-Subject: [RHEL7 PATCH 355/626] KVM: PPC: Book3S HV: Save/restore host PMU registers that are new in POWER8
Bugzilla: 1127366
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: David Gibson <dgibson@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1127366

commit 72cde5a88d37ba88ad1d47aecf957a9e528636d7
Author: Paul Mackerras <paulus@samba.org>
Date:   Tue Mar 25 10:47:08 2014 +1100

    KVM: PPC: Book3S HV: Save/restore host PMU registers that are new in POWER8

    Currently we save the host PMU configuration, counter values, etc.,
    when entering a guest, and restore it on return from the guest.
    (We have to do this because the guest has control of the PMU while
    it is executing.)  However, we missed saving/restoring the SIAR and
    SDAR registers, as well as the registers which are new on POWER8,
    namely SIER and MMCR2.

    This adds code to save the values of these registers when entering
    the guest and restore them on exit.  This also works around the bug
    in POWER8 where setting PMAE with a counter already negative doesn't
    generate an interrupt.

    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Acked-by: Scott Wood <scottwood@freescale.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/include/asm/kvm_book3s_asm.h b/arch/powerpc/include/asm/kvm_book3s_asm.h
index 98f20c9..b0c8ed5 100644
--- a/arch/powerpc/include/asm/kvm_book3s_asm.h
+++ b/arch/powerpc/include/asm/kvm_book3s_asm.h
@@ -94,7 +94,7 @@ struct kvmppc_host_state {
  unsigned long xics_phys;
  u32 saved_xirr;
  u64 dabr;
- u64 host_mmcr[3];
+ u64 host_mmcr[7]; /* MMCR 0,1,A, SIAR, SDAR, MMCR2, SIER */
  u32 host_pmc[8];
  u64 host_purr;
  u64 host_spurr;
diff --git a/arch/powerpc/kvm/book3s_hv_interrupts.S b/arch/powerpc/kvm/book3s_hv_interrupts.S
index e873796..e18e3cf 100644
--- a/arch/powerpc/kvm/book3s_hv_interrupts.S
+++ b/arch/powerpc/kvm/book3s_hv_interrupts.S
@@ -71,6 +71,14 @@ END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_207S)
  mtmsrd  r10,1
 
  /* Save host PMU registers */
+BEGIN_FTR_SECTION
+ /* Work around P8 PMAE bug */
+ li r3, -1
+ clrrdi r3, r3, 10
+ mfspr r8, SPRN_MMCR2
+ mtspr SPRN_MMCR2, r3  /* freeze all counters using MMCR2 */
+ isync
+END_FTR_SECTION_IFSET(CPU_FTR_ARCH_207S)
  li r3, 1
  sldi r3, r3, 31  /* MMCR0_FC (freeze counters) bit */
  mfspr r7, SPRN_MMCR0  /* save MMCR0 */
@@ -87,9 +95,18 @@ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206)
  cmpwi r5, 0
  beq 31f   /* skip if not */
  mfspr r5, SPRN_MMCR1
+ mfspr r9, SPRN_SIAR
+ mfspr r10, SPRN_SDAR
  std r7, HSTATE_MMCR(r13)
  std r5, HSTATE_MMCR + 8(r13)
  std r6, HSTATE_MMCR + 16(r13)
+ std r9, HSTATE_MMCR + 24(r13)
+ std r10, HSTATE_MMCR + 32(r13)
+BEGIN_FTR_SECTION
+ mfspr r9, SPRN_SIER
+ std r8, HSTATE_MMCR + 40(r13)
+ std r9, HSTATE_MMCR + 48(r13)
+END_FTR_SECTION_IFSET(CPU_FTR_ARCH_207S)
  mfspr r3, SPRN_PMC1
  mfspr r5, SPRN_PMC2
  mfspr r6, SPRN_PMC3
@@ -110,6 +127,11 @@ BEGIN_FTR_SECTION
  stw r10, HSTATE_PMC + 24(r13)
  stw r11, HSTATE_PMC + 28(r13)
 END_FTR_SECTION_IFSET(CPU_FTR_ARCH_201)
+BEGIN_FTR_SECTION
+ mfspr r9, SPRN_SIER
+ std r8, HSTATE_MMCR + 40(r13)
+ std r9, HSTATE_MMCR + 48(r13)
+END_FTR_SECTION_IFSET(CPU_FTR_ARCH_207S)
 31:
 
  /*
diff --git a/arch/powerpc/kvm/book3s_hv_rmhandlers.S b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
index 26014f6..96236ff 100644
--- a/arch/powerpc/kvm/book3s_hv_rmhandlers.S
+++ b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
@@ -106,8 +106,18 @@ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_201)
  ld r3, HSTATE_MMCR(r13)
  ld r4, HSTATE_MMCR + 8(r13)
  ld r5, HSTATE_MMCR + 16(r13)
+ ld r6, HSTATE_MMCR + 24(r13)
+ ld r7, HSTATE_MMCR + 32(r13)
  mtspr SPRN_MMCR1, r4
  mtspr SPRN_MMCRA, r5
+ mtspr SPRN_SIAR, r6
+ mtspr SPRN_SDAR, r7
+BEGIN_FTR_SECTION
+ ld r8, HSTATE_MMCR + 40(r13)
+ ld r9, HSTATE_MMCR + 48(r13)
+ mtspr SPRN_MMCR2, r8
+ mtspr SPRN_SIER, r9
+END_FTR_SECTION_IFSET(CPU_FTR_ARCH_207S)
  mtspr SPRN_MMCR0, r3
  isync
 23:
-- 
1.7.1