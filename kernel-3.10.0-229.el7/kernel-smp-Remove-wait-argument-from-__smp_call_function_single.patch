From 08fe3163295b93c4f14ef4a7931cab2474777100 Mon Sep 17 00:00:00 2001
From: Prarit Bhargava <prarit@redhat.com>
Date: Wed, 11 Jun 2014 11:53:13 -0400
Subject: [kernel] smp: Remove wait argument from __smp_call_function_single()

Message-id: <1402487594-26332-14-git-send-email-prarit@redhat.com>
Patchwork-id: 83642
O-Subject: [RHEL7.1 PATCH BZ 1105192 13/14] smp: Remove wait argument from __smp_call_function_single()
Bugzilla: 1105192
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: Neil Horman <nhorman@redhat.com>

commit fce8ad1568c57e7f334018dec4fa1744c926c135
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Feb 24 16:40:01 2014 +0100

    smp: Remove wait argument from __smp_call_function_single()

    The main point of calling __smp_call_function_single() is to send
    an IPI in a pure asynchronous way. By embedding a csd in an object,
    a caller can send the IPI without waiting for a previous one to complete
    as is required by smp_call_function_single() for example. As such,
    sending this kind of IPI can be safe even when irqs are disabled.

    This flexibility comes at the expense of the caller who then needs to
    synchronize the csd lifecycle by himself and make sure that IPIs on a
    single csd are serialized.

    This is how __smp_call_function_single() works when wait = 0 and this
    usecase is relevant.

    Now there don't seem to be any usecase with wait = 1 that can't be
    covered by smp_call_function_single() instead, which is safer. Lets look
    at the two possible scenario:

    1) The user calls __smp_call_function_single(wait = 1) on a csd embedded
       in an object. It looks like a nice and convenient pattern at the first
       sight because we can then retrieve the object from the IPI handler easily.

       But actually it is a waste of memory space in the object since the csd
       can be allocated from the stack by smp_call_function_single(wait = 1)
       and the object can be passed an the IPI argument.

       Besides that, embedding the csd in an object is more error prone
       because the caller must take care of the serialization of the IPIs
       for this csd.

    2) The user calls __smp_call_function_single(wait = 1) on a csd that
       is allocated on the stack. It's ok but smp_call_function_single()
       can do it as well and it already takes care of the allocation on the
       stack. Again it's more simple and less error prone.

    Therefore, using the underscore prepend API version with wait = 1
    is a bad pattern and a sign that the caller can do safer and more
    simple.

    There was a single user of that which has just been converted.
    So lets remove this option to discourage further users.

    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Christoph Hellwig <hch@infradead.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jens Axboe <axboe@fb.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

Cc: Jeff Moyer <jmoyer@redhat.com>
Cc: Vivek Goyal <vgoyal@redhat.com>
Cc: Tony Camuso <tcamuso@redhat.com>
Cc: Rik van Riel <riel@redhat.com>
Cc: Larry Woodman <lwoodman@redhat.com>
Cc: Rafael Aquini <aquini@redhat.com>
Cc: Andy Gospodarek <agospoda@redhat.com>
Cc: Neil Horman <nhorman@redhat.com>
Cc: David S. Miller <davem@redhat.com>
Cc: Jiri Benc <jbenc@redhat.com>
Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/block/blk-mq.c b/block/blk-mq.c
index 1b8b50d..d1877ad 100644
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@ -320,7 +320,7 @@ void __blk_mq_complete_request(struct request *rq)
   rq->csd.func = __blk_mq_complete_request_remote;
   rq->csd.info = rq;
   rq->csd.flags = 0;
-  __smp_call_function_single(ctx->cpu, &rq->csd, 0);
+  __smp_call_function_single(ctx->cpu, &rq->csd);
  } else {
   rq->q->softirq_done_fn(rq);
  }
diff --git a/block/blk-softirq.c b/block/blk-softirq.c
index ec9e606..dfe0545 100644
--- a/block/blk-softirq.c
+++ b/block/blk-softirq.c
@@ -65,7 +65,7 @@ static int raise_blk_irq(int cpu, struct request *rq)
   data->info = rq;
   data->flags = 0;
 
-  __smp_call_function_single(cpu, data, 0);
+  __smp_call_function_single(cpu, data);
   return 0;
  }
 
diff --git a/drivers/cpuidle/coupled.c b/drivers/cpuidle/coupled.c
index fe85390..1523e57 100644
--- a/drivers/cpuidle/coupled.c
+++ b/drivers/cpuidle/coupled.c
@@ -323,7 +323,7 @@ static void cpuidle_coupled_poke(int cpu)
  struct call_single_data *csd = &per_cpu(cpuidle_coupled_poke_cb, cpu);
 
  if (!cpumask_test_and_set_cpu(cpu, &cpuidle_coupled_poke_pending))
-  __smp_call_function_single(cpu, csd, 0);
+  __smp_call_function_single(cpu, csd);
 }
 
 /**
diff --git a/include/linux/smp.h b/include/linux/smp.h
index 0709d33..90e2283 100644
--- a/include/linux/smp.h
+++ b/include/linux/smp.h
@@ -37,7 +37,7 @@ extern unsigned int total_cpus;
 int smp_call_function_single(int cpuid, smp_call_func_t func, void *info,
         int wait);
 
-int __smp_call_function_single(int cpu, struct call_single_data *csd, int wait);
+int __smp_call_function_single(int cpu, struct call_single_data *csd);
 
 #ifdef CONFIG_SMP
 
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 8bdf4be..d02e60b 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -432,7 +432,7 @@ void hrtick_start(struct rq *rq, u64 delay)
  if (rq == this_rq()) {
   hrtimer_restart(timer);
  } else if (!rq->hrtick_csd_pending) {
-  __smp_call_function_single(cpu_of(rq), &rq->hrtick_csd, 0);
+  __smp_call_function_single(cpu_of(rq), &rq->hrtick_csd);
   rq->hrtick_csd_pending = 1;
  }
 }
diff --git a/kernel/smp.c b/kernel/smp.c
index d556882..03a8044 100644
--- a/kernel/smp.c
+++ b/kernel/smp.c
@@ -242,29 +242,18 @@ EXPORT_SYMBOL(smp_call_function_single);
  * __smp_call_function_single(): Run a function on a specific CPU
  * @cpu: The CPU to run on.
  * @csd: Pre-allocated and setup data structure
- * @wait: If true, wait until function has completed on specified CPU.
  *
  * Like smp_call_function_single(), but allow caller to pass in a
  * pre-allocated data structure. Useful for embedding @data inside
  * other structures, for instance.
  */
-int __smp_call_function_single(int cpu, struct call_single_data *csd, int wait)
+int __smp_call_function_single(int cpu, struct call_single_data *csd)
 {
  int err = 0;
- int this_cpu;
 
- this_cpu = get_cpu();
- /*
-  * Can deadlock when called with interrupts disabled.
-  * We allow cpu's that are not yet online though, as no one else can
-  * send smp call function interrupt to this cpu and as such deadlocks
-  * can't happen.
-  */
- WARN_ON_ONCE(cpu_online(this_cpu) && wait && irqs_disabled()
-       && !oops_in_progress);
-
- err = generic_exec_single(cpu, csd, csd->func, csd->info, wait);
- put_cpu();
+ preempt_disable();
+ err = generic_exec_single(cpu, csd, csd->func, csd->info, 0);
+ preempt_enable();
 
  return err;
 }
diff --git a/kernel/softirq.c b/kernel/softirq.c
index 7103366..00a49d7 100644
--- a/kernel/softirq.c
+++ b/kernel/softirq.c
@@ -658,7 +658,7 @@ static int __try_remote_softirq(struct call_single_data *cp, int cpu, int softir
   cp->info = &softirq;
   cp->flags = 0;
 
-  __smp_call_function_single(cpu, cp, 0);
+  __smp_call_function_single(cpu, cp);
   return 0;
  }
  return 1;
diff --git a/kernel/up.c b/kernel/up.c
index 3b07a39..9d7b7fd 100644
--- a/kernel/up.c
+++ b/kernel/up.c
@@ -20,8 +20,7 @@ int smp_call_function_single(int cpu, void (*func) (void *info), void *info,
 }
 EXPORT_SYMBOL(smp_call_function_single);
 
-int __smp_call_function_single(int cpu, struct call_single_data *csd,
-          int wait)
+int __smp_call_function_single(int cpu, struct call_single_data *csd)
 {
  unsigned long flags;
 
diff --git a/net/core/dev.c b/net/core/dev.c
index fd8276c..20e4284 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -4044,7 +4044,7 @@ static void net_rps_action_and_irq_enable(struct softnet_data *sd)
 
    if (cpu_online(remsd->cpu))
     __smp_call_function_single(remsd->cpu,
-          &remsd->csd, 0);
+          &remsd->csd);
    remsd = next;
   }
  } else
-- 
1.7.1