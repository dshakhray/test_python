From ed2a2b9e6e554ef9773d3a0c04347e75c1853a47 Mon Sep 17 00:00:00 2001
From: David Gibson <dgibson@redhat.com>
Date: Mon, 15 Sep 2014 07:12:47 -0400
Subject: [virt] kvm/ppc: book3s/hv - make _PAGE_NUMA take effect

Message-id: <1410765214-16377-32-git-send-email-dgibson@redhat.com>
Patchwork-id: 94718
O-Subject: [PATCH 31/78] KVM: PPC: Book3S: HV: make _PAGE_NUMA take effect
Bugzilla: 1123145 1123133 1123367
RH-Acked-by: Radim Krcmar <rkrcmar@redhat.com>
RH-Acked-by: Don Zickus <dzickus@redhat.com>
RH-Acked-by: Steve Best <sbest@redhat.com>

https://bugzilla.redhat.com/show_bug.cgi?id=1123145

Signed-off-by: David Gibson <dgibson@redhat.com>

commit 1ad9f23873a4ee837643be5a29c05e405ec54e18
Author: pingfank@linux.vnet.ibm.com <pingfank@linux.vnet.ibm.com>
Date:   Tue Apr 15 16:33:40 2014 +0800

    KVM: PPC: Book3S: HV: make _PAGE_NUMA take effect

    Numa fault is a method which help to achieve auto numa balancing.
    When such a page fault takes place, the page fault handler will check
    whether the page is placed correctly. If not, migration should be
    involved to cut down the distance between the cpu and pages.

    A pte with _PAGE_NUMA help to implement numa fault. It means not to
    allow the MMU to access the page directly. So a page fault is triggered
    and numa fault handler gets the opportunity to run checker.

    As for the access of MMU, we need special handling for the powernv's guest.
    When we mark a pte with _PAGE_NUMA, we already call mmu_notifier to
    invalidate it in guest's htab, but when we tried to re-insert them,
    we firstly try to map it in real-mode. Only after this fails, we fallback
    to virt mode, and most of important, we run numa fault handler in virt
    mode.  This patch guards the way of real-mode to ensure that if a pte is
    marked with _PAGE_NUMA, it will NOT be mapped in real mode, instead, it will
    be mapped in virt mode and have the opportunity to be checked with placement.

    Signed-off-by: Liu Ping Fan <pingfank@linux.vnet.ibm.com>
    Reviewed-by: Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
    Signed-off-by: Alexander Graf <agraf@suse.de>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/arch/powerpc/kvm/book3s_hv_rm_mmu.c b/arch/powerpc/kvm/book3s_hv_rm_mmu.c
index 7bb02dd..5a24d3c 100644
--- a/arch/powerpc/kvm/book3s_hv_rm_mmu.c
+++ b/arch/powerpc/kvm/book3s_hv_rm_mmu.c
@@ -235,7 +235,7 @@ long kvmppc_do_h_enter(struct kvm *kvm, unsigned long flags,
   pte_size = psize;
   pte = lookup_linux_pte_and_update(pgdir, hva, writing,
         &pte_size);
-  if (pte_present(pte)) {
+  if (pte_present(pte) && !pte_numa(pte)) {
    if (writing && !pte_write(pte))
     /* make the actual HPTE be read-only */
     ptel = hpte_make_readonly(ptel);
-- 
1.7.1