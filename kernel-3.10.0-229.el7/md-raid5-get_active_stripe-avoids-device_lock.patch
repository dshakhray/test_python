From 6dd4288022837522f8a39bc5ea5c352e8f8f12e9 Mon Sep 17 00:00:00 2001
From: Jes Sorensen <Jes.Sorensen@redhat.com>
Date: Mon, 1 Sep 2014 09:25:59 -0400
Subject: [md] raid5: get_active_stripe avoids device_lock

Message-id: <1409563584-9000-58-git-send-email-Jes.Sorensen@redhat.com>
Patchwork-id: 89984
O-Subject: [RHEL7.1 PATCH 57/82] raid5: get_active_stripe avoids device_lock
Bugzilla: 1085530
RH-Acked-by: Tony Camuso <tcamuso@redhat.com>
RH-Acked-by: Prarit Bhargava <prarit@redhat.com>

From: Shaohua Li <shli@kernel.org>

For sequential workload (or request size big workload), get_active_stripe can
find cached stripe. In this case, we always hold device_lock, which exposes a
lot of lock contention for such workload. If stripe count isn't 0, we don't
need hold the lock actually, since we just increase its count. And this is the
hot code path for such workload. Unfortunately we must delete the BUG_ON.

Signed-off-by: Shaohua Li <shli@fusionio.com>
Signed-off-by: NeilBrown <neilb@suse.de>
(cherry picked from commit e240c1839d11152b0355442f8ac6d2d2d921be36)
Signed-off-by: Jes Sorensen <Jes.Sorensen@redhat.com>
---

Signed-off-by: Jarod Wilson <jarod@redhat.com>

diff --git a/drivers/md/raid5.c b/drivers/md/raid5.c
index 41e4cdb..7d8f45e 100644
--- a/drivers/md/raid5.c
+++ b/drivers/md/raid5.c
@@ -679,14 +679,9 @@ get_active_stripe(struct r5conf *conf, sector_t sector,
     init_stripe(sh, sector, previous);
     atomic_inc(&sh->count);
    }
-  } else {
+  } else if (!atomic_inc_not_zero(&sh->count)) {
    spin_lock(&conf->device_lock);
-   if (atomic_read(&sh->count)) {
-    BUG_ON(!list_empty(&sh->lru)
-        && !test_bit(STRIPE_EXPANDING, &sh->state)
-        && !test_bit(STRIPE_ON_UNPLUG_LIST, &sh->state)
-     );
-   } else {
+   if (!atomic_read(&sh->count)) {
     if (!test_bit(STRIPE_HANDLE, &sh->state))
      atomic_inc(&conf->active_stripes);
     BUG_ON(list_empty(&sh->lru) &&
-- 
1.7.1