From ced033447cf3d78bf5dc857f161680c1ee903ac7 Mon Sep 17 00:00:00 2001
From: Steven Rostedt <srostedt@redhat.com>
Date: Fri, 26 Jul 2013 17:27:28 +0200
Subject: [PATCH 852/858] slub: Default cpu partial to zero size if
 PREEMPT_RT_FULL is defined

As the patch to disable SLUB did not backport as easy as I hoped, and when running it, it would lock up the system. I found that just setting the cpu_partials to default size 0 was a much easier and safer patch.

This avoids the races that exist between a user space task setting the cpu_partials to size zero and a new cpu_partials memory unit being created (and thus still set to something other than zero).

Another nice thing about this patch is that the user can still manually set the cpu_partials if they want the performance with the sacrifice of determination.

Signed-off-by: Steven Rostedt <srostedt@redhat.com>
Signed-off-by: John Kacur <jkacur@redhat.com>
---
 mm/slub.c | 14 +++++++++++++-
 1 file changed, 13 insertions(+), 1 deletion(-)

diff --git a/mm/slub.c b/mm/slub.c
index f6871c5..4f54e0f 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -122,6 +122,18 @@ static inline int kmem_cache_debug(struct kmem_cache *s)
 #endif
 }
 
+#ifdef CONFIG_PREEMPT_RT_FULL
+static inline int kmem_cache_debug_rt(struct kmem_cache *s)
+{
+ return 1;
+}
+#else
+static inline int kmem_cache_debug_rt(struct kmem_cache *s)
+{
+ return kmem_cache_debug(s);
+}
+#endif
+
 /*
  * Issues still to be resolved:
  *
@@ -3112,7 +3124,7 @@ static int kmem_cache_open(struct kmem_cache *s, unsigned long flags)
   *    per node list when we run out of per cpu objects. We only fetch 50%
   *    to keep some capacity around for frees.
   */
- if (kmem_cache_debug(s))
+ if (kmem_cache_debug_rt(s))
   s->cpu_partial = 0;
  else if (s->size >= PAGE_SIZE)
   s->cpu_partial = 2;
-- 
1.8.3.1